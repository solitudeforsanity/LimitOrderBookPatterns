{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 1. Complete make_one_shot_task\n",
    "# 2. Complete test one shot task\n",
    "# 3. Complete plotting\n",
    "# 4. See if using attention with some static probabilities help the detection of spoofing\n",
    "# 5. Look at triple loss and computing it\n",
    "# 6. CNN and attention to top of the book - https://towardsdatascience.com/self-attention-in-computer-vision-2782727021f6\n",
    "    #Propose probabilities learnt through an LSTM network \n",
    "# 7. Higher prediction probabilities for top of book\n",
    "    #https://machinelearningmastery.com/how-to-score-probability-predictions-in-python/\n",
    "# 8. Fuck with data to get the desired result -b rebuild project\n",
    "# 9. Clean up code, make fancy plots, write comments and so on\n",
    "# 10. See if using LSTM to learn probabilities for attention would work \n",
    "# 11. Learn Families of classes for spoofing \n",
    "# 12. Custom loss function for family of identifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "project_path = os.path.abspath(os.path.join('../..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "\n",
    "import config\n",
    "import spoof_ground_truth\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from imageio import imread\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import numpy.random as rng\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv1D,Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling1D, MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tensorflow_addons.losses import triplet_semihard_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "abeo_train_pos = np.load(project_path + '/data/train/20160901_Positive/ABEO_BATS.npy')\n",
    "abeo_train_neg = np.load(project_path + '/data/train/20160901_Negative/ABEO_BATS.npy')\n",
    "\n",
    "abeo_val_pos = np.load(project_path + '/data/train/20160901_Positive/ABEO_NASDAQ.npy')\n",
    "abeo_val_neg = np.load(project_path + '/data/train/20160901_Negative/ABEO_NASDAQ.npy')\n",
    "\n",
    "goog_train_pos = np.load(project_path + '/data/train/20160901_Positive/GOOG_BATS.npy')\n",
    "goog_train_neg = np.load(project_path + '/data/train/20160901_Negative/GOOG_BATS.npy')\n",
    "\n",
    "goog_val_pos = np.load(project_path + '/data/train/20160901_Positive/GOOG_NASDAQ.npy')\n",
    "goog_val_neg = np.load(project_path + '/data/train/20160901_Negative/GOOG_NASDAQ.npy')\n",
    "\n",
    "model_path = project_path + '/weights/spoof'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_cleansed_data(pos_raw, neg_raw, side):\n",
    "        # Retrieve data where the last update was on the side required since otherwise we will be duplicating \n",
    "        pos_side = [i for i, s in enumerate(pos_raw['side'][:]) if s == side]\n",
    "        neg_side = [i for i, s in enumerate(neg_raw['side'][:]) if s == side]\n",
    "        \n",
    "        df_pos = pos_raw[pos_side]\n",
    "        df_neg = neg_raw[neg_side]\n",
    "        \n",
    "        p_mask_large_tops = (df_pos['quantity'][:,0,0,0:15]>1000).any(1)\n",
    "        n_mask_small_tops = (df_neg['quantity'][:,0,0,0:15] < 1500).all(1)\n",
    "        n_mask_large_bottoms = (df_pos['quantity'][:,0,0,0:15] < 2500).all(1) & \\\n",
    "                               (df_pos['quantity'][:,0,0,20:29] > 1000).any(1)\n",
    "        \n",
    "        df_pos_data = df_pos[p_mask_large_tops]\n",
    "        df_neg_small = df_neg[n_mask_small_tops]\n",
    "        df_neg_large = df_pos[n_mask_large_bottoms]\n",
    "        df_neg = np.append(df_neg_small['quantity'], df_neg_large['quantity'], axis=0) \n",
    "        \n",
    "        return df_pos_data['quantity'], df_neg\n",
    "    \n",
    "pos_train, neg_train = retrieve_cleansed_data(goog_train_pos, goog_train_neg, 'B')    \n",
    "pos_val, neg_val = retrieve_cleansed_data(goog_val_pos, goog_val_neg, 'B') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(shape, name=None, dtype=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer weights with mean as 0.0 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)\n",
    "\n",
    "def initialize_bias(shape, name=None, dtype=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer bias with mean as 0.5 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Plot of weights initialized, with mean of 0.0 and standard deviation of 0.01')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Intialize bias with mean 0.0 and standard deviation of 10^-2\n",
    "weights = initialize_weights((1000,1))\n",
    "sns.distplot(weights)\n",
    "plt.title(\"Plot of weights initialized, with mean of 0.0 and standard deviation of 0.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Plot of biases initialized, with mean of 0.0 and standard deviation of 0.01')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Intialize bias with mean 0.5 and standard deviation of 10^-2\n",
    "bias = initialize_bias((1000,1))\n",
    "sns.distplot(bias)\n",
    "plt.title(\"Plot of biases initialized, with mean of 0.0 and standard deviation of 0.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 2, 30, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 2, 30, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 4096)         3954816     input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 4096)         0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            4097        lambda_3[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,958,913\n",
      "Trainable params: 3,958,913\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_siamese_model(input_shape):\n",
    "    \"\"\"\n",
    "        Model architecture\n",
    "    \"\"\"\n",
    "    # Define the tensors for the two input images\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "\n",
    "    # Convolutional Neural Network\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(1,1), activation='relu', strides=1, padding=\"same\", input_shape=input_shape,\n",
    "                     use_bias = True, kernel_initializer=initialize_weights, bias_initializer=initialize_bias))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), activation='relu', strides=1, padding=\"same\", input_shape=input_shape,\n",
    "                     use_bias = True, kernel_initializer=initialize_weights, bias_initializer=initialize_bias))\n",
    "    # model.add(MaxPooling2D())\n",
    "    #model.add(Conv2D(128,kernel_size=(1,1), activation='relu', strides=1, padding=\"same\", input_shape=input_shape,\n",
    "     #                use_bias = True, kernel_initializer='random_uniform', bias_initializer='zeros'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='sigmoid',\n",
    "                   kernel_regularizer=l2(1e-3),\n",
    "                   kernel_initializer='random_uniform',bias_initializer=initialize_bias))\n",
    "\n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "\n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "\n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = Dense(1,activation='sigmoid',bias_initializer='zeros')(L1_distance)\n",
    "\n",
    "     # Connect the inputs with the outputs\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "\n",
    "    # return the model\n",
    "    return siamese_net\n",
    "    \n",
    "model = get_siamese_model((2, 30, 1))\n",
    "model.summary()\n",
    "optimizer = Adam(lr = 0.00006)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"loss_45/dense_76_loss/triplet_loss/Sum:0\", shape=(), dtype=float32)\n",
      "Tensor(\"loss_45/dense_76_loss/triplet_loss/Max:0\", shape=(), dtype=float32)\n",
      "Model: \"model_112\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor (InputLayer)             (None, 2, 30, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive (InputLayer)           (None, 2, 30, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative (InputLayer)           (None, 2, 30, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_111 (Model)               (None, 60)           76220       anchor[0][0]                     \n",
      "                                                                 positive[0][0]                   \n",
      "                                                                 negative[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tripleLossLayer (Concatenate)   (None, 180)          0           model_111[1][0]                  \n",
      "                                                                 model_111[2][0]                  \n",
      "                                                                 model_111[3][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 180)          32580       tripleLossLayer[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 108,800\n",
      "Trainable params: 108,800\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['loss']"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TripletNet(Model):\n",
    "    def __init__(self, shape=(2, 30, 1), dimensions=60):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.model = self.build_triplets_model(shape, dimensions)\n",
    "        self.model.compile(\n",
    "            #loss=tfa.losses.TripletSemiHardLoss(),\n",
    "            loss = triplet_loss,\n",
    "            optimizer=tfa.optimizers.RectifiedAdam(0.001)\n",
    "           # metrics=['accuracy']\n",
    "            #tfa.metrics.MultiLabelConfusionMatrix(num_classes=2)\n",
    "        )\n",
    "        self.fit = self.model.fit\n",
    "        self.fit_generator = self.model.fit_generator\n",
    "        self.predict = self.model.predict\n",
    "        self.evaluate = self.model.evaluate\n",
    "        self.summary = self.model.summary\n",
    "        \n",
    "        \n",
    "    def build_triplets_model(self, shape, dimensions):\n",
    "        net = self.build_embedding(shape, dimensions)\n",
    "     \n",
    "        anchor_input = Input(shape=shape, name='anchor')\n",
    "        positive_input = Input(shape=shape, name='positive')\n",
    "        negative_input = Input(shape=shape, name='negative')\n",
    "\n",
    "        # Get the embedded values\n",
    "        encoded_a = net(anchor_input)\n",
    "        encoded_p = net(positive_input)\n",
    "        encoded_n = net(negative_input)\n",
    "        \n",
    "        # Get the differences\n",
    "      #  L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "      #  d1 = L1_layer([encoded_a, encoded_p])\n",
    "      #  d2 = L1_layer([encoded_a, encoded_n])\n",
    "\n",
    "        # Normalize the differences\n",
    "       # L2_layer = Lambda(lambda tensors:tf.norm(tensors))\n",
    "       # n1 = L2_layer(d1)\n",
    "       # n2 = L2_layer(d2)\n",
    "\n",
    "        # Compare\n",
    "        #out = Activation('sigmoid')(tf.subtract(n2, n1))\n",
    "        # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "           # Add a customized layer to compute the absolute difference between the encodings\n",
    "        \n",
    "      #  L1_distance = L1_layer([n2, n1])\n",
    "        \n",
    "       # prediction = Dense(1,bias_initializer='zeros')(d1)\n",
    "        merged = concatenate([encoded_a, encoded_p, encoded_n], axis=-1, name='tripleLossLayer')\n",
    "        output = Dense(180)(merged)\n",
    "        triplet_net = Model(inputs=[anchor_input, positive_input, negative_input],\\\n",
    "                            outputs=[output])\n",
    "        return triplet_net\n",
    "\n",
    "    def build_embedding(self, input_shape, dimensions):\n",
    "        inp = Input(shape=input_shape)\n",
    "     \n",
    "        out = Conv2D(32, kernel_size=(1,1), activation='relu', strides=1, padding=\"same\", input_shape=input_shape,\n",
    "                   use_bias = True, kernel_initializer=initialize_weights, bias_initializer=initialize_bias)(inp)\n",
    "        out = MaxPooling2D()(out)\n",
    "        out = Conv2D(64, kernel_size=(3,3), activation='relu', strides=1, padding=\"same\",\n",
    "                   use_bias = True, kernel_initializer=initialize_weights, bias_initializer=initialize_bias)(out)\n",
    "        out = Flatten()(out)\n",
    "        out = Dense(dimensions, kernel_regularizer=l2(1e-3), kernel_initializer='random_uniform',\n",
    "                        bias_initializer=initialize_bias)(out)\n",
    "        \n",
    "        L1_layer = Lambda(lambda tensors:tf.math.l2_normalize(tensors, axis=1))\n",
    "        out = L1_layer(out)\n",
    "        \n",
    "        return Model(inputs=inp, outputs=out)\n",
    "\n",
    "triplet_model = TripletNet(shape=(2, 30, 1), dimensions=60)\n",
    "triplet_model.summary()\n",
    "triplet_model.model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Triplet Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplet_batch(batch_size, positive_samples, negative_samples, anchor):\n",
    "    n_examples_p, d, w, h = positive_samples.shape\n",
    "    n_examples_n = negative_samples.shape[0]\n",
    "    triplets = [np.zeros((batch_size, w, h, 1)) for i in range(3)]\n",
    "    \n",
    "    # initialize vector for the targets\n",
    "    targets = np.ones((batch_size,2))\n",
    "    targets[:,1] = 0\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        idx_p = rng.randint(0, n_examples_p)\n",
    "        idx_n = rng.randint(0, n_examples_n)\n",
    "        triplets[0][i,:,:,:] = anchor.reshape(w, h, 1)\n",
    "        triplets[1][i,:,:,:] = positive_samples[idx_p].reshape(w, h, 1)\n",
    "        triplets[2][i,:,:,:] = negative_samples[idx_n].reshape(w, h, 1)\n",
    "    return [triplets[0], triplets[1], triplets[2]], targets\n",
    "\n",
    "def triplet_generator(batch_size, train_data, test_data, anchor):\n",
    "    while True:\n",
    "        inputs, targets = get_triplet_batch(batch_size, pos_train, neg_train, anchor)\n",
    "        yield [inputs, targets], None\n",
    "\n",
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss as defined by formula (3)\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
    "            positive -- the encodings for the positive images, of shape (None, 128)\n",
    "            negative -- the encodings for the negative images, of shape (None, 128)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    ### START CODE HERE ### ( 4 lines)\n",
    "    # Step 1: Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=-1)\n",
    "    print(pos_dist)\n",
    "    # Step 2: Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1\n",
    "  #  neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=-1)\n",
    "    \n",
    "    hardest_positive_dist = tf.reduce_max(tf.square(tf.subtract(anchor, positive)), axis=-1)\n",
    "    print(hardest_positive_dist)\n",
    "    tf.summary.scalar(\"hardest_positive_dist\", tf.reduce_mean(hardest_positive_dist))\n",
    "    \n",
    "    # shape (batch_size,)\n",
    "    hardest_negative_dist = tf.reduce_min(tf.subtract(anchor, negative), axis=-1)\n",
    "    tf.summary.scalar(\"hardest_negative_dist\", tf.reduce_mean(hardest_negative_dist))\n",
    "    \n",
    "     # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "    triplet_loss = tf.maximum(hardest_positive_dist - hardest_negative_dist + alpha, 0.0)\n",
    "\n",
    "    # Get final mean triplet loss\n",
    "    triplet_loss = tf.reduce_mean(triplet_loss)\n",
    "\n",
    "    # Step 3: subtract the two previous distances and add alpha.\n",
    "   # basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
    "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "    loss = tf.reduce_sum(tf.maximum(triplet_loss, 0))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_normal_352:0\", shape=(5, 60), dtype=float32)\n",
      "for distance branch, y_pred.shape:   Tensor(\"concatenate_33/concat:0\", shape=(5, 180), dtype=float32)\n",
      "loss = [290.07104 161.85742   0.        0.      152.97095]\n"
     ]
    }
   ],
   "source": [
    "def triplet_loss1(y_true, y_pred, alpha=0.4):\n",
    "    print(\"for distance branch, y_pred.shape:  \", y_pred)       # [Batch_dim, vec_dim*3]\n",
    "\n",
    "    vec_len = y_pred.shape.as_list()[-1]\n",
    "\n",
    "    anchor = y_pred[:, :int(vec_len/3)]\n",
    "    positve = y_pred[:, int(vec_len/3):int(vec_len*2/3)]\n",
    "    negative = y_pred[:, int(vec_len*2/3):]\n",
    "\n",
    "    pos_dist = K.sum(K.square(anchor - positve), axis=1)\n",
    "    neg_dist = K.sum(K.square(anchor - negative), axis=1)\n",
    "\n",
    "    loss = K.maximum(0., pos_dist - neg_dist + alpha)\n",
    "\n",
    "    return loss\n",
    "a = tf.compat.v1.random_normal([5, 60], mean=6, stddev=0.1, seed = 1)\n",
    "\n",
    "with tf.compat.v1.Session() as test:\n",
    "    tf.compat.v1.set_random_seed(1)\n",
    "    y_true = (None, None, None)\n",
    "    a = tf.compat.v1.random_normal([5, 60], mean=6, stddev=0.1, seed = 1)\n",
    "    print(a)\n",
    "    p = tf.compat.v1.random_normal([5, 60], mean=1, stddev=1, seed = 1)\n",
    "    n = tf.compat.v1.random_normal([5, 60], mean=3, stddev=4, seed = 1)\n",
    "    merged = concatenate([a, p, n], axis=-1)\n",
    "    y_pred = (tf.compat.v1.random_normal([3, 60], mean=6, stddev=0.1, seed = 1),\n",
    "              tf.compat.v1.random_normal([3, 60], mean=1, stddev=1, seed = 1),\n",
    "              tf.compat.v1.random_normal([3, 60], mean=3, stddev=4, seed = 1), \n",
    "              tf.compat.v1.random_normal([3, 60], mean=3, stddev=4, seed = 1))\n",
    "    loss = triplet_loss1(y_true, merged)\n",
    "    \n",
    "    print(\"loss = \" + str(loss.eval()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_every = 10 # interval for evaluating on one-shot tasks\n",
    "loss_every = 20 # interval for printing loss (iterations)\n",
    "batch_size = 32\n",
    "n_iter = 20000\n",
    "N_way = 20 # how many classes for testing one-shot tasks>\n",
    "n_val = 250 # how many one-shot tasks to validate on?\n",
    "best = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training process!\n",
      "-------------------------------------\n",
      "0.25678894\n",
      "0.26142317\n",
      "0.26491317\n",
      "0.24955595\n",
      "0.25389108\n",
      "0.25461754\n",
      "0.2594513\n",
      "0.28797406\n",
      "0.2487621\n",
      "0.2519029\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10 iterations: 0.00322723388671875 mins\n",
      "Train Loss: 0.25190290808677673\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 0.0, previous best: -1\n",
      "0.25978944\n",
      "0.25397995\n",
      "0.26558772\n",
      "0.25741553\n",
      "0.25765023\n",
      "0.25558805\n",
      "0.26162177\n",
      "0.24968973\n",
      "0.25585136\n",
      "0.2471016\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 20 iterations: 0.027243399620056154 mins\n",
      "Train Loss: 0.24710160493850708\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 0.0, previous best: 0.0\n",
      "0.24802911\n",
      "0.2556439\n",
      "0.27399987\n",
      "0.25708437\n",
      "0.25462848\n",
      "0.2640526\n",
      "0.26670802\n",
      "0.26530692\n",
      "0.24975201\n",
      "0.24861415\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 30 iterations: 0.04733421802520752 mins\n",
      "Train Loss: 0.2486141473054886\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 0.0, previous best: 0.0\n",
      "0.25818208\n",
      "0.24795604\n",
      "0.25227314\n",
      "0.25739488\n",
      "0.26051068\n",
      "0.24874087\n",
      "0.24900885\n",
      "0.24833\n",
      "0.27093136\n",
      "0.24847262\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 40 iterations: 0.07201646566390991 mins\n",
      "Train Loss: 0.24847261607646942\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 0.0, previous best: 0.0\n",
      "0.2512274\n",
      "0.25537822\n",
      "0.24406826\n",
      "0.25002912\n",
      "0.24935894\n",
      "0.24794316\n",
      "0.25370708\n",
      "0.2531922\n",
      "0.27614036\n",
      "0.25347757\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 50 iterations: 0.10039211511611938 mins\n",
      "Train Loss: 0.2534775733947754\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 0.0, previous best: 0.0\n",
      "0.24985507\n",
      "0.25535563\n",
      "0.25862712\n",
      "0.25369698\n",
      "0.25034747\n",
      "0.24647102\n",
      "0.252212\n",
      "0.2517687\n",
      "0.24364994\n",
      "0.24653935\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 60 iterations: 0.12230205138524373 mins\n",
      "Train Loss: 0.24653935432434082\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 0.0, previous best: 0.0\n",
      "0.2478411\n",
      "0.24950752\n",
      "0.24626356\n",
      "0.2598424\n",
      "0.25533873\n",
      "0.25151867\n",
      "0.24886476\n",
      "0.25100064\n",
      "0.24985188\n",
      "0.2657985\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 70 iterations: 0.14838591416676838 mins\n",
      "Train Loss: 0.26579850912094116\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 0.0, previous best: 0.0\n",
      "0.244827\n",
      "0.2502634\n",
      "0.24463761\n",
      "0.24629703\n",
      "0.25413236\n",
      "0.24617426\n",
      "0.24959697\n",
      "0.24867153\n",
      "0.24562506\n",
      "0.25755507\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 80 iterations: 0.16761478583017986 mins\n",
      "Train Loss: 0.2575550675392151\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 0.0, previous best: 0.0\n",
      "0.24491134\n",
      "0.25705814\n",
      "0.25555873\n",
      "0.2480889\n",
      "0.24817093\n",
      "0.24286346\n",
      "0.2457684\n",
      "0.24993682\n",
      "0.24708252\n",
      "0.242307\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 90 iterations: 0.19086108207702637 mins\n",
      "Train Loss: 0.24230700731277466\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 0.0, previous best: 0.0\n",
      "0.25629166\n",
      "0.24538846\n",
      "0.24665517\n",
      "0.25788763\n",
      "0.24716328\n",
      "0.24852262\n",
      "0.24906147\n",
      "0.24465132\n",
      "0.2998073\n",
      "0.27799404\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 100 iterations: 0.21588463385899861 mins\n",
      "Train Loss: 0.2779940366744995\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 0.0, previous best: 0.0\n",
      "0.27971232\n",
      "0.24745533\n",
      "0.24570724\n",
      "0.24634314\n",
      "0.25364146\n",
      "0.25059864\n",
      "0.25066304\n",
      "0.2523414\n",
      "0.24904759\n",
      "0.25182337\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 110 iterations: 0.239284618695577 mins\n",
      "Train Loss: 0.251823365688324\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 0.0, previous best: 0.0\n",
      "0.24032553\n",
      "0.25442937\n",
      "0.24972329\n",
      "0.2506655\n",
      "0.24583592\n",
      "0.2427347\n",
      "0.24769562\n",
      "0.24808389\n",
      "0.2538241\n",
      "0.24787194\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 120 iterations: 0.2637008190155029 mins\n",
      "Train Loss: 0.24787193536758423\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 0.0, previous best: 0.0\n",
      "0.24578226\n",
      "0.25461757\n",
      "0.24439918\n",
      "0.24897048\n",
      "0.24418727\n",
      "0.24529606\n",
      "0.2735406\n",
      "0.2482903\n",
      "0.24289358\n",
      "0.24792886\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 130 iterations: 0.2893604516983032 mins\n",
      "Train Loss: 0.24792885780334473\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 0.0, previous best: 0.0\n",
      "0.24098602\n",
      "0.28928968\n",
      "0.24106003\n",
      "0.24371979\n",
      "0.24625134\n",
      "0.2486594\n",
      "0.24521373\n",
      "0.24481343\n",
      "0.24520108\n",
      "0.25711003\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 140 iterations: 0.31543637116750084 mins\n",
      "Train Loss: 0.25711002945899963\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 0.0, previous best: 0.0\n",
      "0.24816628\n",
      "0.25250608\n",
      "0.25671342\n",
      "0.24687555\n",
      "0.25185776\n",
      "0.28242937\n",
      "0.24523759\n",
      "0.2739013\n",
      "0.24227393\n",
      "0.24871789\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 150 iterations: 0.33872807025909424 mins\n",
      "Train Loss: 0.24871788918972015\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 0.0, previous best: 0.0\n",
      "0.2480687\n",
      "0.24672809\n",
      "0.24161091\n",
      "0.24611658\n",
      "0.24991763\n",
      "0.25807548\n",
      "0.24735156\n",
      "0.24377201\n",
      "0.2457355\n",
      "0.32241273\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 160 iterations: 0.3581206480662028 mins\n",
      "Train Loss: 0.32241272926330566\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 0.0, previous best: 0.0\n",
      "0.24498862\n",
      "0.24324404\n",
      "0.25080726\n",
      "0.26659223\n",
      "0.24416855\n",
      "0.25034398\n",
      "0.24496847\n",
      "0.24699634\n",
      "0.24983892\n",
      "0.2459958\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 170 iterations: 0.38138818740844727 mins\n",
      "Train Loss: 0.24599580466747284\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 0.0, previous best: 0.0\n",
      "0.2405994\n",
      "0.24861598\n",
      "0.26356554\n",
      "0.24748327\n",
      "0.25395244\n",
      "0.24837184\n",
      "0.24682848\n",
      "0.24812134\n",
      "0.24822934\n",
      "0.24195807\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 180 iterations: 0.4028717835744222 mins\n",
      "Train Loss: 0.24195806682109833\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 0.0, previous best: 0.0\n",
      "0.25148785\n",
      "0.25174773\n",
      "0.2454484\n",
      "0.25070173\n",
      "0.24178979\n",
      "0.24441195\n",
      "0.24184926\n",
      "0.25063637\n",
      "0.2433715\n",
      "0.24880737\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 190 iterations: 0.4326364000638326 mins\n",
      "Train Loss: 0.2488073706626892\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 0.0, previous best: 0.0\n",
      "0.23901996\n",
      "0.24936222\n",
      "0.2428909\n",
      "0.24568026\n",
      "0.24817726\n",
      "0.24321532\n",
      "0.24471559\n",
      "0.24405272\n",
      "0.24241811\n",
      "0.24433392\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 200 iterations: 0.45819108486175536 mins\n",
      "Train Loss: 0.2443339228630066\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-401-6454750bcbda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time for {0} iterations: {1} mins\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train Loss: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_oneshot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_way\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-398-9c2cc60004dc>\u001b[0m in \u001b[0;36mtest_oneshot\u001b[0;34m(model, N, k, s, verbose)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 (inputs, targets) = get_triplet_batch(batch_size, pos_val, neg_val, \\\n\u001b[0;32m--> 113\u001b[0;31m                                                       spoof_ground_truth.spoof_step1_truth1)\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtriplet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-398-9c2cc60004dc>\u001b[0m in \u001b[0;36mget_triplet_batch\u001b[0;34m(batch_size, positive_samples, negative_samples, anchor)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0midx_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_examples_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0midx_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_examples_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mtriplets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manchor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtriplets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositive_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_p\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "t_start = time.time()\n",
    "for i in range(1, n_iter+1):\n",
    "    (inputs, targets) = get_triplet_batch(batch_size, pos_train, neg_train, spoof_ground_truth.spoof_step1_truth1)\n",
    "    #(inp, tar) = triplet_generator()\n",
    "    loss = triplet_model.model.train_on_batch(inputs, targets)\n",
    "    print(loss)\n",
    "    if i % evaluate_every == 0:\n",
    "        print(\"\\n ------------- \\n\")\n",
    "        print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
    "        print(\"Train Loss: {0}\".format(loss)) \n",
    "        val_acc = test_oneshot(model, N_way, n_val, verbose=True)\n",
    "\n",
    "  \n",
    "        triplet_model.model.save_weights(os.path.join(model_path, 'weights_triplet.{}.h5'.format(i)))\n",
    "        if val_acc >= best:\n",
    "            print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
    "            best = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "data = [[1,2,3],[4,5,6]]\n",
    "data_np = np.asarray(data, np.float32)\n",
    "\n",
    "data_tf = tf.convert_to_tensor(data_np, np.float32)\n",
    "\n",
    "data_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-272-4f28998266eb>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-272-4f28998266eb>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Please provide model inputs as a list or tuple of 2 or 3 elements: (input, target) or (input, target, sample_weights) Received ((<tf.Tensor: shape=(32, 2, 30, 1), dtype=float64, numpy=\narray([[[[9.0e+01],\n         [1.0e+04],\n         [1.0e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]],\n\n        [[7.0e+00],\n         [9.7e+02],\n         [1.5e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]]],\n\n\n       [[[9.0e+01],\n         [1.0e+04],\n         [1.0e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]],\n\n        [[7.0e+00],\n         [9.7e+02],\n         [1.5e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]]],\n\n\n       [[[9.0e+01],\n         [1.0e+04],\n         [1.0e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]],\n\n        [[7.0e+00],\n         [9.7e+02],\n         [1.5e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]]],\n\n\n       ...,\n\n\n       [[[9.0e+01],\n         [1.0e+04],\n         [1.0e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]],\n\n        [[7.0e+00],\n         [9.7e+02],\n         [1.5e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]]],\n\n\n       [[[9.0e+01],\n         [1.0e+04],\n         [1.0e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]],\n\n        [[7.0e+00],\n         [9.7e+02],\n         [1.5e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]]],\n\n\n       [[[9.0e+01],\n         [1.0e+04],\n         [1.0e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]],\n\n        [[7.0e+00],\n         [9.7e+02],\n         [1.5e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]]]])>, <tf.Tensor: shape=(32, 2, 30, 1), dtype=float64, numpy=\narray([[[[3.7625e+04],\n         [5.8610e+05],\n         [3.3610e+05],\n         ...,\n         [5.0850e+05],\n         [7.7970e+05],\n         [1.0506e+06]],\n\n        [[2.6000e+01],\n         [1.0000e+02],\n         [2.0000e+02],\n         ...,\n         [1.0000e+02],\n         [1.0000e+02],\n         [1.0000e+02]]],\n\n\n       [[[3.9070e+03],\n         [1.1570e+06],\n         [2.3620e+05],\n         ...,\n         [8.6210e+05],\n         [6.4957e+06],\n         [4.3970e+05]],\n\n        [[2.0000e+02],\n         [1.0000e+02],\n         [1.0000e+02],\n         ...,\n         [1.0000e+02],\n         [1.0000e+02],\n         [1.0000e+02]]],\n\n\n       [[[7.9430e+03],\n         [8.7960e+05],\n         [3.1110e+05],\n         ...,\n         [0.0000e+00],\n         [0.0000e+00],\n         [0.0000e+00]],\n\n        [[1.0000e+02],\n         [2.0000e+02],\n         [1.9000e+01],\n         ...,\n         [1.0000e+02],\n         [1.0000e+02],\n         [1.0000e+02]]],\n\n\n       ...,\n\n\n       [[[2.9694e+05],\n         [9.0690e+03],\n         [1.0430e+04],\n         ...,\n         [7.6940e+05],\n         [4.0330e+05],\n         [5.9610e+05]],\n\n        [[1.0000e+02],\n         [1.0000e+02],\n         [2.0000e+02],\n         ...,\n         [1.0000e+02],\n         [1.0000e+02],\n         [1.0000e+02]]],\n\n\n       [[[1.4920e+03],\n         [7.4200e+05],\n         [3.2820e+05],\n         ...,\n         [1.9982e+04],\n         [7.0250e+05],\n         [5.6190e+05]],\n\n        [[1.0000e+02],\n         [1.0000e+01],\n         [2.0000e+02],\n         ...,\n         [1.0000e+02],\n         [1.0000e+02],\n         [2.0000e+00]]],\n\n\n       [[[2.2960e+03],\n         [9.3480e+03],\n         [4.9090e+03],\n         ...,\n         [7.0250e+05],\n         [5.6190e+05],\n         [2.4870e+05]],\n\n        [[1.0000e+02],\n         [1.0000e+02],\n         [1.0000e+02],\n         ...,\n         [1.0000e+02],\n         [1.0000e+02],\n         [1.0000e+02]]]])>, <tf.Tensor: shape=(32, 2, 30, 1), dtype=float64, numpy=\narray([[[[8.200e+01],\n         [2.360e+02],\n         [9.810e+02],\n         ...,\n         [1.119e+03],\n         [3.800e+02],\n         [3.280e+02]],\n\n        [[1.000e+02],\n         [1.000e+02],\n         [1.000e+02],\n         ...,\n         [1.000e+02],\n         [1.000e+02],\n         [1.000e+02]]],\n\n\n       [[[1.760e+02],\n         [1.136e+03],\n         [5.270e+02],\n         ...,\n         [0.000e+00],\n         [0.000e+00],\n         [0.000e+00]],\n\n        [[1.000e+02],\n         [1.000e+02],\n         [1.000e+02],\n         ...,\n         [1.000e+02],\n         [1.000e+02],\n         [1.000e+02]]],\n\n\n       [[[3.560e+02],\n         [9.780e+02],\n         [5.100e+02],\n         ...,\n         [6.150e+02],\n         [4.150e+02],\n         [1.078e+03]],\n\n        [[1.000e+02],\n         [1.000e+02],\n         [1.000e+02],\n         ...,\n         [1.000e+02],\n         [1.000e+02],\n         [1.000e+02]]],\n\n\n       ...,\n\n\n       [[[8.050e+02],\n         [1.484e+03],\n         [1.176e+03],\n         ...,\n         [9.890e+02],\n         [1.011e+03],\n         [9.130e+02]],\n\n        [[1.000e+02],\n         [1.000e+02],\n         [1.000e+02],\n         ...,\n         [1.000e+02],\n         [1.000e+02],\n         [1.000e+02]]],\n\n\n       [[[6.100e+01],\n         [1.002e+03],\n         [6.800e+02],\n         ...,\n         [6.150e+02],\n         [4.150e+02],\n         [1.078e+03]],\n\n        [[2.000e+02],\n         [5.000e+01],\n         [1.000e+01],\n         ...,\n         [1.000e+02],\n         [1.000e+02],\n         [1.000e+02]]],\n\n\n       [[[1.094e+03],\n         [1.256e+03],\n         [1.161e+03],\n         ...,\n         [1.452e+03],\n         [6.150e+02],\n         [9.330e+02]],\n\n        [[1.000e+00],\n         [1.000e+02],\n         [1.000e+02],\n         ...,\n         [1.000e+02],\n         [1.000e+02],\n         [1.000e+02]]]])>), <tf.Tensor: shape=(32, 3), dtype=float64, numpy=\narray([[1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.]])>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-272-4f28998266eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                         verbose=1) #callbacks=[checkpoint])\n\u001b[0m",
      "\u001b[0;32m~/Software/anaconda3/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m~/Software/anaconda3/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/Software/anaconda3/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, standardize_function, workers, use_multiprocessing, max_queue_size, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstandardize_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m       \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shuffle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mstandardize_function\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_weight_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sample_weight_mode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m       \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_tensors_from_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m       \u001b[0;31m# Then we map using only the tensor standardization portion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2344\u001b[0m     \u001b[0;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2346\u001b[0;31m       \u001b[0mall_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_model_with_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2347\u001b[0m       \u001b[0mis_build_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2348\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_build_model_with_inputs\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m   2521\u001b[0m     \u001b[0;31m# tensors from the iterator and then standardize them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetV1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2523\u001b[0;31m       \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_tensors_from_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2524\u001b[0m     \u001b[0;31m# We type-check that `inputs` and `targets` are either single arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2525\u001b[0m     \u001b[0;31m# or lists of arrays, and extract a flat list of inputs from the passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mextract_tensors_from_dataset\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m   1676\u001b[0m   \"\"\"\n\u001b[1;32m   1677\u001b[0m   \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1678\u001b[0;31m   \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_iterator_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1679\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36munpack_iterator_input\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1701\u001b[0m           \u001b[0;34m'Please provide model inputs as a list or tuple of 2 or 3 '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m           \u001b[0;34m'elements: (input, target) or (input, target, sample_weights) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1703\u001b[0;31m           'Received %s' % next_element)\n\u001b[0m\u001b[1;32m   1704\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Please provide model inputs as a list or tuple of 2 or 3 elements: (input, target) or (input, target, sample_weights) Received ((<tf.Tensor: shape=(32, 2, 30, 1), dtype=float64, numpy=\narray([[[[9.0e+01],\n         [1.0e+04],\n         [1.0e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]],\n\n        [[7.0e+00],\n         [9.7e+02],\n         [1.5e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]]],\n\n\n       [[[9.0e+01],\n         [1.0e+04],\n         [1.0e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]],\n\n        [[7.0e+00],\n         [9.7e+02],\n         [1.5e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]]],\n\n\n       [[[9.0e+01],\n         [1.0e+04],\n         [1.0e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]],\n\n        [[7.0e+00],\n         [9.7e+02],\n         [1.5e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]]],\n\n\n       ...,\n\n\n       [[[9.0e+01],\n         [1.0e+04],\n         [1.0e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]],\n\n        [[7.0e+00],\n         [9.7e+02],\n         [1.5e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]]],\n\n\n       [[[9.0e+01],\n         [1.0e+04],\n         [1.0e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]],\n\n        [[7.0e+00],\n         [9.7e+02],\n         [1.5e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]]],\n\n\n       [[[9.0e+01],\n         [1.0e+04],\n         [1.0e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]],\n\n        [[7.0e+00],\n         [9.7e+02],\n         [1.5e+01],\n         ...,\n         [0.0e+00],\n         [0.0e+00],\n         [0.0e+00]]]])>, <tf.Tensor: shape=(32, 2, 30, 1), dtype=float64, numpy=\narray([[[[3.7625e+04],\n         [5.8610e+05],\n         [3.3610e+05],\n         ...,\n         [5.0850e+05],\n         [7.7970e+05],\n         [1.0506e+06]],\n\n        [[2.6000e+01],\n         [1.0000e+02],\n         [2.0000e+02],\n         ...,\n         [1.0000e+02],\n         [1.0000e+02],\n         [1.0000e+02]]],\n\n\n       [[[3.9070e+03],\n         [1.1570e+06],\n         [2.3620e+05],\n         ...,\n         [8.6210e+05],\n         [6.4957e+06],\n         [4.3970e+05]],\n\n        [[2.0000e+02],\n         [1.0000e+02],\n         [1.0000e+02],\n         ...,\n         [1.0000e+02],\n         [1.0000e+02],\n         [1.0000e+02]]],\n\n\n       [[[7.9430e+03],\n         [8.7960e+05],\n         [3.1110e+05],\n         ...,\n         [0.0000e+00],\n         [0.0000e+00],\n         [0.0000e+00]],\n\n        [[1.0000e+02],\n         [2.0000e+02],\n         [1.9000e+01],\n         ...,\n         [1.0000e+02],\n         [1.0000e+02],\n         [1.0000e+02]]],\n\n\n       ...,\n\n\n       [[[2.9694e+05],\n         [9.0690e+03],\n         [1.0430e+04],\n         ...,\n         [7.6940e+05],\n         [4.0330e+05],\n         [5.9610e+05]],\n\n        [[1.0000e+02],\n         [1.0000e+02],\n         [2.0000e+02],\n         ...,\n         [1.0000e+02],\n         [1.0000e+02],\n         [1.0000e+02]]],\n\n\n       [[[1.4920e+03],\n         [7.4200e+05],\n         [3.2820e+05],\n         ...,\n         [1.9982e+04],\n         [7.0250e+05],\n         [5.6190e+05]],\n\n        [[1.0000e+02],\n         [1.0000e+01],\n         [2.0000e+02],\n         ...,\n         [1.0000e+02],\n         [1.0000e+02],\n         [2.0000e+00]]],\n\n\n       [[[2.2960e+03],\n         [9.3480e+03],\n         [4.9090e+03],\n         ...,\n         [7.0250e+05],\n         [5.6190e+05],\n         [2.4870e+05]],\n\n        [[1.0000e+02],\n         [1.0000e+02],\n         [1.0000e+02],\n         ...,\n         [1.0000e+02],\n         [1.0000e+02],\n         [1.0000e+02]]]])>, <tf.Tensor: shape=(32, 2, 30, 1), dtype=float64, numpy=\narray([[[[8.200e+01],\n         [2.360e+02],\n         [9.810e+02],\n         ...,\n         [1.119e+03],\n         [3.800e+02],\n         [3.280e+02]],\n\n        [[1.000e+02],\n         [1.000e+02],\n         [1.000e+02],\n         ...,\n         [1.000e+02],\n         [1.000e+02],\n         [1.000e+02]]],\n\n\n       [[[1.760e+02],\n         [1.136e+03],\n         [5.270e+02],\n         ...,\n         [0.000e+00],\n         [0.000e+00],\n         [0.000e+00]],\n\n        [[1.000e+02],\n         [1.000e+02],\n         [1.000e+02],\n         ...,\n         [1.000e+02],\n         [1.000e+02],\n         [1.000e+02]]],\n\n\n       [[[3.560e+02],\n         [9.780e+02],\n         [5.100e+02],\n         ...,\n         [6.150e+02],\n         [4.150e+02],\n         [1.078e+03]],\n\n        [[1.000e+02],\n         [1.000e+02],\n         [1.000e+02],\n         ...,\n         [1.000e+02],\n         [1.000e+02],\n         [1.000e+02]]],\n\n\n       ...,\n\n\n       [[[8.050e+02],\n         [1.484e+03],\n         [1.176e+03],\n         ...,\n         [9.890e+02],\n         [1.011e+03],\n         [9.130e+02]],\n\n        [[1.000e+02],\n         [1.000e+02],\n         [1.000e+02],\n         ...,\n         [1.000e+02],\n         [1.000e+02],\n         [1.000e+02]]],\n\n\n       [[[6.100e+01],\n         [1.002e+03],\n         [6.800e+02],\n         ...,\n         [6.150e+02],\n         [4.150e+02],\n         [1.078e+03]],\n\n        [[2.000e+02],\n         [5.000e+01],\n         [1.000e+01],\n         ...,\n         [1.000e+02],\n         [1.000e+02],\n         [1.000e+02]]],\n\n\n       [[[1.094e+03],\n         [1.256e+03],\n         [1.161e+03],\n         ...,\n         [1.452e+03],\n         [6.150e+02],\n         [9.330e+02]],\n\n        [[1.000e+00],\n         [1.000e+02],\n         [1.000e+02],\n         ...,\n         [1.000e+02],\n         [1.000e+02],\n         [1.000e+02]]]])>), <tf.Tensor: shape=(32, 3), dtype=float64, numpy=\narray([[1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.]])>)"
     ]
    }
   ],
   "source": [
    "train_generator = triplet_generator(batch_size, pos_train, neg_train, spoof_ground_truth.spoof_step1_truth1)\n",
    "val_generator = triplet_generator(batch_size, pos_val, neg_val, spoof_ground_truth.spoof_step1_truth1)\n",
    "\n",
    "model.fit(generator=train_generator, steps_per_epoch=20, epochs=100,\n",
    "                        validation_data=val_generator,\n",
    "                        validation_steps=10,\n",
    "                        verbose=1) #callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training process!\n",
      "-------------------------------------\n",
      "[1.292777, 0.2, 0.76052946, 0.28448996]\n",
      "[0.91208804, 0.2, 0.35548675, 0.30884406]\n",
      "[1.0889847, 0.2, 0.49864873, 0.34257892]\n",
      "[1.0894365, 0.2, 0.51800793, 0.32367185]\n",
      "[0.9980485, 0.2, 0.46863583, 0.28165603]\n",
      "[1.007574, 0.2, 0.51967084, 0.24014668]\n",
      "[1.2048166, 0.2, 0.6302284, 0.32684714]\n",
      "[1.0634065, 0.2, 0.5271299, 0.28855067]\n",
      "[1.2564203, 0.2, 0.32316518, 0.68554676]\n",
      "[0.8869104, 0.2, 0.34534407, 0.29387838]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10 iterations: 0.054940231641133624 mins\n",
      "Train Loss: [0.8869104, 0.2, 0.34534407, 0.29387838]\n",
      "[0.97349346, 0.2, 0.39905876, 0.32676992]\n",
      "[1.23887, 0.2, 0.7331495, 0.25808102]\n",
      "[1.0832039, 0.2, 0.39756158, 0.43802994]\n",
      "[1.0466359, 0.2, 0.52938354, 0.26966965]\n",
      "[0.8787669, 0.2, 0.3762797, 0.2549361]\n",
      "[0.80763364, 0.2, 0.29604995, 0.2640664]\n",
      "[0.832484, 0.2, 0.2966424, 0.28836006]\n",
      "[1.1554942, 0.2, 0.43964, 0.46841034]\n",
      "[0.8073968, 0.2, 0.31956008, 0.24043189]\n",
      "[1.0688647, 0.2, 0.55870295, 0.26279783]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 20 iterations: 0.06679245233535766 mins\n",
      "Train Loss: [1.0688647, 0.2, 0.55870295, 0.26279783]\n",
      "[1.0798528, 0.2, 0.39585266, 0.43667766]\n",
      "[0.9112692, 0.2, 0.40711653, 0.25687185]\n",
      "[0.78547555, 0.2, 0.2926755, 0.24556236]\n",
      "[0.8884879, 0.2, 0.40056884, 0.2407262]\n",
      "[0.87376, 0.2, 0.3519901, 0.27462316]\n",
      "[0.8820533, 0.2, 0.37536123, 0.25959277]\n",
      "[0.8066716, 0.2, 0.31893182, 0.24068925]\n",
      "[0.8364139, 0.2, 0.3566678, 0.23274557]\n",
      "[0.7765736, 0.2, 0.29435268, 0.23527181]\n",
      "[0.83221763, 0.2, 0.33793882, 0.24738233]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 30 iterations: 0.07532184918721517 mins\n",
      "Train Loss: [0.83221763, 0.2, 0.33793882, 0.24738233]\n",
      "[0.8886964, 0.2, 0.40561277, 0.23624115]\n",
      "[0.7211894, 0.2, 0.23764329, 0.23675859]\n",
      "[0.8569704, 0.2, 0.36914444, 0.2410947]\n",
      "[0.90434676, 0.2, 0.41878107, 0.23889084]\n",
      "[0.8188504, 0.2, 0.32902953, 0.24320239]\n",
      "[0.88048255, 0.2, 0.39474684, 0.2391743]\n",
      "[0.7478146, 0.2, 0.26723033, 0.23408078]\n",
      "[0.7886822, 0.2, 0.30713567, 0.235102]\n",
      "[0.884392, 0.2, 0.38519493, 0.25281262]\n",
      "[0.80494654, 0.2, 0.33562922, 0.22299334]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 40 iterations: 0.0818822185198466 mins\n",
      "Train Loss: [0.80494654, 0.2, 0.33562922, 0.22299334]\n",
      "[0.8110291, 0.2, 0.32573202, 0.2390345]\n",
      "[0.8480105, 0.2, 0.34004846, 0.2617618]\n",
      "[0.77553326, 0.2, 0.3075562, 0.22183979]\n",
      "[0.8019466, 0.2, 0.32509503, 0.2307782]\n",
      "[0.70271057, 0.2, 0.22800389, 0.22869807]\n",
      "[0.8069245, 0.2, 0.32757276, 0.23340861]\n",
      "[0.8898827, 0.2, 0.38626665, 0.25773913]\n",
      "[0.9570854, 0.2, 0.3737832, 0.33749163]\n",
      "[0.7471298, 0.2, 0.28034884, 0.22103624]\n",
      "[0.77416444, 0.2, 0.2986618, 0.22982438]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 50 iterations: 0.08698495229085286 mins\n",
      "Train Loss: [0.77416444, 0.2, 0.2986618, 0.22982438]\n",
      "[0.7916167, 0.2, 0.31496924, 0.2310364]\n",
      "[0.7633482, 0.2, 0.2877089, 0.23009649]\n",
      "[0.833364, 0.2, 0.35317728, 0.23471285]\n",
      "[0.83038884, 0.2, 0.36886626, 0.21611756]\n",
      "[0.7322495, 0.2, 0.25948286, 0.22743101]\n",
      "[0.81557244, 0.2, 0.34370738, 0.22659928]\n",
      "[0.8502383, 0.2, 0.38617775, 0.21886517]\n",
      "[0.85860586, 0.2, 0.38138664, 0.23209453]\n",
      "[0.6944086, 0.2, 0.23105423, 0.21830048]\n",
      "[0.7374921, 0.2, 0.26621523, 0.22629446]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 60 iterations: 0.09192425012588501 mins\n",
      "Train Loss: [0.7374921, 0.2, 0.26621523, 0.22629446]\n",
      "[0.7377497, 0.2, 0.2564019, 0.2364377]\n",
      "[0.7386623, 0.2, 0.27184978, 0.22197506]\n",
      "[0.7172316, 0.2, 0.25841385, 0.2140532]\n",
      "[0.74143356, 0.2, 0.2756811, 0.22106142]\n",
      "[0.7506363, 0.2, 0.28108922, 0.22492947]\n",
      "[0.759833, 0.2, 0.290567, 0.22472209]\n",
      "[0.7572624, 0.2, 0.2939549, 0.21883763]\n",
      "[0.9487049, 0.2, 0.48872122, 0.21558805]\n",
      "[0.72121346, 0.2, 0.26125538, 0.21563531]\n",
      "[0.7520642, 0.2, 0.27579096, 0.23202397]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 70 iterations: 0.09632970094680786 mins\n",
      "Train Loss: [0.7520642, 0.2, 0.27579096, 0.23202397]\n",
      "[0.71960455, 0.2, 0.25403908, 0.22138977]\n",
      "[0.72940093, 0.2, 0.2608017, 0.22449769]\n",
      "[0.7417821, 0.2, 0.27893654, 0.21881849]\n",
      "[0.8654268, 0.2, 0.40331626, 0.21815836]\n",
      "[0.7595984, 0.2, 0.289775, 0.22594479]\n",
      "[0.77715755, 0.2, 0.3102033, 0.22314946]\n",
      "[0.7661054, 0.2, 0.2993995, 0.22297494]\n",
      "[0.683631, 0.2, 0.2130025, 0.22697155]\n",
      "[0.74748373, 0.2, 0.27374658, 0.2301545]\n",
      "[0.702485, 0.2, 0.2489812, 0.2099956]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 80 iterations: 0.10133181810379029 mins\n",
      "Train Loss: [0.702485, 0.2, 0.2489812, 0.2099956]\n",
      "[0.7307836, 0.2, 0.27340955, 0.21394058]\n",
      "[0.88568544, 0.2, 0.2528672, 0.38945958]\n",
      "[0.7644098, 0.2, 0.26971, 0.25141564]\n",
      "[0.6864258, 0.2, 0.22243102, 0.22078505]\n",
      "[0.70858103, 0.2, 0.2491891, 0.21625702]\n",
      "[0.7230155, 0.2, 0.27068192, 0.20927362]\n",
      "[0.7150263, 0.2, 0.25462422, 0.21741708]\n",
      "[0.71325845, 0.2, 0.2524271, 0.21792135]\n",
      "[0.7227092, 0.2, 0.252786, 0.22708832]\n",
      "[0.7161088, 0.2, 0.25759163, 0.21575753]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 90 iterations: 0.10533181826273601 mins\n",
      "Train Loss: [0.7161088, 0.2, 0.25759163, 0.21575753]\n",
      "[0.82749027, 0.2, 0.22934815, 0.35545784]\n",
      "[0.69017637, 0.2, 0.23202308, 0.21554372]\n",
      "[0.7165339, 0.2, 0.26449203, 0.20950708]\n",
      "[0.7196437, 0.2, 0.25547037, 0.22171323]\n",
      "[0.6742448, 0.2, 0.21738434, 0.2144752]\n",
      "[0.7465001, 0.2, 0.28982857, 0.21436112]\n",
      "[0.7032616, 0.2, 0.25157288, 0.20945294]\n",
      "[0.672962, 0.2, 0.21862093, 0.21217978]\n",
      "[0.7026231, 0.2, 0.24308401, 0.2174525]\n",
      "[0.7163521, 0.2, 0.2536067, 0.22073364]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 100 iterations: 0.10888496637344361 mins\n",
      "Train Loss: [0.7163521, 0.2, 0.2536067, 0.22073364]\n",
      "[0.7521802, 0.2, 0.29336149, 0.21688199]\n",
      "[0.676814, 0.2, 0.2248879, 0.21006404]\n",
      "[0.7029164, 0.2, 0.24804527, 0.21308383]\n",
      "[0.6919973, 0.2, 0.23909964, 0.21118498]\n",
      "[0.71539587, 0.2, 0.2627029, 0.21105494]\n",
      "[0.72090584, 0.2, 0.26736945, 0.21197324]\n",
      "[0.68142164, 0.2, 0.22591682, 0.21401657]\n",
      "[0.7036325, 0.2, 0.24825563, 0.21396354]\n",
      "[0.68805945, 0.2, 0.23589167, 0.21082886]\n",
      "[0.79808223, 0.2, 0.33193287, 0.22488473]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 110 iterations: 0.112691863377889 mins\n",
      "Train Loss: [0.79808223, 0.2, 0.33193287, 0.22488473]\n",
      "[0.69506574, 0.2, 0.23932998, 0.21454473]\n",
      "[0.68610746, 0.2, 0.23245406, 0.21253571]\n",
      "[0.68713814, 0.2, 0.2354741, 0.2106195]\n",
      "[0.8567824, 0.2, 0.26987022, 0.34594098]\n",
      "[0.71532387, 0.2, 0.26195943, 0.212466]\n",
      "[0.66633505, 0.2, 0.21820122, 0.20730771]\n",
      "[0.69455475, 0.2, 0.23259936, 0.22120145]\n",
      "[0.6937751, 0.2, 0.23912258, 0.21397087]\n",
      "[0.7183386, 0.2, 0.25809136, 0.21963774]\n",
      "[0.70236754, 0.2, 0.23740579, 0.22442417]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 120 iterations: 0.11593261559804281 mins\n",
      "Train Loss: [0.70236754, 0.2, 0.23740579, 0.22442417]\n",
      "[0.6691342, 0.2, 0.21200961, 0.2166586]\n",
      "[0.71530235, 0.2, 0.25268337, 0.22222447]\n",
      "[0.7056764, 0.2, 0.25212342, 0.21322986]\n",
      "[0.820458, 0.2, 0.22510992, 0.35509604]\n",
      "[0.6911598, 0.2, 0.23813745, 0.21283978]\n",
      "[0.66335434, 0.2, 0.20780894, 0.21543215]\n",
      "[0.70767176, 0.2, 0.25969225, 0.20793585]\n",
      "[0.72758, 0.2, 0.2780583, 0.20954758]\n",
      "[0.7524054, 0.2, 0.23605163, 0.2764487]\n",
      "[0.68197644, 0.2, 0.2329469, 0.20919348]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 130 iterations: 0.11925991773605346 mins\n",
      "Train Loss: [0.68197644, 0.2, 0.2329469, 0.20919348]\n",
      "[0.69685423, 0.2, 0.23969835, 0.21738873]\n",
      "[0.6926134, 0.2, 0.23492926, 0.2179857]\n",
      "[0.6844544, 0.2, 0.23938443, 0.20543987]\n",
      "[0.69468987, 0.2, 0.24700038, 0.2081276]\n",
      "[0.6974937, 0.2, 0.24480444, 0.21319528]\n",
      "[0.69127274, 0.2, 0.24421428, 0.20763187]\n",
      "[0.7040751, 0.2, 0.25360093, 0.21111457]\n",
      "[0.68103087, 0.2, 0.2303349, 0.21140322]\n",
      "[0.65265775, 0.2, 0.20871647, 0.20471503]\n",
      "[0.7092974, 0.2, 0.26264942, 0.20748839]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 140 iterations: 0.1225046992301941 mins\n",
      "Train Loss: [0.7092974, 0.2, 0.26264942, 0.20748839]\n",
      "[0.70903254, 0.2, 0.2650916, 0.20484757]\n",
      "[0.788508, 0.2, 0.3340287, 0.21545151]\n",
      "[0.6948112, 0.2, 0.24007648, 0.21576992]\n",
      "[0.6795657, 0.2, 0.22877511, 0.21188833]\n",
      "[0.67867994, 0.2, 0.22755747, 0.21228264]\n",
      "[0.6575266, 0.2, 0.20725113, 0.21149792]\n",
      "[0.6687268, 0.2, 0.22130731, 0.2087041]\n",
      "[0.6648972, 0.2, 0.21621235, 0.21003158]\n",
      "[0.6943146, 0.2, 0.24894688, 0.20677648]\n",
      "[0.69988745, 0.2, 0.25292307, 0.20843506]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 150 iterations: 0.12549331585566204 mins\n",
      "Train Loss: [0.69988745, 0.2, 0.25292307, 0.20843506]\n",
      "[0.7030947, 0.2, 0.23850372, 0.22612292]\n",
      "[0.65234125, 0.2, 0.20862608, 0.20530815]\n",
      "[0.6794896, 0.2, 0.23057996, 0.2105637]\n",
      "[0.6776226, 0.2, 0.22874562, 0.21059212]\n",
      "[0.659679, 0.2, 0.21361746, 0.20783748]\n",
      "[0.6860621, 0.2, 0.23665151, 0.2112474]\n",
      "[0.6810081, 0.2, 0.23011535, 0.21279031]\n",
      "[0.760913, 0.2, 0.22334132, 0.29952964]\n",
      "[0.6791047, 0.2, 0.23172788, 0.20939407]\n",
      "[0.677388, 0.2, 0.22673722, 0.21272752]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 160 iterations: 0.12846105098724364 mins\n",
      "Train Loss: [0.677388, 0.2, 0.22673722, 0.21272752]\n",
      "[0.829493, 0.2, 0.2973386, 0.2942905]\n",
      "[0.6802502, 0.2, 0.23504625, 0.2073976]\n",
      "[0.6750707, 0.2, 0.22522226, 0.21209925]\n",
      "[0.6857926, 0.2, 0.23730579, 0.21079482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67347395, 0.2, 0.22632739, 0.20951179]\n",
      "[0.68037933, 0.2, 0.22497106, 0.21783069]\n",
      "[0.6920162, 0.2, 0.23904033, 0.21545546]\n",
      "[0.6707344, 0.2, 0.21939407, 0.21387674]\n",
      "[0.6660047, 0.2, 0.21521159, 0.2133862]\n",
      "[0.7496261, 0.2, 0.2175811, 0.29469457]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 170 iterations: 0.1326890985171 mins\n",
      "Train Loss: [0.7496261, 0.2, 0.2175811, 0.29469457]\n",
      "[0.6872586, 0.2, 0.24037504, 0.20958881]\n",
      "[0.67462486, 0.2, 0.22878648, 0.2085992]\n",
      "[0.683156, 0.2, 0.23518766, 0.21078429]\n",
      "[0.67316514, 0.2, 0.22284289, 0.21319354]\n",
      "[0.660046, 0.2, 0.20816018, 0.21481204]\n",
      "[0.6888587, 0.2, 0.24013665, 0.21170315]\n",
      "[0.67550236, 0.2, 0.23175265, 0.2067852]\n",
      "[0.67248285, 0.2, 0.22814265, 0.20742995]\n",
      "[0.6579684, 0.2, 0.20912951, 0.21198273]\n",
      "[0.65598, 0.2, 0.21032085, 0.2088572]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 180 iterations: 0.1359485348065694 mins\n",
      "Train Loss: [0.65598, 0.2, 0.21032085, 0.2088572]\n",
      "[0.68075186, 0.2, 0.229491, 0.214513]\n",
      "[0.6634684, 0.2, 0.21403924, 0.21273518]\n",
      "[0.6726183, 0.2, 0.2294075, 0.20657112]\n",
      "[0.67334455, 0.2, 0.23071972, 0.20603894]\n",
      "[0.6749713, 0.2, 0.23017164, 0.20826767]\n",
      "[0.6771598, 0.2, 0.2321034, 0.20857811]\n",
      "[0.68095404, 0.2, 0.22933039, 0.21519871]\n",
      "[0.66650057, 0.2, 0.21950218, 0.21062614]\n",
      "[0.6828916, 0.2, 0.2343491, 0.2122229]\n",
      "[0.7427557, 0.2, 0.2382848, 0.2682034]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 190 iterations: 0.13983633518218994 mins\n",
      "Train Loss: [0.7427557, 0.2, 0.2382848, 0.2682034]\n",
      "[0.66403115, 0.2, 0.22076482, 0.20704986]\n",
      "[0.6659654, 0.2, 0.22358096, 0.20621859]\n",
      "[0.6687068, 0.2, 0.22676675, 0.20582488]\n",
      "[0.6803012, 0.2, 0.2409311, 0.20330554]\n",
      "[0.67155814, 0.2, 0.22845124, 0.20709243]\n",
      "[0.65789515, 0.2, 0.21357489, 0.20835628]\n",
      "[0.66868806, 0.2, 0.22141519, 0.21135946]\n",
      "[0.68820655, 0.2, 0.24326627, 0.20907709]\n",
      "[0.6583594, 0.2, 0.21630177, 0.20624454]\n",
      "[0.6686924, 0.2, 0.22501642, 0.2079127]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 200 iterations: 0.14411776860555012 mins\n",
      "Train Loss: [0.6686924, 0.2, 0.22501642, 0.2079127]\n",
      "[0.6832438, 0.2, 0.23992936, 0.2076007]\n",
      "[0.7609377, 0.2, 0.27190635, 0.25336686]\n",
      "[0.65636766, 0.2, 0.20843652, 0.21231405]\n",
      "[0.66356534, 0.2, 0.221046, 0.20694956]\n",
      "[0.6931663, 0.2, 0.25447708, 0.20316695]\n",
      "[0.6562343, 0.2, 0.2104678, 0.21029146]\n",
      "[0.74667346, 0.2, 0.30405843, 0.20718709]\n",
      "[0.662035, 0.2, 0.22372283, 0.20293073]\n",
      "[0.6660508, 0.2, 0.22341254, 0.20730296]\n",
      "[0.6533042, 0.2, 0.21623318, 0.20178154]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 210 iterations: 0.1469847520192464 mins\n",
      "Train Loss: [0.6533042, 0.2, 0.21623318, 0.20178154]\n",
      "[0.6511556, 0.2, 0.21224901, 0.20366284]\n",
      "[0.66809314, 0.2, 0.22803053, 0.20486441]\n",
      "[0.6750768, 0.2, 0.23504177, 0.20488241]\n",
      "[0.66354805, 0.2, 0.21995328, 0.20848714]\n",
      "[0.6614235, 0.2, 0.2199692, 0.2063918]\n",
      "[0.6558972, 0.2, 0.2117623, 0.20911767]\n",
      "[0.67302865, 0.2, 0.23182121, 0.20623547]\n",
      "[0.6726851, 0.2, 0.22740938, 0.2103487]\n",
      "[0.6857902, 0.2, 0.24364252, 0.20726527]\n",
      "[0.6484551, 0.2, 0.21112105, 0.20249586]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 220 iterations: 0.14954888423283894 mins\n",
      "Train Loss: [0.6484551, 0.2, 0.21112105, 0.20249586]\n",
      "[0.6882365, 0.2, 0.24714021, 0.20630227]\n",
      "[0.66564715, 0.2, 0.22691144, 0.20398554]\n",
      "[0.6548613, 0.2, 0.2092378, 0.21091709]\n",
      "[0.66041, 0.2, 0.22209089, 0.20365632]\n",
      "[0.6504996, 0.2, 0.20784597, 0.20803457]\n",
      "[0.6604532, 0.2, 0.22153957, 0.20433849]\n",
      "[0.71196115, 0.2, 0.23063649, 0.24679337]\n",
      "[0.66553396, 0.2, 0.22343908, 0.20760751]\n",
      "[0.67311746, 0.2, 0.23600325, 0.20267048]\n",
      "[0.6592931, 0.2, 0.21434985, 0.2105429]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 230 iterations: 0.15190208355585735 mins\n",
      "Train Loss: [0.6592931, 0.2, 0.21434985, 0.2105429]\n",
      "[0.6721607, 0.2, 0.22990274, 0.20790052]\n",
      "[0.66449404, 0.2, 0.21515085, 0.21502861]\n",
      "[0.6726199, 0.2, 0.23056643, 0.20778129]\n",
      "[0.6507903, 0.2, 0.21229836, 0.2042618]\n",
      "[0.6464406, 0.2, 0.20743948, 0.20481285]\n",
      "[0.66251516, 0.2, 0.220912, 0.20745663]\n",
      "[0.6540344, 0.2, 0.21637493, 0.20355447]\n",
      "[0.66112345, 0.2, 0.21523078, 0.21182892]\n",
      "[0.69640166, 0.2, 0.2585269, 0.20385177]\n",
      "[0.65434, 0.2, 0.2149723, 0.20538446]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 240 iterations: 0.15430449644724528 mins\n",
      "Train Loss: [0.65434, 0.2, 0.2149723, 0.20538446]\n",
      "[0.6751697, 0.2, 0.22872716, 0.21249925]\n",
      "[0.66124195, 0.2, 0.22004764, 0.20729077]\n",
      "[0.6651696, 0.2, 0.22030811, 0.2109975]\n",
      "[0.68242276, 0.2, 0.216538, 0.23206021]\n",
      "[0.6505466, 0.2, 0.20816329, 0.20859796]\n",
      "[0.6513975, 0.2, 0.21349429, 0.20415695]\n",
      "[0.65859973, 0.2, 0.21893828, 0.20595369]\n",
      "[0.66656286, 0.2, 0.2296133, 0.20328033]\n",
      "[0.7274951, 0.2, 0.28598186, 0.20788257]\n",
      "[0.6511975, 0.2, 0.2122861, 0.20531741]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 250 iterations: 0.15676393111546835 mins\n",
      "Train Loss: [0.6511975, 0.2, 0.2122861, 0.20531741]\n",
      "[0.65353316, 0.2, 0.21441562, 0.20556042]\n",
      "[0.6545948, 0.2, 0.21394457, 0.20713003]\n",
      "[0.6461099, 0.2, 0.20798664, 0.20464016]\n",
      "[0.65446687, 0.2, 0.20952758, 0.21149343]\n",
      "[0.64047205, 0.2, 0.20421284, 0.2028504]\n",
      "[0.6636207, 0.2, 0.22401698, 0.20623186]\n",
      "[0.67050517, 0.2, 0.22987263, 0.20729731]\n",
      "[0.64473325, 0.2, 0.20477897, 0.20665537]\n",
      "[0.681457, 0.2, 0.2021578, 0.24603668]\n",
      "[0.65190256, 0.2, 0.21372885, 0.20494719]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 260 iterations: 0.15946071942647297 mins\n",
      "Train Loss: [0.65190256, 0.2, 0.21372885, 0.20494719]\n",
      "[0.6421634, 0.2, 0.20493463, 0.20403804]\n",
      "[0.65273017, 0.2, 0.21523213, 0.20434327]\n",
      "[0.66352, 0.2, 0.22587077, 0.20453024]\n",
      "[0.64911747, 0.2, 0.21189424, 0.20414008]\n",
      "[0.70635265, 0.2, 0.2101783, 0.26312724]\n",
      "[0.6624939, 0.2, 0.20838131, 0.22109994]\n",
      "[0.66494584, 0.2, 0.22744183, 0.20452571]\n",
      "[0.64982677, 0.2, 0.21269836, 0.20418428]\n",
      "[0.64894384, 0.2, 0.20957805, 0.20645584]\n",
      "[0.65222657, 0.2, 0.21489793, 0.20445313]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 270 iterations: 0.1624991496404012 mins\n",
      "Train Loss: [0.65222657, 0.2, 0.21489793, 0.20445313]\n",
      "[0.6652943, 0.2, 0.22752835, 0.20492479]\n",
      "[0.6570563, 0.2, 0.21884279, 0.20540708]\n",
      "[0.66528654, 0.2, 0.21100365, 0.22151145]\n",
      "[0.6776795, 0.2, 0.23765999, 0.2072823]\n",
      "[0.6702393, 0.2, 0.23000894, 0.20752746]\n",
      "[0.65162635, 0.2, 0.2154298, 0.2035277]\n",
      "[0.6533705, 0.2, 0.21515657, 0.20557906]\n",
      "[0.65671957, 0.2, 0.21632813, 0.2077906]\n",
      "[0.6666263, 0.2, 0.23036465, 0.2036946]\n",
      "[0.6519456, 0.2, 0.21550888, 0.20390368]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 280 iterations: 0.16543501615524292 mins\n",
      "Train Loss: [0.6519456, 0.2, 0.21550888, 0.20390368]\n",
      "[0.66489166, 0.2, 0.2264108, 0.20598193]\n",
      "[0.68215543, 0.2, 0.2162981, 0.23339228]\n",
      "[0.64321184, 0.2, 0.20365596, 0.20712507]\n",
      "[0.659387, 0.2, 0.21841621, 0.20857422]\n",
      "[0.65335464, 0.2, 0.215022, 0.20597023]\n",
      "[0.6461603, 0.2, 0.21160825, 0.20222375]\n",
      "[0.6508823, 0.2, 0.21430378, 0.20428447]\n",
      "[0.6917007, 0.2, 0.20683874, 0.25260222]\n",
      "[0.6531912, 0.2, 0.21876901, 0.20219631]\n",
      "[0.65819985, 0.2, 0.219896, 0.20611125]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 290 iterations: 0.16894681453704835 mins\n",
      "Train Loss: [0.65819985, 0.2, 0.219896, 0.20611125]\n",
      "[0.6582611, 0.2, 0.2166315, 0.20947017]\n",
      "[0.6410949, 0.2, 0.20573995, 0.20322815]\n",
      "[0.64350635, 0.2, 0.20702545, 0.20438679]\n",
      "[0.6533782, 0.2, 0.21587868, 0.20543814]\n",
      "[0.67050505, 0.2, 0.2135151, 0.22496112]\n",
      "[0.63762265, 0.2, 0.20314719, 0.20247883]\n",
      "[0.6459733, 0.2, 0.21081352, 0.20319603]\n",
      "[0.65559983, 0.2, 0.22082807, 0.20284098]\n",
      "[0.64004624, 0.2, 0.20294811, 0.20520023]\n",
      "[0.6482408, 0.2, 0.21080437, 0.20557147]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 300 iterations: 0.17169919808705647 mins\n",
      "Train Loss: [0.6482408, 0.2, 0.21080437, 0.20557147]\n",
      "[0.6572913, 0.2, 0.21679288, 0.2086666]\n",
      "[0.64851767, 0.2, 0.20676593, 0.20995271]\n",
      "[0.70421445, 0.2, 0.22490275, 0.24754553]\n",
      "[0.6605106, 0.2, 0.20989716, 0.21887912]\n",
      "[0.65003794, 0.2, 0.2153188, 0.20301643]\n",
      "[0.6582659, 0.2, 0.21848121, 0.20811376]\n",
      "[0.6440538, 0.2, 0.20751444, 0.20490007]\n",
      "[0.63783956, 0.2, 0.20469685, 0.20153497]\n",
      "[0.6489187, 0.2, 0.21242608, 0.20491652]\n",
      "[0.6658318, 0.2, 0.23083507, 0.20345213]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 310 iterations: 0.17403563261032104 mins\n",
      "Train Loss: [0.6658318, 0.2, 0.23083507, 0.20345213]\n",
      "[0.659909, 0.2, 0.22078961, 0.20760608]\n",
      "[0.6443339, 0.2, 0.20723896, 0.20561264]\n",
      "[0.66411823, 0.2, 0.22756232, 0.20510483]\n",
      "[0.6451374, 0.2, 0.20942307, 0.20429425]\n",
      "[0.66348624, 0.2, 0.22617392, 0.20592318]\n",
      "[0.6524857, 0.2, 0.21720473, 0.20392258]\n",
      "[0.6480945, 0.2, 0.21452262, 0.20224437]\n",
      "[0.6414777, 0.2, 0.2074689, 0.20271209]\n",
      "[0.65470666, 0.2, 0.21933296, 0.20410788]\n",
      "[0.65163213, 0.2, 0.21611674, 0.20428036]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 320 iterations: 0.17660458087921144 mins\n",
      "Train Loss: [0.65163213, 0.2, 0.21611674, 0.20428036]\n",
      "[0.66584796, 0.2, 0.23116669, 0.2034772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66612524, 0.2, 0.22920041, 0.20575172]\n",
      "[0.6605266, 0.2, 0.218644, 0.21074033]\n",
      "[0.6490301, 0.2, 0.21102698, 0.20689145]\n",
      "[0.6441749, 0.2, 0.20731227, 0.20578162]\n",
      "[0.65372235, 0.2, 0.21704052, 0.20563148]\n",
      "[0.66076607, 0.2, 0.2256972, 0.20404884]\n",
      "[0.64069355, 0.2, 0.20610307, 0.20360008]\n",
      "[0.6489851, 0.2, 0.21545988, 0.20256452]\n",
      "[0.65865606, 0.2, 0.22315523, 0.20457022]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 330 iterations: 0.1792203664779663 mins\n",
      "Train Loss: [0.65865606, 0.2, 0.22315523, 0.20457022]\n",
      "[0.6512725, 0.2, 0.21760201, 0.20276958]\n",
      "[0.6446004, 0.2, 0.21129878, 0.20243046]\n",
      "[0.63807607, 0.2, 0.20420595, 0.20302896]\n",
      "[0.6539358, 0.2, 0.21445692, 0.20866795]\n",
      "[0.66259146, 0.2, 0.22610104, 0.2057097]\n",
      "[0.66296226, 0.2, 0.22633989, 0.20587173]\n",
      "[0.64891034, 0.2, 0.21184587, 0.2063439]\n",
      "[0.6397767, 0.2, 0.204196, 0.20489044]\n",
      "[0.64379615, 0.2, 0.2114341, 0.20170219]\n",
      "[0.6474191, 0.2, 0.21042238, 0.20636694]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 340 iterations: 0.18169318437576293 mins\n",
      "Train Loss: [0.6474191, 0.2, 0.21042238, 0.20636694]\n",
      "[0.6503581, 0.2, 0.21651188, 0.20324643]\n",
      "[0.64911854, 0.2, 0.21411356, 0.20443535]\n",
      "[0.6527508, 0.2, 0.21799263, 0.20421867]\n",
      "[0.667297, 0.2, 0.2291945, 0.2075933]\n",
      "[0.6493115, 0.2, 0.21482496, 0.20400745]\n",
      "[0.6465888, 0.2, 0.20704041, 0.2090996]\n",
      "[0.64621055, 0.2, 0.21233205, 0.20346017]\n",
      "[0.647097, 0.2, 0.21028067, 0.20642827]\n",
      "[0.67496747, 0.2, 0.20470303, 0.23990682]\n",
      "[0.63807887, 0.2, 0.2039995, 0.2037511]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 350 iterations: 0.18390775124231976 mins\n",
      "Train Loss: [0.63807887, 0.2, 0.2039995, 0.2037511]\n",
      "[0.6582299, 0.2, 0.22254255, 0.20538837]\n",
      "[0.6540576, 0.2, 0.21723765, 0.20655017]\n",
      "[0.64396167, 0.2, 0.20982032, 0.20390023]\n",
      "[0.6418532, 0.2, 0.20700179, 0.20463884]\n",
      "[0.647791, 0.2, 0.21189356, 0.20571351]\n",
      "[0.6409099, 0.2, 0.204695, 0.20605947]\n",
      "[0.65026563, 0.2, 0.21662433, 0.20351467]\n",
      "[0.6421001, 0.2, 0.20887211, 0.20313002]\n",
      "[0.6521537, 0.2, 0.2171272, 0.20495735]\n",
      "[0.638652, 0.2, 0.20247494, 0.20613652]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 360 iterations: 0.1862048347791036 mins\n",
      "Train Loss: [0.638652, 0.2, 0.20247494, 0.20613652]\n",
      "[0.6379389, 0.2, 0.20239776, 0.20552908]\n",
      "[0.64250267, 0.2, 0.2116426, 0.20087658]\n",
      "[0.6735006, 0.2, 0.23847085, 0.20507486]\n",
      "[0.64931554, 0.2, 0.21301822, 0.20637028]\n",
      "[0.64827555, 0.2, 0.21450022, 0.20387644]\n",
      "[0.64131427, 0.2, 0.21088837, 0.20055537]\n",
      "[0.63784873, 0.2, 0.20294182, 0.2050646]\n",
      "[0.6458617, 0.2, 0.21136168, 0.20468608]\n",
      "[0.65063256, 0.2, 0.21523765, 0.20560919]\n",
      "[0.64188755, 0.2, 0.20822547, 0.20390439]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 370 iterations: 0.1882729689280192 mins\n",
      "Train Loss: [0.64188755, 0.2, 0.20822547, 0.20390439]\n",
      "[0.6509648, 0.2, 0.2191331, 0.2021022]\n",
      "[0.63888365, 0.2, 0.20641457, 0.20276766]\n",
      "[0.64332503, 0.2, 0.20832011, 0.20533179]\n",
      "[0.641711, 0.2, 0.20660584, 0.20546025]\n",
      "[0.6439567, 0.2, 0.21202081, 0.2023192]\n",
      "[0.6492137, 0.2, 0.21678242, 0.20284283]\n",
      "[0.6506664, 0.2, 0.21887761, 0.20222846]\n",
      "[0.63580453, 0.2, 0.20306884, 0.203203]\n",
      "[0.63687956, 0.2, 0.20274456, 0.20462999]\n",
      "[0.65367615, 0.2, 0.21782003, 0.20637867]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 380 iterations: 0.1907840847969055 mins\n",
      "Train Loss: [0.65367615, 0.2, 0.21782003, 0.20637867]\n",
      "[0.6393522, 0.2, 0.20651384, 0.20338835]\n",
      "[0.63624793, 0.2, 0.20343316, 0.20339198]\n",
      "[0.71657956, 0.2, 0.21198599, 0.27519804]\n",
      "[0.6455581, 0.2, 0.21101451, 0.20517541]\n",
      "[0.6469321, 0.2, 0.21531121, 0.20227991]\n",
      "[0.6445782, 0.2, 0.2123236, 0.20294072]\n",
      "[0.6406982, 0.2, 0.20646857, 0.20494229]\n",
      "[0.6356908, 0.2, 0.2036465, 0.20278363]\n",
      "[0.6360182, 0.2, 0.20348547, 0.20329873]\n",
      "[0.6398963, 0.2, 0.20911708, 0.20157221]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 390 iterations: 0.19580936431884766 mins\n",
      "Train Loss: [0.6398963, 0.2, 0.20911708, 0.20157221]\n",
      "[0.6376113, 0.2, 0.20411238, 0.20431899]\n",
      "[0.68562824, 0.2, 0.22624081, 0.23023441]\n",
      "[0.6347259, 0.2, 0.20216757, 0.2034318]\n",
      "[0.6409121, 0.2, 0.21036847, 0.20144337]\n",
      "[0.64225185, 0.2, 0.21015403, 0.20302385]\n",
      "[0.6534052, 0.2, 0.22050251, 0.20385507]\n",
      "[0.637122, 0.2, 0.20412666, 0.20397377]\n",
      "[0.6389998, 0.2, 0.20715265, 0.20285156]\n",
      "[0.65307087, 0.2, 0.21968557, 0.20441583]\n",
      "[0.6472158, 0.2, 0.21492478, 0.20334749]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 400 iterations: 0.19901130199432374 mins\n",
      "Train Loss: [0.6472158, 0.2, 0.21492478, 0.20334749]\n",
      "[0.6527545, 0.2, 0.22148067, 0.20235635]\n",
      "[0.6353401, 0.2, 0.20334573, 0.20310293]\n",
      "[0.65265405, 0.2, 0.2199517, 0.20383696]\n",
      "[0.6410043, 0.2, 0.21156973, 0.2005976]\n",
      "[0.65002704, 0.2, 0.2184008, 0.20281701]\n",
      "[0.6476685, 0.2, 0.2154743, 0.2034125]\n",
      "[0.6623533, 0.2, 0.23129241, 0.20230636]\n",
      "[0.65121585, 0.2, 0.22018957, 0.20229858]\n",
      "[0.6439086, 0.2, 0.21017553, 0.2050318]\n",
      "[0.6455849, 0.2, 0.20937009, 0.20753972]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 410 iterations: 0.2021241505940755 mins\n",
      "Train Loss: [0.6455849, 0.2, 0.20937009, 0.20753972]\n",
      "[0.64914155, 0.2, 0.21642531, 0.20406736]\n",
      "[0.65295064, 0.2, 0.21886958, 0.20545815]\n",
      "[0.66919553, 0.2, 0.21734494, 0.22325376]\n",
      "[0.64507836, 0.2, 0.21354887, 0.20295809]\n",
      "[0.64265907, 0.2, 0.21112561, 0.20298696]\n",
      "[0.6394718, 0.2, 0.20537418, 0.20557576]\n",
      "[0.65863746, 0.2, 0.2259877, 0.20415244]\n",
      "[0.6615533, 0.2, 0.23071605, 0.20236428]\n",
      "[0.6370904, 0.2, 0.2072688, 0.20137271]\n",
      "[0.6623078, 0.2, 0.23095791, 0.20292567]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 420 iterations: 0.2053680181503296 mins\n",
      "Train Loss: [0.6623078, 0.2, 0.23095791, 0.20292567]\n",
      "[0.63577515, 0.2, 0.20307685, 0.20429699]\n",
      "[0.65357053, 0.2, 0.21765144, 0.20754075]\n",
      "[0.64248353, 0.2, 0.20977205, 0.2043562]\n",
      "[0.6431566, 0.2, 0.20979282, 0.20503165]\n",
      "[0.6515538, 0.2, 0.21832417, 0.20492105]\n",
      "[0.65459234, 0.2, 0.21766967, 0.20863764]\n",
      "[0.64239734, 0.2, 0.20644224, 0.20769334]\n",
      "[0.65465045, 0.2, 0.22235431, 0.20405774]\n",
      "[0.63698894, 0.2, 0.20403984, 0.20473427]\n",
      "[0.66073364, 0.2, 0.22637323, 0.20616943]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 430 iterations: 0.20771448214848837 mins\n",
      "Train Loss: [0.66073364, 0.2, 0.22637323, 0.20616943]\n",
      "[0.64891684, 0.2, 0.2159739, 0.20477583]\n",
      "[0.69746506, 0.2, 0.21087003, 0.25845173]\n",
      "[0.6449459, 0.2, 0.2115489, 0.20527753]\n",
      "[0.65881336, 0.2, 0.22413088, 0.20658663]\n",
      "[0.6469226, 0.2, 0.2144127, 0.20443742]\n",
      "[0.6475904, 0.2, 0.21387477, 0.20566656]\n",
      "[0.63485366, 0.2, 0.20279564, 0.20403227]\n",
      "[0.64040637, 0.2, 0.20711622, 0.2052878]\n",
      "[0.6402366, 0.2, 0.20820676, 0.20405123]\n",
      "[0.63981533, 0.2, 0.20430337, 0.20755714]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 440 iterations: 0.21134239832560223 mins\n",
      "Train Loss: [0.63981533, 0.2, 0.20430337, 0.20755714]\n",
      "[0.6509578, 0.2, 0.2184118, 0.20461531]\n",
      "[0.6501526, 0.2, 0.21787985, 0.20436601]\n",
      "[0.64711225, 0.2, 0.21460168, 0.2046274]\n",
      "[0.63884145, 0.2, 0.208309, 0.20267287]\n",
      "[0.64547986, 0.2, 0.20962547, 0.20801878]\n",
      "[0.7042203, 0.2, 0.20935449, 0.26705438]\n",
      "[0.67226917, 0.2, 0.23502126, 0.20945978]\n",
      "[0.707717, 0.2, 0.27069068, 0.20926131]\n",
      "[0.6383884, 0.2, 0.20641604, 0.20423067]\n",
      "[0.6375134, 0.2, 0.20502363, 0.2047714]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 450 iterations: 0.21526004870732626 mins\n",
      "Train Loss: [0.6375134, 0.2, 0.20502363, 0.2047714]\n",
      "[0.6402809, 0.2, 0.20641252, 0.20617352]\n",
      "[0.65153146, 0.2, 0.22134891, 0.20251147]\n",
      "[0.6424193, 0.2, 0.21148859, 0.20328307]\n",
      "[0.6661449, 0.2, 0.23391752, 0.20460324]\n",
      "[0.65020937, 0.2, 0.20671871, 0.21588947]\n",
      "[0.64870673, 0.2, 0.21640012, 0.20472805]\n",
      "[0.64046854, 0.2, 0.20811895, 0.20479389]\n",
      "[0.64751244, 0.2, 0.21311733, 0.20686243]\n",
      "[0.65394545, 0.2, 0.22205287, 0.2043832]\n",
      "[0.6290745, 0.2, 0.20192929, 0.19965905]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 460 iterations: 0.21904131571451824 mins\n",
      "Train Loss: [0.6290745, 0.2, 0.20192929, 0.19965905]\n",
      "[0.64119816, 0.2, 0.21017237, 0.2035631]\n",
      "[0.6359076, 0.2, 0.20418227, 0.20428558]\n",
      "[0.6604319, 0.2, 0.23086943, 0.202145]\n",
      "[0.6425148, 0.2, 0.21295628, 0.20216255]\n",
      "[0.64094317, 0.2, 0.2109578, 0.20261051]\n",
      "[0.6381935, 0.2, 0.20744665, 0.2033935]\n",
      "[0.6402787, 0.2, 0.20856312, 0.20438366]\n",
      "[0.6415427, 0.2, 0.21146853, 0.2027638]\n",
      "[0.66218036, 0.2, 0.2310006, 0.20389102]\n",
      "[0.6397404, 0.2, 0.20878017, 0.2036927]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 470 iterations: 0.2229351003964742 mins\n",
      "Train Loss: [0.6397404, 0.2, 0.20878017, 0.2036927]\n",
      "[0.6423703, 0.2, 0.20745218, 0.20767258]\n",
      "[0.6566975, 0.2, 0.22378, 0.20569412]\n",
      "[0.6363246, 0.2, 0.20874955, 0.20037381]\n",
      "[0.6907323, 0.2, 0.2593197, 0.20423375]\n",
      "[0.6434639, 0.2, 0.21504492, 0.20125967]\n",
      "[0.64541, 0.2, 0.21230096, 0.20596957]\n",
      "[0.643827, 0.2, 0.21532488, 0.20138283]\n",
      "[0.6491206, 0.2, 0.219837, 0.2021845]\n",
      "[0.6378333, 0.2, 0.2081216, 0.20263277]\n",
      "[0.6673596, 0.2, 0.23799554, 0.20230597]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 480 iterations: 0.22597928444544474 mins\n",
      "Train Loss: [0.6673596, 0.2, 0.23799554, 0.20230597]\n",
      "[0.6555047, 0.2, 0.2216919, 0.20677567]\n",
      "[0.6442372, 0.2, 0.21156682, 0.20565423]\n",
      "[0.6427462, 0.2, 0.20832185, 0.2074298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64154315, 0.2, 0.21052256, 0.20404798]\n",
      "[0.63456756, 0.2, 0.20287585, 0.20474173]\n",
      "[0.634871, 0.2, 0.20506571, 0.2028779]\n",
      "[0.6410287, 0.2, 0.21221676, 0.20190755]\n",
      "[0.6315559, 0.2, 0.2030358, 0.20163898]\n",
      "[0.6457309, 0.2, 0.21587482, 0.20299827]\n",
      "[0.64930713, 0.2, 0.20377435, 0.2186982]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 490 iterations: 0.22984215021133422 mins\n",
      "Train Loss: [0.64930713, 0.2, 0.20377435, 0.2186982]\n",
      "[0.64167166, 0.2, 0.20623302, 0.2086273]\n",
      "[0.6367811, 0.2, 0.20268135, 0.20731127]\n",
      "[0.6478152, 0.2, 0.2162887, 0.20476109]\n",
      "[0.65216446, 0.2, 0.22298238, 0.20243932]\n",
      "[0.642221, 0.2, 0.21212901, 0.2033716]\n",
      "[0.64388263, 0.2, 0.21443856, 0.20274583]\n",
      "[0.64686435, 0.2, 0.21507606, 0.20511188]\n",
      "[0.6428902, 0.2, 0.21467504, 0.20156066]\n",
      "[0.6393032, 0.2, 0.20822072, 0.20445004]\n",
      "[0.63053304, 0.2, 0.20147708, 0.20244585]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 500 iterations: 0.23336573441823324 mins\n",
      "Train Loss: [0.63053304, 0.2, 0.20147708, 0.20244585]\n",
      "[0.63845277, 0.2, 0.208793, 0.2030724]\n",
      "[0.63127846, 0.2, 0.20245226, 0.20226134]\n",
      "[0.6409219, 0.2, 0.21200828, 0.20237125]\n",
      "[0.6328928, 0.2, 0.20279019, 0.20358264]\n",
      "[0.63928103, 0.2, 0.21076155, 0.20202202]\n",
      "[0.63247067, 0.2, 0.20245765, 0.20353815]\n",
      "[0.6309373, 0.2, 0.20256878, 0.20191588]\n",
      "[0.655179, 0.2, 0.22565229, 0.20309597]\n",
      "[0.6429748, 0.2, 0.21286795, 0.2036974]\n",
      "[0.6400422, 0.2, 0.21111633, 0.20253745]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 510 iterations: 0.23852755228678385 mins\n",
      "Train Loss: [0.6400422, 0.2, 0.21111633, 0.20253745]\n",
      "[0.63764656, 0.2, 0.20644926, 0.20482932]\n",
      "[0.6567627, 0.2, 0.21445693, 0.21595813]\n",
      "[0.63220376, 0.2, 0.20218703, 0.2036902]\n",
      "[0.6437146, 0.2, 0.20382385, 0.21358562]\n",
      "[0.63804245, 0.2, 0.20759763, 0.20416108]\n",
      "[0.6372829, 0.2, 0.20367111, 0.20734912]\n",
      "[0.6374086, 0.2, 0.20735598, 0.20381054]\n",
      "[0.638454, 0.2, 0.21091378, 0.20131877]\n",
      "[0.64118683, 0.2, 0.21152976, 0.20345615]\n",
      "[0.6371972, 0.2, 0.2065848, 0.20443161]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 520 iterations: 0.24200899600982667 mins\n",
      "Train Loss: [0.6371972, 0.2, 0.2065848, 0.20443161]\n",
      "[0.64696753, 0.2, 0.22016421, 0.20064247]\n",
      "[0.64533097, 0.2, 0.21620269, 0.20298772]\n",
      "[0.63929474, 0.2, 0.20981306, 0.20336108]\n",
      "[0.64084226, 0.2, 0.2127739, 0.20196843]\n",
      "[0.6490011, 0.2, 0.21941587, 0.20350575]\n",
      "[0.6374935, 0.2, 0.20856623, 0.20286836]\n",
      "[0.63733417, 0.2, 0.20960234, 0.20169371]\n",
      "[0.63496554, 0.2, 0.20402108, 0.20492738]\n",
      "[0.6481324, 0.2, 0.21655105, 0.20558597]\n",
      "[0.6459276, 0.2, 0.21508351, 0.20487022]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 530 iterations: 0.24519468148549398 mins\n",
      "Train Loss: [0.6459276, 0.2, 0.21508351, 0.20487022]\n",
      "[0.6320171, 0.2, 0.20433064, 0.20173436]\n",
      "[0.6362603, 0.2, 0.20621008, 0.20411989]\n",
      "[0.6388595, 0.2, 0.21076217, 0.20218872]\n",
      "[0.63003516, 0.2, 0.20120943, 0.20293817]\n",
      "[0.6363438, 0.2, 0.20654218, 0.20393476]\n",
      "[0.6372522, 0.2, 0.20744687, 0.20396073]\n",
      "[0.6362278, 0.2, 0.20683113, 0.2035738]\n",
      "[0.634556, 0.2, 0.20153563, 0.20721997]\n",
      "[0.63533217, 0.2, 0.20688513, 0.20266856]\n",
      "[0.6358397, 0.2, 0.20508319, 0.20500076]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 540 iterations: 0.24946251312891643 mins\n",
      "Train Loss: [0.6358397, 0.2, 0.20508319, 0.20500076]\n",
      "[0.6453342, 0.2, 0.20492901, 0.21467215]\n",
      "[0.6290066, 0.2, 0.20087738, 0.20241919]\n",
      "[0.6340433, 0.2, 0.20606975, 0.20228612]\n",
      "[0.63031673, 0.2, 0.2032819, 0.2013696]\n",
      "[0.63734317, 0.2, 0.20933326, 0.20236662]\n",
      "[0.64352715, 0.2, 0.2167415, 0.20116468]\n",
      "[0.6426941, 0.2, 0.21286722, 0.20422779]\n",
      "[0.62992364, 0.2, 0.20280413, 0.20154221]\n",
      "[0.6438679, 0.2, 0.21335424, 0.20495811]\n",
      "[0.63253963, 0.2, 0.20575252, 0.2012532]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 550 iterations: 0.25238279898961385 mins\n",
      "Train Loss: [0.63253963, 0.2, 0.20575252, 0.2012532]\n",
      "[0.6495325, 0.2, 0.21763541, 0.2063846]\n",
      "[0.6526911, 0.2, 0.20742436, 0.21977557]\n",
      "[0.6320238, 0.2, 0.20443033, 0.20212354]\n",
      "[0.65035355, 0.2, 0.20219022, 0.2227145]\n",
      "[0.6331587, 0.2, 0.19958545, 0.20814589]\n",
      "[0.64451796, 0.2, 0.21876593, 0.20034644]\n",
      "[0.6357555, 0.2, 0.20720574, 0.20316589]\n",
      "[0.6334521, 0.2, 0.20588036, 0.20220955]\n",
      "[0.6342929, 0.2, 0.20732759, 0.2016244]\n",
      "[0.6326216, 0.2, 0.20130791, 0.20599388]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 560 iterations: 0.25564688046773276 mins\n",
      "Train Loss: [0.6326216, 0.2, 0.20130791, 0.20599388]\n",
      "[0.6455917, 0.2, 0.21515211, 0.20514089]\n",
      "[0.6354377, 0.2, 0.20740391, 0.20275648]\n",
      "[0.64222056, 0.2, 0.21336989, 0.20359439]\n",
      "[0.63439643, 0.2, 0.2041034, 0.20505749]\n",
      "[0.67244095, 0.2, 0.23134649, 0.21588005]\n",
      "[0.64572746, 0.2, 0.21604894, 0.20448191]\n",
      "[0.6493615, 0.2, 0.21802343, 0.20615916]\n",
      "[0.63371164, 0.2, 0.20322621, 0.20532398]\n",
      "[0.6282274, 0.2, 0.20295848, 0.20012522]\n",
      "[0.67025316, 0.2, 0.24031255, 0.20481467]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 570 iterations: 0.25850146611531577 mins\n",
      "Train Loss: [0.67025316, 0.2, 0.24031255, 0.20481467]\n",
      "[0.64079016, 0.2, 0.21469387, 0.20099008]\n",
      "[0.63290995, 0.2, 0.20358387, 0.20423965]\n",
      "[0.6315617, 0.2, 0.20275792, 0.20373704]\n",
      "[0.6396415, 0.2, 0.21024111, 0.20435342]\n",
      "[0.6549721, 0.2, 0.22838254, 0.20156248]\n",
      "[0.63819945, 0.2, 0.20515418, 0.20803773]\n",
      "[0.651164, 0.2, 0.21850067, 0.20767483]\n",
      "[0.62901145, 0.2, 0.20308053, 0.20096146]\n",
      "[0.64898026, 0.2, 0.22329326, 0.20073707]\n",
      "[0.63467395, 0.2, 0.20724101, 0.20250262]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 580 iterations: 0.2611202319463094 mins\n",
      "Train Loss: [0.63467395, 0.2, 0.20724101, 0.20250262]\n",
      "[0.6344409, 0.2, 0.20613371, 0.20339647]\n",
      "[0.63920474, 0.2, 0.21057847, 0.20373549]\n",
      "[0.6377174, 0.2, 0.21128824, 0.20155844]\n",
      "[0.6441047, 0.2, 0.21414763, 0.20510659]\n",
      "[0.7258677, 0.2, 0.20432909, 0.2967084]\n",
      "[0.65077865, 0.2, 0.22494245, 0.20102625]\n",
      "[0.64963573, 0.2, 0.21803226, 0.2068137]\n",
      "[0.6320321, 0.2, 0.20235519, 0.20490704]\n",
      "[0.7693274, 0.2, 0.22716618, 0.3174115]\n",
      "[0.63683516, 0.2, 0.20919767, 0.20290655]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 590 iterations: 0.26495293378829954 mins\n",
      "Train Loss: [0.63683516, 0.2, 0.20919767, 0.20290655]\n",
      "[0.6425737, 0.2, 0.2162718, 0.20158964]\n",
      "[0.62916267, 0.2, 0.20288274, 0.2015859]\n",
      "[0.6412102, 0.2, 0.20865408, 0.20788011]\n",
      "[0.67405, 0.2, 0.20845518, 0.24093659]\n",
      "[0.6273976, 0.2, 0.20211798, 0.20063978]\n",
      "[0.63003725, 0.2, 0.20289193, 0.20252371]\n",
      "[0.63283944, 0.2, 0.20479573, 0.20344049]\n",
      "[0.6305747, 0.2, 0.20364569, 0.20234427]\n",
      "[0.6439033, 0.2, 0.21868569, 0.20065184]\n",
      "[0.6334925, 0.2, 0.20451461, 0.20443082]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 600 iterations: 0.2693418304125468 mins\n",
      "Train Loss: [0.6334925, 0.2, 0.20451461, 0.20443082]\n",
      "[0.6527318, 0.2, 0.22340661, 0.20479704]\n",
      "[0.6451392, 0.2, 0.2179441, 0.20268564]\n",
      "[0.6297779, 0.2, 0.20351148, 0.20177583]\n",
      "[0.6668105, 0.2, 0.23942639, 0.20291221]\n",
      "[0.6379173, 0.2, 0.20853199, 0.2049318]\n",
      "[0.62864685, 0.2, 0.2036617, 0.20055]\n",
      "[0.6294377, 0.2, 0.20189497, 0.20312591]\n",
      "[0.62898904, 0.2, 0.20265363, 0.20193718]\n",
      "[0.6282147, 0.2, 0.20154631, 0.20228894]\n",
      "[0.6340769, 0.2, 0.20823799, 0.20147842]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 610 iterations: 0.27405108213424684 mins\n",
      "Train Loss: [0.6340769, 0.2, 0.20823799, 0.20147842]\n",
      "[0.6418398, 0.2, 0.2081783, 0.20932025]\n",
      "[0.6435201, 0.2, 0.21727979, 0.2019184]\n",
      "[0.63411784, 0.2, 0.20809881, 0.20171642]\n",
      "[0.6976108, 0.2, 0.20662554, 0.266702]\n",
      "[0.6325303, 0.2, 0.2023148, 0.20595117]\n",
      "[0.6377142, 0.2, 0.2086567, 0.20481199]\n",
      "[0.6670997, 0.2, 0.22444515, 0.21842791]\n",
      "[0.6509873, 0.2, 0.22452801, 0.20225157]\n",
      "[0.62974966, 0.2, 0.2036843, 0.201876]\n",
      "[0.6460827, 0.2, 0.21052317, 0.21138898]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 620 iterations: 0.27764738400777184 mins\n",
      "Train Loss: [0.6460827, 0.2, 0.21052317, 0.21138898]\n",
      "[0.65148836, 0.2, 0.22166426, 0.20567177]\n",
      "[0.6328608, 0.2, 0.20373848, 0.20498788]\n",
      "[0.6876173, 0.2, 0.2604601, 0.20304042]\n",
      "[0.62888575, 0.2, 0.20276421, 0.20202076]\n",
      "[0.6365754, 0.2, 0.20968665, 0.2028041]\n",
      "[0.6376305, 0.2, 0.2116145, 0.20194781]\n",
      "[0.62966716, 0.2, 0.20201942, 0.20359619]\n",
      "[0.65644777, 0.2, 0.22991998, 0.20249307]\n",
      "[0.6277757, 0.2, 0.2003324, 0.20342542]\n",
      "[0.69351673, 0.2, 0.2607203, 0.20879544]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 630 iterations: 0.2820580005645752 mins\n",
      "Train Loss: [0.69351673, 0.2, 0.2607203, 0.20879544]\n",
      "[0.63457227, 0.2, 0.20704919, 0.20353995]\n",
      "[0.62938803, 0.2, 0.203977, 0.20144594]\n",
      "[0.6508106, 0.2, 0.22003269, 0.20683098]\n",
      "[0.6583046, 0.2, 0.22803198, 0.20634378]\n",
      "[0.7418958, 0.2, 0.2256176, 0.2923673]\n",
      "[0.6294898, 0.2, 0.2015405, 0.20405573]\n",
      "[0.6445039, 0.2, 0.21949545, 0.20113254]\n",
      "[0.64610964, 0.2, 0.21945187, 0.2027994]\n",
      "[0.6338521, 0.2, 0.20576082, 0.20425035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64371026, 0.2, 0.21533555, 0.20455135]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 640 iterations: 0.2847805460294088 mins\n",
      "Train Loss: [0.64371026, 0.2, 0.21533555, 0.20455135]\n",
      "[0.6304865, 0.2, 0.20650625, 0.20017438]\n",
      "[0.65156174, 0.2, 0.2201939, 0.20757972]\n",
      "[0.6490005, 0.2, 0.21504606, 0.21018425]\n",
      "[0.63574785, 0.2, 0.21049869, 0.2014966]\n",
      "[0.65805894, 0.2, 0.22826476, 0.20605914]\n",
      "[0.6355591, 0.2, 0.20910312, 0.20273808]\n",
      "[0.6482463, 0.2, 0.22222093, 0.20232445]\n",
      "[0.6365824, 0.2, 0.21095932, 0.20193915]\n",
      "[0.6300658, 0.2, 0.20603056, 0.20036842]\n",
      "[0.63786364, 0.2, 0.21234468, 0.2018695]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 650 iterations: 0.2874864339828491 mins\n",
      "Train Loss: [0.63786364, 0.2, 0.21234468, 0.2018695]\n",
      "[0.6306251, 0.2, 0.2012057, 0.20578775]\n",
      "[0.63675046, 0.2, 0.21093078, 0.20220582]\n",
      "[0.6303856, 0.2, 0.20375973, 0.20303014]\n",
      "[0.6365608, 0.2, 0.2100776, 0.20290555]\n",
      "[0.63975906, 0.2, 0.21197812, 0.20422119]\n",
      "[0.6389843, 0.2, 0.21469483, 0.20074743]\n",
      "[0.62419474, 0.2, 0.19910544, 0.20156527]\n",
      "[0.63503057, 0.2, 0.20661612, 0.20490812]\n",
      "[0.64362276, 0.2, 0.2169016, 0.20323247]\n",
      "[0.633316, 0.2, 0.2041279, 0.2057171]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 660 iterations: 0.2899637818336487 mins\n",
      "Train Loss: [0.633316, 0.2, 0.2041279, 0.2057171]\n",
      "[0.63995385, 0.2, 0.2149734, 0.2015271]\n",
      "[0.6296308, 0.2, 0.2028338, 0.2033616]\n",
      "[0.62875175, 0.2, 0.20316553, 0.20216893]\n",
      "[0.638022, 0.2, 0.21125038, 0.2033726]\n",
      "[0.6306808, 0.2, 0.20458847, 0.20271143]\n",
      "[0.6379285, 0.2, 0.21204342, 0.20252259]\n",
      "[0.63434917, 0.2, 0.2076189, 0.20338622]\n",
      "[0.6519794, 0.2, 0.22348715, 0.20516664]\n",
      "[0.6372484, 0.2, 0.2092094, 0.20473146]\n",
      "[0.6845169, 0.2, 0.25631928, 0.2049082]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 670 iterations: 0.2929988185564677 mins\n",
      "Train Loss: [0.6845169, 0.2, 0.25631928, 0.2049082]\n",
      "[0.632437, 0.2, 0.20697406, 0.20219326]\n",
      "[0.64237595, 0.2, 0.20005997, 0.21906395]\n",
      "[0.63313854, 0.2, 0.20508587, 0.20481826]\n",
      "[0.6432132, 0.2, 0.21861659, 0.20137951]\n",
      "[0.62635976, 0.2, 0.20285237, 0.2003072]\n",
      "[0.6474543, 0.2, 0.21809247, 0.20617868]\n",
      "[0.62787855, 0.2, 0.201411, 0.2033011]\n",
      "[0.6432214, 0.2, 0.21499239, 0.20507944]\n",
      "[0.64083296, 0.2, 0.2047928, 0.21290755]\n",
      "[0.65042853, 0.2, 0.22422329, 0.20308983]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 680 iterations: 0.2957622806231181 mins\n",
      "Train Loss: [0.65042853, 0.2, 0.22422329, 0.20308983]\n",
      "[0.635391, 0.2, 0.20958126, 0.20271133]\n",
      "[0.65015775, 0.2, 0.2230837, 0.20399292]\n",
      "[0.6391524, 0.2, 0.21413729, 0.20195074]\n",
      "[0.641024, 0.2, 0.21209124, 0.20588525]\n",
      "[0.64072174, 0.2, 0.21477458, 0.20291649]\n",
      "[0.6513175, 0.2, 0.21320282, 0.21510084]\n",
      "[0.64444506, 0.2, 0.21704768, 0.20440172]\n",
      "[0.6360029, 0.2, 0.20989326, 0.20313181]\n",
      "[0.6435226, 0.2, 0.21625249, 0.20430976]\n",
      "[0.62863517, 0.2, 0.20266463, 0.20302701]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 690 iterations: 0.2995625336964925 mins\n",
      "Train Loss: [0.62863517, 0.2, 0.20266463, 0.20302701]\n",
      "[0.64455795, 0.2, 0.2194689, 0.20216234]\n",
      "[0.63810855, 0.2, 0.21203595, 0.20316301]\n",
      "[0.6454197, 0.2, 0.21395251, 0.2085748]\n",
      "[0.6316021, 0.2, 0.206666, 0.20206122]\n",
      "[0.6311161, 0.2, 0.20041162, 0.20784687]\n",
      "[0.6384891, 0.2, 0.20545478, 0.21019417]\n",
      "[0.7075002, 0.2, 0.20631059, 0.27836737]\n",
      "[0.64359254, 0.2, 0.21667393, 0.20411345]\n",
      "[0.6277455, 0.2, 0.20139718, 0.20356017]\n",
      "[0.6341681, 0.2, 0.20623885, 0.2051579]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 700 iterations: 0.30213675101598103 mins\n",
      "Train Loss: [0.6341681, 0.2, 0.20623885, 0.2051579]\n",
      "[0.6503522, 0.2, 0.22494067, 0.20265707]\n",
      "[0.6322158, 0.2, 0.2017741, 0.20770404]\n",
      "[0.6590269, 0.2, 0.23251094, 0.20379508]\n",
      "[0.62689894, 0.2, 0.20248039, 0.20171425]\n",
      "[0.6333874, 0.2, 0.20738561, 0.20331429]\n",
      "[0.66211134, 0.2, 0.23645967, 0.20298114]\n",
      "[0.66739136, 0.2, 0.24422057, 0.20051679]\n",
      "[0.6454177, 0.2, 0.22107598, 0.20170942]\n",
      "[0.6493286, 0.2, 0.22402333, 0.20269383]\n",
      "[0.6369294, 0.2, 0.21330056, 0.20103748]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 710 iterations: 0.3044555346171061 mins\n",
      "Train Loss: [0.6369294, 0.2, 0.21330056, 0.20103748]\n",
      "[0.6308262, 0.2, 0.20444971, 0.20380497]\n",
      "[0.6250081, 0.2, 0.20163763, 0.2008183]\n",
      "[0.6560163, 0.2, 0.2282814, 0.20520194]\n",
      "[0.64657134, 0.2, 0.22236428, 0.20169272]\n",
      "[0.65023315, 0.2, 0.21753626, 0.2102009]\n",
      "[0.6362659, 0.2, 0.20917018, 0.20461756]\n",
      "[0.6295871, 0.2, 0.20291165, 0.20421503]\n",
      "[0.63811046, 0.2, 0.2087214, 0.20694618]\n",
      "[0.6342068, 0.2, 0.20867233, 0.20310895]\n",
      "[0.6290735, 0.2, 0.20255813, 0.20410724]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 720 iterations: 0.3068124334017436 mins\n",
      "Train Loss: [0.6290735, 0.2, 0.20255813, 0.20410724]\n",
      "[0.64987314, 0.2, 0.22369339, 0.20378862]\n",
      "[0.6388771, 0.2, 0.20680472, 0.20969817]\n",
      "[0.63305926, 0.2, 0.20889524, 0.20180683]\n",
      "[0.66971606, 0.2, 0.21013193, 0.23724407]\n",
      "[0.6329824, 0.2, 0.20669144, 0.20396782]\n",
      "[0.62831575, 0.2, 0.20358196, 0.20242769]\n",
      "[0.6450591, 0.2, 0.21971218, 0.20305794]\n",
      "[0.6338873, 0.2, 0.20891322, 0.20270221]\n",
      "[0.62604135, 0.2, 0.20273413, 0.20105249]\n",
      "[0.6350332, 0.2, 0.20602728, 0.20676863]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 730 iterations: 0.30893041292826334 mins\n",
      "Train Loss: [0.6350332, 0.2, 0.20602728, 0.20676863]\n",
      "[0.62994766, 0.2, 0.20297083, 0.20475681]\n",
      "[0.6370979, 0.2, 0.20822904, 0.20666602]\n",
      "[0.6296864, 0.2, 0.20453905, 0.20296103]\n",
      "[0.64643234, 0.2, 0.221985, 0.20227744]\n",
      "[0.63256353, 0.2, 0.20598172, 0.20442843]\n",
      "[0.6452886, 0.2, 0.22118053, 0.20197077]\n",
      "[0.642301, 0.2, 0.2157909, 0.20438875]\n",
      "[0.62969416, 0.2, 0.20714036, 0.2004485]\n",
      "[0.63953537, 0.2, 0.212716, 0.20473008]\n",
      "[0.63344085, 0.2, 0.20873702, 0.20263012]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 740 iterations: 0.3111666003863017 mins\n",
      "Train Loss: [0.63344085, 0.2, 0.20873702, 0.20263012]\n",
      "[0.6326108, 0.2, 0.20968942, 0.20086339]\n",
      "[0.63708633, 0.2, 0.214116, 0.20092794]\n",
      "[0.6266901, 0.2, 0.20550263, 0.19916084]\n",
      "[0.6309181, 0.2, 0.20483904, 0.20406711]\n",
      "[0.64038676, 0.2, 0.2173526, 0.20103435]\n",
      "[0.63030255, 0.2, 0.20540631, 0.2029073]\n",
      "[0.6396387, 0.2, 0.21467267, 0.2029872]\n",
      "[0.64033985, 0.2, 0.21291809, 0.20545284]\n",
      "[0.6307342, 0.2, 0.20660843, 0.20216797]\n",
      "[0.6294961, 0.2, 0.20509721, 0.20245226]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 750 iterations: 0.31409064928690594 mins\n",
      "Train Loss: [0.6294961, 0.2, 0.20509721, 0.20245226]\n",
      "[0.6392849, 0.2, 0.21435994, 0.20298974]\n",
      "[0.6507562, 0.2, 0.2279858, 0.20084706]\n",
      "[0.64892435, 0.2, 0.21532984, 0.21168336]\n",
      "[0.64333457, 0.2, 0.2181285, 0.20330746]\n",
      "[0.62998325, 0.2, 0.20553805, 0.20255928]\n",
      "[0.6341249, 0.2, 0.20701392, 0.20523849]\n",
      "[0.631699, 0.2, 0.20521964, 0.20462301]\n",
      "[0.63373816, 0.2, 0.2082065, 0.20369135]\n",
      "[0.62829036, 0.2, 0.2047058, 0.20176013]\n",
      "[0.6265911, 0.2, 0.20284155, 0.20194118]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 760 iterations: 0.3161746978759766 mins\n",
      "Train Loss: [0.6265911, 0.2, 0.20284155, 0.20194118]\n",
      "[0.63521725, 0.2, 0.21121009, 0.20221503]\n",
      "[0.6407847, 0.2, 0.21725719, 0.20175186]\n",
      "[0.6299832, 0.2, 0.20751248, 0.20071127]\n",
      "[0.62306094, 0.2, 0.19993654, 0.20138147]\n",
      "[0.6356304, 0.2, 0.20910743, 0.20479666]\n",
      "[0.6379933, 0.2, 0.21497232, 0.20131218]\n",
      "[0.64434344, 0.2, 0.22108938, 0.20156254]\n",
      "[0.6454507, 0.2, 0.20707066, 0.2167058]\n",
      "[0.63286746, 0.2, 0.2099201, 0.201291]\n",
      "[0.6255581, 0.2, 0.20273612, 0.20118313]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 770 iterations: 0.31878085136413575 mins\n",
      "Train Loss: [0.6255581, 0.2, 0.20273612, 0.20118313]\n",
      "[0.6351601, 0.2, 0.20962201, 0.20391703]\n",
      "[0.63099414, 0.2, 0.20688039, 0.20251042]\n",
      "[0.6304316, 0.2, 0.20743176, 0.20141411]\n",
      "[0.643344, 0.2, 0.21866983, 0.20310636]\n",
      "[0.62636817, 0.2, 0.20354486, 0.20127386]\n",
      "[0.6327194, 0.2, 0.20828357, 0.20290457]\n",
      "[0.6446317, 0.2, 0.21988335, 0.20323507]\n",
      "[0.6340057, 0.2, 0.21161982, 0.2008903]\n",
      "[0.633216, 0.2, 0.21082345, 0.2009145]\n",
      "[0.6332377, 0.2, 0.2095267, 0.20225058]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 780 iterations: 0.32094061374664307 mins\n",
      "Train Loss: [0.6332377, 0.2, 0.2095267, 0.20225058]\n",
      "[0.6294001, 0.2, 0.20589061, 0.20206632]\n",
      "[0.62878126, 0.2, 0.20366706, 0.20368838]\n",
      "[0.635496, 0.2, 0.21149679, 0.2025907]\n",
      "[0.63902587, 0.2, 0.21464767, 0.20298682]\n",
      "[0.6438482, 0.2, 0.2178553, 0.20461836]\n",
      "[0.63549864, 0.2, 0.21031612, 0.2038249]\n",
      "[0.63286203, 0.2, 0.20879166, 0.20272936]\n",
      "[0.6296937, 0.2, 0.20168222, 0.20668711]\n",
      "[0.7001721, 0.2, 0.21084437, 0.26801997]\n",
      "[0.64132816, 0.2, 0.21798486, 0.20205155]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 790 iterations: 0.32287301619847614 mins\n",
      "Train Loss: [0.64132816, 0.2, 0.21798486, 0.20205155]\n",
      "[0.6338186, 0.2, 0.20380992, 0.20873235]\n",
      "[0.63056386, 0.2, 0.20531777, 0.20398527]\n",
      "[0.6423166, 0.2, 0.21570328, 0.20536774]\n",
      "[0.6349554, 0.2, 0.20997109, 0.20375423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6439478, 0.2, 0.2184235, 0.20430958]\n",
      "[0.64095354, 0.2, 0.21121602, 0.20853804]\n",
      "[0.64118785, 0.2, 0.2136998, 0.20630394]\n",
      "[0.6428028, 0.2, 0.21851774, 0.20311606]\n",
      "[0.62668264, 0.2, 0.20285143, 0.20267734]\n",
      "[0.6367379, 0.2, 0.21248274, 0.20311648]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 800 iterations: 0.3250646988550822 mins\n",
      "Train Loss: [0.6367379, 0.2, 0.21248274, 0.20311648]\n",
      "[0.6262817, 0.2, 0.20375015, 0.2014084]\n",
      "[0.63502795, 0.2, 0.21066166, 0.20325893]\n",
      "[0.6320311, 0.2, 0.20738587, 0.2035536]\n",
      "[0.6403738, 0.2, 0.21374522, 0.20555286]\n",
      "[0.65649325, 0.2, 0.23443718, 0.20099588]\n",
      "[0.63417244, 0.2, 0.20974453, 0.20338449]\n",
      "[0.6296684, 0.2, 0.20434631, 0.20429514]\n",
      "[0.62691593, 0.2, 0.20334491, 0.20256026]\n",
      "[0.6262366, 0.2, 0.20252942, 0.2027125]\n",
      "[0.65098375, 0.2, 0.226981, 0.20302412]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 810 iterations: 0.32708326578140257 mins\n",
      "Train Loss: [0.65098375, 0.2, 0.226981, 0.20302412]\n",
      "[0.6304683, 0.2, 0.2069645, 0.20254178]\n",
      "[0.6350126, 0.2, 0.21086136, 0.2032056]\n",
      "[0.6303199, 0.2, 0.20571803, 0.20367225]\n",
      "[0.6273566, 0.2, 0.20408346, 0.20235948]\n",
      "[0.63591814, 0.2, 0.21050379, 0.20451696]\n",
      "[0.62988687, 0.2, 0.20535807, 0.20364745]\n",
      "[0.63470536, 0.2, 0.21117081, 0.20266925]\n",
      "[0.64880675, 0.2, 0.22507891, 0.20287885]\n",
      "[0.6728412, 0.2, 0.21109772, 0.24091034]\n",
      "[0.7248106, 0.2, 0.3003122, 0.20368049]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 820 iterations: 0.3292993823687235 mins\n",
      "Train Loss: [0.7248106, 0.2, 0.3003122, 0.20368049]\n",
      "[0.6305966, 0.2, 0.2059707, 0.20381922]\n",
      "[0.627978, 0.2, 0.20305839, 0.20412448]\n",
      "[0.64063025, 0.2, 0.21588326, 0.20396355]\n",
      "[0.63621175, 0.2, 0.21080466, 0.20463523]\n",
      "[0.64870006, 0.2, 0.22435816, 0.20358168]\n",
      "[0.63821745, 0.2, 0.21633513, 0.20113385]\n",
      "[0.62328804, 0.2, 0.20105375, 0.20149788]\n",
      "[0.63028073, 0.2, 0.20690875, 0.20264809]\n",
      "[0.63843685, 0.2, 0.21569413, 0.20203163]\n",
      "[0.65398806, 0.2, 0.20874679, 0.22454317]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 830 iterations: 0.33244523604710896 mins\n",
      "Train Loss: [0.65398806, 0.2, 0.20874679, 0.22454317]\n",
      "[0.6304119, 0.2, 0.20844492, 0.20128219]\n",
      "[0.6316329, 0.2, 0.20808427, 0.20287742]\n",
      "[0.64222324, 0.2, 0.2182615, 0.20330398]\n",
      "[0.64757115, 0.2, 0.22464646, 0.20228098]\n",
      "[0.6257991, 0.2, 0.20244554, 0.20272456]\n",
      "[0.6248186, 0.2, 0.20216148, 0.20204209]\n",
      "[0.6292466, 0.2, 0.20316288, 0.20548253]\n",
      "[0.6290253, 0.2, 0.20491995, 0.20351787]\n",
      "[0.6266544, 0.2, 0.20325871, 0.20282225]\n",
      "[0.6389405, 0.2, 0.21595107, 0.20242992]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 840 iterations: 0.3353142182032267 mins\n",
      "Train Loss: [0.6389405, 0.2, 0.21595107, 0.20242992]\n",
      "[0.63394874, 0.2, 0.20923279, 0.20417032]\n",
      "[0.6392349, 0.2, 0.21421084, 0.20449227]\n",
      "[0.62473345, 0.2, 0.20212594, 0.2020897]\n",
      "[0.63153374, 0.2, 0.20519319, 0.20583698]\n",
      "[0.63749814, 0.2, 0.21403386, 0.20297499]\n",
      "[0.67443734, 0.2, 0.22446807, 0.22949456]\n",
      "[0.64204717, 0.2, 0.21763356, 0.20395282]\n",
      "[0.6354594, 0.2, 0.21320283, 0.20180942]\n",
      "[0.6516539, 0.2, 0.22494142, 0.20627894]\n",
      "[0.6378597, 0.2, 0.21589905, 0.20154038]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 850 iterations: 0.33852373361587523 mins\n",
      "Train Loss: [0.6378597, 0.2, 0.21589905, 0.20154038]\n",
      "[0.63970524, 0.2, 0.21447095, 0.20482834]\n",
      "[0.64264613, 0.2, 0.21972585, 0.20252828]\n",
      "[0.62539846, 0.2, 0.20305543, 0.20196523]\n",
      "[0.62804323, 0.2, 0.2036916, 0.20398805]\n",
      "[0.6261921, 0.2, 0.20341146, 0.20243119]\n",
      "[0.6366642, 0.2, 0.21389744, 0.20243156]\n",
      "[0.6254046, 0.2, 0.20346159, 0.2016221]\n",
      "[0.65366066, 0.2, 0.23006958, 0.20328468]\n",
      "[0.6351676, 0.2, 0.21233247, 0.20254342]\n",
      "[0.66888976, 0.2, 0.2158152, 0.2327975]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 860 iterations: 0.34130223194758097 mins\n",
      "Train Loss: [0.66888976, 0.2, 0.2158152, 0.2327975]\n",
      "[0.6455354, 0.2, 0.2229628, 0.20230961]\n",
      "[0.6373459, 0.2, 0.21185547, 0.20524119]\n",
      "[0.6469237, 0.2, 0.22049926, 0.2061892]\n",
      "[0.63337326, 0.2, 0.20909983, 0.20405185]\n",
      "[0.6346957, 0.2, 0.21166044, 0.20282733]\n",
      "[0.6381897, 0.2, 0.21357314, 0.2044222]\n",
      "[0.6289072, 0.2, 0.20573424, 0.20299207]\n",
      "[0.6314316, 0.2, 0.20876795, 0.20249613]\n",
      "[0.63152343, 0.2, 0.20839775, 0.20297137]\n",
      "[0.6324174, 0.2, 0.20625249, 0.20602381]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 870 iterations: 0.34512396653493244 mins\n",
      "Train Loss: [0.6324174, 0.2, 0.20625249, 0.20602381]\n",
      "[0.6332067, 0.2, 0.20722643, 0.20585226]\n",
      "[0.632428, 0.2, 0.20801227, 0.20430082]\n",
      "[0.62473863, 0.2, 0.20313975, 0.201497]\n",
      "[0.6376697, 0.2, 0.21536699, 0.20221403]\n",
      "[0.64020896, 0.2, 0.21748333, 0.20265016]\n",
      "[0.6459271, 0.2, 0.22190578, 0.20395921]\n",
      "[0.65386266, 0.2, 0.23070587, 0.20310806]\n",
      "[0.67817384, 0.2, 0.21934329, 0.2387951]\n",
      "[0.63661945, 0.2, 0.21411385, 0.20248626]\n",
      "[0.6281288, 0.2, 0.20605394, 0.20207083]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 880 iterations: 0.34968820015589397 mins\n",
      "Train Loss: [0.6281288, 0.2, 0.20605394, 0.20207083]\n",
      "[0.65120167, 0.2, 0.22621189, 0.20500058]\n",
      "[0.6304924, 0.2, 0.20488273, 0.20563467]\n",
      "[0.62864137, 0.2, 0.20559594, 0.20308438]\n",
      "[0.6278749, 0.2, 0.20663925, 0.20128861]\n",
      "[0.6302701, 0.2, 0.20588405, 0.20445323]\n",
      "[0.63546556, 0.2, 0.21323885, 0.20230791]\n",
      "[0.63185495, 0.2, 0.20895682, 0.20299333]\n",
      "[0.63270247, 0.2, 0.20870602, 0.20410593]\n",
      "[0.63531464, 0.2, 0.21290386, 0.20253432]\n",
      "[0.6331254, 0.2, 0.21027963, 0.2029833]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 890 iterations: 0.3530086318651835 mins\n",
      "Train Loss: [0.6331254, 0.2, 0.21027963, 0.2029833]\n",
      "[0.646133, 0.2, 0.22469759, 0.20158686]\n",
      "[0.63523954, 0.2, 0.21205053, 0.20335409]\n",
      "[0.6343586, 0.2, 0.2111337, 0.20340349]\n",
      "[0.63387465, 0.2, 0.21146436, 0.20260215]\n",
      "[0.6293231, 0.2, 0.20808403, 0.20144373]\n",
      "[0.62875193, 0.2, 0.20658767, 0.20238173]\n",
      "[0.63770604, 0.2, 0.21398875, 0.20394734]\n",
      "[0.63857734, 0.2, 0.21715297, 0.20166722]\n",
      "[0.6311387, 0.2, 0.20858555, 0.20280883]\n",
      "[0.62772983, 0.2, 0.20199366, 0.20600495]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 900 iterations: 0.35603833198547363 mins\n",
      "Train Loss: [0.62772983, 0.2, 0.20199366, 0.20600495]\n",
      "[0.6326017, 0.2, 0.20535389, 0.20752974]\n",
      "[0.6353526, 0.2, 0.21085984, 0.20478804]\n",
      "[0.62556964, 0.2, 0.20186482, 0.20401274]\n",
      "[0.6320845, 0.2, 0.20741357, 0.20499177]\n",
      "[0.63391507, 0.2, 0.21195966, 0.20228967]\n",
      "[0.6320175, 0.2, 0.20937417, 0.2029908]\n",
      "[0.62911487, 0.2, 0.2079492, 0.20152651]\n",
      "[0.6277714, 0.2, 0.20627475, 0.20187096]\n",
      "[0.6610139, 0.2, 0.21321973, 0.22818215]\n",
      "[0.63224626, 0.2, 0.21018584, 0.20246136]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 910 iterations: 0.3593078017234802 mins\n",
      "Train Loss: [0.63224626, 0.2, 0.21018584, 0.20246136]\n",
      "[0.64106935, 0.2, 0.21554591, 0.20593728]\n",
      "[0.62405056, 0.2, 0.20275691, 0.20172043]\n",
      "[0.6259057, 0.2, 0.20223898, 0.20410645]\n",
      "[0.64234567, 0.2, 0.2149965, 0.20780212]\n",
      "[0.6333772, 0.2, 0.21102819, 0.20281509]\n",
      "[0.6311784, 0.2, 0.20903534, 0.20262265]\n",
      "[0.6266464, 0.2, 0.20455104, 0.20258854]\n",
      "[0.6318355, 0.2, 0.2113135, 0.20102946]\n",
      "[0.6304902, 0.2, 0.20979948, 0.20121321]\n",
      "[0.63171256, 0.2, 0.2104589, 0.20179136]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 920 iterations: 0.3621442159016927 mins\n",
      "Train Loss: [0.63171256, 0.2, 0.2104589, 0.20179136]\n",
      "[0.6294696, 0.2, 0.20713629, 0.2028864]\n",
      "[0.6558046, 0.2, 0.20863596, 0.22773686]\n",
      "[0.6263505, 0.2, 0.20225152, 0.2046812]\n",
      "[0.62976515, 0.2, 0.20893891, 0.20142221]\n",
      "[0.624027, 0.2, 0.2018831, 0.20275344]\n",
      "[0.6260833, 0.2, 0.20601338, 0.20069298]\n",
      "[0.6372613, 0.2, 0.2157567, 0.20214143]\n",
      "[0.6432972, 0.2, 0.2185333, 0.20541467]\n",
      "[0.68299097, 0.2, 0.20736837, 0.25629038]\n",
      "[0.62772363, 0.2, 0.2067842, 0.20162079]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 930 iterations: 0.3649755358695984 mins\n",
      "Train Loss: [0.62772363, 0.2, 0.2067842, 0.20162079]\n",
      "[0.62494975, 0.2, 0.20426367, 0.20138048]\n",
      "[0.6247014, 0.2, 0.20345093, 0.2019575]\n",
      "[0.6285797, 0.2, 0.20627683, 0.20302229]\n",
      "[0.6364775, 0.2, 0.21512718, 0.20208186]\n",
      "[0.6280664, 0.2, 0.20640472, 0.20240556]\n",
      "[0.63150424, 0.2, 0.21014571, 0.20211476]\n",
      "[0.67114705, 0.2, 0.22869009, 0.2232255]\n",
      "[0.641841, 0.2, 0.22059721, 0.20202665]\n",
      "[0.63046026, 0.2, 0.21035011, 0.20090663]\n",
      "[0.6293307, 0.2, 0.20705543, 0.20308483]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 940 iterations: 0.3672087510426839 mins\n",
      "Train Loss: [0.6293307, 0.2, 0.20705543, 0.20308483]\n",
      "[0.6362399, 0.2, 0.21092859, 0.20613356]\n",
      "[0.6383339, 0.2, 0.2125774, 0.2065911]\n",
      "[0.63377166, 0.2, 0.20934221, 0.20527646]\n",
      "[0.6329943, 0.2, 0.20734882, 0.20650461]\n",
      "[0.6359504, 0.2, 0.21319897, 0.20362249]\n",
      "[0.6275684, 0.2, 0.20524079, 0.20321049]\n",
      "[0.6400933, 0.2, 0.21619986, 0.20478806]\n",
      "[0.63097197, 0.2, 0.2101368, 0.20174147]\n",
      "[0.62898856, 0.2, 0.20624983, 0.20365676]\n",
      "[0.63276666, 0.2, 0.21236908, 0.20132723]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 950 iterations: 0.3694844683011373 mins\n",
      "Train Loss: [0.63276666, 0.2, 0.21236908, 0.20132723]\n",
      "[0.6320037, 0.2, 0.20842896, 0.20451617]\n",
      "[0.62979573, 0.2, 0.208913, 0.20183586]\n",
      "[0.6860909, 0.2, 0.20606223, 0.26099375]\n",
      "[0.6309322, 0.2, 0.20918027, 0.20273218]\n",
      "[0.6496264, 0.2, 0.22869995, 0.20192112]\n",
      "[0.62539345, 0.2, 0.20374197, 0.20266013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6266286, 0.2, 0.20408508, 0.20356596]\n",
      "[0.63485706, 0.2, 0.21149199, 0.20440112]\n",
      "[0.65782434, 0.2, 0.23473203, 0.20414181]\n",
      "[0.6348045, 0.2, 0.20941772, 0.20644921]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 960 iterations: 0.3722790320714315 mins\n",
      "Train Loss: [0.6348045, 0.2, 0.20941772, 0.20644921]\n",
      "[0.6585184, 0.2, 0.21447688, 0.22511674]\n",
      "[0.64738166, 0.2, 0.22253226, 0.20593725]\n",
      "[0.62393004, 0.2, 0.2028537, 0.20217657]\n",
      "[0.6273235, 0.2, 0.20445974, 0.20397653]\n",
      "[0.6300175, 0.2, 0.20710213, 0.20404062]\n",
      "[0.6599506, 0.2, 0.20921935, 0.23186865]\n",
      "[0.63467103, 0.2, 0.21303885, 0.20278268]\n",
      "[0.64513373, 0.2, 0.22395043, 0.20234665]\n",
      "[0.6406206, 0.2, 0.21788657, 0.20390975]\n",
      "[0.6263615, 0.2, 0.20401642, 0.2035328]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 970 iterations: 0.3751255830128988 mins\n",
      "Train Loss: [0.6263615, 0.2, 0.20401642, 0.2035328]\n",
      "[0.6428429, 0.2, 0.21647075, 0.20757194]\n",
      "[0.626579, 0.2, 0.20308664, 0.20470329]\n",
      "[0.6318025, 0.2, 0.21135329, 0.20167133]\n",
      "[0.63962895, 0.2, 0.21657582, 0.20428646]\n",
      "[0.6399732, 0.2, 0.20175982, 0.21945778]\n",
      "[0.6363661, 0.2, 0.21301621, 0.20460449]\n",
      "[0.628898, 0.2, 0.20732363, 0.20283899]\n",
      "[0.62892836, 0.2, 0.2076369, 0.20256634]\n",
      "[0.6339771, 0.2, 0.21306956, 0.20219299]\n",
      "[0.6382482, 0.2, 0.21703695, 0.20250751]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 980 iterations: 0.3771410663922628 mins\n",
      "Train Loss: [0.6382482, 0.2, 0.21703695, 0.20250751]\n",
      "[0.6272521, 0.2, 0.20577176, 0.20278771]\n",
      "[0.63834745, 0.2, 0.21520557, 0.20446062]\n",
      "[0.6312916, 0.2, 0.20966466, 0.20295733]\n",
      "[0.64137936, 0.2, 0.22084628, 0.20187522]\n",
      "[0.63389885, 0.2, 0.20981234, 0.20544055]\n",
      "[0.6428165, 0.2, 0.2216654, 0.20251682]\n",
      "[0.6944948, 0.2, 0.21510446, 0.26076758]\n",
      "[0.62582624, 0.2, 0.20187041, 0.2053453]\n",
      "[0.6395181, 0.2, 0.2181502, 0.20276977]\n",
      "[0.6297535, 0.2, 0.20349018, 0.20767727]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 990 iterations: 0.379407266775767 mins\n",
      "Train Loss: [0.6297535, 0.2, 0.20349018, 0.20767727]\n",
      "[0.67952496, 0.2, 0.25832385, 0.20262718]\n",
      "[0.6296648, 0.2, 0.2045779, 0.20652694]\n",
      "[0.6332143, 0.2, 0.21323813, 0.2014298]\n",
      "[0.629562, 0.2, 0.20905395, 0.20197497]\n",
      "[0.6276621, 0.2, 0.20712112, 0.20202073]\n",
      "[0.6320736, 0.2, 0.21212178, 0.20144431]\n",
      "[0.62789774, 0.2, 0.20833755, 0.20106542]\n",
      "[0.6331069, 0.2, 0.21347578, 0.20114891]\n",
      "[0.63569665, 0.2, 0.21345858, 0.20376836]\n",
      "[0.6314849, 0.2, 0.20865427, 0.20437309]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1000 iterations: 0.38216014703114826 mins\n",
      "Train Loss: [0.6314849, 0.2, 0.20865427, 0.20437309]\n",
      "[0.65967304, 0.2, 0.20623478, 0.23499258]\n",
      "[0.63306534, 0.2, 0.2116477, 0.20298408]\n",
      "[0.6272026, 0.2, 0.20688647, 0.20189115]\n",
      "[0.6227463, 0.2, 0.20289643, 0.20143162]\n",
      "[0.63448024, 0.2, 0.20912743, 0.20693995]\n",
      "[0.63044506, 0.2, 0.20733742, 0.20469989]\n",
      "[0.6278331, 0.2, 0.20703213, 0.20239843]\n",
      "[0.6257482, 0.2, 0.20550172, 0.2018497]\n",
      "[0.62537515, 0.2, 0.20554829, 0.20143664]\n",
      "[0.62831074, 0.2, 0.20645092, 0.20347738]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1010 iterations: 0.38416924873987834 mins\n",
      "Train Loss: [0.62831074, 0.2, 0.20645092, 0.20347738]\n",
      "[0.6456743, 0.2, 0.22342509, 0.20387553]\n",
      "[0.62734157, 0.2, 0.20575543, 0.20322205]\n",
      "[0.6254921, 0.2, 0.20634739, 0.20079133]\n",
      "[0.6257758, 0.2, 0.2053363, 0.20209777]\n",
      "[0.6295133, 0.2, 0.20816486, 0.20301968]\n",
      "[0.622313, 0.2, 0.20232254, 0.20167533]\n",
      "[0.6290644, 0.2, 0.20977682, 0.20098667]\n",
      "[0.6717189, 0.2, 0.24961363, 0.20381926]\n",
      "[0.62272054, 0.2, 0.20134689, 0.2031016]\n",
      "[0.6214494, 0.2, 0.20035131, 0.20284015]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1020 iterations: 0.386221182346344 mins\n",
      "Train Loss: [0.6214494, 0.2, 0.20035131, 0.20284015]\n",
      "[0.6331965, 0.2, 0.21123683, 0.20371582]\n",
      "[0.62898463, 0.2, 0.20958576, 0.20116909]\n",
      "[0.63024676, 0.2, 0.2097366, 0.20229478]\n",
      "[0.6364268, 0.2, 0.21606565, 0.2021602]\n",
      "[0.63162035, 0.2, 0.209182, 0.20425196]\n",
      "[0.6300443, 0.2, 0.20981105, 0.20206113]\n",
      "[0.63693035, 0.2, 0.21358244, 0.20518982]\n",
      "[0.62682855, 0.2, 0.20587274, 0.20281143]\n",
      "[0.6248039, 0.2, 0.2034138, 0.20325905]\n",
      "[0.62360895, 0.2, 0.20422146, 0.20126969]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1030 iterations: 0.3881888151168823 mins\n",
      "Train Loss: [0.62360895, 0.2, 0.20422146, 0.20126969]\n",
      "[0.62770444, 0.2, 0.20716642, 0.2024333]\n",
      "[0.6278813, 0.2, 0.20756152, 0.2022282]\n",
      "[0.6245189, 0.2, 0.20331135, 0.20312902]\n",
      "[0.6239973, 0.2, 0.20517457, 0.20075747]\n",
      "[0.6275147, 0.2, 0.207983, 0.20147966]\n",
      "[0.62044793, 0.2, 0.20083895, 0.20157018]\n",
      "[0.63284576, 0.2, 0.2123452, 0.2024752]\n",
      "[0.6295786, 0.2, 0.20723931, 0.20432712]\n",
      "[0.624001, 0.2, 0.20303509, 0.20296665]\n",
      "[0.622129, 0.2, 0.20242572, 0.20171653]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1040 iterations: 0.3902476986249288 mins\n",
      "Train Loss: [0.622129, 0.2, 0.20242572, 0.20171653]\n",
      "[0.6366566, 0.2, 0.20906122, 0.20962141]\n",
      "[0.64524055, 0.2, 0.22319123, 0.20408788]\n",
      "[0.6265464, 0.2, 0.20643848, 0.20215873]\n",
      "[0.64397496, 0.2, 0.20695585, 0.21908222]\n",
      "[0.6224971, 0.2, 0.20203885, 0.20253326]\n",
      "[0.66959995, 0.2, 0.25025848, 0.20142862]\n",
      "[0.65880466, 0.2, 0.1997515, 0.24115224]\n",
      "[0.6248427, 0.2, 0.20210506, 0.20484832]\n",
      "[0.6344131, 0.2, 0.21403731, 0.20249791]\n",
      "[0.6272169, 0.2, 0.20667587, 0.20267464]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1050 iterations: 0.39220279852549234 mins\n",
      "Train Loss: [0.6272169, 0.2, 0.20667587, 0.20267464]\n",
      "[0.62405396, 0.2, 0.20300813, 0.20319113]\n",
      "[0.6397958, 0.2, 0.21922573, 0.20272699]\n",
      "[0.62188244, 0.2, 0.20277035, 0.20128047]\n",
      "[0.62744063, 0.2, 0.20846009, 0.20116037]\n",
      "[0.6249872, 0.2, 0.20339724, 0.20378119]\n",
      "[0.65420854, 0.2, 0.23458564, 0.20182562]\n",
      "[0.6235938, 0.2, 0.2051115, 0.20069627]\n",
      "[0.6337593, 0.2, 0.21320555, 0.20277922]\n",
      "[0.63583255, 0.2, 0.21706006, 0.2010094]\n",
      "[0.6361456, 0.2, 0.21571863, 0.2026756]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1060 iterations: 0.39438464641571047 mins\n",
      "Train Loss: [0.6361456, 0.2, 0.21571863, 0.2026756]\n",
      "[0.63523084, 0.2, 0.21423371, 0.20325756]\n",
      "[0.62251455, 0.2, 0.20131059, 0.20347613]\n",
      "[0.6196365, 0.2, 0.20131771, 0.2006029]\n",
      "[0.62414354, 0.2, 0.20231214, 0.20412764]\n",
      "[0.672436, 0.2, 0.25232795, 0.20241694]\n",
      "[0.6204906, 0.2, 0.20157146, 0.20124194]\n",
      "[0.63397753, 0.2, 0.21459247, 0.20172139]\n",
      "[0.64218503, 0.2, 0.20673211, 0.21780257]\n",
      "[0.63604766, 0.2, 0.21590044, 0.20251006]\n",
      "[0.6361187, 0.2, 0.21386991, 0.2046242]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1070 iterations: 0.39890324672063193 mins\n",
      "Train Loss: [0.6361187, 0.2, 0.21386991, 0.2046242]\n",
      "[0.6251861, 0.2, 0.20474656, 0.20282717]\n",
      "[0.6335338, 0.2, 0.21303761, 0.20289575]\n",
      "[0.63284916, 0.2, 0.21395482, 0.20130548]\n",
      "[0.62679034, 0.2, 0.2045843, 0.20462856]\n",
      "[0.6248018, 0.2, 0.20592038, 0.20131527]\n",
      "[0.62927216, 0.2, 0.20730582, 0.20441146]\n",
      "[0.6257859, 0.2, 0.20353793, 0.20470396]\n",
      "[0.6281108, 0.2, 0.20573494, 0.204843]\n",
      "[0.6278067, 0.2, 0.20679605, 0.20348859]\n",
      "[0.64843994, 0.2, 0.22645429, 0.20447432]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1080 iterations: 0.40097766717274985 mins\n",
      "Train Loss: [0.64843994, 0.2, 0.22645429, 0.20447432]\n",
      "[0.6445207, 0.2, 0.22456646, 0.20245345]\n",
      "[0.636033, 0.2, 0.21441436, 0.20412846]\n",
      "[0.62726593, 0.2, 0.20830862, 0.20147742]\n",
      "[0.62842214, 0.2, 0.20600145, 0.20495099]\n",
      "[0.62764734, 0.2, 0.20740165, 0.20278612]\n",
      "[0.6327661, 0.2, 0.21185061, 0.20346616]\n",
      "[0.6347886, 0.2, 0.21299328, 0.20435646]\n",
      "[0.6300686, 0.2, 0.20944627, 0.20319423]\n",
      "[0.6288624, 0.2, 0.20906125, 0.20238397]\n",
      "[0.63348436, 0.2, 0.21516714, 0.20091079]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1090 iterations: 0.40428573290506997 mins\n",
      "Train Loss: [0.63348436, 0.2, 0.21516714, 0.20091079]\n",
      "[0.62313455, 0.2, 0.2038466, 0.20189212]\n",
      "[0.65386695, 0.2, 0.20829174, 0.2281903]\n",
      "[0.6312134, 0.2, 0.21193336, 0.20190528]\n",
      "[0.6290672, 0.2, 0.20860574, 0.2030968]\n",
      "[0.62828326, 0.2, 0.20825534, 0.2026735]\n",
      "[0.6273472, 0.2, 0.20630443, 0.2036978]\n",
      "[0.6583097, 0.2, 0.23700203, 0.20397225]\n",
      "[0.629065, 0.2, 0.20861559, 0.20312284]\n",
      "[0.6358833, 0.2, 0.21501777, 0.20354779]\n",
      "[0.6197835, 0.2, 0.20129094, 0.20118392]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1100 iterations: 0.4073309977849325 mins\n",
      "Train Loss: [0.6197835, 0.2, 0.20129094, 0.20118392]\n",
      "[0.6322782, 0.2, 0.2128083, 0.2021705]\n",
      "[0.6355804, 0.2, 0.21243696, 0.20585357]\n",
      "[0.6323265, 0.2, 0.21018401, 0.20486224]\n",
      "[0.6321598, 0.2, 0.21032473, 0.20456466]\n",
      "[0.6330608, 0.2, 0.21258222, 0.20321813]\n",
      "[0.6388248, 0.2, 0.21804002, 0.2035343]\n",
      "[0.6261634, 0.2, 0.20589621, 0.20302644]\n",
      "[0.64388627, 0.2, 0.22098342, 0.20567194]\n",
      "[0.66791314, 0.2, 0.2085381, 0.24215417]\n",
      "[0.62737507, 0.2, 0.203973, 0.20619078]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1110 iterations: 0.4114290356636047 mins\n",
      "Train Loss: [0.62737507, 0.2, 0.203973, 0.20619078]\n",
      "[0.6290182, 0.2, 0.20442514, 0.20739119]\n",
      "[0.6224798, 0.2, 0.2028005, 0.20248699]\n",
      "[0.6283887, 0.2, 0.20626654, 0.20493965]\n",
      "[0.63337016, 0.2, 0.21291816, 0.20327938]\n",
      "[0.68837446, 0.2, 0.26906344, 0.2021485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6258728, 0.2, 0.20652595, 0.20219317]\n",
      "[0.63240135, 0.2, 0.2106733, 0.20458338]\n",
      "[0.62427926, 0.2, 0.2028099, 0.20433381]\n",
      "[0.6551752, 0.2, 0.2293895, 0.20865978]\n",
      "[0.6381166, 0.2, 0.2149257, 0.20607255]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1120 iterations: 0.41563348372777303 mins\n",
      "Train Loss: [0.6381166, 0.2, 0.2149257, 0.20607255]\n",
      "[0.6321769, 0.2, 0.20889607, 0.20617041]\n",
      "[0.6276914, 0.2, 0.20749633, 0.20309241]\n",
      "[0.6244196, 0.2, 0.2027122, 0.20461233]\n",
      "[0.65376705, 0.2, 0.22758126, 0.20909822]\n",
      "[0.64252853, 0.2, 0.22298068, 0.20246767]\n",
      "[0.621437, 0.2, 0.20200785, 0.20235634]\n",
      "[0.63131213, 0.2, 0.21091838, 0.20332865]\n",
      "[0.66352254, 0.2, 0.21075852, 0.23570666]\n",
      "[0.6274737, 0.2, 0.2089268, 0.20149693]\n",
      "[0.6301822, 0.2, 0.2092183, 0.2039212]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1130 iterations: 0.4191747665405273 mins\n",
      "Train Loss: [0.6301822, 0.2, 0.2092183, 0.2039212]\n",
      "[0.62490803, 0.2, 0.20612371, 0.20174876]\n",
      "[0.62093854, 0.2, 0.20245278, 0.2014575]\n",
      "[0.62736505, 0.2, 0.20777984, 0.20256451]\n",
      "[0.625073, 0.2, 0.20619935, 0.20186086]\n",
      "[0.6293691, 0.2, 0.21076088, 0.20160356]\n",
      "[0.62589955, 0.2, 0.2063466, 0.20255688]\n",
      "[0.63624996, 0.2, 0.21516764, 0.2040952]\n",
      "[0.6218811, 0.2, 0.20168535, 0.2032172]\n",
      "[0.62655896, 0.2, 0.20820223, 0.20138684]\n",
      "[0.6332543, 0.2, 0.21014675, 0.20614634]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1140 iterations: 0.42338866790135704 mins\n",
      "Train Loss: [0.6332543, 0.2, 0.21014675, 0.20614634]\n",
      "[0.6241014, 0.2, 0.20581678, 0.2013337]\n",
      "[0.6851655, 0.2, 0.21182562, 0.25639883]\n",
      "[0.6291589, 0.2, 0.21001114, 0.20221525]\n",
      "[0.63611656, 0.2, 0.21593657, 0.2032558]\n",
      "[0.6559053, 0.2, 0.2088697, 0.23011974]\n",
      "[0.6276643, 0.2, 0.20900689, 0.20174924]\n",
      "[0.63994765, 0.2, 0.22161588, 0.20143132]\n",
      "[0.62779355, 0.2, 0.2073365, 0.20356487]\n",
      "[0.6503625, 0.2, 0.20468847, 0.2287901]\n",
      "[0.6394143, 0.2, 0.22119935, 0.2013389]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1150 iterations: 0.4274108648300171 mins\n",
      "Train Loss: [0.6394143, 0.2, 0.22119935, 0.2013389]\n",
      "[0.6480984, 0.2, 0.20715699, 0.22407366]\n",
      "[0.66332436, 0.2, 0.20699097, 0.23947316]\n",
      "[0.62668014, 0.2, 0.20729093, 0.2025364]\n",
      "[0.6302463, 0.2, 0.21228392, 0.20111714]\n",
      "[0.6221329, 0.2, 0.20293017, 0.20236549]\n",
      "[0.6521458, 0.2, 0.20881654, 0.22650008]\n",
      "[0.63349646, 0.2, 0.20927353, 0.20740162]\n",
      "[0.6274214, 0.2, 0.2079594, 0.20264877]\n",
      "[0.63719374, 0.2, 0.21790034, 0.2024884]\n",
      "[0.6254365, 0.2, 0.20730424, 0.20133568]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1160 iterations: 0.4301637331644694 mins\n",
      "Train Loss: [0.6254365, 0.2, 0.20730424, 0.20133568]\n",
      "[0.6652963, 0.2, 0.21391697, 0.23459134]\n",
      "[0.6580672, 0.2, 0.21621247, 0.2250754]\n",
      "[0.6369151, 0.2, 0.20563304, 0.2145113]\n",
      "[0.6216978, 0.2, 0.20326266, 0.20167327]\n",
      "[0.6265485, 0.2, 0.20873548, 0.20106007]\n",
      "[0.6290982, 0.2, 0.20926355, 0.20309062]\n",
      "[0.6313138, 0.2, 0.20683512, 0.20774344]\n",
      "[0.6229462, 0.2, 0.20257372, 0.20364588]\n",
      "[0.6276211, 0.2, 0.20398986, 0.20691346]\n",
      "[0.6264736, 0.2, 0.20814489, 0.20161979]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1170 iterations: 0.43262831767400106 mins\n",
      "Train Loss: [0.6264736, 0.2, 0.20814489, 0.20161979]\n",
      "[0.6231781, 0.2, 0.2039511, 0.20252723]\n",
      "[0.62857366, 0.2, 0.20884608, 0.20303716]\n",
      "[0.6288435, 0.2, 0.2091862, 0.20297661]\n",
      "[0.6196173, 0.2, 0.2015082, 0.20143858]\n",
      "[0.626003, 0.2, 0.20753352, 0.20180926]\n",
      "[0.62836987, 0.2, 0.2098341, 0.2018862]\n",
      "[0.6219064, 0.2, 0.20387036, 0.2013972]\n",
      "[0.6327928, 0.2, 0.21315028, 0.20301452]\n",
      "[0.638131, 0.2, 0.21585813, 0.20565583]\n",
      "[0.6402397, 0.2, 0.21461926, 0.20901427]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1180 iterations: 0.43551303148269654 mins\n",
      "Train Loss: [0.6402397, 0.2, 0.21461926, 0.20901427]\n",
      "[0.6377571, 0.2, 0.21726456, 0.20389688]\n",
      "[0.62375194, 0.2, 0.20472844, 0.20243852]\n",
      "[0.6345611, 0.2, 0.21501207, 0.20297475]\n",
      "[0.6267274, 0.2, 0.20759499, 0.20256862]\n",
      "[0.6365611, 0.2, 0.2133627, 0.20664528]\n",
      "[0.6321887, 0.2, 0.21129856, 0.20434763]\n",
      "[0.6339783, 0.2, 0.21585064, 0.20159581]\n",
      "[0.6323589, 0.2, 0.21158242, 0.20425542]\n",
      "[0.63652796, 0.2, 0.21592602, 0.20409113]\n",
      "[0.6359971, 0.2, 0.21425486, 0.20524159]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1190 iterations: 0.4387166857719421 mins\n",
      "Train Loss: [0.6359971, 0.2, 0.21425486, 0.20524159]\n",
      "[0.6354471, 0.2, 0.21380062, 0.20515598]\n",
      "[0.63463634, 0.2, 0.21421902, 0.20393671]\n",
      "[0.64211226, 0.2, 0.20430261, 0.22133853]\n",
      "[0.6271968, 0.2, 0.20882675, 0.20190808]\n",
      "[0.62575924, 0.2, 0.20698869, 0.2023178]\n",
      "[0.6731465, 0.2, 0.2536974, 0.2030054]\n",
      "[0.64077526, 0.2, 0.22336543, 0.2009732]\n",
      "[0.6744072, 0.2, 0.2550315, 0.20294586]\n",
      "[0.62368006, 0.2, 0.20286034, 0.20439467]\n",
      "[0.6241372, 0.2, 0.20361628, 0.2041009]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1200 iterations: 0.4417836666107178 mins\n",
      "Train Loss: [0.6241372, 0.2, 0.20361628, 0.2041009]\n",
      "[0.6323663, 0.2, 0.21136004, 0.20459142]\n",
      "[0.6239519, 0.2, 0.2050145, 0.20252793]\n",
      "[0.63167644, 0.2, 0.21394664, 0.2013262]\n",
      "[0.6276412, 0.2, 0.20808458, 0.20315948]\n",
      "[0.6276992, 0.2, 0.20835218, 0.20295678]\n",
      "[0.628935, 0.2, 0.21084914, 0.20170303]\n",
      "[0.6468706, 0.2, 0.20941593, 0.22108065]\n",
      "[0.630193, 0.2, 0.21185581, 0.20197178]\n",
      "[0.6354426, 0.2, 0.21578822, 0.2032972]\n",
      "[0.6225956, 0.2, 0.20444068, 0.2018057]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1210 iterations: 0.44479968150456745 mins\n",
      "Train Loss: [0.6225956, 0.2, 0.20444068, 0.2018057]\n",
      "[0.6875957, 0.2, 0.2689649, 0.20228961]\n",
      "[0.63820595, 0.2, 0.21939483, 0.2024776]\n",
      "[0.62267786, 0.2, 0.20553747, 0.20081493]\n",
      "[0.6247045, 0.2, 0.20694716, 0.20144011]\n",
      "[0.62331176, 0.2, 0.20571254, 0.20129067]\n",
      "[0.632418, 0.2, 0.21486521, 0.20125367]\n",
      "[0.6310033, 0.2, 0.21269432, 0.20201951]\n",
      "[0.6333029, 0.2, 0.2156756, 0.20134747]\n",
      "[0.6299246, 0.2, 0.21004996, 0.20360442]\n",
      "[0.63193643, 0.2, 0.2125054, 0.20317073]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1220 iterations: 0.44869949817657473 mins\n",
      "Train Loss: [0.63193643, 0.2, 0.2125054, 0.20317073]\n",
      "[0.6735642, 0.2, 0.21440117, 0.24291267]\n",
      "[0.6203808, 0.2, 0.20194672, 0.20219348]\n",
      "[0.6249879, 0.2, 0.20824279, 0.20051417]\n",
      "[0.63476866, 0.2, 0.21409002, 0.20445727]\n",
      "[0.6368848, 0.2, 0.21771486, 0.2029582]\n",
      "[0.6345101, 0.2, 0.21398896, 0.20431845]\n",
      "[0.6244586, 0.2, 0.20604958, 0.20221539]\n",
      "[0.6241144, 0.2, 0.20345408, 0.20447583]\n",
      "[0.6289344, 0.2, 0.210881, 0.20187868]\n",
      "[0.62895375, 0.2, 0.20994477, 0.20284374]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1230 iterations: 0.45185873508453367 mins\n",
      "Train Loss: [0.62895375, 0.2, 0.20994477, 0.20284374]\n",
      "[0.63024855, 0.2, 0.20805885, 0.20603347]\n",
      "[0.6258349, 0.2, 0.20809989, 0.20158793]\n",
      "[0.62884957, 0.2, 0.20946994, 0.20324178]\n",
      "[0.6290814, 0.2, 0.20809425, 0.20485838]\n",
      "[0.62926155, 0.2, 0.21104275, 0.20209913]\n",
      "[0.6261747, 0.2, 0.20696273, 0.20310123]\n",
      "[0.6266663, 0.2, 0.20504929, 0.205515]\n",
      "[0.62620485, 0.2, 0.20359185, 0.20652004]\n",
      "[0.6244101, 0.2, 0.20605552, 0.20227087]\n",
      "[0.6217908, 0.2, 0.20298538, 0.20273115]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1240 iterations: 0.45483988523483276 mins\n",
      "Train Loss: [0.6217908, 0.2, 0.20298538, 0.20273115]\n",
      "[0.62102413, 0.2, 0.2029364, 0.20202294]\n",
      "[0.6231963, 0.2, 0.20405689, 0.20308463]\n",
      "[0.62019527, 0.2, 0.20297503, 0.20117536]\n",
      "[0.63656396, 0.2, 0.21361925, 0.20690963]\n",
      "[0.6286786, 0.2, 0.20868383, 0.20397009]\n",
      "[0.62695396, 0.2, 0.20905727, 0.20188259]\n",
      "[0.62750113, 0.2, 0.20802568, 0.203472]\n",
      "[0.6237446, 0.2, 0.20438191, 0.20337029]\n",
      "[0.6298318, 0.2, 0.21028832, 0.20356171]\n",
      "[0.6186011, 0.2, 0.20131774, 0.20131241]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1250 iterations: 0.4576034982999166 mins\n",
      "Train Loss: [0.6186011, 0.2, 0.20131774, 0.20131241]\n",
      "[0.6222164, 0.2, 0.20457098, 0.20168518]\n",
      "[0.6262604, 0.2, 0.2063883, 0.20392302]\n",
      "[0.62737167, 0.2, 0.2080451, 0.20338832]\n",
      "[0.6264193, 0.2, 0.20790218, 0.20258972]\n",
      "[0.6260376, 0.2, 0.2037704, 0.20635097]\n",
      "[0.63203335, 0.2, 0.21131223, 0.20481573]\n",
      "[0.6339716, 0.2, 0.2143982, 0.20367871]\n",
      "[0.62395924, 0.2, 0.20684336, 0.20123172]\n",
      "[0.62410486, 0.2, 0.20564356, 0.20258793]\n",
      "[0.61876744, 0.2, 0.20096274, 0.20194222]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1260 iterations: 0.4604413628578186 mins\n",
      "Train Loss: [0.61876744, 0.2, 0.20096274, 0.20194222]\n",
      "[0.6352396, 0.2, 0.21681625, 0.20257191]\n",
      "[0.620539, 0.2, 0.20167795, 0.20302065]\n",
      "[0.62595594, 0.2, 0.20851803, 0.20160845]\n",
      "[0.6215521, 0.2, 0.2037697, 0.2019645]\n",
      "[0.6231588, 0.2, 0.20509797, 0.20225458]\n",
      "[0.634623, 0.2, 0.21430044, 0.20452788]\n",
      "[0.6212458, 0.2, 0.20382832, 0.20163411]\n",
      "[0.6259522, 0.2, 0.20661765, 0.2035625]\n",
      "[0.6287837, 0.2, 0.21174054, 0.2012826]\n",
      "[0.62354076, 0.2, 0.20624244, 0.201549]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1270 iterations: 0.4638292153676351 mins\n",
      "Train Loss: [0.62354076, 0.2, 0.20624244, 0.201549]\n",
      "[0.62400466, 0.2, 0.20649318, 0.20177354]\n",
      "[0.6290894, 0.2, 0.20944518, 0.20391738]\n",
      "[0.6274171, 0.2, 0.21004291, 0.20165819]\n",
      "[0.6245672, 0.2, 0.20611212, 0.20274942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62673753, 0.2, 0.20889929, 0.20214286]\n",
      "[0.62617993, 0.2, 0.20949867, 0.20099601]\n",
      "[0.62753505, 0.2, 0.2109171, 0.20094262]\n",
      "[0.6431785, 0.2, 0.22400613, 0.20350744]\n",
      "[0.62233156, 0.2, 0.20497485, 0.20170148]\n",
      "[0.6293278, 0.2, 0.21091036, 0.20277253]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1280 iterations: 0.46804479757944745 mins\n",
      "Train Loss: [0.6293278, 0.2, 0.21091036, 0.20277253]\n",
      "[0.6240835, 0.2, 0.20577115, 0.2026775]\n",
      "[0.62594056, 0.2, 0.20694853, 0.20336749]\n",
      "[0.62062347, 0.2, 0.20403105, 0.20097822]\n",
      "[0.6275619, 0.2, 0.21134903, 0.2006088]\n",
      "[0.62264353, 0.2, 0.20518366, 0.20186599]\n",
      "[0.62531537, 0.2, 0.20713621, 0.20259586]\n",
      "[0.6361311, 0.2, 0.21738137, 0.20317711]\n",
      "[0.62786335, 0.2, 0.2093615, 0.20294012]\n",
      "[0.61975634, 0.2, 0.20216353, 0.20204179]\n",
      "[0.62833256, 0.2, 0.21083173, 0.2019603]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1290 iterations: 0.47093343337376914 mins\n",
      "Train Loss: [0.62833256, 0.2, 0.21083173, 0.2019603]\n",
      "[0.6221047, 0.2, 0.20499216, 0.20158237]\n",
      "[0.6227642, 0.2, 0.20620872, 0.2010359]\n",
      "[0.6236044, 0.2, 0.20714894, 0.20094654]\n",
      "[0.6242117, 0.2, 0.20517227, 0.20354141]\n",
      "[0.6224119, 0.2, 0.20200218, 0.20492269]\n",
      "[0.63050026, 0.2, 0.21447344, 0.20055078]\n",
      "[0.6375824, 0.2, 0.21922885, 0.20288794]\n",
      "[0.6583449, 0.2, 0.2077589, 0.23513077]\n",
      "[0.6263764, 0.2, 0.20779483, 0.20313643]\n",
      "[0.62616324, 0.2, 0.20599914, 0.20472853]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1300 iterations: 0.47328929901123046 mins\n",
      "Train Loss: [0.62616324, 0.2, 0.20599914, 0.20472853]\n",
      "[0.62102294, 0.2, 0.20423988, 0.2013565]\n",
      "[0.62692755, 0.2, 0.20803542, 0.20347525]\n",
      "[0.6204654, 0.2, 0.2041232, 0.20093495]\n",
      "[0.6285293, 0.2, 0.20928337, 0.20384821]\n",
      "[0.627656, 0.2, 0.21169962, 0.20056826]\n",
      "[0.62388504, 0.2, 0.2065034, 0.20200306]\n",
      "[0.61603075, 0.2, 0.20031025, 0.20035146]\n",
      "[0.62098587, 0.2, 0.20301656, 0.20260993]\n",
      "[0.62045383, 0.2, 0.20316285, 0.20194106]\n",
      "[0.6239162, 0.2, 0.20536064, 0.20321535]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1310 iterations: 0.47598851919174195 mins\n",
      "Train Loss: [0.6239162, 0.2, 0.20536064, 0.20321535]\n",
      "[0.630229, 0.2, 0.21190757, 0.20299119]\n",
      "[0.6230903, 0.2, 0.20501886, 0.20275106]\n",
      "[0.6366332, 0.2, 0.21791472, 0.20340809]\n",
      "[0.6286569, 0.2, 0.20619865, 0.20715772]\n",
      "[0.6386783, 0.2, 0.22108825, 0.2022988]\n",
      "[0.6243948, 0.2, 0.20619005, 0.20292275]\n",
      "[0.68505144, 0.2, 0.21812584, 0.2516529]\n",
      "[0.62921596, 0.2, 0.21239042, 0.20156173]\n",
      "[0.62672186, 0.2, 0.20946826, 0.20199847]\n",
      "[0.61882067, 0.2, 0.20192699, 0.20164746]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1320 iterations: 0.4786215345064799 mins\n",
      "Train Loss: [0.61882067, 0.2, 0.20192699, 0.20164746]\n",
      "[0.6201199, 0.2, 0.20419316, 0.20068944]\n",
      "[0.6190832, 0.2, 0.20253865, 0.201316]\n",
      "[0.625449, 0.2, 0.20586729, 0.20436206]\n",
      "[0.62230265, 0.2, 0.20471899, 0.20237298]\n",
      "[0.6353277, 0.2, 0.20788229, 0.21224391]\n",
      "[0.62011355, 0.2, 0.20342942, 0.2014914]\n",
      "[0.6259288, 0.2, 0.2074694, 0.2032755]\n",
      "[0.62626326, 0.2, 0.20457496, 0.20651339]\n",
      "[0.6283567, 0.2, 0.20957205, 0.20361874]\n",
      "[0.63103515, 0.2, 0.21243018, 0.20344809]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1330 iterations: 0.48224411805470785 mins\n",
      "Train Loss: [0.63103515, 0.2, 0.21243018, 0.20344809]\n",
      "[0.6355511, 0.2, 0.21680893, 0.20359427]\n",
      "[0.6216381, 0.2, 0.2055332, 0.20096608]\n",
      "[0.6220444, 0.2, 0.20389417, 0.20302127]\n",
      "[0.64378554, 0.2, 0.21331179, 0.21535468]\n",
      "[0.620861, 0.2, 0.20412338, 0.20162772]\n",
      "[0.62200314, 0.2, 0.2045646, 0.20233749]\n",
      "[0.62633455, 0.2, 0.20916194, 0.20208077]\n",
      "[0.6247983, 0.2, 0.2055975, 0.20411839]\n",
      "[0.6185108, 0.2, 0.20092598, 0.20251194]\n",
      "[0.63102466, 0.2, 0.21464814, 0.20131324]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1340 iterations: 0.4848361333211263 mins\n",
      "Train Loss: [0.63102466, 0.2, 0.21464814, 0.20131324]\n",
      "[0.6231561, 0.2, 0.2048122, 0.20329012]\n",
      "[0.626727, 0.2, 0.21049567, 0.20118688]\n",
      "[0.66255844, 0.2, 0.20696004, 0.24056323]\n",
      "[0.62478995, 0.2, 0.20619167, 0.20357308]\n",
      "[0.6221684, 0.2, 0.20393756, 0.20321509]\n",
      "[0.62193835, 0.2, 0.205325, 0.20160641]\n",
      "[0.6285595, 0.2, 0.20583628, 0.20772484]\n",
      "[0.6198373, 0.2, 0.20402633, 0.20082138]\n",
      "[0.62755615, 0.2, 0.210324, 0.20225145]\n",
      "[0.62879485, 0.2, 0.21228111, 0.20154203]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1350 iterations: 0.48691133260726926 mins\n",
      "Train Loss: [0.62879485, 0.2, 0.21228111, 0.20154203]\n",
      "[0.62919676, 0.2, 0.2118876, 0.20234653]\n",
      "[0.62104976, 0.2, 0.20272188, 0.20337449]\n",
      "[0.62194556, 0.2, 0.20693615, 0.20006543]\n",
      "[0.63318974, 0.2, 0.21396723, 0.20428815]\n",
      "[0.63186723, 0.2, 0.21321641, 0.20372555]\n",
      "[0.62204516, 0.2, 0.20441468, 0.2027143]\n",
      "[0.6282162, 0.2, 0.21055664, 0.20275262]\n",
      "[0.6204886, 0.2, 0.20363876, 0.20195219]\n",
      "[0.6258793, 0.2, 0.20920399, 0.20178713]\n",
      "[0.62043965, 0.2, 0.20416327, 0.20139787]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1360 iterations: 0.4891978144645691 mins\n",
      "Train Loss: [0.62043965, 0.2, 0.20416327, 0.20139787]\n",
      "[0.63274133, 0.2, 0.2149462, 0.20292632]\n",
      "[0.6246812, 0.2, 0.20768338, 0.20213859]\n",
      "[0.63122666, 0.2, 0.20835786, 0.20801887]\n",
      "[0.6226655, 0.2, 0.20704424, 0.20078222]\n",
      "[0.62762547, 0.2, 0.21266979, 0.2001265]\n",
      "[0.63255554, 0.2, 0.2172984, 0.20043775]\n",
      "[0.65813804, 0.2, 0.21113302, 0.23219326]\n",
      "[0.6374792, 0.2, 0.22245102, 0.20022339]\n",
      "[0.6198464, 0.2, 0.2038645, 0.20118356]\n",
      "[0.61918676, 0.2, 0.20412849, 0.20026624]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1370 iterations: 0.4951457977294922 mins\n",
      "Train Loss: [0.61918676, 0.2, 0.20412849, 0.20026624]\n",
      "[0.61962706, 0.2, 0.20411663, 0.20072454]\n",
      "[0.63929, 0.2, 0.22138928, 0.203121]\n",
      "[0.62021965, 0.2, 0.2016634, 0.20378233]\n",
      "[0.6328778, 0.2, 0.21427974, 0.20383012]\n",
      "[0.626897, 0.2, 0.21111593, 0.20101891]\n",
      "[0.62380666, 0.2, 0.20807241, 0.20097807]\n",
      "[0.6334935, 0.2, 0.21268743, 0.20605637]\n",
      "[0.6206392, 0.2, 0.20219192, 0.20370463]\n",
      "[0.6401071, 0.2, 0.21325098, 0.2121208]\n",
      "[0.6263901, 0.2, 0.20722045, 0.20444186]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1380 iterations: 0.49903244972229005 mins\n",
      "Train Loss: [0.6263901, 0.2, 0.20722045, 0.20444186]\n",
      "[0.6315632, 0.2, 0.21477777, 0.20206547]\n",
      "[0.6310188, 0.2, 0.21304718, 0.20325957]\n",
      "[0.664385, 0.2, 0.24664584, 0.20303504]\n",
      "[0.61988395, 0.2, 0.2041524, 0.20103611]\n",
      "[0.62332994, 0.2, 0.20655595, 0.20208724]\n",
      "[0.62290204, 0.2, 0.20431373, 0.2039098]\n",
      "[0.6226779, 0.2, 0.20689757, 0.20110905]\n",
      "[0.6239803, 0.2, 0.20721501, 0.2021004]\n",
      "[0.62681335, 0.2, 0.20606609, 0.20608829]\n",
      "[0.62784004, 0.2, 0.20807353, 0.20511323]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1390 iterations: 0.5016241470972697 mins\n",
      "Train Loss: [0.62784004, 0.2, 0.20807353, 0.20511323]\n",
      "[0.62141407, 0.2, 0.20436265, 0.2024037]\n",
      "[0.6453007, 0.2, 0.22800046, 0.20265792]\n",
      "[0.6253707, 0.2, 0.20801921, 0.20271426]\n",
      "[0.6265928, 0.2, 0.20994641, 0.20201448]\n",
      "[0.6242598, 0.2, 0.20719881, 0.20243457]\n",
      "[0.62580746, 0.2, 0.20964898, 0.20153782]\n",
      "[0.6252171, 0.2, 0.20652986, 0.20407286]\n",
      "[0.62338614, 0.2, 0.20634778, 0.20243064]\n",
      "[0.6459908, 0.2, 0.22477704, 0.20661296]\n",
      "[0.62823254, 0.2, 0.21160316, 0.2020366]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1400 iterations: 0.5047669490178426 mins\n",
      "Train Loss: [0.62823254, 0.2, 0.21160316, 0.2020366]\n",
      "[0.62967914, 0.2, 0.21365124, 0.2014433]\n",
      "[0.6260155, 0.2, 0.21038105, 0.20105815]\n",
      "[0.6260417, 0.2, 0.20915902, 0.20231488]\n",
      "[0.6285597, 0.2, 0.21276377, 0.20123732]\n",
      "[0.62530464, 0.2, 0.20673236, 0.20402241]\n",
      "[0.62533313, 0.2, 0.20955928, 0.20123279]\n",
      "[0.62686205, 0.2, 0.21005031, 0.2022795]\n",
      "[0.619204, 0.2, 0.20233035, 0.20235038]\n",
      "[0.61829823, 0.2, 0.20154662, 0.20223746]\n",
      "[0.6340075, 0.2, 0.21507697, 0.2044257]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1410 iterations: 0.508237898349762 mins\n",
      "Train Loss: [0.6340075, 0.2, 0.21507697, 0.2044257]\n",
      "[0.63537073, 0.2, 0.21726812, 0.20360717]\n",
      "[0.62747556, 0.2, 0.2106405, 0.20234919]\n",
      "[0.62062275, 0.2, 0.20393565, 0.20221047]\n",
      "[0.6303391, 0.2, 0.21448754, 0.20138438]\n",
      "[0.6279949, 0.2, 0.21055043, 0.20298621]\n",
      "[0.62291545, 0.2, 0.20604531, 0.20242022]\n",
      "[0.62590986, 0.2, 0.21004906, 0.20141907]\n",
      "[0.62443954, 0.2, 0.20842418, 0.2015817]\n",
      "[0.6276611, 0.2, 0.21070828, 0.2025277]\n",
      "[0.6257584, 0.2, 0.20647013, 0.2048718]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1420 iterations: 0.5111654996871948 mins\n",
      "Train Loss: [0.6257584, 0.2, 0.20647013, 0.2048718]\n",
      "[0.62961787, 0.2, 0.21187952, 0.20333068]\n",
      "[0.6198687, 0.2, 0.20416066, 0.20130952]\n",
      "[0.64374834, 0.2, 0.20785783, 0.2215011]\n",
      "[0.6250942, 0.2, 0.20959948, 0.20111564]\n",
      "[0.61723983, 0.2, 0.2016216, 0.20124893]\n",
      "[0.63131887, 0.2, 0.21452363, 0.2024354]\n",
      "[0.6283649, 0.2, 0.20997287, 0.20404112]\n",
      "[0.6194976, 0.2, 0.20246743, 0.20268777]\n",
      "[0.633234, 0.2, 0.20888536, 0.21001479]\n",
      "[0.62302405, 0.2, 0.20583679, 0.2028628]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1430 iterations: 0.5140297333399455 mins\n",
      "Train Loss: [0.62302405, 0.2, 0.20583679, 0.2028628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62126654, 0.2, 0.20512292, 0.20182836]\n",
      "[0.622988, 0.2, 0.20731355, 0.20136818]\n",
      "[0.62496716, 0.2, 0.20915297, 0.20151678]\n",
      "[0.6435101, 0.2, 0.22660366, 0.20261802]\n",
      "[0.64223033, 0.2, 0.2245409, 0.20340973]\n",
      "[0.62960756, 0.2, 0.21194208, 0.20339453]\n",
      "[0.6276525, 0.2, 0.2085691, 0.20482096]\n",
      "[0.6255532, 0.2, 0.21048884, 0.20081028]\n",
      "[0.6240859, 0.2, 0.20761113, 0.20222926]\n",
      "[0.6207053, 0.2, 0.2040602, 0.20240827]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1440 iterations: 0.5177619496981303 mins\n",
      "Train Loss: [0.6207053, 0.2, 0.2040602, 0.20240827]\n",
      "[0.62388295, 0.2, 0.2067371, 0.20291807]\n",
      "[0.6231865, 0.2, 0.20700866, 0.20195927]\n",
      "[0.624244, 0.2, 0.20663117, 0.20340346]\n",
      "[0.6247846, 0.2, 0.2077608, 0.20282373]\n",
      "[0.6189882, 0.2, 0.20228904, 0.20250818]\n",
      "[0.63157624, 0.2, 0.21408816, 0.20330644]\n",
      "[0.6246296, 0.2, 0.20771126, 0.2027459]\n",
      "[0.62157637, 0.2, 0.20608471, 0.20132798]\n",
      "[0.6154174, 0.2, 0.20037334, 0.2008888]\n",
      "[0.6234311, 0.2, 0.20756383, 0.20172021]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1450 iterations: 0.5205224831899007 mins\n",
      "Train Loss: [0.6234311, 0.2, 0.20756383, 0.20172021]\n",
      "[0.6356956, 0.2, 0.21949993, 0.2020567]\n",
      "[0.6231233, 0.2, 0.20809473, 0.20089734]\n",
      "[0.6206913, 0.2, 0.20390657, 0.2026611]\n",
      "[0.6300354, 0.2, 0.21458259, 0.20133676]\n",
      "[0.62679225, 0.2, 0.21029909, 0.20238455]\n",
      "[0.63385445, 0.2, 0.20881084, 0.21094266]\n",
      "[0.63265604, 0.2, 0.21638405, 0.20217887]\n",
      "[0.6191121, 0.2, 0.20165905, 0.2033678]\n",
      "[0.6441818, 0.2, 0.20626485, 0.22383979]\n",
      "[0.6285878, 0.2, 0.21178854, 0.2027303]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1460 iterations: 0.524356464544932 mins\n",
      "Train Loss: [0.6285878, 0.2, 0.21178854, 0.2027303]\n",
      "[0.6248624, 0.2, 0.20967752, 0.20112406]\n",
      "[0.6512127, 0.2, 0.23582833, 0.20133175]\n",
      "[0.61590147, 0.2, 0.19994497, 0.20191129]\n",
      "[0.62925476, 0.2, 0.21132815, 0.20388871]\n",
      "[0.6331101, 0.2, 0.21709515, 0.20198461]\n",
      "[0.626437, 0.2, 0.20824324, 0.20417012]\n",
      "[0.6199091, 0.2, 0.20545664, 0.20043531]\n",
      "[0.6571599, 0.2, 0.2036088, 0.2395407]\n",
      "[0.6271196, 0.2, 0.2095772, 0.20353886]\n",
      "[0.62289757, 0.2, 0.20542863, 0.20347191]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1470 iterations: 0.527312715848287 mins\n",
      "Train Loss: [0.62289757, 0.2, 0.20542863, 0.20347191]\n",
      "[0.624974, 0.2, 0.20855181, 0.2024317]\n",
      "[0.61970407, 0.2, 0.20228058, 0.2034393]\n",
      "[0.63271594, 0.2, 0.21679471, 0.20194332]\n",
      "[0.631195, 0.2, 0.21430717, 0.20291632]\n",
      "[0.6226158, 0.2, 0.2070088, 0.2016424]\n",
      "[0.62682545, 0.2, 0.2066735, 0.20619439]\n",
      "[0.6203421, 0.2, 0.20594151, 0.20045024]\n",
      "[0.6289734, 0.2, 0.20992705, 0.20510365]\n",
      "[0.6582319, 0.2, 0.2104035, 0.2338934]\n",
      "[0.6257491, 0.2, 0.20808823, 0.20373204]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1480 iterations: 0.5303857127825419 mins\n",
      "Train Loss: [0.6257491, 0.2, 0.20808823, 0.20373204]\n",
      "[0.63710237, 0.2, 0.21720095, 0.20597887]\n",
      "[0.6185174, 0.2, 0.20219776, 0.20240304]\n",
      "[0.62481904, 0.2, 0.20632082, 0.20458807]\n",
      "[0.62722754, 0.2, 0.20935373, 0.2039699]\n",
      "[0.6218607, 0.2, 0.20682105, 0.20114216]\n",
      "[0.63969064, 0.2, 0.21895197, 0.20684747]\n",
      "[0.6205244, 0.2, 0.20489961, 0.20173988]\n",
      "[0.62610894, 0.2, 0.20766723, 0.20456319]\n",
      "[0.62844944, 0.2, 0.2123938, 0.20218363]\n",
      "[0.6216344, 0.2, 0.20614947, 0.20161949]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1490 iterations: 0.533941900730133 mins\n",
      "Train Loss: [0.6216344, 0.2, 0.20614947, 0.20161949]\n",
      "[0.62082267, 0.2, 0.20477074, 0.20219316]\n",
      "[0.62236315, 0.2, 0.20476356, 0.20374732]\n",
      "[0.62487715, 0.2, 0.20860979, 0.2024218]\n",
      "[0.61982906, 0.2, 0.20355651, 0.20243339]\n",
      "[0.6311177, 0.2, 0.21402569, 0.20325932]\n",
      "[0.62320524, 0.2, 0.20803668, 0.20134278]\n",
      "[0.6296888, 0.2, 0.21477978, 0.20109025]\n",
      "[0.6260389, 0.2, 0.2096947, 0.20253241]\n",
      "[0.62675446, 0.2, 0.20874088, 0.20420884]\n",
      "[0.65832454, 0.2, 0.23883624, 0.20569077]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1500 iterations: 0.5372717181841532 mins\n",
      "Train Loss: [0.65832454, 0.2, 0.23883624, 0.20569077]\n",
      "[0.62356824, 0.2, 0.20919925, 0.20057672]\n",
      "[0.6260518, 0.2, 0.20901535, 0.20324945]\n",
      "[0.64171803, 0.2, 0.20998292, 0.21795367]\n",
      "[0.63523066, 0.2, 0.21559729, 0.2058575]\n",
      "[0.629686, 0.2, 0.21240106, 0.20351449]\n",
      "[0.6267394, 0.2, 0.21106158, 0.20191282]\n",
      "[0.65557694, 0.2, 0.2399475, 0.20187016]\n",
      "[0.6168176, 0.2, 0.20162481, 0.20143826]\n",
      "[0.62347287, 0.2, 0.2027545, 0.20696887]\n",
      "[0.6241944, 0.2, 0.20926812, 0.20118222]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1510 iterations: 0.5394472638765971 mins\n",
      "Train Loss: [0.6241944, 0.2, 0.20926812, 0.20118222]\n",
      "[0.6251146, 0.2, 0.20615058, 0.20522569]\n",
      "[0.6238056, 0.2, 0.20652647, 0.20354643]\n",
      "[0.6256247, 0.2, 0.21001345, 0.20188448]\n",
      "[0.6252927, 0.2, 0.20835488, 0.2032171]\n",
      "[0.625609, 0.2, 0.2101009, 0.20179372]\n",
      "[0.6252642, 0.2, 0.2098896, 0.20166688]\n",
      "[0.6277778, 0.2, 0.20819883, 0.20587789]\n",
      "[0.62694633, 0.2, 0.20909964, 0.2041524]\n",
      "[0.6558471, 0.2, 0.23835176, 0.20380767]\n",
      "[0.6313745, 0.2, 0.21435438, 0.20333844]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1520 iterations: 0.541849950949351 mins\n",
      "Train Loss: [0.6313745, 0.2, 0.21435438, 0.20333844]\n",
      "[0.6274248, 0.2, 0.21165657, 0.202092]\n",
      "[0.6242593, 0.2, 0.2074795, 0.20310883]\n",
      "[0.6238925, 0.2, 0.20615603, 0.20407076]\n",
      "[0.63642234, 0.2, 0.21853752, 0.20422432]\n",
      "[0.61827874, 0.2, 0.20321567, 0.2014075]\n",
      "[0.6222765, 0.2, 0.2069835, 0.20164259]\n",
      "[0.6307976, 0.2, 0.21379425, 0.20335881]\n",
      "[0.6239646, 0.2, 0.2086916, 0.20163427]\n",
      "[0.62837, 0.2, 0.2130489, 0.20168853]\n",
      "[0.61937326, 0.2, 0.20489676, 0.20085014]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1530 iterations: 0.5443958004315694 mins\n",
      "Train Loss: [0.61937326, 0.2, 0.20489676, 0.20085014]\n",
      "[0.6227053, 0.2, 0.20653191, 0.20255342]\n",
      "[0.6416327, 0.2, 0.22523716, 0.2027822]\n",
      "[0.62594205, 0.2, 0.20866889, 0.2036665]\n",
      "[0.61872125, 0.2, 0.20244718, 0.20267431]\n",
      "[0.6415762, 0.2, 0.22183241, 0.20615113]\n",
      "[0.6259049, 0.2, 0.21109767, 0.2012212]\n",
      "[0.6249061, 0.2, 0.20786887, 0.20345786]\n",
      "[0.62330633, 0.2, 0.20759419, 0.20213939]\n",
      "[0.6231318, 0.2, 0.20711152, 0.20245448]\n",
      "[0.624129, 0.2, 0.20471333, 0.20585676]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1540 iterations: 0.5467938343683879 mins\n",
      "Train Loss: [0.624129, 0.2, 0.20471333, 0.20585676]\n",
      "[0.6258948, 0.2, 0.20923758, 0.20310499]\n",
      "[0.626664, 0.2, 0.21174437, 0.20137438]\n",
      "[0.63217264, 0.2, 0.21318121, 0.20545332]\n",
      "[0.62777776, 0.2, 0.21261616, 0.20163049]\n",
      "[0.62786347, 0.2, 0.20978783, 0.2045515]\n",
      "[0.62303686, 0.2, 0.20586076, 0.20365894]\n",
      "[0.62093204, 0.2, 0.2065559, 0.2008663]\n",
      "[0.6274334, 0.2, 0.20973375, 0.20419714]\n",
      "[0.61804324, 0.2, 0.2022877, 0.20226045]\n",
      "[0.62298745, 0.2, 0.20643927, 0.20306064]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1550 iterations: 0.5497036337852478 mins\n",
      "Train Loss: [0.62298745, 0.2, 0.20643927, 0.20306064]\n",
      "[0.6319756, 0.2, 0.21402133, 0.20447415]\n",
      "[0.63303065, 0.2, 0.21632707, 0.20323077]\n",
      "[0.62234986, 0.2, 0.2049173, 0.20396717]\n",
      "[0.62239033, 0.2, 0.20671353, 0.20221922]\n",
      "[0.6189998, 0.2, 0.20216511, 0.20338522]\n",
      "[0.6160901, 0.2, 0.20152514, 0.20112354]\n",
      "[0.61892796, 0.2, 0.20205832, 0.20343629]\n",
      "[0.6309184, 0.2, 0.21385224, 0.2036409]\n",
      "[0.62745863, 0.2, 0.20619586, 0.20784591]\n",
      "[0.6475592, 0.2, 0.21015155, 0.22399959]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1560 iterations: 0.5518778165181478 mins\n",
      "Train Loss: [0.6475592, 0.2, 0.21015155, 0.22399959]\n",
      "[0.6268867, 0.2, 0.21173765, 0.20174932]\n",
      "[0.62994134, 0.2, 0.20661308, 0.20993614]\n",
      "[0.62624764, 0.2, 0.21044093, 0.20242432]\n",
      "[0.6280779, 0.2, 0.21286987, 0.20183483]\n",
      "[0.6173945, 0.2, 0.20297188, 0.20105803]\n",
      "[0.63046646, 0.2, 0.21233416, 0.2047759]\n",
      "[0.62266815, 0.2, 0.2081195, 0.20120004]\n",
      "[0.62470955, 0.2, 0.20841797, 0.20295066]\n",
      "[0.63334805, 0.2, 0.21581438, 0.20420028]\n",
      "[0.6336108, 0.2, 0.21617773, 0.20410648]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1570 iterations: 0.5543995499610901 mins\n",
      "Train Loss: [0.6336108, 0.2, 0.21617773, 0.20410648]\n",
      "[0.62947273, 0.2, 0.21403523, 0.20211786]\n",
      "[0.6373368, 0.2, 0.2025184, 0.2215056]\n",
      "[0.6250915, 0.2, 0.21002302, 0.20176251]\n",
      "[0.6270641, 0.2, 0.20999181, 0.20377277]\n",
      "[0.623973, 0.2, 0.20818144, 0.20249826]\n",
      "[0.623297, 0.2, 0.20786111, 0.2021487]\n",
      "[0.63102263, 0.2, 0.20216624, 0.21557505]\n",
      "[0.6243928, 0.2, 0.20925367, 0.20186168]\n",
      "[0.6281268, 0.2, 0.21214549, 0.20270765]\n",
      "[0.6282708, 0.2, 0.21117799, 0.20382313]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1580 iterations: 0.5570637663205464 mins\n",
      "Train Loss: [0.6282708, 0.2, 0.21117799, 0.20382313]\n",
      "[0.6278298, 0.2, 0.20459831, 0.20996544]\n",
      "[0.6201018, 0.2, 0.20319186, 0.20364688]\n",
      "[0.61658645, 0.2, 0.20131965, 0.20200692]\n",
      "[0.629845, 0.2, 0.2143172, 0.20227127]\n",
      "[0.6362589, 0.2, 0.21960779, 0.20339794]\n",
      "[0.62306285, 0.2, 0.20686051, 0.2029524]\n",
      "[0.6489694, 0.2, 0.23010863, 0.20561445]\n",
      "[0.62678206, 0.2, 0.20846404, 0.20507587]\n",
      "[0.626265, 0.2, 0.21174313, 0.2012841]\n",
      "[0.62196887, 0.2, 0.20691963, 0.20181641]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1590 iterations: 0.5602085510889689 mins\n",
      "Train Loss: [0.62196887, 0.2, 0.20691963, 0.20181641]\n",
      "[0.62614566, 0.2, 0.20889688, 0.20402136]\n",
      "[0.62265944, 0.2, 0.20642257, 0.20301494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63044226, 0.2, 0.21490638, 0.20231973]\n",
      "[0.61814225, 0.2, 0.20147066, 0.2034606]\n",
      "[0.6209691, 0.2, 0.20582919, 0.20193468]\n",
      "[0.6224326, 0.2, 0.2072775, 0.20195608]\n",
      "[0.62284505, 0.2, 0.20682333, 0.20282915]\n",
      "[0.62417674, 0.2, 0.20548223, 0.20550877]\n",
      "[0.6219089, 0.2, 0.20568563, 0.20304447]\n",
      "[0.61810744, 0.2, 0.20229045, 0.20264511]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1600 iterations: 0.562298850218455 mins\n",
      "Train Loss: [0.61810744, 0.2, 0.20229045, 0.20264511]\n",
      "[0.6195792, 0.2, 0.2046464, 0.20176822]\n",
      "[0.6241559, 0.2, 0.20528807, 0.20571081]\n",
      "[0.6182254, 0.2, 0.20181912, 0.2032577]\n",
      "[0.6245357, 0.2, 0.20939043, 0.20200554]\n",
      "[0.62952274, 0.2, 0.2117144, 0.20467733]\n",
      "[0.62405443, 0.2, 0.20838177, 0.20255005]\n",
      "[0.6194567, 0.2, 0.20421566, 0.20212685]\n",
      "[0.62800354, 0.2, 0.21310227, 0.20179537]\n",
      "[0.6236091, 0.2, 0.20301905, 0.20749266]\n",
      "[0.652728, 0.2, 0.23729524, 0.20234394]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1610 iterations: 0.5646645665168762 mins\n",
      "Train Loss: [0.652728, 0.2, 0.23729524, 0.20234394]\n",
      "[0.6361425, 0.2, 0.20960982, 0.21344654]\n",
      "[0.62505263, 0.2, 0.2091449, 0.2028227]\n",
      "[0.62518084, 0.2, 0.208506, 0.2035908]\n",
      "[0.6281519, 0.2, 0.21238051, 0.20268787]\n",
      "[0.6191745, 0.2, 0.2040179, 0.20207305]\n",
      "[0.6310064, 0.2, 0.21058804, 0.20733503]\n",
      "[0.6188273, 0.2, 0.20355389, 0.20219052]\n",
      "[0.6382848, 0.2, 0.2238733, 0.20132941]\n",
      "[0.6251679, 0.2, 0.20434129, 0.20774676]\n",
      "[0.6317103, 0.2, 0.2161756, 0.20245783]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1620 iterations: 0.5668537696202596 mins\n",
      "Train Loss: [0.6317103, 0.2, 0.2161756, 0.20245783]\n",
      "[0.6207106, 0.2, 0.20574631, 0.2018909]\n",
      "[0.6215103, 0.2, 0.20644666, 0.201994]\n",
      "[0.622498, 0.2, 0.20708098, 0.2023513]\n",
      "[0.62943316, 0.2, 0.20585084, 0.21052104]\n",
      "[0.6263885, 0.2, 0.21012501, 0.20320699]\n",
      "[0.634025, 0.2, 0.20762092, 0.21335308]\n",
      "[0.6291727, 0.2, 0.2095829, 0.20654437]\n",
      "[0.6264216, 0.2, 0.20941244, 0.20396982]\n",
      "[0.6238814, 0.2, 0.2068505, 0.20399782]\n",
      "[0.6430763, 0.2, 0.22615847, 0.20389117]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1630 iterations: 0.5705822666486104 mins\n",
      "Train Loss: [0.6430763, 0.2, 0.22615847, 0.20389117]\n",
      "[0.62121475, 0.2, 0.20582591, 0.20236896]\n",
      "[0.6248676, 0.2, 0.20702308, 0.20483176]\n",
      "[0.6281317, 0.2, 0.20952266, 0.20560399]\n",
      "[0.63148713, 0.2, 0.21234497, 0.2061449]\n",
      "[0.6177149, 0.2, 0.20177086, 0.20295446]\n",
      "[0.6392531, 0.2, 0.22447668, 0.2017945]\n",
      "[0.6348702, 0.2, 0.21885268, 0.2030436]\n",
      "[0.6269741, 0.2, 0.21108823, 0.20291956]\n",
      "[0.621984, 0.2, 0.2067482, 0.20227757]\n",
      "[0.6177981, 0.2, 0.20332702, 0.20152077]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1640 iterations: 0.5749841133753458 mins\n",
      "Train Loss: [0.6177981, 0.2, 0.20332702, 0.20152077]\n",
      "[0.62609816, 0.2, 0.21063128, 0.20252469]\n",
      "[0.62651044, 0.2, 0.2092103, 0.20436643]\n",
      "[0.6325693, 0.2, 0.2185254, 0.20111912]\n",
      "[0.623791, 0.2, 0.20890978, 0.20196533]\n",
      "[0.6251432, 0.2, 0.20905559, 0.20318039]\n",
      "[0.6295488, 0.2, 0.2143753, 0.2022747]\n",
      "[0.61847866, 0.2, 0.20353709, 0.2020509]\n",
      "[0.61791867, 0.2, 0.20246632, 0.20256978]\n",
      "[0.62417126, 0.2, 0.20913488, 0.20216198]\n",
      "[0.6288125, 0.2, 0.21170418, 0.2042425]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1650 iterations: 0.5779455184936524 mins\n",
      "Train Loss: [0.6288125, 0.2, 0.21170418, 0.2042425]\n",
      "[0.6302906, 0.2, 0.2160234, 0.20140947]\n",
      "[0.62715006, 0.2, 0.21288455, 0.20141572]\n",
      "[0.6171172, 0.2, 0.20314756, 0.2011277]\n",
      "[0.62516505, 0.2, 0.20958734, 0.20274365]\n",
      "[0.6178758, 0.2, 0.20219405, 0.20285553]\n",
      "[0.62706983, 0.2, 0.21078227, 0.20346911]\n",
      "[0.6199813, 0.2, 0.20555522, 0.20161515]\n",
      "[0.62169546, 0.2, 0.207929, 0.20096312]\n",
      "[0.6235548, 0.2, 0.20860668, 0.20215285]\n",
      "[0.6234804, 0.2, 0.20592633, 0.20476675]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1660 iterations: 0.5802191019058227 mins\n",
      "Train Loss: [0.6234804, 0.2, 0.20592633, 0.20476675]\n",
      "[0.6329327, 0.2, 0.21613875, 0.20401435]\n",
      "[0.6277398, 0.2, 0.2125461, 0.20242158]\n",
      "[0.6171545, 0.2, 0.2016834, 0.20270687]\n",
      "[0.62945634, 0.2, 0.2139674, 0.20273246]\n",
      "[0.6174752, 0.2, 0.20292313, 0.2018032]\n",
      "[0.62076896, 0.2, 0.20717606, 0.20085196]\n",
      "[0.620891, 0.2, 0.20689468, 0.20126306]\n",
      "[0.6184633, 0.2, 0.20358466, 0.20215282]\n",
      "[0.64723855, 0.2, 0.2021, 0.23242022]\n",
      "[0.63056797, 0.2, 0.21331167, 0.204546]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1670 iterations: 0.5842721978823344 mins\n",
      "Train Loss: [0.63056797, 0.2, 0.21331167, 0.204546]\n",
      "[0.62457335, 0.2, 0.20806682, 0.20380424]\n",
      "[0.6260196, 0.2, 0.20539576, 0.20792955]\n",
      "[0.66155845, 0.2, 0.21888953, 0.22998242]\n",
      "[0.62987196, 0.2, 0.2153216, 0.20187123]\n",
      "[0.62178147, 0.2, 0.20753573, 0.20157315]\n",
      "[0.6229631, 0.2, 0.20714954, 0.20314714]\n",
      "[0.62317437, 0.2, 0.20778471, 0.20272923]\n",
      "[0.6273874, 0.2, 0.2108846, 0.20384811]\n",
      "[0.62515086, 0.2, 0.21079947, 0.20170298]\n",
      "[0.6297496, 0.2, 0.212254, 0.20485331]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1680 iterations: 0.5873445312182108 mins\n",
      "Train Loss: [0.6297496, 0.2, 0.212254, 0.20485331]\n",
      "[0.6316472, 0.2, 0.21755698, 0.20145433]\n",
      "[0.661309, 0.2, 0.22312614, 0.22555307]\n",
      "[0.64385843, 0.2, 0.23009627, 0.20113815]\n",
      "[0.6168285, 0.2, 0.20215964, 0.20204698]\n",
      "[0.62390596, 0.2, 0.20739868, 0.2038873]\n",
      "[0.6258383, 0.2, 0.21228191, 0.20093831]\n",
      "[0.6212684, 0.2, 0.20633757, 0.20231435]\n",
      "[0.6188127, 0.2, 0.20325084, 0.2029473]\n",
      "[0.62538034, 0.2, 0.21184263, 0.2009255]\n",
      "[0.6226361, 0.2, 0.20891479, 0.20111127]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1690 iterations: 0.5902184128761292 mins\n",
      "Train Loss: [0.6226361, 0.2, 0.20891479, 0.20111127]\n",
      "[0.619444, 0.2, 0.20459224, 0.20224433]\n",
      "[0.6239926, 0.2, 0.20806044, 0.20332773]\n",
      "[0.6265323, 0.2, 0.2128565, 0.20107462]\n",
      "[0.63108975, 0.2, 0.21525018, 0.20324253]\n",
      "[0.650708, 0.2, 0.23570865, 0.20240662]\n",
      "[0.6225583, 0.2, 0.20614736, 0.2038206]\n",
      "[0.6343775, 0.2, 0.21538994, 0.2063992]\n",
      "[0.6215989, 0.2, 0.20757931, 0.20143302]\n",
      "[0.6436791, 0.2, 0.22486095, 0.20623338]\n",
      "[0.6258947, 0.2, 0.20977013, 0.20354162]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1700 iterations: 0.5924765189488729 mins\n",
      "Train Loss: [0.6258947, 0.2, 0.20977013, 0.20354162]\n",
      "[0.62510264, 0.2, 0.20768297, 0.20483896]\n",
      "[0.6238726, 0.2, 0.20760985, 0.20368508]\n",
      "[0.62868255, 0.2, 0.2134925, 0.20261587]\n",
      "[0.62619054, 0.2, 0.20942752, 0.20419279]\n",
      "[0.62284386, 0.2, 0.20852377, 0.20175345]\n",
      "[0.6280165, 0.2, 0.21281701, 0.20263678]\n",
      "[0.61848915, 0.2, 0.20421314, 0.20171763]\n",
      "[0.6242481, 0.2, 0.21052882, 0.20116551]\n",
      "[0.6204199, 0.2, 0.20482337, 0.20304775]\n",
      "[0.62226117, 0.2, 0.20820293, 0.20151496]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1710 iterations: 0.5944377978642782 mins\n",
      "Train Loss: [0.62226117, 0.2, 0.20820293, 0.20151496]\n",
      "[0.6236648, 0.2, 0.20904562, 0.20208192]\n",
      "[0.62623626, 0.2, 0.21064934, 0.20305595]\n",
      "[0.6264182, 0.2, 0.21087757, 0.20301609]\n",
      "[0.62333775, 0.2, 0.20808044, 0.20273931]\n",
      "[0.62158, 0.2, 0.20804724, 0.2010215]\n",
      "[0.61993706, 0.2, 0.20507284, 0.20235938]\n",
      "[0.62304395, 0.2, 0.2048371, 0.20570841]\n",
      "[0.6209866, 0.2, 0.20508502, 0.20340972]\n",
      "[0.6204034, 0.2, 0.20176288, 0.2061556]\n",
      "[0.62384754, 0.2, 0.2093953, 0.20197466]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1720 iterations: 0.5969154675801595 mins\n",
      "Train Loss: [0.62384754, 0.2, 0.2093953, 0.20197466]\n",
      "[0.64450973, 0.2, 0.20747188, 0.22456802]\n",
      "[0.6289186, 0.2, 0.21053684, 0.20591925]\n",
      "[0.62411, 0.2, 0.2105914, 0.2010636]\n",
      "[0.63499475, 0.2, 0.21431692, 0.2082301]\n",
      "[0.62701017, 0.2, 0.20901658, 0.20555285]\n",
      "[0.65514517, 0.2, 0.21311511, 0.22959626]\n",
      "[0.6243243, 0.2, 0.20934798, 0.20254901]\n",
      "[0.6290783, 0.2, 0.21107757, 0.20557949]\n",
      "[0.619056, 0.2, 0.20530625, 0.20133393]\n",
      "[0.61804783, 0.2, 0.20404944, 0.20158868]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1730 iterations: 0.5993051648139953 mins\n",
      "Train Loss: [0.61804783, 0.2, 0.20404944, 0.20158868]\n",
      "[0.62409973, 0.2, 0.20520827, 0.20648769]\n",
      "[0.6308503, 0.2, 0.21400958, 0.20444325]\n",
      "[0.6209666, 0.2, 0.20621307, 0.20236176]\n",
      "[0.6393748, 0.2, 0.22214277, 0.20484662]\n",
      "[0.64221865, 0.2, 0.225584, 0.20425494]\n",
      "[0.62612873, 0.2, 0.21229856, 0.20145662]\n",
      "[0.6211611, 0.2, 0.20615098, 0.2026432]\n",
      "[0.64661765, 0.2, 0.2308046, 0.20345262]\n",
      "[0.6158623, 0.2, 0.20215647, 0.20134886]\n",
      "[0.6265159, 0.2, 0.21315299, 0.20100947]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1740 iterations: 0.602440599600474 mins\n",
      "Train Loss: [0.6265159, 0.2, 0.21315299, 0.20100947]\n",
      "[0.6152794, 0.2, 0.20158222, 0.20134737]\n",
      "[0.6255819, 0.2, 0.21091087, 0.2023252]\n",
      "[0.62799263, 0.2, 0.21153262, 0.20411839]\n",
      "[0.6316727, 0.2, 0.21664506, 0.2026912]\n",
      "[0.61712664, 0.2, 0.20455359, 0.20024304]\n",
      "[0.6319852, 0.2, 0.21566358, 0.20399822]\n",
      "[0.62849563, 0.2, 0.21244784, 0.20373146]\n",
      "[0.6278404, 0.2, 0.21263663, 0.20289436]\n",
      "[0.61757046, 0.2, 0.20154405, 0.20372412]\n",
      "[0.61524105, 0.2, 0.20073919, 0.2022068]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1750 iterations: 0.6049715320269267 mins\n",
      "Train Loss: [0.61524105, 0.2, 0.20073919, 0.2022068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6207254, 0.2, 0.20194702, 0.20649064]\n",
      "[0.6203406, 0.2, 0.20562008, 0.20244016]\n",
      "[0.62884736, 0.2, 0.21400288, 0.20257148]\n",
      "[0.6236574, 0.2, 0.2080038, 0.20338807]\n",
      "[0.6188941, 0.2, 0.20323531, 0.20340036]\n",
      "[0.63140535, 0.2, 0.21717505, 0.20197906]\n",
      "[0.62700295, 0.2, 0.20947216, 0.2052866]\n",
      "[0.6220958, 0.2, 0.20463528, 0.20522343]\n",
      "[0.6225055, 0.2, 0.20819189, 0.20208344]\n",
      "[0.62294203, 0.2, 0.20832767, 0.20239139]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1760 iterations: 0.6102170666058858 mins\n",
      "Train Loss: [0.62294203, 0.2, 0.20832767, 0.20239139]\n",
      "[0.62264967, 0.2, 0.20853747, 0.20189694]\n",
      "[0.6190884, 0.2, 0.20565557, 0.20122497]\n",
      "[0.62186533, 0.2, 0.20181096, 0.20785372]\n",
      "[0.61964923, 0.2, 0.20621781, 0.20123813]\n",
      "[0.6272955, 0.2, 0.21432056, 0.20078838]\n",
      "[0.6189802, 0.2, 0.2057707, 0.20103021]\n",
      "[0.6172868, 0.2, 0.20208979, 0.20302483]\n",
      "[0.6254023, 0.2, 0.21244249, 0.20079502]\n",
      "[0.6241115, 0.2, 0.21111022, 0.20084356]\n",
      "[0.6188257, 0.2, 0.20559728, 0.20107755]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1770 iterations: 0.6156360824902852 mins\n",
      "Train Loss: [0.6188257, 0.2, 0.20559728, 0.20107755]\n",
      "[0.62045294, 0.2, 0.20637862, 0.20193043]\n",
      "[0.616548, 0.2, 0.20136462, 0.20304659]\n",
      "[0.6222021, 0.2, 0.20847896, 0.20159353]\n",
      "[0.6223128, 0.2, 0.20429872, 0.20589125]\n",
      "[0.6298319, 0.2, 0.20647536, 0.21124087]\n",
      "[0.6221026, 0.2, 0.2068187, 0.20317626]\n",
      "[0.61827797, 0.2, 0.20404358, 0.20213456]\n",
      "[0.6207854, 0.2, 0.20684189, 0.20185176]\n",
      "[0.6239562, 0.2, 0.20821734, 0.20365483]\n",
      "[0.6198648, 0.2, 0.20478757, 0.20300113]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1780 iterations: 0.6182586828867594 mins\n",
      "Train Loss: [0.6198648, 0.2, 0.20478757, 0.20300113]\n",
      "[0.62350065, 0.2, 0.21003701, 0.20139539]\n",
      "[0.61929727, 0.2, 0.20415874, 0.20307787]\n",
      "[0.6166614, 0.2, 0.2037867, 0.2008215]\n",
      "[0.6215444, 0.2, 0.20431247, 0.20518628]\n",
      "[0.62796444, 0.2, 0.21271841, 0.20320788]\n",
      "[0.62549305, 0.2, 0.2066835, 0.20677885]\n",
      "[0.62909585, 0.2, 0.21411945, 0.20295286]\n",
      "[0.62398124, 0.2, 0.2109461, 0.20101877]\n",
      "[0.61565787, 0.2, 0.20071957, 0.2029291]\n",
      "[0.633244, 0.2, 0.21834762, 0.20289443]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1790 iterations: 0.6214088638623555 mins\n",
      "Train Loss: [0.633244, 0.2, 0.21834762, 0.20289443]\n",
      "[0.62101394, 0.2, 0.20714538, 0.20187357]\n",
      "[0.6457527, 0.2, 0.22920789, 0.204557]\n",
      "[0.61999416, 0.2, 0.20474853, 0.20326513]\n",
      "[0.62430614, 0.2, 0.20853788, 0.20379493]\n",
      "[0.63842064, 0.2, 0.21091491, 0.21553963]\n",
      "[0.6156752, 0.2, 0.20198125, 0.20173423]\n",
      "[0.6164774, 0.2, 0.20118167, 0.20334226]\n",
      "[0.6242364, 0.2, 0.20935495, 0.20293431]\n",
      "[0.6157979, 0.2, 0.20305064, 0.20080617]\n",
      "[0.6216417, 0.2, 0.20789845, 0.20180833]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1800 iterations: 0.6238788008689881 mins\n",
      "Train Loss: [0.6216417, 0.2, 0.20789845, 0.20180833]\n",
      "[0.6215574, 0.2, 0.2057475, 0.20388106]\n",
      "[0.6219246, 0.2, 0.20825824, 0.20174326]\n",
      "[0.62701184, 0.2, 0.2131225, 0.20197217]\n",
      "[0.6226988, 0.2, 0.20765604, 0.20313083]\n",
      "[0.6281577, 0.2, 0.21489555, 0.20135528]\n",
      "[0.61673415, 0.2, 0.2026853, 0.20214729]\n",
      "[0.6183725, 0.2, 0.20375295, 0.20272349]\n",
      "[0.6625965, 0.2, 0.21684416, 0.23386204]\n",
      "[0.6242262, 0.2, 0.21085727, 0.20148325]\n",
      "[0.6197306, 0.2, 0.20766611, 0.20018318]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1810 iterations: 0.6262902458508809 mins\n",
      "Train Loss: [0.6197306, 0.2, 0.20766611, 0.20018318]\n",
      "[0.62856597, 0.2, 0.21462499, 0.20206392]\n",
      "[0.61952573, 0.2, 0.2053319, 0.20232117]\n",
      "[0.624488, 0.2, 0.20464505, 0.20797496]\n",
      "[0.62737304, 0.2, 0.21263877, 0.20287165]\n",
      "[0.62187016, 0.2, 0.20883425, 0.20117883]\n",
      "[0.6199328, 0.2, 0.20505846, 0.20302287]\n",
      "[0.618149, 0.2, 0.2052522, 0.20105115]\n",
      "[0.6295316, 0.2, 0.21559685, 0.20209488]\n",
      "[0.63372946, 0.2, 0.21941426, 0.2024819]\n",
      "[0.6210655, 0.2, 0.2024704, 0.20676835]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1820 iterations: 0.6289604345957438 mins\n",
      "Train Loss: [0.6210655, 0.2, 0.2024704, 0.20676835]\n",
      "[0.62507015, 0.2, 0.21135023, 0.2018996]\n",
      "[0.6222573, 0.2, 0.20827493, 0.20216848]\n",
      "[0.6184538, 0.2, 0.20456444, 0.20208178]\n",
      "[0.61819625, 0.2, 0.20538083, 0.20101446]\n",
      "[0.6807572, 0.2, 0.2656672, 0.20329627]\n",
      "[0.6246246, 0.2, 0.21043895, 0.20239097]\n",
      "[0.637307, 0.2, 0.22225326, 0.20325752]\n",
      "[0.63159454, 0.2, 0.21780407, 0.20199315]\n",
      "[0.62543416, 0.2, 0.21179377, 0.20184124]\n",
      "[0.6168672, 0.2, 0.20283051, 0.20223671]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1830 iterations: 0.6324314475059509 mins\n",
      "Train Loss: [0.6168672, 0.2, 0.20283051, 0.20223671]\n",
      "[0.6198118, 0.2, 0.20699951, 0.20101175]\n",
      "[0.61949396, 0.2, 0.20527361, 0.20241998]\n",
      "[0.61739975, 0.2, 0.20425183, 0.20134799]\n",
      "[0.6182181, 0.2, 0.20362172, 0.20279741]\n",
      "[0.62012833, 0.2, 0.20561115, 0.2027198]\n",
      "[0.6201252, 0.2, 0.20695649, 0.2013733]\n",
      "[0.62230587, 0.2, 0.20879756, 0.2017156]\n",
      "[0.6346448, 0.2, 0.21875326, 0.20410198]\n",
      "[0.61873543, 0.2, 0.20590173, 0.20104837]\n",
      "[0.6209036, 0.2, 0.20721638, 0.20190625]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1840 iterations: 0.6349515159924825 mins\n",
      "Train Loss: [0.6209036, 0.2, 0.20721638, 0.20190625]\n",
      "[0.62003124, 0.2, 0.20426798, 0.20398673]\n",
      "[0.6236082, 0.2, 0.20904207, 0.20279425]\n",
      "[0.62011176, 0.2, 0.20516425, 0.20318028]\n",
      "[0.6285118, 0.2, 0.21646187, 0.20028728]\n",
      "[0.6253163, 0.2, 0.20584044, 0.20771857]\n",
      "[0.64104676, 0.2, 0.20320217, 0.22609247]\n",
      "[0.6248801, 0.2, 0.20627865, 0.20685379]\n",
      "[0.6227658, 0.2, 0.20779715, 0.20322572]\n",
      "[0.6240132, 0.2, 0.20997329, 0.20230144]\n",
      "[0.62363935, 0.2, 0.21046965, 0.2014358]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1850 iterations: 0.6373627344767253 mins\n",
      "Train Loss: [0.62363935, 0.2, 0.21046965, 0.2014358]\n",
      "[0.62245154, 0.2, 0.20675375, 0.20396863]\n",
      "[0.61948377, 0.2, 0.20475514, 0.20300443]\n",
      "[0.6155937, 0.2, 0.20209779, 0.20177694]\n",
      "[0.6250605, 0.2, 0.20681742, 0.20652992]\n",
      "[0.61424315, 0.2, 0.20135456, 0.20118128]\n",
      "[0.621551, 0.2, 0.20930868, 0.20054096]\n",
      "[0.6318599, 0.2, 0.21377406, 0.20639099]\n",
      "[0.6295681, 0.2, 0.21316372, 0.20471577]\n",
      "[0.6189474, 0.2, 0.20519863, 0.20206589]\n",
      "[0.6240823, 0.2, 0.21053444, 0.2018705]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1860 iterations: 0.6397262334823608 mins\n",
      "Train Loss: [0.6240823, 0.2, 0.21053444, 0.2018705]\n",
      "[0.62385994, 0.2, 0.21099599, 0.20119254]\n",
      "[0.6295802, 0.2, 0.21385632, 0.20405807]\n",
      "[0.6247933, 0.2, 0.21177958, 0.20135285]\n",
      "[0.61929995, 0.2, 0.20608047, 0.20156246]\n",
      "[0.6240676, 0.2, 0.20822407, 0.20419054]\n",
      "[0.6221577, 0.2, 0.20351708, 0.20699163]\n",
      "[0.6235817, 0.2, 0.20991543, 0.20202148]\n",
      "[0.6214413, 0.2, 0.20665863, 0.20314229]\n",
      "[0.6251394, 0.2, 0.21074712, 0.20275672]\n",
      "[0.6210884, 0.2, 0.2058207, 0.20363705]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1870 iterations: 0.6419290661811828 mins\n",
      "Train Loss: [0.6210884, 0.2, 0.2058207, 0.20363705]\n",
      "[0.6199765, 0.2, 0.20671977, 0.20163131]\n",
      "[0.63389426, 0.2, 0.21635093, 0.20592315]\n",
      "[0.62201464, 0.2, 0.2061609, 0.20423831]\n",
      "[0.6260367, 0.2, 0.20927344, 0.20515278]\n",
      "[0.6205071, 0.2, 0.20471126, 0.20419039]\n",
      "[0.61763394, 0.2, 0.20420648, 0.20182694]\n",
      "[0.6629825, 0.2, 0.2087486, 0.24263853]\n",
      "[0.6351588, 0.2, 0.22113627, 0.20243248]\n",
      "[0.6180253, 0.2, 0.2022061, 0.20423396]\n",
      "[0.62404054, 0.2, 0.20940612, 0.20305385]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1880 iterations: 0.6447367151578267 mins\n",
      "Train Loss: [0.62404054, 0.2, 0.20940612, 0.20305385]\n",
      "[0.61967826, 0.2, 0.2033388, 0.20476392]\n",
      "[0.63569754, 0.2, 0.21226037, 0.21186619]\n",
      "[0.62191767, 0.2, 0.20307657, 0.20727369]\n",
      "[0.61738497, 0.2, 0.20418958, 0.20163165]\n",
      "[0.61754084, 0.2, 0.20415944, 0.2018216]\n",
      "[0.62549436, 0.2, 0.21277004, 0.20116888]\n",
      "[0.6197483, 0.2, 0.20393841, 0.20425878]\n",
      "[0.6246413, 0.2, 0.20958899, 0.20350543]\n",
      "[0.62054616, 0.2, 0.20726769, 0.20173594]\n",
      "[0.62124574, 0.2, 0.20602855, 0.20367905]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1890 iterations: 0.6488409320513407 mins\n",
      "Train Loss: [0.62124574, 0.2, 0.20602855, 0.20367905]\n",
      "[0.6202956, 0.2, 0.20760164, 0.20116028]\n",
      "[0.61820346, 0.2, 0.20323016, 0.2034441]\n",
      "[0.6196571, 0.2, 0.20746376, 0.2006689]\n",
      "[0.6253155, 0.2, 0.20950747, 0.20428874]\n",
      "[0.6238185, 0.2, 0.20733672, 0.20496836]\n",
      "[0.6320739, 0.2, 0.21914583, 0.20142071]\n",
      "[0.6295102, 0.2, 0.21233942, 0.20566995]\n",
      "[0.61770254, 0.2, 0.20542015, 0.20078772]\n",
      "[0.620658, 0.2, 0.20836762, 0.2008017]\n",
      "[0.6305072, 0.2, 0.2163484, 0.20267624]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1900 iterations: 0.6519930164019266 mins\n",
      "Train Loss: [0.6305072, 0.2, 0.2163484, 0.20267624]\n",
      "[0.6238303, 0.2, 0.21010365, 0.20224991]\n",
      "[0.62890005, 0.2, 0.21611853, 0.20131049]\n",
      "[0.62880784, 0.2, 0.21115834, 0.20618415]\n",
      "[0.6297299, 0.2, 0.21621382, 0.20205614]\n",
      "[0.6307282, 0.2, 0.21714139, 0.20213224]\n",
      "[0.6146331, 0.2, 0.20175426, 0.20142977]\n",
      "[0.6167509, 0.2, 0.2046661, 0.20064133]\n",
      "[0.619502, 0.2, 0.20673014, 0.2013339]\n",
      "[0.6275436, 0.2, 0.21202365, 0.20408766]\n",
      "[0.6410251, 0.2, 0.22757107, 0.20202744]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1910 iterations: 0.6549050132433574 mins\n",
      "Train Loss: [0.6410251, 0.2, 0.22757107, 0.20202744]\n",
      "[0.6194691, 0.2, 0.20614572, 0.20190275]\n",
      "[0.6300544, 0.2, 0.21299343, 0.20564607]\n",
      "[0.6330089, 0.2, 0.21883997, 0.20275925]\n",
      "[0.6311537, 0.2, 0.21865256, 0.20109674]\n",
      "[0.62545836, 0.2, 0.21297842, 0.20108026]\n",
      "[0.61900777, 0.2, 0.20587316, 0.20173915]\n",
      "[0.6343248, 0.2, 0.20797129, 0.21496233]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.618936, 0.2, 0.20660634, 0.20094174]\n",
      "[0.62107277, 0.2, 0.20846072, 0.20122758]\n",
      "[0.6179864, 0.2, 0.20415957, 0.20244603]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1920 iterations: 0.6573917349179585 mins\n",
      "Train Loss: [0.6179864, 0.2, 0.20415957, 0.20244603]\n",
      "[0.6216832, 0.2, 0.2075993, 0.20270692]\n",
      "[0.6190041, 0.2, 0.20552832, 0.20210284]\n",
      "[0.61921173, 0.2, 0.20782137, 0.20002183]\n",
      "[0.61530185, 0.2, 0.20211303, 0.20182487]\n",
      "[0.65689385, 0.2, 0.21133098, 0.23420352]\n",
      "[0.6158503, 0.2, 0.2035395, 0.20095588]\n",
      "[0.6276118, 0.2, 0.2139376, 0.20232354]\n",
      "[0.62069726, 0.2, 0.20666672, 0.20268412]\n",
      "[0.62131304, 0.2, 0.20940952, 0.20056169]\n",
      "[0.6251983, 0.2, 0.21050596, 0.2033553]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1930 iterations: 0.6611026326815287 mins\n",
      "Train Loss: [0.6251983, 0.2, 0.21050596, 0.2033553]\n",
      "[0.6230993, 0.2, 0.21061663, 0.20115042]\n",
      "[0.62094355, 0.2, 0.2070919, 0.20252451]\n",
      "[0.6280016, 0.2, 0.21371366, 0.20296578]\n",
      "[0.6234959, 0.2, 0.20879577, 0.20338315]\n",
      "[0.62888676, 0.2, 0.21355116, 0.20402388]\n",
      "[0.6182497, 0.2, 0.20603776, 0.20090534]\n",
      "[0.6308493, 0.2, 0.21632956, 0.20321825]\n",
      "[0.6229676, 0.2, 0.2094532, 0.20221834]\n",
      "[0.6218942, 0.2, 0.2087736, 0.20183074]\n",
      "[0.63187605, 0.2, 0.21876341, 0.20182924]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1940 iterations: 0.6645394523938497 mins\n",
      "Train Loss: [0.63187605, 0.2, 0.21876341, 0.20182924]\n",
      "[0.6231589, 0.2, 0.2084968, 0.20338535]\n",
      "[0.626207, 0.2, 0.21312837, 0.2018086]\n",
      "[0.61918896, 0.2, 0.20582351, 0.20210193]\n",
      "[0.6219908, 0.2, 0.20958278, 0.20115112]\n",
      "[0.6169748, 0.2, 0.20426978, 0.20145433]\n",
      "[0.6271874, 0.2, 0.21174209, 0.20420083]\n",
      "[0.6184317, 0.2, 0.20521966, 0.20197435]\n",
      "[0.63597, 0.2, 0.2211689, 0.20357034]\n",
      "[0.62005866, 0.2, 0.2076221, 0.2012128]\n",
      "[0.6215021, 0.2, 0.20844105, 0.20184407]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1950 iterations: 0.6668535828590393 mins\n",
      "Train Loss: [0.6215021, 0.2, 0.20844105, 0.20184407]\n",
      "[0.63396186, 0.2, 0.2193816, 0.20337015]\n",
      "[0.62450266, 0.2, 0.20521122, 0.20808811]\n",
      "[0.61947083, 0.2, 0.20721929, 0.20105493]\n",
      "[0.6260398, 0.2, 0.21107067, 0.20377913]\n",
      "[0.62220085, 0.2, 0.20784028, 0.2031767]\n",
      "[0.63580143, 0.2, 0.20602445, 0.21859913]\n",
      "[0.62386554, 0.2, 0.21020941, 0.20248379]\n",
      "[0.6291128, 0.2, 0.21568055, 0.20226549]\n",
      "[0.6674612, 0.2, 0.234713, 0.22158583]\n",
      "[0.6445582, 0.2, 0.20220011, 0.2311988]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1960 iterations: 0.6689941843350729 mins\n",
      "Train Loss: [0.6445582, 0.2, 0.20220011, 0.2311988]\n",
      "[0.61902577, 0.2, 0.20468365, 0.20318505]\n",
      "[0.62559474, 0.2, 0.21227144, 0.20216773]\n",
      "[0.6284083, 0.2, 0.21349484, 0.20375893]\n",
      "[0.62042314, 0.2, 0.20518222, 0.20408745]\n",
      "[0.6149284, 0.2, 0.20532615, 0.19845001]\n",
      "[0.6171604, 0.2, 0.2041485, 0.20186064]\n",
      "[0.61767924, 0.2, 0.20392305, 0.2026039]\n",
      "[0.625695, 0.2, 0.2131188, 0.20142147]\n",
      "[0.6227956, 0.2, 0.20998117, 0.20165661]\n",
      "[0.6233912, 0.2, 0.20771214, 0.20451748]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1970 iterations: 0.6709478974342347 mins\n",
      "Train Loss: [0.6233912, 0.2, 0.20771214, 0.20451748]\n",
      "[0.64027303, 0.2, 0.22590835, 0.20319945]\n",
      "[0.6238763, 0.2, 0.21078667, 0.20192063]\n",
      "[0.6199431, 0.2, 0.20655823, 0.20221241]\n",
      "[0.62388635, 0.2, 0.21135694, 0.20135391]\n",
      "[0.61819834, 0.2, 0.20588087, 0.20113924]\n",
      "[0.6183478, 0.2, 0.2049461, 0.20222162]\n",
      "[0.6373413, 0.2, 0.21834531, 0.20781483]\n",
      "[0.6224202, 0.2, 0.20831536, 0.20292331]\n",
      "[0.63007253, 0.2, 0.21280104, 0.2060903]\n",
      "[0.6618533, 0.2, 0.2259695, 0.22470373]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1980 iterations: 0.6732121864954631 mins\n",
      "Train Loss: [0.6618533, 0.2, 0.2259695, 0.22470373]\n",
      "[0.63018847, 0.2, 0.21793015, 0.20107937]\n",
      "[0.6553676, 0.2, 0.2375956, 0.2065944]\n",
      "[0.6179484, 0.2, 0.20452426, 0.20224695]\n",
      "[0.65279657, 0.2, 0.20140159, 0.24021848]\n",
      "[0.674194, 0.2, 0.2617892, 0.20122893]\n",
      "[0.61541325, 0.2, 0.20260336, 0.20162468]\n",
      "[0.6277885, 0.2, 0.21466155, 0.20193304]\n",
      "[0.62745166, 0.2, 0.2125827, 0.20366687]\n",
      "[0.6350645, 0.2, 0.2203791, 0.20347558]\n",
      "[0.62340295, 0.2, 0.20676115, 0.2054247]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1990 iterations: 0.6758211334546407 mins\n",
      "Train Loss: [0.62340295, 0.2, 0.20676115, 0.2054247]\n",
      "[0.6141777, 0.2, 0.20208883, 0.20086522]\n",
      "[0.61940193, 0.2, 0.20686294, 0.20130964]\n",
      "[0.6231584, 0.2, 0.21001168, 0.2019125]\n",
      "[0.61808753, 0.2, 0.20434965, 0.2024996]\n",
      "[0.6214571, 0.2, 0.20771828, 0.20249762]\n",
      "[0.6183922, 0.2, 0.20394711, 0.20320182]\n",
      "[0.6146623, 0.2, 0.20171514, 0.20170258]\n",
      "[0.6260146, 0.2, 0.2137299, 0.20103998]\n",
      "[0.61847484, 0.2, 0.20514567, 0.20208521]\n",
      "[0.6183235, 0.2, 0.20370978, 0.20337099]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2000 iterations: 0.6799017667770386 mins\n",
      "Train Loss: [0.6183235, 0.2, 0.20370978, 0.20337099]\n",
      "[0.62556595, 0.2, 0.21266276, 0.20166275]\n",
      "[0.6212621, 0.2, 0.20194344, 0.20808081]\n",
      "[0.6234101, 0.2, 0.20895621, 0.20321947]\n",
      "[0.62143964, 0.2, 0.20653923, 0.20367013]\n",
      "[0.6247109, 0.2, 0.20515029, 0.20833464]\n",
      "[0.6185152, 0.2, 0.2046183, 0.20267601]\n",
      "[0.6266023, 0.2, 0.21087494, 0.2045121]\n",
      "[0.61865914, 0.2, 0.20498948, 0.2024603]\n",
      "[0.6131299, 0.2, 0.20168506, 0.20024179]\n",
      "[0.6271465, 0.2, 0.2101031, 0.20584722]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2010 iterations: 0.683124299844106 mins\n",
      "Train Loss: [0.6271465, 0.2, 0.2101031, 0.20584722]\n",
      "[0.6353542, 0.2, 0.22064568, 0.20351975]\n",
      "[0.61730427, 0.2, 0.20402105, 0.20210129]\n",
      "[0.61754715, 0.2, 0.20441915, 0.20195317]\n",
      "[0.62337524, 0.2, 0.20863582, 0.20357195]\n",
      "[0.6249021, 0.2, 0.20824024, 0.2055017]\n",
      "[0.6177003, 0.2, 0.20155916, 0.20498879]\n",
      "[0.6182091, 0.2, 0.20325926, 0.20380533]\n",
      "[0.62128115, 0.2, 0.20472533, 0.20541912]\n",
      "[0.6204119, 0.2, 0.20691219, 0.20237064]\n",
      "[0.6297339, 0.2, 0.21542716, 0.20318563]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2020 iterations: 0.6859778165817261 mins\n",
      "Train Loss: [0.6297339, 0.2, 0.21542716, 0.20318563]\n",
      "[0.62849706, 0.2, 0.21285409, 0.20452964]\n",
      "[0.6185013, 0.2, 0.2061829, 0.20121263]\n",
      "[0.62325174, 0.2, 0.2104273, 0.20172615]\n",
      "[0.6211674, 0.2, 0.20594263, 0.20413412]\n",
      "[0.62054217, 0.2, 0.20577183, 0.2036872]\n",
      "[0.6213409, 0.2, 0.20825073, 0.20201452]\n",
      "[0.6165104, 0.2, 0.20461163, 0.20083086]\n",
      "[0.6325597, 0.2, 0.2177515, 0.20374854]\n",
      "[0.6265251, 0.2, 0.21107908, 0.2043942]\n",
      "[0.62408596, 0.2, 0.21177429, 0.20126739]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2030 iterations: 0.6888658324877421 mins\n",
      "Train Loss: [0.62408596, 0.2, 0.21177429, 0.20126739]\n",
      "[0.6167079, 0.2, 0.2046609, 0.20101024]\n",
      "[0.6260224, 0.2, 0.21275756, 0.2022356]\n",
      "[0.6136623, 0.2, 0.20157355, 0.20106697]\n",
      "[0.6136517, 0.2, 0.2008022, 0.20183538]\n",
      "[0.6213238, 0.2, 0.20551498, 0.20480253]\n",
      "[0.62274945, 0.2, 0.20907034, 0.20268074]\n",
      "[0.630709, 0.2, 0.21652302, 0.20319568]\n",
      "[0.6181967, 0.2, 0.20492388, 0.20229031]\n",
      "[0.61505324, 0.2, 0.20162237, 0.20245616]\n",
      "[0.62099427, 0.2, 0.20774274, 0.20228474]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2040 iterations: 0.691737417380015 mins\n",
      "Train Loss: [0.62099427, 0.2, 0.20774274, 0.20228474]\n",
      "[0.62511134, 0.2, 0.21063806, 0.20351435]\n",
      "[0.62051386, 0.2, 0.20871669, 0.20084637]\n",
      "[0.6213715, 0.2, 0.21059093, 0.19983792]\n",
      "[0.61319935, 0.2, 0.20184276, 0.20042156]\n",
      "[0.62782025, 0.2, 0.21487981, 0.20201306]\n",
      "[0.61699724, 0.2, 0.20420271, 0.20187488]\n",
      "[0.61679494, 0.2, 0.20443518, 0.20144777]\n",
      "[0.6207499, 0.2, 0.20835853, 0.20148711]\n",
      "[0.61858267, 0.2, 0.20566024, 0.20202602]\n",
      "[0.6228966, 0.2, 0.20962887, 0.20237914]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2050 iterations: 0.6940556486447652 mins\n",
      "Train Loss: [0.6228966, 0.2, 0.20962887, 0.20237914]\n",
      "[0.6192928, 0.2, 0.2042891, 0.2041229]\n",
      "[0.62801105, 0.2, 0.21415178, 0.20298675]\n",
      "[0.6268603, 0.2, 0.21207397, 0.203922]\n",
      "[0.615955, 0.2, 0.20214015, 0.20295814]\n",
      "[0.62156385, 0.2, 0.20817074, 0.20254403]\n",
      "[0.6160299, 0.2, 0.20312871, 0.20205955]\n",
      "[0.6390295, 0.2, 0.22494085, 0.2032544]\n",
      "[0.6223585, 0.2, 0.21001378, 0.20151769]\n",
      "[0.62052923, 0.2, 0.20817971, 0.20152967]\n",
      "[0.618914, 0.2, 0.20658468, 0.20151651]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2060 iterations: 0.696441666285197 mins\n",
      "Train Loss: [0.618914, 0.2, 0.20658468, 0.20151651]\n",
      "[0.6200835, 0.2, 0.2075953, 0.20168182]\n",
      "[0.6350397, 0.2, 0.2212801, 0.20295943]\n",
      "[0.6151808, 0.2, 0.20312048, 0.2012666]\n",
      "[0.61395335, 0.2, 0.2011138, 0.20205222]\n",
      "[0.63034177, 0.2, 0.21616097, 0.20339979]\n",
      "[0.6222902, 0.2, 0.21003443, 0.20148075]\n",
      "[0.62557036, 0.2, 0.21335551, 0.2014457]\n",
      "[0.6233619, 0.2, 0.21050538, 0.20209308]\n",
      "[0.619853, 0.2, 0.20702685, 0.20206867]\n",
      "[0.61843675, 0.2, 0.20276205, 0.2049236]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2070 iterations: 0.6993732651074728 mins\n",
      "Train Loss: [0.61843675, 0.2, 0.20276205, 0.2049236]\n",
      "[0.6268353, 0.2, 0.21457642, 0.20151421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61550426, 0.2, 0.20246978, 0.20229594]\n",
      "[0.61966914, 0.2, 0.208103, 0.20083384]\n",
      "[0.63131577, 0.2, 0.21922879, 0.20136102]\n",
      "[0.62812567, 0.2, 0.21577786, 0.20162824]\n",
      "[0.61498976, 0.2, 0.20253439, 0.20174193]\n",
      "[0.6204353, 0.2, 0.20429851, 0.20542979]\n",
      "[0.61874247, 0.2, 0.20652702, 0.20151477]\n",
      "[0.6198289, 0.2, 0.20661615, 0.20251836]\n",
      "[0.6144528, 0.2, 0.20247857, 0.2012854]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2080 iterations: 0.702396563688914 mins\n",
      "Train Loss: [0.6144528, 0.2, 0.20247857, 0.2012854]\n",
      "[0.620924, 0.2, 0.20880131, 0.20143959]\n",
      "[0.6173267, 0.2, 0.204961, 0.20168823]\n",
      "[0.6148007, 0.2, 0.20255624, 0.20157266]\n",
      "[0.6190258, 0.2, 0.20691028, 0.2014495]\n",
      "[0.6173961, 0.2, 0.2029338, 0.20380227]\n",
      "[0.61888266, 0.2, 0.20455915, 0.2036696]\n",
      "[0.63201463, 0.2, 0.22093388, 0.20043322]\n",
      "[0.61540127, 0.2, 0.20252052, 0.2022401]\n",
      "[0.6249395, 0.2, 0.21288759, 0.20141791]\n",
      "[0.6157002, 0.2, 0.20287788, 0.20219375]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2090 iterations: 0.7074198365211487 mins\n",
      "Train Loss: [0.6157002, 0.2, 0.20287788, 0.20219375]\n",
      "[0.61916333, 0.2, 0.20528625, 0.203254]\n",
      "[0.6200414, 0.2, 0.20663527, 0.20278841]\n",
      "[0.6204573, 0.2, 0.20900127, 0.2008437]\n",
      "[0.61806196, 0.2, 0.2049228, 0.20253289]\n",
      "[0.6164332, 0.2, 0.20423308, 0.20159988]\n",
      "[0.6146898, 0.2, 0.20087454, 0.20322116]\n",
      "[0.6206, 0.2, 0.20859249, 0.20141956]\n",
      "[0.642662, 0.2, 0.20185614, 0.23022358]\n",
      "[0.61848193, 0.2, 0.20623657, 0.20166841]\n",
      "[0.6163659, 0.2, 0.20325334, 0.202541]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2100 iterations: 0.7114088296890259 mins\n",
      "Train Loss: [0.6163659, 0.2, 0.20325334, 0.202541]\n",
      "[0.61958045, 0.2, 0.20762645, 0.201388]\n",
      "[0.61800176, 0.2, 0.20535113, 0.20208986]\n",
      "[0.6204569, 0.2, 0.2089997, 0.20090124]\n",
      "[0.6156547, 0.2, 0.20376474, 0.20133886]\n",
      "[0.6160513, 0.2, 0.20387663, 0.20162833]\n",
      "[0.62130445, 0.2, 0.2085025, 0.20226014]\n",
      "[0.6155509, 0.2, 0.20394142, 0.20107204]\n",
      "[0.6262719, 0.2, 0.20474942, 0.21098962]\n",
      "[0.6280625, 0.2, 0.21482779, 0.20270663]\n",
      "[0.61696416, 0.2, 0.20562011, 0.20082022]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2110 iterations: 0.7149992823600769 mins\n",
      "Train Loss: [0.61696416, 0.2, 0.20562011, 0.20082022]\n",
      "[0.6295312, 0.2, 0.21422343, 0.20478785]\n",
      "[0.6138593, 0.2, 0.20139776, 0.20194398]\n",
      "[0.6319848, 0.2, 0.21928917, 0.20218006]\n",
      "[0.61702096, 0.2, 0.20586795, 0.2006393]\n",
      "[0.61901695, 0.2, 0.20466004, 0.20384489]\n",
      "[0.6191322, 0.2, 0.20536776, 0.20325431]\n",
      "[0.6214874, 0.2, 0.20768905, 0.20329039]\n",
      "[0.6354829, 0.2, 0.2227519, 0.20222558]\n",
      "[0.61511505, 0.2, 0.20282198, 0.20179003]\n",
      "[0.642515, 0.2, 0.23062584, 0.20138888]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2120 iterations: 0.7184738993644715 mins\n",
      "Train Loss: [0.642515, 0.2, 0.23062584, 0.20138888]\n",
      "[0.6138388, 0.2, 0.20300178, 0.20034002]\n",
      "[0.61286944, 0.2, 0.20169765, 0.20067917]\n",
      "[0.63193727, 0.2, 0.216276, 0.20517398]\n",
      "[0.6133654, 0.2, 0.20201488, 0.2008682]\n",
      "[0.6252734, 0.2, 0.21160403, 0.20319209]\n",
      "[0.61912674, 0.2, 0.2073935, 0.20126131]\n",
      "[0.637179, 0.2, 0.22510025, 0.20161247]\n",
      "[0.6154889, 0.2, 0.20273925, 0.20228846]\n",
      "[0.6225534, 0.2, 0.21055156, 0.20154601]\n",
      "[0.6136676, 0.2, 0.20172521, 0.20149185]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2130 iterations: 0.7217548131942749 mins\n",
      "Train Loss: [0.6136676, 0.2, 0.20172521, 0.20149185]\n",
      "[0.6167694, 0.2, 0.20575719, 0.20056726]\n",
      "[0.61738056, 0.2, 0.20637304, 0.20056826]\n",
      "[0.6446649, 0.2, 0.23299111, 0.20124027]\n",
      "[0.6426768, 0.2, 0.21908519, 0.2131663]\n",
      "[0.62028813, 0.2, 0.20740157, 0.20246738]\n",
      "[0.6211524, 0.2, 0.2100616, 0.20067665]\n",
      "[0.62899154, 0.2, 0.21706559, 0.20151629]\n",
      "[0.61281615, 0.2, 0.20140307, 0.20100734]\n",
      "[0.6288349, 0.2, 0.21447682, 0.20395617]\n",
      "[0.6268901, 0.2, 0.21367592, 0.20281592]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2140 iterations: 0.7249574661254883 mins\n",
      "Train Loss: [0.6268901, 0.2, 0.21367592, 0.20281592]\n",
      "[0.61392057, 0.2, 0.20286155, 0.2006641]\n",
      "[0.6126195, 0.2, 0.20199934, 0.20022933]\n",
      "[0.6238799, 0.2, 0.20697379, 0.20651928]\n",
      "[0.6340629, 0.2, 0.22056004, 0.20312074]\n",
      "[0.61329967, 0.2, 0.20217326, 0.20074834]\n",
      "[0.6156097, 0.2, 0.20352276, 0.20171344]\n",
      "[0.6369431, 0.2, 0.22123224, 0.2053421]\n",
      "[0.6139693, 0.2, 0.20262817, 0.20097652]\n",
      "[0.6187221, 0.2, 0.2066609, 0.20170063]\n",
      "[0.61775243, 0.2, 0.20449749, 0.20289828]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2150 iterations: 0.728196382522583 mins\n",
      "Train Loss: [0.61775243, 0.2, 0.20449749, 0.20289828]\n",
      "[0.63144255, 0.2, 0.21912584, 0.2019634]\n",
      "[0.61375797, 0.2, 0.19838136, 0.20502687]\n",
      "[0.6296721, 0.2, 0.21210067, 0.20722558]\n",
      "[0.6146696, 0.2, 0.20162216, 0.2027052]\n",
      "[0.6229768, 0.2, 0.20959266, 0.203045]\n",
      "[0.6157565, 0.2, 0.20264995, 0.2027717]\n",
      "[0.62437695, 0.2, 0.21407236, 0.19997425]\n",
      "[0.6115423, 0.2, 0.20131809, 0.19989833]\n",
      "[0.6248902, 0.2, 0.20922755, 0.20534168]\n",
      "[0.6231391, 0.2, 0.21003924, 0.20278305]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2160 iterations: 0.7320154309272766 mins\n",
      "Train Loss: [0.6231391, 0.2, 0.21003924, 0.20278305]\n",
      "[0.64856887, 0.2, 0.19892961, 0.23932631]\n",
      "[0.61926246, 0.2, 0.20514363, 0.2038107]\n",
      "[0.63052297, 0.2, 0.21904755, 0.20117098]\n",
      "[0.6237699, 0.2, 0.2082296, 0.20523967]\n",
      "[0.61732906, 0.2, 0.20472382, 0.20230862]\n",
      "[0.6160827, 0.2, 0.20069319, 0.20509678]\n",
      "[0.62195104, 0.2, 0.20689435, 0.20476796]\n",
      "[0.6342166, 0.2, 0.21571083, 0.20822115]\n",
      "[0.6355125, 0.2, 0.2227997, 0.20243278]\n",
      "[0.6204116, 0.2, 0.20795417, 0.20218064]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2170 iterations: 0.7345209836959838 mins\n",
      "Train Loss: [0.6204116, 0.2, 0.20795417, 0.20218064]\n",
      "[0.6208669, 0.2, 0.20262565, 0.20796686]\n",
      "[0.62709945, 0.2, 0.21601948, 0.20080648]\n",
      "[0.6209455, 0.2, 0.20954712, 0.20112354]\n",
      "[0.6583209, 0.2, 0.2452041, 0.20284073]\n",
      "[0.62359405, 0.2, 0.21106221, 0.20225276]\n",
      "[0.62589335, 0.2, 0.21351488, 0.20209624]\n",
      "[0.6243546, 0.2, 0.21143268, 0.2026358]\n",
      "[0.6341153, 0.2, 0.22323714, 0.20058823]\n",
      "[0.61057633, 0.2, 0.19928522, 0.2009976]\n",
      "[0.62929744, 0.2, 0.21216376, 0.20683707]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2180 iterations: 0.7376033306121826 mins\n",
      "Train Loss: [0.62929744, 0.2, 0.21216376, 0.20683707]\n",
      "[0.62178135, 0.2, 0.2100415, 0.20144023]\n",
      "[0.61314976, 0.2, 0.20113474, 0.20171389]\n",
      "[0.6155723, 0.2, 0.2048034, 0.20046687]\n",
      "[0.6290947, 0.2, 0.2185416, 0.20025086]\n",
      "[0.61522365, 0.2, 0.20332673, 0.20159478]\n",
      "[0.6394145, 0.2, 0.21654324, 0.21257019]\n",
      "[0.618138, 0.2, 0.20537192, 0.20246635]\n",
      "[0.6315477, 0.2, 0.21864611, 0.20260333]\n",
      "[0.61807305, 0.2, 0.2061808, 0.2015953]\n",
      "[0.6178688, 0.2, 0.20687242, 0.2007009]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2190 iterations: 0.7404479304949443 mins\n",
      "Train Loss: [0.6178688, 0.2, 0.20687242, 0.2007009]\n",
      "[0.61961013, 0.2, 0.20741397, 0.20190237]\n",
      "[0.6292372, 0.2, 0.21494828, 0.20399673]\n",
      "[0.6122039, 0.2, 0.20063666, 0.20127696]\n",
      "[0.6346625, 0.2, 0.20917127, 0.2152032]\n",
      "[0.617065, 0.2, 0.20351733, 0.20326033]\n",
      "[0.631867, 0.2, 0.21885534, 0.20272504]\n",
      "[0.6190443, 0.2, 0.20580898, 0.20294957]\n",
      "[0.61999595, 0.2, 0.20891848, 0.20079313]\n",
      "[0.6391055, 0.2, 0.21316257, 0.21565968]\n",
      "[0.62173355, 0.2, 0.20644118, 0.20500962]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2200 iterations: 0.7433796167373657 mins\n",
      "Train Loss: [0.62173355, 0.2, 0.20644118, 0.20500962]\n",
      "[0.61378765, 0.2, 0.2015024, 0.20200294]\n",
      "[0.6161013, 0.2, 0.20466022, 0.20115863]\n",
      "[0.64450425, 0.2, 0.23333266, 0.2008891]\n",
      "[0.65085626, 0.2, 0.23865262, 0.20192158]\n",
      "[0.61680365, 0.2, 0.20499046, 0.20153101]\n",
      "[0.61452895, 0.2, 0.20224407, 0.20200339]\n",
      "[0.6169286, 0.2, 0.20588021, 0.20076817]\n",
      "[0.6163326, 0.2, 0.20536172, 0.20069225]\n",
      "[0.63450307, 0.2, 0.22133268, 0.20289354]\n",
      "[0.6284587, 0.2, 0.2105093, 0.2076789]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2210 iterations: 0.7461146831512451 mins\n",
      "Train Loss: [0.6284587, 0.2, 0.2105093, 0.2076789]\n",
      "[0.6431413, 0.2, 0.22955288, 0.20332262]\n",
      "[0.6113467, 0.2, 0.19961554, 0.20146964]\n",
      "[0.6200313, 0.2, 0.20432536, 0.20544869]\n",
      "[0.6534159, 0.2, 0.20690809, 0.2362546]\n",
      "[0.6253666, 0.2, 0.20892395, 0.20619455]\n",
      "[0.6163117, 0.2, 0.20514585, 0.2009223]\n",
      "[0.61619586, 0.2, 0.20543808, 0.20051824]\n",
      "[0.6217255, 0.2, 0.20847881, 0.20301059]\n",
      "[0.62466556, 0.2, 0.21015373, 0.20427871]\n",
      "[0.6289094, 0.2, 0.21113142, 0.20754746]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2220 iterations: 0.7497471809387207 mins\n",
      "Train Loss: [0.6289094, 0.2, 0.21113142, 0.20754746]\n",
      "[0.6187877, 0.2, 0.20428406, 0.20427579]\n",
      "[0.61340827, 0.2, 0.2024878, 0.2006952]\n",
      "[0.6111376, 0.2, 0.19896196, 0.20195258]\n",
      "[0.62649167, 0.2, 0.21439523, 0.2018748]\n",
      "[0.61718243, 0.2, 0.20104478, 0.2059173]\n",
      "[0.62675023, 0.2, 0.2139754, 0.20255555]\n",
      "[0.6114127, 0.2, 0.19905984, 0.20213297]\n",
      "[0.67280054, 0.2, 0.21365374, 0.24892628]\n",
      "[0.61686265, 0.2, 0.20547879, 0.20115986]\n",
      "[0.64565897, 0.2, 0.23476653, 0.20066391]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2230 iterations: 0.7521947503089905 mins\n",
      "Train Loss: [0.64565897, 0.2, 0.23476653, 0.20066391]\n",
      "[0.6193072, 0.2, 0.20857413, 0.20050018]\n",
      "[0.6672893, 0.2, 0.2144668, 0.24258451]\n",
      "[0.62138474, 0.2, 0.20888014, 0.20226103]\n",
      "[0.62648416, 0.2, 0.21552968, 0.20070502]\n",
      "[0.6207541, 0.2, 0.20995443, 0.20054221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6128509, 0.2, 0.20217608, 0.20040955]\n",
      "[0.63303995, 0.2, 0.21857171, 0.20419611]\n",
      "[0.62910837, 0.2, 0.21707304, 0.2017576]\n",
      "[0.6174019, 0.2, 0.2026388, 0.20448041]\n",
      "[0.61221045, 0.2, 0.20079964, 0.20112395]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2240 iterations: 0.7552114009857178 mins\n",
      "Train Loss: [0.61221045, 0.2, 0.20079964, 0.20112395]\n",
      "[0.65273917, 0.2, 0.24216805, 0.2002811]\n",
      "[0.62370086, 0.2, 0.20345184, 0.20995656]\n",
      "[0.6267371, 0.2, 0.21285792, 0.203585]\n",
      "[0.62651587, 0.2, 0.21077465, 0.2054435]\n",
      "[0.6147276, 0.2, 0.20302391, 0.2014016]\n",
      "[0.6282112, 0.2, 0.21322414, 0.20468093]\n",
      "[0.6648844, 0.2, 0.20323333, 0.25134104]\n",
      "[0.6298781, 0.2, 0.21749261, 0.20207162]\n",
      "[0.6282283, 0.2, 0.21455885, 0.20335163]\n",
      "[0.63913417, 0.2, 0.22833519, 0.20047735]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2250 iterations: 0.7583551327387492 mins\n",
      "Train Loss: [0.63913417, 0.2, 0.22833519, 0.20047735]\n",
      "[0.63382447, 0.2, 0.22192544, 0.20157354]\n",
      "[0.61297613, 0.2, 0.20014925, 0.20249891]\n",
      "[0.62524986, 0.2, 0.21418618, 0.20073391]\n",
      "[0.62927085, 0.2, 0.21709245, 0.20184802]\n",
      "[0.61772543, 0.2, 0.20681937, 0.20057613]\n",
      "[0.63055575, 0.2, 0.21659043, 0.20363675]\n",
      "[0.6244881, 0.2, 0.214113, 0.20004897]\n",
      "[0.6400155, 0.2, 0.22496685, 0.20472535]\n",
      "[0.6176516, 0.2, 0.20296226, 0.20436844]\n",
      "[0.61781687, 0.2, 0.20200595, 0.20549329]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2260 iterations: 0.7611698985099793 mins\n",
      "Train Loss: [0.61781687, 0.2, 0.20200595, 0.20549329]\n",
      "[0.625203, 0.2, 0.21247965, 0.20240965]\n",
      "[0.6263727, 0.2, 0.21448056, 0.20158269]\n",
      "[0.61910015, 0.2, 0.20034745, 0.20844774]\n",
      "[0.62694114, 0.2, 0.2136259, 0.20301479]\n",
      "[0.6287041, 0.2, 0.21544619, 0.2029623]\n",
      "[0.6168304, 0.2, 0.2034152, 0.20312475]\n",
      "[0.615083, 0.2, 0.20383132, 0.20096706]\n",
      "[0.62887305, 0.2, 0.2181295, 0.20046517]\n",
      "[0.62729394, 0.2, 0.21490379, 0.20211828]\n",
      "[0.6113668, 0.2, 0.19933838, 0.201763]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2270 iterations: 0.764829683303833 mins\n",
      "Train Loss: [0.6113668, 0.2, 0.19933838, 0.201763]\n",
      "[0.6176725, 0.2, 0.20162705, 0.20578694]\n",
      "[0.61578536, 0.2, 0.2035324, 0.2020018]\n",
      "[0.62697214, 0.2, 0.21548972, 0.20123872]\n",
      "[0.6506188, 0.2, 0.23737991, 0.20300277]\n",
      "[0.621323, 0.2, 0.21082874, 0.20026532]\n",
      "[0.6150853, 0.2, 0.20321473, 0.20164838]\n",
      "[0.6279349, 0.2, 0.21586695, 0.20185369]\n",
      "[0.616708, 0.2, 0.20480227, 0.20169841]\n",
      "[0.6143414, 0.2, 0.20298468, 0.20115629]\n",
      "[0.6177839, 0.2, 0.20513998, 0.2024502]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2280 iterations: 0.767438801129659 mins\n",
      "Train Loss: [0.6177839, 0.2, 0.20513998, 0.2024502]\n",
      "[0.61371267, 0.2, 0.20229255, 0.20123301]\n",
      "[0.62580794, 0.2, 0.21286361, 0.20276396]\n",
      "[0.6283569, 0.2, 0.21569371, 0.20248981]\n",
      "[0.6262253, 0.2, 0.21292266, 0.20313619]\n",
      "[0.6176825, 0.2, 0.2057111, 0.20181192]\n",
      "[0.62273985, 0.2, 0.21106395, 0.20152356]\n",
      "[0.61585665, 0.2, 0.20533657, 0.20037548]\n",
      "[0.6200527, 0.2, 0.2075301, 0.20238595]\n",
      "[0.6239112, 0.2, 0.21269087, 0.20109172]\n",
      "[0.6221172, 0.2, 0.20944366, 0.20255359]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2290 iterations: 0.7697784463564555 mins\n",
      "Train Loss: [0.6221172, 0.2, 0.20944366, 0.20255359]\n",
      "[0.61873657, 0.2, 0.20650993, 0.20211524]\n",
      "[0.6503635, 0.2, 0.2399216, 0.20033903]\n",
      "[0.6623813, 0.2, 0.25076, 0.20152453]\n",
      "[0.61360264, 0.2, 0.20269352, 0.20081593]\n",
      "[0.62734425, 0.2, 0.21398091, 0.20327365]\n",
      "[0.6318035, 0.2, 0.22058927, 0.20112783]\n",
      "[0.61763996, 0.2, 0.20656158, 0.20099445]\n",
      "[0.6273773, 0.2, 0.21586916, 0.20142701]\n",
      "[0.6344959, 0.2, 0.22132528, 0.2030928]\n",
      "[0.6157399, 0.2, 0.20305882, 0.2026034]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2300 iterations: 0.7731788992881775 mins\n",
      "Train Loss: [0.6157399, 0.2, 0.20305882, 0.2026034]\n",
      "[0.623497, 0.2, 0.21144837, 0.20197089]\n",
      "[0.6400084, 0.2, 0.21017684, 0.21975331]\n",
      "[0.6326399, 0.2, 0.22083977, 0.20172086]\n",
      "[0.61501664, 0.2, 0.20407543, 0.20086014]\n",
      "[0.6235214, 0.2, 0.21157178, 0.20186709]\n",
      "[0.6176837, 0.2, 0.20651458, 0.20108527]\n",
      "[0.6644509, 0.2, 0.24908294, 0.20528309]\n",
      "[0.6148854, 0.2, 0.20380159, 0.2009967]\n",
      "[0.6209973, 0.2, 0.20890898, 0.20199943]\n",
      "[0.6157139, 0.2, 0.20431289, 0.20131063]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2310 iterations: 0.7760556817054749 mins\n",
      "Train Loss: [0.6157139, 0.2, 0.20431289, 0.20131063]\n",
      "[0.6346479, 0.2, 0.21889783, 0.20565884]\n",
      "[0.6242858, 0.2, 0.2116888, 0.2025049]\n",
      "[0.63893044, 0.2, 0.20353264, 0.22530594]\n",
      "[0.612505, 0.2, 0.2021705, 0.20024598]\n",
      "[0.6247344, 0.2, 0.21002665, 0.20462197]\n",
      "[0.6275825, 0.2, 0.213726, 0.20377262]\n",
      "[0.61858934, 0.2, 0.20539674, 0.20311005]\n",
      "[0.620771, 0.2, 0.20878597, 0.20190392]\n",
      "[0.6234159, 0.2, 0.21121883, 0.20211765]\n",
      "[0.656684, 0.2, 0.2451125, 0.20149352]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2320 iterations: 0.7797828634579976 mins\n",
      "Train Loss: [0.656684, 0.2, 0.2451125, 0.20149352]\n",
      "[0.6234534, 0.2, 0.20949276, 0.20388508]\n",
      "[0.6294642, 0.2, 0.21876538, 0.20062551]\n",
      "[0.61515445, 0.2, 0.20284471, 0.20223837]\n",
      "[0.62321484, 0.2, 0.2094264, 0.20371881]\n",
      "[0.63035446, 0.2, 0.21882829, 0.20145881]\n",
      "[0.620072, 0.2, 0.20707309, 0.2029336]\n",
      "[0.6160834, 0.2, 0.20273733, 0.2032825]\n",
      "[0.63125706, 0.2, 0.21875408, 0.20244105]\n",
      "[0.6337624, 0.2, 0.2167315, 0.20697078]\n",
      "[0.61977476, 0.2, 0.20812371, 0.20159326]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2330 iterations: 0.7838334997495016 mins\n",
      "Train Loss: [0.61977476, 0.2, 0.20812371, 0.20159326]\n",
      "[0.6226238, 0.2, 0.21053588, 0.20203115]\n",
      "[0.66795677, 0.2, 0.21286261, 0.2450378]\n",
      "[0.6257898, 0.2, 0.21432015, 0.20141335]\n",
      "[0.6177519, 0.2, 0.20607983, 0.20161404]\n",
      "[0.62530756, 0.2, 0.21383363, 0.201414]\n",
      "[0.6143194, 0.2, 0.20336376, 0.20089361]\n",
      "[0.6196187, 0.2, 0.20775205, 0.20180313]\n",
      "[0.631091, 0.2, 0.21728753, 0.20373876]\n",
      "[0.63041365, 0.2, 0.21846287, 0.20188542]\n",
      "[0.62058747, 0.2, 0.20928979, 0.20123129]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2340 iterations: 0.7882685184478759 mins\n",
      "Train Loss: [0.62058747, 0.2, 0.20928979, 0.20123129]\n",
      "[0.625722, 0.2, 0.21200259, 0.20365177]\n",
      "[0.6302526, 0.2, 0.21822806, 0.20195474]\n",
      "[0.6139748, 0.2, 0.20253313, 0.20136878]\n",
      "[0.6231842, 0.2, 0.21031454, 0.20279264]\n",
      "[0.62504756, 0.2, 0.21300386, 0.20196135]\n",
      "[0.62450874, 0.2, 0.2134814, 0.2009398]\n",
      "[0.61883664, 0.2, 0.2070508, 0.20169067]\n",
      "[0.6222497, 0.2, 0.21070099, 0.20144561]\n",
      "[0.62844056, 0.2, 0.21780948, 0.20052002]\n",
      "[0.6142492, 0.2, 0.20265947, 0.20147076]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2350 iterations: 0.7910715500513713 mins\n",
      "Train Loss: [0.6142492, 0.2, 0.20265947, 0.20147076]\n",
      "[0.62882197, 0.2, 0.21647558, 0.20221967]\n",
      "[0.6234261, 0.2, 0.21118031, 0.2021125]\n",
      "[0.6150043, 0.2, 0.20352277, 0.20134135]\n",
      "[0.6283887, 0.2, 0.21676703, 0.2014741]\n",
      "[0.62231404, 0.2, 0.21036436, 0.20179568]\n",
      "[0.6220967, 0.2, 0.2113667, 0.20057003]\n",
      "[0.6159548, 0.2, 0.20453206, 0.20125747]\n",
      "[0.6216829, 0.2, 0.21003915, 0.20147303]\n",
      "[0.6234396, 0.2, 0.21222833, 0.20103723]\n",
      "[0.63674664, 0.2, 0.20825139, 0.2183178]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2360 iterations: 0.7941083828608195 mins\n",
      "Train Loss: [0.63674664, 0.2, 0.20825139, 0.2183178]\n",
      "[0.624717, 0.2, 0.21330245, 0.20123318]\n",
      "[0.613254, 0.2, 0.20193733, 0.20113096]\n",
      "[0.6150347, 0.2, 0.20337975, 0.201464]\n",
      "[0.63231057, 0.2, 0.21926971, 0.20284642]\n",
      "[0.6230865, 0.2, 0.21070252, 0.20218544]\n",
      "[0.62967235, 0.2, 0.2190633, 0.20040648]\n",
      "[0.6390608, 0.2, 0.20960744, 0.2192461]\n",
      "[0.6304418, 0.2, 0.21964218, 0.20058662]\n",
      "[0.62321764, 0.2, 0.21193917, 0.20105918]\n",
      "[0.62102866, 0.2, 0.21026482, 0.20053796]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2370 iterations: 0.7973582148551941 mins\n",
      "Train Loss: [0.62102866, 0.2, 0.21026482, 0.20053796]\n",
      "[0.6273263, 0.2, 0.21537195, 0.20172031]\n",
      "[0.62558836, 0.2, 0.21377362, 0.20157242]\n",
      "[0.62056506, 0.2, 0.20956074, 0.20075393]\n",
      "[0.6266293, 0.2, 0.21589415, 0.20047702]\n",
      "[0.6182581, 0.2, 0.20649943, 0.20149276]\n",
      "[0.623992, 0.2, 0.21219182, 0.20152788]\n",
      "[0.6224995, 0.2, 0.21069504, 0.2015253]\n",
      "[0.6207129, 0.2, 0.20772566, 0.20270275]\n",
      "[0.6299617, 0.2, 0.21891262, 0.20076051]\n",
      "[0.6239914, 0.2, 0.21021727, 0.20348717]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2380 iterations: 0.8004196524620056 mins\n",
      "Train Loss: [0.6239914, 0.2, 0.21021727, 0.20348717]\n",
      "[0.6232325, 0.2, 0.21138386, 0.20156355]\n",
      "[0.63112277, 0.2, 0.21943772, 0.2014015]\n",
      "[0.6273701, 0.2, 0.21461333, 0.20247515]\n",
      "[0.6278221, 0.2, 0.21606293, 0.20148022]\n",
      "[0.62575823, 0.2, 0.21374522, 0.20173724]\n",
      "[0.61681324, 0.2, 0.20416129, 0.20237996]\n",
      "[0.6164561, 0.2, 0.20289345, 0.20329554]\n",
      "[0.6272271, 0.2, 0.21519922, 0.20176739]\n",
      "[0.63557196, 0.2, 0.22447827, 0.20084052]\n",
      "[0.6485692, 0.2, 0.21572576, 0.22259887]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2390 iterations: 0.803308614095052 mins\n",
      "Train Loss: [0.6485692, 0.2, 0.21572576, 0.22259887]\n",
      "[0.63020223, 0.2, 0.21952528, 0.20044097]\n",
      "[0.6237447, 0.2, 0.21161593, 0.20190217]\n",
      "[0.63483423, 0.2, 0.22395065, 0.20066711]\n",
      "[0.6179224, 0.2, 0.20471725, 0.20299873]\n",
      "[0.6206724, 0.2, 0.20911072, 0.2013655]\n",
      "[0.6226209, 0.2, 0.21052913, 0.20190647]\n",
      "[0.6235651, 0.2, 0.21134743, 0.20204368]\n",
      "[0.62307316, 0.2, 0.21103203, 0.20187894]\n",
      "[0.61513054, 0.2, 0.20389827, 0.2010822]\n",
      "[0.6195193, 0.2, 0.20893042, 0.2004509]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2400 iterations: 0.8063035329182943 mins\n",
      "Train Loss: [0.6195193, 0.2, 0.20893042, 0.2004509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6174353, 0.2, 0.20653181, 0.20077762]\n",
      "[0.6134998, 0.2, 0.20218508, 0.20120123]\n",
      "[0.65398616, 0.2, 0.20248526, 0.24139972]\n",
      "[0.6184335, 0.2, 0.206824, 0.20151982]\n",
      "[0.6234706, 0.2, 0.21058828, 0.20280425]\n",
      "[0.62865853, 0.2, 0.2173558, 0.20123634]\n",
      "[0.6180996, 0.2, 0.2065143, 0.20153016]\n",
      "[0.6135456, 0.2, 0.20133357, 0.20216817]\n",
      "[0.62543, 0.2, 0.21235226, 0.20304543]\n",
      "[0.6130586, 0.2, 0.20176597, 0.20127228]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2410 iterations: 0.8090789834658305 mins\n",
      "Train Loss: [0.6130586, 0.2, 0.20176597, 0.20127228]\n",
      "[0.6194063, 0.2, 0.2082238, 0.20117414]\n",
      "[0.6227668, 0.2, 0.21061729, 0.20215333]\n",
      "[0.62373835, 0.2, 0.20904398, 0.20471047]\n",
      "[0.6268198, 0.2, 0.20986436, 0.20698376]\n",
      "[0.6256955, 0.2, 0.21365917, 0.20207691]\n",
      "[0.6156965, 0.2, 0.20448516, 0.20126422]\n",
      "[0.6137098, 0.2, 0.20156963, 0.20220535]\n",
      "[0.61426914, 0.2, 0.20356524, 0.20078115]\n",
      "[0.6277152, 0.2, 0.21628189, 0.20152248]\n",
      "[0.6272216, 0.2, 0.21531712, 0.20200531]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2420 iterations: 0.8118281960487366 mins\n",
      "Train Loss: [0.6272216, 0.2, 0.21531712, 0.20200531]\n",
      "[0.6199499, 0.2, 0.20894106, 0.20112091]\n",
      "[0.63644296, 0.2, 0.22356783, 0.2029981]\n",
      "[0.6131758, 0.2, 0.2022608, 0.20104824]\n",
      "[0.6225325, 0.2, 0.2110776, 0.20159812]\n",
      "[0.61374396, 0.2, 0.20186806, 0.2020285]\n",
      "[0.6224702, 0.2, 0.20945379, 0.20317814]\n",
      "[0.64919966, 0.2, 0.21342067, 0.22594953]\n",
      "[0.6234182, 0.2, 0.21238063, 0.20121627]\n",
      "[0.63136417, 0.2, 0.21905808, 0.20249254]\n",
      "[0.6507822, 0.2, 0.24010621, 0.2008692]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2430 iterations: 0.8157202959060669 mins\n",
      "Train Loss: [0.6507822, 0.2, 0.24010621, 0.2008692]\n",
      "[0.6186494, 0.2, 0.20750819, 0.20133775]\n",
      "[0.6162233, 0.2, 0.20491086, 0.20151143]\n",
      "[0.6207809, 0.2, 0.20898311, 0.20199917]\n",
      "[0.6134356, 0.2, 0.20232514, 0.20131382]\n",
      "[0.6223198, 0.2, 0.21168895, 0.20083608]\n",
      "[0.629051, 0.2, 0.21759425, 0.2016637]\n",
      "[0.65056163, 0.2, 0.21933728, 0.22143279]\n",
      "[0.61599934, 0.2, 0.20420621, 0.202003]\n",
      "[0.6136589, 0.2, 0.20273866, 0.20113176]\n",
      "[0.6145815, 0.2, 0.20202611, 0.20276879]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2440 iterations: 0.8188390493392944 mins\n",
      "Train Loss: [0.6145815, 0.2, 0.20202611, 0.20276879]\n",
      "[0.6158941, 0.2, 0.20325597, 0.20285355]\n",
      "[0.6540684, 0.2, 0.21034878, 0.23393703]\n",
      "[0.6244789, 0.2, 0.21012336, 0.20457698]\n",
      "[0.636562, 0.2, 0.20953006, 0.2172567]\n",
      "[0.62824416, 0.2, 0.21637923, 0.20209172]\n",
      "[0.62159413, 0.2, 0.20851809, 0.20330413]\n",
      "[0.6314332, 0.2, 0.21954034, 0.20212205]\n",
      "[0.619683, 0.2, 0.20736234, 0.20255058]\n",
      "[0.62697464, 0.2, 0.2144524, 0.2027529]\n",
      "[0.6352818, 0.2, 0.22316876, 0.20234469]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2450 iterations: 0.8218851486841837 mins\n",
      "Train Loss: [0.6352818, 0.2, 0.22316876, 0.20234469]\n",
      "[0.696194, 0.2, 0.20827352, 0.27815336]\n",
      "[0.6296309, 0.2, 0.21778964, 0.20207462]\n",
      "[0.62629193, 0.2, 0.2153037, 0.20122188]\n",
      "[0.6234494, 0.2, 0.21218513, 0.20149836]\n",
      "[0.68369263, 0.2, 0.21944222, 0.25448552]\n",
      "[0.6334032, 0.2, 0.22059205, 0.20304635]\n",
      "[0.6182032, 0.2, 0.20675963, 0.20167877]\n",
      "[0.6184944, 0.2, 0.20670418, 0.20202605]\n",
      "[0.61321306, 0.2, 0.2021484, 0.20130137]\n",
      "[0.6273046, 0.2, 0.21592799, 0.20161435]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2460 iterations: 0.825455884138743 mins\n",
      "Train Loss: [0.6273046, 0.2, 0.21592799, 0.20161435]\n",
      "[0.6167003, 0.2, 0.20490931, 0.20203009]\n",
      "[0.61566466, 0.2, 0.20380694, 0.20209853]\n",
      "[0.6196966, 0.2, 0.20668094, 0.20325877]\n",
      "[0.6153012, 0.2, 0.20295277, 0.20259406]\n",
      "[0.6210681, 0.2, 0.20911215, 0.20220383]\n",
      "[0.61632603, 0.2, 0.20479535, 0.20178074]\n",
      "[0.6252128, 0.2, 0.21447201, 0.20099355]\n",
      "[0.61548734, 0.2, 0.20435609, 0.20138669]\n",
      "[0.61499745, 0.2, 0.20359164, 0.20166457]\n",
      "[0.6338387, 0.2, 0.20988931, 0.21421179]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2470 iterations: 0.8281635999679565 mins\n",
      "Train Loss: [0.6338387, 0.2, 0.20988931, 0.21421179]\n",
      "[0.63239336, 0.2, 0.22008325, 0.20257556]\n",
      "[0.6236818, 0.2, 0.21262807, 0.20132247]\n",
      "[0.6164652, 0.2, 0.20606221, 0.20067413]\n",
      "[0.61828727, 0.2, 0.20670915, 0.20185138]\n",
      "[0.61646944, 0.2, 0.2048065, 0.2019378]\n",
      "[0.629633, 0.2, 0.20609733, 0.21381244]\n",
      "[0.6143595, 0.2, 0.2029254, 0.2017122]\n",
      "[0.6207747, 0.2, 0.209003, 0.2020509]\n",
      "[0.6220131, 0.2, 0.2113649, 0.200929]\n",
      "[0.61781, 0.2, 0.20736508, 0.20072727]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2480 iterations: 0.83067893187205 mins\n",
      "Train Loss: [0.61781, 0.2, 0.20736508, 0.20072727]\n",
      "[0.6131527, 0.2, 0.20255576, 0.20087977]\n",
      "[0.6177208, 0.2, 0.20607643, 0.20192789]\n",
      "[0.62048507, 0.2, 0.20706147, 0.20370868]\n",
      "[0.61403203, 0.2, 0.2026094, 0.20170927]\n",
      "[0.61577225, 0.2, 0.20521773, 0.20084299]\n",
      "[0.63354975, 0.2, 0.22166115, 0.202179]\n",
      "[0.6215279, 0.2, 0.20876665, 0.2030535]\n",
      "[0.63151413, 0.2, 0.2203771, 0.20143126]\n",
      "[0.6184285, 0.2, 0.20724508, 0.20147945]\n",
      "[0.62210435, 0.2, 0.21064256, 0.2017603]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2490 iterations: 0.8332518299420675 mins\n",
      "Train Loss: [0.62210435, 0.2, 0.21064256, 0.2017603]\n",
      "[0.62551045, 0.2, 0.21427481, 0.20153716]\n",
      "[0.61720586, 0.2, 0.20558125, 0.20192945]\n",
      "[0.62099254, 0.2, 0.20957223, 0.20172912]\n",
      "[0.61257267, 0.2, 0.20171829, 0.20116727]\n",
      "[0.61351657, 0.2, 0.20230028, 0.20153373]\n",
      "[0.6188425, 0.2, 0.20713246, 0.20203261]\n",
      "[0.6148111, 0.2, 0.20321244, 0.20192656]\n",
      "[0.62760717, 0.2, 0.21415308, 0.20378728]\n",
      "[0.6241369, 0.2, 0.2118104, 0.2026653]\n",
      "[0.6230989, 0.2, 0.21217096, 0.20127255]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2500 iterations: 0.8359792669614156 mins\n",
      "Train Loss: [0.6230989, 0.2, 0.21217096, 0.20127255]\n",
      "[0.6155477, 0.2, 0.20381197, 0.20208621]\n",
      "[0.62343526, 0.2, 0.21217926, 0.20161308]\n",
      "[0.7194672, 0.2, 0.24145816, 0.26837263]\n",
      "[0.6130917, 0.2, 0.20263442, 0.20082515]\n",
      "[0.6173099, 0.2, 0.20603319, 0.20164861]\n",
      "[0.61334705, 0.2, 0.20265235, 0.20107023]\n",
      "[0.6295763, 0.2, 0.2167301, 0.20322555]\n",
      "[0.6237933, 0.2, 0.21226007, 0.20191708]\n",
      "[0.61346173, 0.2, 0.20253721, 0.20131314]\n",
      "[0.6212692, 0.2, 0.21052417, 0.20113954]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2510 iterations: 0.8383795142173767 mins\n",
      "Train Loss: [0.6212692, 0.2, 0.21052417, 0.20113954]\n",
      "[0.66376525, 0.2, 0.20764445, 0.24652132]\n",
      "[0.6252895, 0.2, 0.21466614, 0.20102659]\n",
      "[0.6221608, 0.2, 0.21221331, 0.20035255]\n",
      "[0.6298507, 0.2, 0.21819168, 0.20206615]\n",
      "[0.62484455, 0.2, 0.21342188, 0.20183162]\n",
      "[0.62129825, 0.2, 0.20956835, 0.20214063]\n",
      "[0.6170943, 0.2, 0.20478477, 0.20272224]\n",
      "[0.6255224, 0.2, 0.21447656, 0.20146064]\n",
      "[0.6155715, 0.2, 0.20464882, 0.20133877]\n",
      "[0.6198813, 0.2, 0.20842896, 0.20187025]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2520 iterations: 0.8405727664629619 mins\n",
      "Train Loss: [0.6198813, 0.2, 0.20842896, 0.20187025]\n",
      "[0.6258316, 0.2, 0.21414663, 0.20210548]\n",
      "[0.6125599, 0.2, 0.2020247, 0.20095952]\n",
      "[0.6171704, 0.2, 0.20421916, 0.20337999]\n",
      "[0.61552304, 0.2, 0.20487146, 0.20108528]\n",
      "[0.61230344, 0.2, 0.20153154, 0.20121104]\n",
      "[0.61695397, 0.2, 0.20611297, 0.20128539]\n",
      "[0.61555105, 0.2, 0.20269708, 0.20330371]\n",
      "[0.62169194, 0.2, 0.21053371, 0.20161319]\n",
      "[0.6181704, 0.2, 0.20818484, 0.20044579]\n",
      "[0.61631465, 0.2, 0.20555778, 0.20122232]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2530 iterations: 0.8439043998718262 mins\n",
      "Train Loss: [0.61631465, 0.2, 0.20555778, 0.20122232]\n",
      "[0.6476655, 0.2, 0.20622002, 0.23191616]\n",
      "[0.6237934, 0.2, 0.20942253, 0.20484573]\n",
      "[0.6281975, 0.2, 0.21559152, 0.20308477]\n",
      "[0.6267239, 0.2, 0.21526174, 0.20194514]\n",
      "[0.62567866, 0.2, 0.21559119, 0.20057404]\n",
      "[0.6198065, 0.2, 0.2080332, 0.20226173]\n",
      "[0.6399422, 0.2, 0.21039695, 0.22003537]\n",
      "[0.6248398, 0.2, 0.21391968, 0.20141147]\n",
      "[0.615168, 0.2, 0.2049148, 0.20074645]\n",
      "[0.6206419, 0.2, 0.20876847, 0.20236808]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2540 iterations: 0.8460117657979329 mins\n",
      "Train Loss: [0.6206419, 0.2, 0.20876847, 0.20236808]\n",
      "[0.6471954, 0.2, 0.2049594, 0.23273228]\n",
      "[0.61649394, 0.2, 0.20350257, 0.20348974]\n",
      "[0.6144269, 0.2, 0.20327954, 0.20164779]\n",
      "[0.6236362, 0.2, 0.21191542, 0.2022237]\n",
      "[0.6393385, 0.2, 0.21509221, 0.21475181]\n",
      "[0.61543494, 0.2, 0.20414278, 0.20180024]\n",
      "[0.6259986, 0.2, 0.21344727, 0.20306174]\n",
      "[0.62557876, 0.2, 0.21516727, 0.20092417]\n",
      "[0.6484504, 0.2, 0.21335524, 0.22561002]\n",
      "[0.6162033, 0.2, 0.20558284, 0.20113592]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2550 iterations: 0.8498196522394816 mins\n",
      "Train Loss: [0.6162033, 0.2, 0.20558284, 0.20113592]\n",
      "[0.6137473, 0.2, 0.20268421, 0.20157892]\n",
      "[0.6323745, 0.2, 0.22177516, 0.2011156]\n",
      "[0.62169516, 0.2, 0.20961641, 0.20259532]\n",
      "[0.619823, 0.2, 0.20820941, 0.20213039]\n",
      "[0.6177558, 0.2, 0.2068477, 0.2014255]\n",
      "[0.6354179, 0.2, 0.22311215, 0.2028255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6262494, 0.2, 0.21579438, 0.20097765]\n",
      "[0.61967427, 0.2, 0.20820278, 0.20199727]\n",
      "[0.62491727, 0.2, 0.21428248, 0.20116372]\n",
      "[0.6202507, 0.2, 0.20655079, 0.20423204]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2560 iterations: 0.8541211326917012 mins\n",
      "Train Loss: [0.6202507, 0.2, 0.20655079, 0.20423204]\n",
      "[0.6185002, 0.2, 0.2078677, 0.20116818]\n",
      "[0.627509, 0.2, 0.21526437, 0.20278387]\n",
      "[0.6128076, 0.2, 0.20224068, 0.20110978]\n",
      "[0.61612296, 0.2, 0.20498042, 0.2016894]\n",
      "[0.6189638, 0.2, 0.20786951, 0.20164563]\n",
      "[0.6150368, 0.2, 0.2029559, 0.20263709]\n",
      "[0.6125936, 0.2, 0.2019329, 0.201222]\n",
      "[0.61494493, 0.2, 0.20414855, 0.20136335]\n",
      "[0.62504685, 0.2, 0.21512623, 0.20049381]\n",
      "[0.63883203, 0.2, 0.20543726, 0.22397383]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2570 iterations: 0.8567400654157002 mins\n",
      "Train Loss: [0.63883203, 0.2, 0.20543726, 0.22397383]\n",
      "[0.6171166, 0.2, 0.2040881, 0.20361246]\n",
      "[0.6242889, 0.2, 0.21351852, 0.20135865]\n",
      "[0.61330134, 0.2, 0.20271073, 0.20118256]\n",
      "[0.6256504, 0.2, 0.21547757, 0.20076847]\n",
      "[0.6170565, 0.2, 0.20550545, 0.20215033]\n",
      "[0.64064914, 0.2, 0.23055696, 0.2006947]\n",
      "[0.6267451, 0.2, 0.21566857, 0.20168155]\n",
      "[0.61398005, 0.2, 0.20366433, 0.20092298]\n",
      "[0.6148175, 0.2, 0.20313892, 0.20228648]\n",
      "[0.63043964, 0.2, 0.21939896, 0.20164801]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2580 iterations: 0.8592591166496277 mins\n",
      "Train Loss: [0.63043964, 0.2, 0.21939896, 0.20164801]\n",
      "[0.6194655, 0.2, 0.20842984, 0.20164141]\n",
      "[0.61420363, 0.2, 0.20463309, 0.20017245]\n",
      "[0.6191753, 0.2, 0.20959848, 0.20017391]\n",
      "[0.61496717, 0.2, 0.20443413, 0.2011251]\n",
      "[0.6338985, 0.2, 0.22090684, 0.20357913]\n",
      "[0.62930506, 0.2, 0.21747571, 0.20241357]\n",
      "[0.6146846, 0.2, 0.2049776, 0.20028807]\n",
      "[0.62698317, 0.2, 0.21535707, 0.20220117]\n",
      "[0.6160324, 0.2, 0.20455296, 0.20204945]\n",
      "[0.6193919, 0.2, 0.20878011, 0.20117757]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2590 iterations: 0.8614168008168538 mins\n",
      "Train Loss: [0.6193919, 0.2, 0.20878011, 0.20117757]\n",
      "[0.6138301, 0.2, 0.20388383, 0.20050795]\n",
      "[0.6187156, 0.2, 0.20863089, 0.20064242]\n",
      "[0.61680716, 0.2, 0.20474961, 0.20260756]\n",
      "[0.6223634, 0.2, 0.20603271, 0.20687594]\n",
      "[0.6281896, 0.2, 0.2164203, 0.20231077]\n",
      "[0.6176183, 0.2, 0.20531915, 0.20283642]\n",
      "[0.62615144, 0.2, 0.2163733, 0.20031297]\n",
      "[0.6151582, 0.2, 0.20543844, 0.20025411]\n",
      "[0.62168926, 0.2, 0.20909391, 0.20312992]\n",
      "[0.6375887, 0.2, 0.20854582, 0.219578]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2600 iterations: 0.8634772658348083 mins\n",
      "Train Loss: [0.6375887, 0.2, 0.20854582, 0.219578]\n",
      "[0.6140766, 0.2, 0.2040357, 0.20057571]\n",
      "[0.62055385, 0.2, 0.21043375, 0.20065705]\n",
      "[0.6695192, 0.2, 0.25713626, 0.20292075]\n",
      "[0.6160069, 0.2, 0.2057586, 0.20078555]\n",
      "[0.6152506, 0.2, 0.20243208, 0.20335536]\n",
      "[0.61912596, 0.2, 0.20896134, 0.20070128]\n",
      "[0.6239231, 0.2, 0.21382557, 0.20063491]\n",
      "[0.65105665, 0.2, 0.21316724, 0.22842784]\n",
      "[0.6191499, 0.2, 0.20834602, 0.20134291]\n",
      "[0.6194185, 0.2, 0.20889416, 0.20106429]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2610 iterations: 0.8656859358151754 mins\n",
      "Train Loss: [0.6194185, 0.2, 0.20889416, 0.20106429]\n",
      "[0.6216561, 0.2, 0.21192254, 0.20027547]\n",
      "[0.64423984, 0.2, 0.20438455, 0.23039968]\n",
      "[0.62257934, 0.2, 0.21188024, 0.20124465]\n",
      "[0.61733055, 0.2, 0.20655549, 0.20132172]\n",
      "[0.6346675, 0.2, 0.2233599, 0.20185567]\n",
      "[0.62503827, 0.2, 0.2142454, 0.20134306]\n",
      "[0.6683546, 0.2, 0.25708655, 0.20182076]\n",
      "[0.6153029, 0.2, 0.20542015, 0.20043394]\n",
      "[0.6157896, 0.2, 0.20446645, 0.20187353]\n",
      "[0.6267761, 0.2, 0.21686073, 0.20046549]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2620 iterations: 0.8692414164543152 mins\n",
      "Train Loss: [0.6267761, 0.2, 0.21686073, 0.20046549]\n",
      "[0.6372154, 0.2, 0.22579418, 0.20197152]\n",
      "[0.6355986, 0.2, 0.22300522, 0.20314446]\n",
      "[0.65218127, 0.2, 0.20832987, 0.23440373]\n",
      "[0.6219171, 0.2, 0.21169949, 0.20077136]\n",
      "[0.61343294, 0.2, 0.20345512, 0.20053351]\n",
      "[0.62434286, 0.2, 0.21322198, 0.20167936]\n",
      "[0.62148815, 0.2, 0.21047224, 0.20157798]\n",
      "[0.6225353, 0.2, 0.2116022, 0.2014988]\n",
      "[0.6163834, 0.2, 0.20453256, 0.20242101]\n",
      "[0.6174829, 0.2, 0.20746024, 0.20059778]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2630 iterations: 0.8722502628962199 mins\n",
      "Train Loss: [0.6174829, 0.2, 0.20746024, 0.20059778]\n",
      "[0.6211036, 0.2, 0.2096751, 0.20200896]\n",
      "[0.6396186, 0.2, 0.2250966, 0.20510821]\n",
      "[0.622874, 0.2, 0.2117754, 0.20169042]\n",
      "[0.6180664, 0.2, 0.2036243, 0.20503937]\n",
      "[0.6407551, 0.2, 0.2072739, 0.22408493]\n",
      "[0.62448555, 0.2, 0.21379189, 0.20130304]\n",
      "[0.6237678, 0.2, 0.21124862, 0.2031342]\n",
      "[0.62847906, 0.2, 0.21640053, 0.20269904]\n",
      "[0.6139614, 0.2, 0.20306556, 0.2015216]\n",
      "[0.63898164, 0.2, 0.2180999, 0.21151306]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2640 iterations: 0.8763306657473247 mins\n",
      "Train Loss: [0.63898164, 0.2, 0.2180999, 0.21151306]\n",
      "[0.62501895, 0.2, 0.21273756, 0.20291783]\n",
      "[0.61966246, 0.2, 0.20745878, 0.20284507]\n",
      "[0.6436904, 0.2, 0.23207206, 0.20226468]\n",
      "[0.6141257, 0.2, 0.20362945, 0.20114622]\n",
      "[0.6164873, 0.2, 0.20527263, 0.20186834]\n",
      "[0.6180765, 0.2, 0.20775762, 0.20097631]\n",
      "[0.616036, 0.2, 0.20586249, 0.20083503]\n",
      "[0.63360155, 0.2, 0.20683259, 0.2174349]\n",
      "[0.6252687, 0.2, 0.21021084, 0.20572563]\n",
      "[0.61352646, 0.2, 0.2017374, 0.20245868]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2650 iterations: 0.8797579685846965 mins\n",
      "Train Loss: [0.61352646, 0.2, 0.2017374, 0.20245868]\n",
      "[0.62398463, 0.2, 0.21323477, 0.20142119]\n",
      "[0.6212746, 0.2, 0.2113218, 0.2006259]\n",
      "[0.624776, 0.2, 0.2139674, 0.20148355]\n",
      "[0.6282275, 0.2, 0.21498442, 0.20392007]\n",
      "[0.62091964, 0.2, 0.20957062, 0.20202827]\n",
      "[0.6226941, 0.2, 0.21050547, 0.20287082]\n",
      "[0.6154719, 0.2, 0.20404626, 0.20211096]\n",
      "[0.62636244, 0.2, 0.21577373, 0.20127773]\n",
      "[0.61792886, 0.2, 0.20671473, 0.20190705]\n",
      "[0.6173561, 0.2, 0.20675504, 0.20129806]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2660 iterations: 0.8825810790061951 mins\n",
      "Train Loss: [0.6173561, 0.2, 0.20675504, 0.20129806]\n",
      "[0.6213675, 0.2, 0.21053472, 0.20153417]\n",
      "[0.6265001, 0.2, 0.21495408, 0.20225202]\n",
      "[0.631175, 0.2, 0.21937051, 0.20251492]\n",
      "[0.6249959, 0.2, 0.21398556, 0.20172584]\n",
      "[0.6172185, 0.2, 0.20454234, 0.20339781]\n",
      "[0.6359062, 0.2, 0.20251423, 0.22411986]\n",
      "[0.62190837, 0.2, 0.21042205, 0.20221862]\n",
      "[0.6162773, 0.2, 0.2060985, 0.20091534]\n",
      "[0.6256273, 0.2, 0.21418983, 0.20217788]\n",
      "[0.6166728, 0.2, 0.2050923, 0.20232432]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2670 iterations: 0.885043716430664 mins\n",
      "Train Loss: [0.6166728, 0.2, 0.2050923, 0.20232432]\n",
      "[0.6390792, 0.2, 0.22567317, 0.2041529]\n",
      "[0.6416057, 0.2, 0.20357731, 0.22877803]\n",
      "[0.6149019, 0.2, 0.20248763, 0.20316866]\n",
      "[0.617375, 0.2, 0.20591252, 0.2022207]\n",
      "[0.6211435, 0.2, 0.21018709, 0.2017202]\n",
      "[0.6219682, 0.2, 0.21133313, 0.20140299]\n",
      "[0.6265758, 0.2, 0.21523564, 0.20211141]\n",
      "[0.6158383, 0.2, 0.20566098, 0.20095126]\n",
      "[0.6462876, 0.2, 0.23647301, 0.20059186]\n",
      "[0.65230507, 0.2, 0.22795628, 0.21512762]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2680 iterations: 0.8875828186670939 mins\n",
      "Train Loss: [0.65230507, 0.2, 0.22795628, 0.21512762]\n",
      "[0.62047696, 0.2, 0.20912299, 0.20213513]\n",
      "[0.61596787, 0.2, 0.20354949, 0.2032012]\n",
      "[0.6174121, 0.2, 0.20666644, 0.20152994]\n",
      "[0.62998617, 0.2, 0.21711974, 0.2036521]\n",
      "[0.62047416, 0.2, 0.21040417, 0.20085698]\n",
      "[0.6338297, 0.2, 0.21973078, 0.20488745]\n",
      "[0.6409611, 0.2, 0.23057786, 0.20117286]\n",
      "[0.62541014, 0.2, 0.21256724, 0.20363301]\n",
      "[0.62489134, 0.2, 0.21141252, 0.20426928]\n",
      "[0.61319584, 0.2, 0.20261043, 0.2013764]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2690 iterations: 0.8900320688883464 mins\n",
      "Train Loss: [0.61319584, 0.2, 0.20261043, 0.2013764]\n",
      "[0.61594474, 0.2, 0.20606416, 0.20067254]\n",
      "[0.6168896, 0.2, 0.20748946, 0.2001933]\n",
      "[0.61139673, 0.2, 0.20104493, 0.20114678]\n",
      "[0.61285615, 0.2, 0.2007675, 0.2028856]\n",
      "[0.61800045, 0.2, 0.20704606, 0.20175354]\n",
      "[0.6214905, 0.2, 0.2098705, 0.20242138]\n",
      "[0.6233119, 0.2, 0.2116143, 0.20250112]\n",
      "[0.62834513, 0.2, 0.21672764, 0.20242316]\n",
      "[0.6135078, 0.2, 0.20333919, 0.2009764]\n",
      "[0.6268165, 0.2, 0.21666373, 0.20096308]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2700 iterations: 0.8921119292577108 mins\n",
      "Train Loss: [0.6268165, 0.2, 0.21666373, 0.20096308]\n",
      "[0.61683506, 0.2, 0.20715016, 0.20049773]\n",
      "[0.6238917, 0.2, 0.21307433, 0.20163272]\n",
      "[0.61805534, 0.2, 0.20469835, 0.20417494]\n",
      "[0.62007856, 0.2, 0.21035719, 0.20054261]\n",
      "[0.61407393, 0.2, 0.20352137, 0.20137706]\n",
      "[0.61267346, 0.2, 0.20255058, 0.20095105]\n",
      "[0.63145953, 0.2, 0.2211367, 0.20115466]\n",
      "[0.61778706, 0.2, 0.20641598, 0.20220685]\n",
      "[0.62057865, 0.2, 0.20735647, 0.20406187]\n",
      "[0.6147439, 0.2, 0.20562124, 0.19996616]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2710 iterations: 0.8940126856168111 mins\n",
      "Train Loss: [0.6147439, 0.2, 0.20562124, 0.19996616]\n",
      "[0.6447917, 0.2, 0.23233895, 0.20330022]\n",
      "[0.61478066, 0.2, 0.202689, 0.20294282]\n",
      "[0.62975556, 0.2, 0.21825564, 0.20235515]\n",
      "[0.62759614, 0.2, 0.21663114, 0.20182453]\n",
      "[0.61660695, 0.2, 0.20610705, 0.20136371]\n",
      "[0.62572765, 0.2, 0.21571524, 0.20088081]\n",
      "[0.61638045, 0.2, 0.20545848, 0.201795]\n",
      "[0.6202067, 0.2, 0.21124397, 0.19984065]\n",
      "[0.6274598, 0.2, 0.2157361, 0.20260698]\n",
      "[0.6204018, 0.2, 0.21008173, 0.20120864]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2720 iterations: 0.8966402173042297 mins\n",
      "Train Loss: [0.6204018, 0.2, 0.21008173, 0.20120864]\n",
      "[0.61193776, 0.2, 0.20172034, 0.2011113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6132623, 0.2, 0.20306705, 0.20109442]\n",
      "[0.6251519, 0.2, 0.21570775, 0.20034902]\n",
      "[0.62503004, 0.2, 0.2150648, 0.20087597]\n",
      "[0.67122364, 0.2, 0.26159927, 0.20054069]\n",
      "[0.6169417, 0.2, 0.20758988, 0.20027623]\n",
      "[0.6169111, 0.2, 0.20716202, 0.2006805]\n",
      "[0.616069, 0.2, 0.20598708, 0.2010195]\n",
      "[0.6275901, 0.2, 0.21592611, 0.20260718]\n",
      "[0.62187964, 0.2, 0.21077268, 0.20205545]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2730 iterations: 0.8999837795893352 mins\n",
      "Train Loss: [0.62187964, 0.2, 0.21077268, 0.20205545]\n",
      "[0.61917555, 0.2, 0.20872599, 0.20140302]\n",
      "[0.65869343, 0.2, 0.2483361, 0.20131542]\n",
      "[0.6145748, 0.2, 0.2031624, 0.20237918]\n",
      "[0.61997473, 0.2, 0.20919603, 0.20175275]\n",
      "[0.61514485, 0.2, 0.20407309, 0.20205201]\n",
      "[0.6197494, 0.2, 0.20973459, 0.2010005]\n",
      "[0.6239036, 0.2, 0.21220335, 0.20269065]\n",
      "[0.6238796, 0.2, 0.21380968, 0.2010646]\n",
      "[0.6423348, 0.2, 0.214774, 0.21855925]\n",
      "[0.64142036, 0.2, 0.21229935, 0.22012295]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2740 iterations: 0.9027657667795818 mins\n",
      "Train Loss: [0.64142036, 0.2, 0.21229935, 0.22012295]\n",
      "[0.62808585, 0.2, 0.21752098, 0.2015678]\n",
      "[0.62369764, 0.2, 0.21368009, 0.20102085]\n",
      "[0.61814374, 0.2, 0.20602569, 0.20312157]\n",
      "[0.6289012, 0.2, 0.21857907, 0.20132591]\n",
      "[0.6183115, 0.2, 0.20700715, 0.20230874]\n",
      "[0.6141876, 0.2, 0.20295125, 0.20224169]\n",
      "[0.6524271, 0.2, 0.23869318, 0.20474063]\n",
      "[0.6227286, 0.2, 0.21166605, 0.20207141]\n",
      "[0.6232686, 0.2, 0.21325293, 0.20102635]\n",
      "[0.62470096, 0.2, 0.21541934, 0.20029385]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2750 iterations: 0.9046131650606791 mins\n",
      "Train Loss: [0.62470096, 0.2, 0.21541934, 0.20029385]\n",
      "[0.61941004, 0.2, 0.20767868, 0.20274518]\n",
      "[0.6174803, 0.2, 0.20619239, 0.20230348]\n",
      "[0.62477183, 0.2, 0.21274659, 0.2030428]\n",
      "[0.7890903, 0.2, 0.37820488, 0.20190418]\n",
      "[0.6230078, 0.2, 0.2122617, 0.20175031]\n",
      "[0.61472034, 0.2, 0.20406885, 0.20164143]\n",
      "[0.62024313, 0.2, 0.2088844, 0.20233525]\n",
      "[0.6186598, 0.2, 0.20882286, 0.20080122]\n",
      "[0.6162687, 0.2, 0.20587075, 0.20135112]\n",
      "[0.61944586, 0.2, 0.20919465, 0.20119385]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2760 iterations: 0.9064745982487996 mins\n",
      "Train Loss: [0.61944586, 0.2, 0.20919465, 0.20119385]\n",
      "[0.6465141, 0.2, 0.20329715, 0.23415013]\n",
      "[0.6208524, 0.2, 0.21006773, 0.20171107]\n",
      "[0.62300766, 0.2, 0.21168359, 0.20224412]\n",
      "[0.6181638, 0.2, 0.20856953, 0.20050885]\n",
      "[0.62313366, 0.2, 0.21241426, 0.20162903]\n",
      "[0.61328036, 0.2, 0.20308204, 0.20110312]\n",
      "[0.62657565, 0.2, 0.21536706, 0.20210898]\n",
      "[0.6198983, 0.2, 0.20972846, 0.2010666]\n",
      "[0.6167987, 0.2, 0.20749977, 0.20019257]\n",
      "[0.6371946, 0.2, 0.22449748, 0.20358822]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2770 iterations: 0.9087682684262594 mins\n",
      "Train Loss: [0.6371946, 0.2, 0.22449748, 0.20358822]\n",
      "[0.6236162, 0.2, 0.21311851, 0.20138648]\n",
      "[0.6320539, 0.2, 0.22195135, 0.20098929]\n",
      "[0.626153, 0.2, 0.21434957, 0.20268759]\n",
      "[0.62320274, 0.2, 0.21301498, 0.2010697]\n",
      "[0.6217978, 0.2, 0.21177036, 0.2009077]\n",
      "[0.619536, 0.2, 0.20851249, 0.20190272]\n",
      "[0.61904883, 0.2, 0.20645528, 0.2034726]\n",
      "[0.62101436, 0.2, 0.20948039, 0.20241255]\n",
      "[0.61572295, 0.2, 0.20486812, 0.20173329]\n",
      "[0.61419165, 0.2, 0.2025221, 0.20254847]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2780 iterations: 0.9119739969571431 mins\n",
      "Train Loss: [0.61419165, 0.2, 0.2025221, 0.20254847]\n",
      "[0.6137822, 0.2, 0.20411372, 0.20054834]\n",
      "[0.625896, 0.2, 0.21681124, 0.19996612]\n",
      "[0.60988486, 0.2, 0.20028427, 0.20048442]\n",
      "[0.6166053, 0.2, 0.20482554, 0.20266639]\n",
      "[0.6154929, 0.2, 0.20496228, 0.20142043]\n",
      "[0.61260444, 0.2, 0.20172633, 0.20177145]\n",
      "[0.6259723, 0.2, 0.2151074, 0.20176212]\n",
      "[0.63773155, 0.2, 0.22735058, 0.2012822]\n",
      "[0.6224571, 0.2, 0.21194665, 0.20141551]\n",
      "[0.64743763, 0.2, 0.2372767, 0.20107016]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2790 iterations: 0.9147090514500936 mins\n",
      "Train Loss: [0.64743763, 0.2, 0.2372767, 0.20107016]\n",
      "[0.62250805, 0.2, 0.2131102, 0.20030709]\n",
      "[0.63957673, 0.2, 0.22934397, 0.20114253]\n",
      "[0.6178514, 0.2, 0.20494509, 0.20381735]\n",
      "[0.6641132, 0.2, 0.25398487, 0.20104127]\n",
      "[0.61772126, 0.2, 0.20648888, 0.20215188]\n",
      "[0.6148918, 0.2, 0.20501302, 0.2008036]\n",
      "[0.61955774, 0.2, 0.2092483, 0.20123844]\n",
      "[0.6148032, 0.2, 0.20425656, 0.20147909]\n",
      "[0.6183002, 0.2, 0.20788352, 0.20135209]\n",
      "[0.62710834, 0.2, 0.21683086, 0.20121486]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2800 iterations: 0.9168589472770691 mins\n",
      "Train Loss: [0.62710834, 0.2, 0.21683086, 0.20121486]\n",
      "[0.6658046, 0.2, 0.22835563, 0.22838748]\n",
      "[0.6207338, 0.2, 0.20976952, 0.20189826]\n",
      "[0.6198979, 0.2, 0.20825516, 0.20257103]\n",
      "[0.62581396, 0.2, 0.21302448, 0.20371139]\n",
      "[0.6202902, 0.2, 0.20816796, 0.20303781]\n",
      "[0.62242955, 0.2, 0.21119963, 0.20213902]\n",
      "[0.6228399, 0.2, 0.21017109, 0.203572]\n",
      "[0.61744237, 0.2, 0.2058961, 0.20244381]\n",
      "[0.61737454, 0.2, 0.20742571, 0.20084143]\n",
      "[0.6245332, 0.2, 0.20905907, 0.20636219]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2810 iterations: 0.9189755161603291 mins\n",
      "Train Loss: [0.6245332, 0.2, 0.20905907, 0.20636219]\n",
      "[0.61953247, 0.2, 0.20469221, 0.20572406]\n",
      "[0.6235797, 0.2, 0.21156731, 0.20289262]\n",
      "[0.6204856, 0.2, 0.20851058, 0.20285258]\n",
      "[0.6307905, 0.2, 0.21948066, 0.20218527]\n",
      "[0.62952405, 0.2, 0.21892351, 0.2014743]\n",
      "[0.61166036, 0.2, 0.20107962, 0.2014536]\n",
      "[0.6195828, 0.2, 0.20817845, 0.20227738]\n",
      "[0.6186751, 0.2, 0.20892258, 0.20062612]\n",
      "[0.6211088, 0.2, 0.20989099, 0.20209274]\n",
      "[0.6238879, 0.2, 0.21255176, 0.2022123]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2820 iterations: 0.9215959827105205 mins\n",
      "Train Loss: [0.6238879, 0.2, 0.21255176, 0.2022123]\n",
      "[0.6246802, 0.2, 0.21330526, 0.2022529]\n",
      "[0.62142414, 0.2, 0.20726405, 0.20504072]\n",
      "[0.61853737, 0.2, 0.20729773, 0.20212363]\n",
      "[0.6129812, 0.2, 0.20236526, 0.20150346]\n",
      "[0.61107713, 0.2, 0.20090379, 0.20106491]\n",
      "[0.61694926, 0.2, 0.20651647, 0.2013291]\n",
      "[0.6987709, 0.2, 0.27355498, 0.21611686]\n",
      "[0.6205704, 0.2, 0.21043596, 0.20103966]\n",
      "[0.6163453, 0.2, 0.20568718, 0.20156805]\n",
      "[0.61793447, 0.2, 0.20666726, 0.20218162]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2830 iterations: 0.9250921169916789 mins\n",
      "Train Loss: [0.61793447, 0.2, 0.20666726, 0.20218162]\n",
      "[0.6182422, 0.2, 0.20860378, 0.20055711]\n",
      "[0.6213719, 0.2, 0.2106662, 0.20162883]\n",
      "[0.6230965, 0.2, 0.21307619, 0.20094787]\n",
      "[0.62259984, 0.2, 0.21170887, 0.20182273]\n",
      "[0.6137628, 0.2, 0.20379242, 0.20090668]\n",
      "[0.6135648, 0.2, 0.20315197, 0.20135331]\n",
      "[0.61234105, 0.2, 0.20195104, 0.20133463]\n",
      "[0.6196577, 0.2, 0.2097451, 0.20086156]\n",
      "[0.6183788, 0.2, 0.2077434, 0.20158832]\n",
      "[0.6141719, 0.2, 0.20325276, 0.20187566]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2840 iterations: 0.9281839489936828 mins\n",
      "Train Loss: [0.6141719, 0.2, 0.20325276, 0.20187566]\n",
      "[0.63330626, 0.2, 0.22305517, 0.20121159]\n",
      "[0.6147914, 0.2, 0.20387068, 0.20188524]\n",
      "[0.6133679, 0.2, 0.20293874, 0.20139791]\n",
      "[0.61599237, 0.2, 0.20528035, 0.20168497]\n",
      "[0.61638266, 0.2, 0.20649755, 0.20086229]\n",
      "[0.6247961, 0.2, 0.21483906, 0.20093864]\n",
      "[0.61966383, 0.2, 0.20998347, 0.20066677]\n",
      "[0.61923754, 0.2, 0.20957614, 0.20065258]\n",
      "[0.6176785, 0.2, 0.2074613, 0.20121333]\n",
      "[0.6250251, 0.2, 0.21517405, 0.20085211]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2850 iterations: 0.932280433177948 mins\n",
      "Train Loss: [0.6250251, 0.2, 0.21517405, 0.20085211]\n",
      "[0.61828494, 0.2, 0.20872122, 0.20056969]\n",
      "[0.61472684, 0.2, 0.20433356, 0.20140411]\n",
      "[0.6310016, 0.2, 0.20866217, 0.21335524]\n",
      "[0.6150941, 0.2, 0.20410438, 0.20201008]\n",
      "[0.61778206, 0.2, 0.20628655, 0.20251982]\n",
      "[0.62191546, 0.2, 0.21234067, 0.20060256]\n",
      "[0.6224349, 0.2, 0.21059342, 0.20287146]\n",
      "[0.6694769, 0.2, 0.23389119, 0.22661747]\n",
      "[0.62131953, 0.2, 0.2112725, 0.20107916]\n",
      "[0.61245614, 0.2, 0.2028956, 0.2005924]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2860 iterations: 0.9344882011413574 mins\n",
      "Train Loss: [0.61245614, 0.2, 0.2028956, 0.2005924]\n",
      "[0.6137376, 0.2, 0.20396447, 0.20080446]\n",
      "[0.6112203, 0.2, 0.20083748, 0.20141408]\n",
      "[0.6193548, 0.2, 0.2081325, 0.2022536]\n",
      "[0.61934006, 0.2, 0.20951524, 0.20085645]\n",
      "[0.62535906, 0.2, 0.21452446, 0.20186706]\n",
      "[0.6252366, 0.2, 0.21521102, 0.20105922]\n",
      "[0.6260008, 0.2, 0.21530968, 0.20172666]\n",
      "[0.61681694, 0.2, 0.20684943, 0.20100579]\n",
      "[0.6162968, 0.2, 0.20529348, 0.20204419]\n",
      "[0.61979234, 0.2, 0.20839375, 0.20244198]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2870 iterations: 0.9366022666295369 mins\n",
      "Train Loss: [0.61979234, 0.2, 0.20839375, 0.20244198]\n",
      "[0.61412495, 0.2, 0.20449632, 0.20067441]\n",
      "[0.62858564, 0.2, 0.21726881, 0.20236535]\n",
      "[0.6174786, 0.2, 0.204648, 0.20388214]\n",
      "[0.6130901, 0.2, 0.20307165, 0.20107287]\n",
      "[0.6140917, 0.2, 0.20091134, 0.20423785]\n",
      "[0.6316594, 0.2, 0.22160946, 0.20111091]\n",
      "[0.6277218, 0.2, 0.21630684, 0.20247956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61505616, 0.2, 0.20501027, 0.2011138]\n",
      "[0.6222042, 0.2, 0.21174131, 0.20153421]\n",
      "[0.6116747, 0.2, 0.20094933, 0.20180008]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2880 iterations: 0.939057715733846 mins\n",
      "Train Loss: [0.6116747, 0.2, 0.20094933, 0.20180008]\n",
      "[0.6201744, 0.2, 0.21010937, 0.20114383]\n",
      "[0.6312463, 0.2, 0.20389715, 0.21843192]\n",
      "[0.619706, 0.2, 0.20924667, 0.2015432]\n",
      "[0.6233083, 0.2, 0.21205647, 0.20233671]\n",
      "[0.6248823, 0.2, 0.21271487, 0.20325287]\n",
      "[0.61433345, 0.2, 0.20485057, 0.20056841]\n",
      "[0.6254297, 0.2, 0.2123091, 0.20420644]\n",
      "[0.6210231, 0.2, 0.20901923, 0.20308983]\n",
      "[0.63738805, 0.2, 0.22529347, 0.20318049]\n",
      "[0.6397344, 0.2, 0.2293043, 0.20151561]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2890 iterations: 0.9418810486793519 mins\n",
      "Train Loss: [0.6397344, 0.2, 0.2293043, 0.20151561]\n",
      "[0.62023836, 0.2, 0.20929801, 0.20202486]\n",
      "[0.6358799, 0.2, 0.22334513, 0.20361759]\n",
      "[0.6364859, 0.2, 0.22365105, 0.20391618]\n",
      "[0.6167758, 0.2, 0.20643035, 0.20142491]\n",
      "[0.6187976, 0.2, 0.20788273, 0.20199166]\n",
      "[0.6212746, 0.2, 0.21017274, 0.2021754]\n",
      "[0.6224958, 0.2, 0.21119969, 0.20236611]\n",
      "[0.6219699, 0.2, 0.21196441, 0.201072]\n",
      "[0.620126, 0.2, 0.20816456, 0.20302455]\n",
      "[0.6186243, 0.2, 0.20690718, 0.20277703]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2900 iterations: 0.9454861362775167 mins\n",
      "Train Loss: [0.6186243, 0.2, 0.20690718, 0.20277703]\n",
      "[0.6152574, 0.2, 0.20530924, 0.20100528]\n",
      "[0.61698973, 0.2, 0.20664884, 0.20139566]\n",
      "[0.61626095, 0.2, 0.20525293, 0.20206052]\n",
      "[0.6554205, 0.2, 0.24389203, 0.20257895]\n",
      "[0.6204735, 0.2, 0.20588805, 0.20563434]\n",
      "[0.6281459, 0.2, 0.21447913, 0.2047137]\n",
      "[0.6309619, 0.2, 0.2078357, 0.21417056]\n",
      "[0.6285336, 0.2, 0.21793392, 0.20164123]\n",
      "[0.62827045, 0.2, 0.21800803, 0.20130122]\n",
      "[0.6173971, 0.2, 0.2053146, 0.20311727]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2910 iterations: 0.9482754667599996 mins\n",
      "Train Loss: [0.6173971, 0.2, 0.2053146, 0.20311727]\n",
      "[0.62394327, 0.2, 0.21164571, 0.20332915]\n",
      "[0.620642, 0.2, 0.20965755, 0.20201299]\n",
      "[0.6189664, 0.2, 0.20850171, 0.20149004]\n",
      "[0.6224522, 0.2, 0.21063751, 0.20283751]\n",
      "[0.6194808, 0.2, 0.21009327, 0.20040816]\n",
      "[0.6171894, 0.2, 0.20720981, 0.20099865]\n",
      "[0.6265146, 0.2, 0.21301068, 0.20452328]\n",
      "[0.61792946, 0.2, 0.20766303, 0.20128584]\n",
      "[0.6290414, 0.2, 0.21787097, 0.20219031]\n",
      "[0.62596714, 0.2, 0.20206651, 0.21492179]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2920 iterations: 0.9502849658330281 mins\n",
      "Train Loss: [0.62596714, 0.2, 0.20206651, 0.21492179]\n",
      "[0.61797136, 0.2, 0.20585692, 0.20313533]\n",
      "[0.62630653, 0.2, 0.21482481, 0.20250231]\n",
      "[0.61531824, 0.2, 0.20554166, 0.20079647]\n",
      "[0.6144004, 0.2, 0.20430104, 0.20111918]\n",
      "[0.6185026, 0.2, 0.20806043, 0.20146269]\n",
      "[0.6254173, 0.2, 0.21303059, 0.20340797]\n",
      "[0.6153232, 0.2, 0.2056016, 0.2007439]\n",
      "[0.6236209, 0.2, 0.21479097, 0.19985393]\n",
      "[0.6178846, 0.2, 0.20569457, 0.20321569]\n",
      "[0.61736596, 0.2, 0.20674196, 0.2016521]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2930 iterations: 0.9519790490468343 mins\n",
      "Train Loss: [0.61736596, 0.2, 0.20674196, 0.2016521]\n",
      "[0.6394944, 0.2, 0.22717072, 0.20335448]\n",
      "[0.61736137, 0.2, 0.20718835, 0.20120773]\n",
      "[0.6135307, 0.2, 0.20440315, 0.20016633]\n",
      "[0.6171042, 0.2, 0.20667033, 0.2014773]\n",
      "[0.61314684, 0.2, 0.20279258, 0.20140272]\n",
      "[0.62216556, 0.2, 0.2123291, 0.20089039]\n",
      "[0.6205722, 0.2, 0.20942266, 0.20220917]\n",
      "[0.62869126, 0.2, 0.21886024, 0.20089668]\n",
      "[0.6212597, 0.2, 0.21067291, 0.2016582]\n",
      "[0.62141544, 0.2, 0.210746, 0.20174661]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2940 iterations: 0.9538141647974651 mins\n",
      "Train Loss: [0.62141544, 0.2, 0.210746, 0.20174661]\n",
      "[0.63067955, 0.2, 0.21943343, 0.2023293]\n",
      "[0.63342375, 0.2, 0.22386995, 0.20064305]\n",
      "[0.6197625, 0.2, 0.20980231, 0.2010553]\n",
      "[0.6203214, 0.2, 0.20963816, 0.20178434]\n",
      "[0.61596346, 0.2, 0.20313784, 0.20393264]\n",
      "[0.6228717, 0.2, 0.21228205, 0.20170273]\n",
      "[0.6137762, 0.2, 0.2040377, 0.20085755]\n",
      "[0.62605673, 0.2, 0.20745632, 0.20972532]\n",
      "[0.613642, 0.2, 0.20411418, 0.20065805]\n",
      "[0.630623, 0.2, 0.22127862, 0.20047939]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2950 iterations: 0.9567010958989461 mins\n",
      "Train Loss: [0.630623, 0.2, 0.22127862, 0.20047939]\n",
      "[0.61723053, 0.2, 0.2069469, 0.20142266]\n",
      "[0.6114549, 0.2, 0.20124526, 0.2013521]\n",
      "[0.6233082, 0.2, 0.2138099, 0.20064405]\n",
      "[0.6238165, 0.2, 0.21387923, 0.20108593]\n",
      "[0.6294791, 0.2, 0.21836105, 0.20226952]\n",
      "[0.61651987, 0.2, 0.20760116, 0.20007306]\n",
      "[0.62121713, 0.2, 0.21151148, 0.20086284]\n",
      "[0.61845535, 0.2, 0.2083371, 0.20127803]\n",
      "[0.61153936, 0.2, 0.2021087, 0.2005933]\n",
      "[0.61818045, 0.2, 0.20913094, 0.20021552]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2960 iterations: 0.9596680998802185 mins\n",
      "Train Loss: [0.61818045, 0.2, 0.20913094, 0.20021552]\n",
      "[0.61637914, 0.2, 0.20713834, 0.20041044]\n",
      "[0.6249751, 0.2, 0.2155571, 0.20059219]\n",
      "[0.6201261, 0.2, 0.21031606, 0.20098856]\n",
      "[0.6124794, 0.2, 0.20216483, 0.20149776]\n",
      "[0.6303183, 0.2, 0.2212082, 0.20029806]\n",
      "[0.6192709, 0.2, 0.21054363, 0.19991985]\n",
      "[0.6132104, 0.2, 0.2035074, 0.20090026]\n",
      "[0.6150962, 0.2, 0.20515959, 0.20113856]\n",
      "[0.6164299, 0.2, 0.20659325, 0.20104378]\n",
      "[0.6148926, 0.2, 0.20507753, 0.20102745]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2970 iterations: 0.9618013819058736 mins\n",
      "Train Loss: [0.6148926, 0.2, 0.20507753, 0.20102745]\n",
      "[0.6161535, 0.2, 0.20639813, 0.20097335]\n",
      "[0.61491436, 0.2, 0.20540352, 0.20073475]\n",
      "[0.6220428, 0.2, 0.21242549, 0.2008472]\n",
      "[0.6155441, 0.2, 0.20648813, 0.20029223]\n",
      "[0.6144567, 0.2, 0.20400807, 0.20169131]\n",
      "[0.63292265, 0.2, 0.21550499, 0.2086668]\n",
      "[0.62643707, 0.2, 0.21704629, 0.2006471]\n",
      "[0.6148883, 0.2, 0.2045371, 0.20161383]\n",
      "[0.61543185, 0.2, 0.20642076, 0.20027973]\n",
      "[0.6206677, 0.2, 0.20890687, 0.20303524]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2980 iterations: 0.9642468651135763 mins\n",
      "Train Loss: [0.6206677, 0.2, 0.20890687, 0.20303524]\n",
      "[0.6139372, 0.2, 0.20397392, 0.20124291]\n",
      "[0.6191238, 0.2, 0.20903192, 0.2013763]\n",
      "[0.61466426, 0.2, 0.20530348, 0.20064956]\n",
      "[0.61768436, 0.2, 0.20553496, 0.20344234]\n",
      "[0.6156612, 0.2, 0.20525637, 0.20170201]\n",
      "[0.618586, 0.2, 0.20920672, 0.20068143]\n",
      "[0.60961366, 0.2, 0.2002512, 0.20066959]\n",
      "[0.61926967, 0.2, 0.20888123, 0.20170073]\n",
      "[0.613536, 0.2, 0.2039944, 0.20085922]\n",
      "[0.61865157, 0.2, 0.208767, 0.20120767]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2990 iterations: 0.9661133011182149 mins\n",
      "Train Loss: [0.61865157, 0.2, 0.208767, 0.20120767]\n",
      "[0.6139929, 0.2, 0.2047773, 0.20054434]\n",
      "[0.612803, 0.2, 0.20310125, 0.20103617]\n",
      "[0.61341846, 0.2, 0.20429702, 0.20046088]\n",
      "[0.62572414, 0.2, 0.2152014, 0.20186703]\n",
      "[0.61889845, 0.2, 0.20757441, 0.20266983]\n",
      "[0.62739843, 0.2, 0.21781181, 0.20093386]\n",
      "[0.62908745, 0.2, 0.21913774, 0.20129804]\n",
      "[0.61237407, 0.2, 0.20309497, 0.20062831]\n",
      "[0.61775845, 0.2, 0.20836167, 0.20074698]\n",
      "[0.6265821, 0.2, 0.21752883, 0.2004048]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3000 iterations: 0.9684478998184204 mins\n",
      "Train Loss: [0.6265821, 0.2, 0.21752883, 0.2004048]\n",
      "[0.6164974, 0.2, 0.2068653, 0.20098504]\n",
      "[0.6154226, 0.2, 0.20570493, 0.20107238]\n",
      "[0.61786824, 0.2, 0.20866317, 0.20056193]\n",
      "[0.61604154, 0.2, 0.20629817, 0.20110296]\n",
      "[0.6716514, 0.2, 0.2616269, 0.20138739]\n",
      "[0.6205259, 0.2, 0.21011838, 0.20177382]\n",
      "[0.6233285, 0.2, 0.2133466, 0.20135593]\n",
      "[0.6249846, 0.2, 0.21533662, 0.20102838]\n",
      "[0.6219629, 0.2, 0.21228689, 0.20106192]\n",
      "[0.6130161, 0.2, 0.20149258, 0.20291503]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3010 iterations: 0.9718540827433269 mins\n",
      "Train Loss: [0.6130161, 0.2, 0.20149258, 0.20291503]\n",
      "[0.6266235, 0.2, 0.2120789, 0.20594145]\n",
      "[0.6118754, 0.2, 0.20269533, 0.20058212]\n",
      "[0.6139795, 0.2, 0.2038363, 0.20155047]\n",
      "[0.6496844, 0.2, 0.2405422, 0.20055427]\n",
      "[0.6177333, 0.2, 0.20626014, 0.20288683]\n",
      "[0.6386137, 0.2, 0.22865005, 0.20137951]\n",
      "[0.62248075, 0.2, 0.21149516, 0.20240073]\n",
      "[0.61412835, 0.2, 0.20249057, 0.20305285]\n",
      "[0.61723924, 0.2, 0.20727514, 0.20137931]\n",
      "[0.61800814, 0.2, 0.20815869, 0.20126496]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3020 iterations: 0.9753683129946391 mins\n",
      "Train Loss: [0.61800814, 0.2, 0.20815869, 0.20126496]\n",
      "[0.61180496, 0.2, 0.20223233, 0.20098875]\n",
      "[0.62718415, 0.2, 0.21773183, 0.20086995]\n",
      "[0.61445135, 0.2, 0.20520957, 0.20066133]\n",
      "[0.6559831, 0.2, 0.24692793, 0.20047748]\n",
      "[0.61679053, 0.2, 0.20650926, 0.20170411]\n",
      "[0.6148527, 0.2, 0.20522688, 0.20104896]\n",
      "[0.61788315, 0.2, 0.20862988, 0.20067641]\n",
      "[0.6238425, 0.2, 0.21409939, 0.20116681]\n",
      "[0.60792845, 0.2, 0.19934002, 0.2000136]\n",
      "[0.6229126, 0.2, 0.21351309, 0.20082636]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3030 iterations: 0.9779659152030945 mins\n",
      "Train Loss: [0.6229126, 0.2, 0.21351309, 0.20082636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.623392, 0.2, 0.21129057, 0.2035303]\n",
      "[0.6258531, 0.2, 0.21580425, 0.20147981]\n",
      "[0.6279043, 0.2, 0.21773842, 0.20159894]\n",
      "[0.61565244, 0.2, 0.204959, 0.20212848]\n",
      "[0.616644, 0.2, 0.20698103, 0.20110053]\n",
      "[0.6219978, 0.2, 0.21237332, 0.20106493]\n",
      "[0.6134298, 0.2, 0.20371845, 0.2011548]\n",
      "[0.6145679, 0.2, 0.20502684, 0.20098823]\n",
      "[0.61546206, 0.2, 0.20609567, 0.20081797]\n",
      "[0.6152189, 0.2, 0.20547146, 0.20120376]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3040 iterations: 0.9833221316337586 mins\n",
      "Train Loss: [0.6152189, 0.2, 0.20547146, 0.20120376]\n",
      "[0.61715215, 0.2, 0.207741, 0.20087226]\n",
      "[0.6222662, 0.2, 0.21298364, 0.20074792]\n",
      "[0.6267088, 0.2, 0.2166967, 0.20148163]\n",
      "[0.6160022, 0.2, 0.20680915, 0.20066674]\n",
      "[0.6131643, 0.2, 0.20366953, 0.2009728]\n",
      "[0.6330825, 0.2, 0.20853059, 0.21603462]\n",
      "[0.6142729, 0.2, 0.2056004, 0.20015806]\n",
      "[0.6142716, 0.2, 0.20464839, 0.20111144]\n",
      "[0.61541516, 0.2, 0.20599069, 0.2009158]\n",
      "[0.6108493, 0.2, 0.20163994, 0.20070376]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3050 iterations: 0.9872758189837137 mins\n",
      "Train Loss: [0.6108493, 0.2, 0.20163994, 0.20070376]\n",
      "[0.63339835, 0.2, 0.22129187, 0.20360404]\n",
      "[0.61780643, 0.2, 0.20744422, 0.20186381]\n",
      "[0.61241, 0.2, 0.20329519, 0.20062007]\n",
      "[0.61232173, 0.2, 0.2038279, 0.20000255]\n",
      "[0.6158499, 0.2, 0.20586036, 0.20150168]\n",
      "[0.61600333, 0.2, 0.20667598, 0.20084226]\n",
      "[0.6359922, 0.2, 0.22613391, 0.20137593]\n",
      "[0.6210146, 0.2, 0.21235535, 0.2001794]\n",
      "[0.6282681, 0.2, 0.21933341, 0.20045714]\n",
      "[0.62024677, 0.2, 0.2115638, 0.20020731]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3060 iterations: 0.990017851193746 mins\n",
      "Train Loss: [0.62024677, 0.2, 0.2115638, 0.20020731]\n",
      "[0.61441344, 0.2, 0.20487793, 0.20106104]\n",
      "[0.61834455, 0.2, 0.20959096, 0.20028019]\n",
      "[0.6275718, 0.2, 0.21796608, 0.20113336]\n",
      "[0.6226218, 0.2, 0.21199235, 0.20215793]\n",
      "[0.61266506, 0.2, 0.20241323, 0.20178096]\n",
      "[0.61501455, 0.2, 0.20570084, 0.20084263]\n",
      "[0.6360235, 0.2, 0.22637199, 0.20118067]\n",
      "[0.62395614, 0.2, 0.21427703, 0.20121029]\n",
      "[0.61324376, 0.2, 0.20398787, 0.20078832]\n",
      "[0.6196361, 0.2, 0.20972307, 0.20144677]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3070 iterations: 0.9920369982719421 mins\n",
      "Train Loss: [0.6196361, 0.2, 0.20972307, 0.20144677]\n",
      "[0.61549973, 0.2, 0.20680924, 0.20022489]\n",
      "[0.6307134, 0.2, 0.22200015, 0.20024818]\n",
      "[0.61749816, 0.2, 0.20791067, 0.20112306]\n",
      "[0.62355447, 0.2, 0.21413453, 0.2009557]\n",
      "[0.61915267, 0.2, 0.21022078, 0.20046753]\n",
      "[0.6208507, 0.2, 0.21042642, 0.20195967]\n",
      "[0.6112, 0.2, 0.20181395, 0.20092164]\n",
      "[0.625014, 0.2, 0.21604557, 0.20050374]\n",
      "[0.6189281, 0.2, 0.20960394, 0.20085894]\n",
      "[0.61970764, 0.2, 0.21079512, 0.20044668]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3080 iterations: 0.9942115664482116 mins\n",
      "Train Loss: [0.61970764, 0.2, 0.21079512, 0.20044668]\n",
      "[0.6213432, 0.2, 0.2119625, 0.20092484]\n",
      "[0.61527723, 0.2, 0.20593397, 0.20089532]\n",
      "[0.6233095, 0.2, 0.2116624, 0.20320547]\n",
      "[0.6144545, 0.2, 0.20385244, 0.20216505]\n",
      "[0.617203, 0.2, 0.20647278, 0.20229745]\n",
      "[0.6176406, 0.2, 0.20720607, 0.20200579]\n",
      "[0.6407635, 0.2, 0.23154934, 0.20078944]\n",
      "[0.6290101, 0.2, 0.21806636, 0.2025222]\n",
      "[0.6168707, 0.2, 0.20538189, 0.2030716]\n",
      "[0.61808115, 0.2, 0.20954128, 0.20012698]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3090 iterations: 0.9982824842135112 mins\n",
      "Train Loss: [0.61808115, 0.2, 0.20954128, 0.20012698]\n",
      "[0.61254567, 0.2, 0.20236626, 0.20177108]\n",
      "[0.6291544, 0.2, 0.22004277, 0.20070459]\n",
      "[0.6127382, 0.2, 0.20281775, 0.20151435]\n",
      "[0.6180392, 0.2, 0.20880479, 0.20082912]\n",
      "[0.6672599, 0.2, 0.25636074, 0.2024946]\n",
      "[0.61617535, 0.2, 0.20712936, 0.20063543]\n",
      "[0.6247318, 0.2, 0.21378253, 0.20253353]\n",
      "[0.622875, 0.2, 0.20401503, 0.21043935]\n",
      "[0.6132116, 0.2, 0.20357409, 0.20121653]\n",
      "[0.6542311, 0.2, 0.21473998, 0.23106988]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3100 iterations: 1.0009122331937155 mins\n",
      "Train Loss: [0.6542311, 0.2, 0.21473998, 0.23106988]\n",
      "[0.61598366, 0.2, 0.20714754, 0.20041366]\n",
      "[0.6144636, 0.2, 0.20512517, 0.20091452]\n",
      "[0.6171867, 0.2, 0.20590574, 0.20285562]\n",
      "[0.6155528, 0.2, 0.20484677, 0.20227963]\n",
      "[0.632227, 0.2, 0.22001234, 0.20378786]\n",
      "[0.6251054, 0.2, 0.21613777, 0.20054114]\n",
      "[0.6167527, 0.2, 0.20848686, 0.19984001]\n",
      "[0.6146542, 0.2, 0.2039414, 0.20228764]\n",
      "[0.6271987, 0.2, 0.21889797, 0.1998767]\n",
      "[0.6272461, 0.2, 0.21726458, 0.2015587]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3110 iterations: 1.0031458814938863 mins\n",
      "Train Loss: [0.6272461, 0.2, 0.21726458, 0.2015587]\n",
      "[0.6111792, 0.2, 0.20274334, 0.20001355]\n",
      "[0.61438495, 0.2, 0.20565693, 0.20030661]\n",
      "[0.6222268, 0.2, 0.21211971, 0.20168664]\n",
      "[0.6228115, 0.2, 0.21395722, 0.20043541]\n",
      "[0.621886, 0.2, 0.21171796, 0.20175117]\n",
      "[0.6150721, 0.2, 0.20536, 0.20129816]\n",
      "[0.61769277, 0.2, 0.20837784, 0.20090456]\n",
      "[0.61757344, 0.2, 0.20822057, 0.2009462]\n",
      "[0.6269908, 0.2, 0.21727918, 0.20130935]\n",
      "[0.6195468, 0.2, 0.20742595, 0.20372336]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3120 iterations: 1.0051428000132243 mins\n",
      "Train Loss: [0.6195468, 0.2, 0.20742595, 0.20372336]\n",
      "[0.61328495, 0.2, 0.20333543, 0.20155683]\n",
      "[0.61902004, 0.2, 0.20822507, 0.20240694]\n",
      "[0.6314925, 0.2, 0.22259754, 0.20051177]\n",
      "[0.62578726, 0.2, 0.2154742, 0.20193648]\n",
      "[0.6152454, 0.2, 0.20462732, 0.20224713]\n",
      "[0.6183195, 0.2, 0.20859875, 0.20135519]\n",
      "[0.6603961, 0.2, 0.2048292, 0.24720643]\n",
      "[0.6118316, 0.2, 0.20169541, 0.20177941]\n",
      "[0.62002677, 0.2, 0.21061738, 0.20105587]\n",
      "[0.6124951, 0.2, 0.20320155, 0.20094365]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3130 iterations: 1.006971498330434 mins\n",
      "Train Loss: [0.6124951, 0.2, 0.20320155, 0.20094365]\n",
      "[0.61423147, 0.2, 0.20566781, 0.20021704]\n",
      "[0.62150544, 0.2, 0.21091506, 0.20224704]\n",
      "[0.622651, 0.2, 0.21381749, 0.20049281]\n",
      "[0.61930096, 0.2, 0.2107345, 0.20022857]\n",
      "[0.61469656, 0.2, 0.20363174, 0.20272984]\n",
      "[0.6212051, 0.2, 0.21116199, 0.20171113]\n",
      "[0.6307863, 0.2, 0.22028759, 0.20217054]\n",
      "[0.61090463, 0.2, 0.20273994, 0.1998403]\n",
      "[0.61458284, 0.2, 0.20459592, 0.20166622]\n",
      "[0.62725157, 0.2, 0.21687067, 0.20206386]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3140 iterations: 1.0106245477994282 mins\n",
      "Train Loss: [0.62725157, 0.2, 0.21687067, 0.20206386]\n",
      "[0.63071275, 0.2, 0.22117327, 0.20122555]\n",
      "[0.6208939, 0.2, 0.21038835, 0.20219438]\n",
      "[0.61230654, 0.2, 0.20270507, 0.2012931]\n",
      "[0.61415285, 0.2, 0.20447583, 0.20137171]\n",
      "[0.6147959, 0.2, 0.20571385, 0.2007798]\n",
      "[0.616412, 0.2, 0.20741971, 0.2006933]\n",
      "[0.6232436, 0.2, 0.21381016, 0.2011376]\n",
      "[0.61844426, 0.2, 0.20954037, 0.20061132]\n",
      "[0.6190215, 0.2, 0.21060675, 0.20012501]\n",
      "[0.62319124, 0.2, 0.21329798, 0.20160562]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3150 iterations: 1.0134332497914633 mins\n",
      "Train Loss: [0.62319124, 0.2, 0.21329798, 0.20160562]\n",
      "[0.6125681, 0.2, 0.2024889, 0.20179355]\n",
      "[0.62053883, 0.2, 0.21139371, 0.20086142]\n",
      "[0.6108889, 0.2, 0.20151715, 0.20108958]\n",
      "[0.61255217, 0.2, 0.20337574, 0.20089655]\n",
      "[0.61763984, 0.2, 0.20674753, 0.20261481]\n",
      "[0.63396066, 0.2, 0.22558792, 0.20009725]\n",
      "[0.65973705, 0.2, 0.20515144, 0.2463119]\n",
      "[0.6224014, 0.2, 0.21265317, 0.2014763]\n",
      "[0.6253988, 0.2, 0.21648976, 0.20063747]\n",
      "[0.61059517, 0.2, 0.20138215, 0.20094083]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3160 iterations: 1.0158106644948324 mins\n",
      "Train Loss: [0.61059517, 0.2, 0.20138215, 0.20094083]\n",
      "[0.6151065, 0.2, 0.2058023, 0.201031]\n",
      "[0.6186047, 0.2, 0.20945054, 0.20088033]\n",
      "[0.61485285, 0.2, 0.20593241, 0.20064518]\n",
      "[0.62248826, 0.2, 0.2108457, 0.20336555]\n",
      "[0.6290439, 0.2, 0.2190371, 0.2017296]\n",
      "[0.62242913, 0.2, 0.21372493, 0.20042537]\n",
      "[0.6224136, 0.2, 0.21206151, 0.20207012]\n",
      "[0.6260409, 0.2, 0.2178365, 0.19991873]\n",
      "[0.6115657, 0.2, 0.20277728, 0.20050015]\n",
      "[0.6246588, 0.2, 0.21515219, 0.20121603]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3170 iterations: 1.017801547050476 mins\n",
      "Train Loss: [0.6246588, 0.2, 0.21515219, 0.20121603]\n",
      "[0.6154477, 0.2, 0.20622075, 0.20093432]\n",
      "[0.6250174, 0.2, 0.21612826, 0.20059544]\n",
      "[0.6120757, 0.2, 0.20251124, 0.20127039]\n",
      "[0.61524755, 0.2, 0.20593685, 0.20101617]\n",
      "[0.6176196, 0.2, 0.20837007, 0.20095514]\n",
      "[0.6108237, 0.2, 0.20026837, 0.20226069]\n",
      "[0.62193, 0.2, 0.2115583, 0.20207676]\n",
      "[0.6125473, 0.2, 0.20315921, 0.20109333]\n",
      "[0.6252536, 0.2, 0.21596585, 0.2009937]\n",
      "[0.6441268, 0.2, 0.23439312, 0.20144077]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3180 iterations: 1.0205055991808574 mins\n",
      "Train Loss: [0.6441268, 0.2, 0.23439312, 0.20144077]\n",
      "[0.62272394, 0.2, 0.21372946, 0.20070162]\n",
      "[0.62428737, 0.2, 0.21468134, 0.20131247]\n",
      "[0.60970795, 0.2, 0.20049159, 0.20092122]\n",
      "[0.6119723, 0.2, 0.20218816, 0.20148699]\n",
      "[0.61386234, 0.2, 0.20492414, 0.20063964]\n",
      "[0.63204974, 0.2, 0.22247925, 0.2012711]\n",
      "[0.6635361, 0.2, 0.20384918, 0.2513877]\n",
      "[0.6216018, 0.2, 0.21057975, 0.20272492]\n",
      "[0.62637633, 0.2, 0.21707228, 0.2010081]\n",
      "[0.62155014, 0.2, 0.21323684, 0.20001803]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3190 iterations: 1.0231813828150431 mins\n",
      "Train Loss: [0.62155014, 0.2, 0.21323684, 0.20001803]\n",
      "[0.6202895, 0.2, 0.20908773, 0.20290674]\n",
      "[0.62259066, 0.2, 0.21326979, 0.20102543]\n",
      "[0.6927391, 0.2, 0.28337553, 0.20106731]\n",
      "[0.6200593, 0.2, 0.21042041, 0.20133702]\n",
      "[0.6165557, 0.2, 0.20732263, 0.20092525]\n",
      "[0.6131499, 0.2, 0.20368, 0.20115596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6188983, 0.2, 0.20898801, 0.20159109]\n",
      "[0.6651675, 0.2, 0.22286005, 0.23398311]\n",
      "[0.6184508, 0.2, 0.20889863, 0.20122257]\n",
      "[0.623067, 0.2, 0.21365832, 0.20107433]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3200 iterations: 1.0265620827674866 mins\n",
      "Train Loss: [0.623067, 0.2, 0.21365832, 0.20107433]\n",
      "[0.62653905, 0.2, 0.21595664, 0.2022433]\n",
      "[0.61945146, 0.2, 0.20968977, 0.20141801]\n",
      "[0.62664914, 0.2, 0.21668072, 0.2016212]\n",
      "[0.6533445, 0.2, 0.22128233, 0.22371218]\n",
      "[0.6252663, 0.2, 0.21454483, 0.20237045]\n",
      "[0.6450626, 0.2, 0.23482534, 0.20188507]\n",
      "[0.61450505, 0.2, 0.20582286, 0.20032911]\n",
      "[0.61855227, 0.2, 0.2085324, 0.2016665]\n",
      "[0.62382495, 0.2, 0.21487948, 0.20059204]\n",
      "[0.6209589, 0.2, 0.20635143, 0.20625491]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3210 iterations: 1.0290189822514852 mins\n",
      "Train Loss: [0.6209589, 0.2, 0.20635143, 0.20625491]\n",
      "[0.6157324, 0.2, 0.20557424, 0.2018068]\n",
      "[0.671187, 0.2, 0.26186767, 0.20096962]\n",
      "[0.62095505, 0.2, 0.21094213, 0.20166324]\n",
      "[0.62270427, 0.2, 0.20960012, 0.2047542]\n",
      "[0.6306992, 0.2, 0.21808203, 0.2042671]\n",
      "[0.6127494, 0.2, 0.20265788, 0.20174141]\n",
      "[0.62299, 0.2, 0.21191023, 0.20273004]\n",
      "[0.6121397, 0.2, 0.2026081, 0.20118283]\n",
      "[0.66425407, 0.2, 0.23317449, 0.22273256]\n",
      "[0.6164124, 0.2, 0.20257407, 0.2054924]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3220 iterations: 1.0311486005783081 mins\n",
      "Train Loss: [0.6164124, 0.2, 0.20257407, 0.2054924]\n",
      "[0.62823975, 0.2, 0.21800452, 0.20189017]\n",
      "[0.6495345, 0.2, 0.23856336, 0.20262669]\n",
      "[0.6431403, 0.2, 0.23175053, 0.20304501]\n",
      "[0.6133296, 0.2, 0.20144957, 0.20353365]\n",
      "[0.61955225, 0.2, 0.21039678, 0.20080787]\n",
      "[0.61946833, 0.2, 0.20999229, 0.20112753]\n",
      "[0.6125682, 0.2, 0.20383216, 0.20038699]\n",
      "[0.62891376, 0.2, 0.21876118, 0.20180349]\n",
      "[0.6218866, 0.2, 0.21255702, 0.20098114]\n",
      "[0.610887, 0.2, 0.20099513, 0.20154466]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3230 iterations: 1.0333996136983237 mins\n",
      "Train Loss: [0.610887, 0.2, 0.20099513, 0.20154466]\n",
      "[0.6744107, 0.2, 0.21019736, 0.25586832]\n",
      "[0.633725, 0.2, 0.2239887, 0.20139429]\n",
      "[0.6198493, 0.2, 0.21101268, 0.2004973]\n",
      "[0.61891156, 0.2, 0.20623921, 0.2043356]\n",
      "[0.61436963, 0.2, 0.20516677, 0.20086965]\n",
      "[0.6171386, 0.2, 0.20821168, 0.20059729]\n",
      "[0.61405534, 0.2, 0.2049182, 0.20081118]\n",
      "[0.6278913, 0.2, 0.21929005, 0.20027898]\n",
      "[0.62132627, 0.2, 0.21135361, 0.20165414]\n",
      "[0.6309048, 0.2, 0.20513193, 0.21745887]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3240 iterations: 1.035534417629242 mins\n",
      "Train Loss: [0.6309048, 0.2, 0.20513193, 0.21745887]\n",
      "[0.6161792, 0.2, 0.2038107, 0.20405933]\n",
      "[0.6145006, 0.2, 0.2045954, 0.2015997]\n",
      "[0.61145604, 0.2, 0.20137313, 0.20178066]\n",
      "[0.6147314, 0.2, 0.20444597, 0.20198596]\n",
      "[0.63142824, 0.2, 0.20518497, 0.21794604]\n",
      "[0.6258419, 0.2, 0.21727996, 0.2002663]\n",
      "[0.62045974, 0.2, 0.21058786, 0.20157698]\n",
      "[0.61148256, 0.2, 0.2010858, 0.20210205]\n",
      "[0.61419445, 0.2, 0.20457216, 0.20132782]\n",
      "[0.61739814, 0.2, 0.20766734, 0.2014366]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3250 iterations: 1.037830897172292 mins\n",
      "Train Loss: [0.61739814, 0.2, 0.20766734, 0.2014366]\n",
      "[0.6232437, 0.2, 0.21287718, 0.20207255]\n",
      "[0.62159586, 0.2, 0.21339026, 0.19991219]\n",
      "[0.6217927, 0.2, 0.211381, 0.20211886]\n",
      "[0.629871, 0.2, 0.21879937, 0.20277868]\n",
      "[0.63146514, 0.2, 0.22132534, 0.20184655]\n",
      "[0.6220826, 0.2, 0.21200897, 0.20177935]\n",
      "[0.61391526, 0.2, 0.20314686, 0.20247293]\n",
      "[0.6189698, 0.2, 0.21048173, 0.20019163]\n",
      "[0.6336513, 0.2, 0.2208651, 0.20448871]\n",
      "[0.61911243, 0.2, 0.21003667, 0.20077746]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3260 iterations: 1.0398143649101257 mins\n",
      "Train Loss: [0.61911243, 0.2, 0.21003667, 0.20077746]\n",
      "[0.6147267, 0.2, 0.20575666, 0.20067035]\n",
      "[0.6200398, 0.2, 0.2103435, 0.20139518]\n",
      "[0.62085867, 0.2, 0.2082313, 0.20432492]\n",
      "[0.62228507, 0.2, 0.21335939, 0.20062192]\n",
      "[0.64394176, 0.2, 0.20916593, 0.2264706]\n",
      "[0.6174429, 0.2, 0.20659165, 0.20254299]\n",
      "[0.62916714, 0.2, 0.21904257, 0.20181315]\n",
      "[0.6122479, 0.2, 0.20391473, 0.20001814]\n",
      "[0.62334776, 0.2, 0.21357739, 0.20145178]\n",
      "[0.61600107, 0.2, 0.20681335, 0.20086533]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3270 iterations: 1.0423227349917095 mins\n",
      "Train Loss: [0.61600107, 0.2, 0.20681335, 0.20086533]\n",
      "[0.61280555, 0.2, 0.20386223, 0.20061724]\n",
      "[0.618993, 0.2, 0.20719603, 0.20346753]\n",
      "[0.61641985, 0.2, 0.20558916, 0.20249815]\n",
      "[0.6201182, 0.2, 0.20935947, 0.20242348]\n",
      "[0.6410229, 0.2, 0.23075992, 0.20192416]\n",
      "[0.6217897, 0.2, 0.21298707, 0.2004607]\n",
      "[0.6271346, 0.2, 0.21668005, 0.20211005]\n",
      "[0.63362086, 0.2, 0.21594213, 0.20933191]\n",
      "[0.6132602, 0.2, 0.20377554, 0.20113587]\n",
      "[0.620917, 0.2, 0.21150643, 0.20106015]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3280 iterations: 1.0446884830792744 mins\n",
      "Train Loss: [0.620917, 0.2, 0.21150643, 0.20106015]\n",
      "[0.61536044, 0.2, 0.20484811, 0.20216046]\n",
      "[0.61288965, 0.2, 0.20295304, 0.20158313]\n",
      "[0.613271, 0.2, 0.20179825, 0.20311834]\n",
      "[0.6200013, 0.2, 0.21082884, 0.20081735]\n",
      "[0.6173531, 0.2, 0.20651096, 0.20248677]\n",
      "[0.6124474, 0.2, 0.20202859, 0.20206307]\n",
      "[0.6136509, 0.2, 0.20559654, 0.19969897]\n",
      "[0.61111474, 0.2, 0.19890976, 0.20385094]\n",
      "[0.65166235, 0.2, 0.2400821, 0.2032273]\n",
      "[0.6157877, 0.2, 0.20611295, 0.20132382]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3290 iterations: 1.0468594988187154 mins\n",
      "Train Loss: [0.6157877, 0.2, 0.20611295, 0.20132382]\n",
      "[0.61448306, 0.2, 0.20586658, 0.20026731]\n",
      "[0.6123421, 0.2, 0.20282876, 0.20116596]\n",
      "[0.67035335, 0.2, 0.2619194, 0.20008826]\n",
      "[0.618644, 0.2, 0.20937717, 0.20092405]\n",
      "[0.61943007, 0.2, 0.20882936, 0.2022606]\n",
      "[0.6127348, 0.2, 0.20345083, 0.20094652]\n",
      "[0.6091338, 0.2, 0.1971017, 0.20369756]\n",
      "[0.6195629, 0.2, 0.20988594, 0.2013449]\n",
      "[0.63060504, 0.2, 0.22007906, 0.20219645]\n",
      "[0.6146323, 0.2, 0.20422234, 0.20208293]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3300 iterations: 1.051596717039744 mins\n",
      "Train Loss: [0.6146323, 0.2, 0.20422234, 0.20208293]\n",
      "[0.61504847, 0.2, 0.20509568, 0.2016285]\n",
      "[0.6137886, 0.2, 0.2042807, 0.20118678]\n",
      "[0.6834854, 0.2, 0.21668988, 0.25847793]\n",
      "[0.6280271, 0.2, 0.21756814, 0.20214412]\n",
      "[0.6246915, 0.2, 0.21444859, 0.20193014]\n",
      "[0.6154329, 0.2, 0.20664096, 0.20048162]\n",
      "[0.6245671, 0.2, 0.21569556, 0.20056345]\n",
      "[0.61504066, 0.2, 0.20276849, 0.20396665]\n",
      "[0.6203515, 0.2, 0.21092361, 0.20112485]\n",
      "[0.6347301, 0.2, 0.2233107, 0.20311894]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3310 iterations: 1.0545620520909627 mins\n",
      "Train Loss: [0.6347301, 0.2, 0.2233107, 0.20311894]\n",
      "[0.6186223, 0.2, 0.20738155, 0.20294243]\n",
      "[0.6126572, 0.2, 0.20269068, 0.20167015]\n",
      "[0.6168753, 0.2, 0.20775887, 0.20082194]\n",
      "[0.6257657, 0.2, 0.21456134, 0.20291296]\n",
      "[0.6216735, 0.2, 0.21021572, 0.20317014]\n",
      "[0.6246973, 0.2, 0.2142786, 0.20213519]\n",
      "[0.61699814, 0.2, 0.20776378, 0.20095523]\n",
      "[0.62696046, 0.2, 0.2171426, 0.20154357]\n",
      "[0.62278163, 0.2, 0.21303286, 0.20147943]\n",
      "[0.6148571, 0.2, 0.20372501, 0.20286831]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3320 iterations: 1.0581506808598837 mins\n",
      "Train Loss: [0.6148571, 0.2, 0.20372501, 0.20286831]\n",
      "[0.6265462, 0.2, 0.2176797, 0.20060867]\n",
      "[0.6375757, 0.2, 0.20605204, 0.22327146]\n",
      "[0.63006884, 0.2, 0.21895202, 0.20287001]\n",
      "[0.6159725, 0.2, 0.20600264, 0.20172885]\n",
      "[0.6266508, 0.2, 0.21683475, 0.20158017]\n",
      "[0.6113528, 0.2, 0.20150082, 0.20162082]\n",
      "[0.6162299, 0.2, 0.20573498, 0.20226829]\n",
      "[0.62052965, 0.2, 0.21138687, 0.20092067]\n",
      "[0.60972625, 0.2, 0.20068404, 0.20082429]\n",
      "[0.6637863, 0.2, 0.2197257, 0.23584698]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3330 iterations: 1.0611571669578552 mins\n",
      "Train Loss: [0.6637863, 0.2, 0.2197257, 0.23584698]\n",
      "[0.6224161, 0.2, 0.21125463, 0.20295087]\n",
      "[0.6268984, 0.2, 0.21799724, 0.20069316]\n",
      "[0.61690533, 0.2, 0.20647629, 0.20222373]\n",
      "[0.6123373, 0.2, 0.2042033, 0.19993159]\n",
      "[0.61994904, 0.2, 0.20709485, 0.20465495]\n",
      "[0.6165789, 0.2, 0.20697923, 0.20140328]\n",
      "[0.621655, 0.2, 0.21208838, 0.20137332]\n",
      "[0.62452805, 0.2, 0.21507417, 0.20126371]\n",
      "[0.61620134, 0.2, 0.20682418, 0.20118958]\n",
      "[0.63128567, 0.2, 0.22034307, 0.20275778]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3340 iterations: 1.0647632002830505 mins\n",
      "Train Loss: [0.63128567, 0.2, 0.22034307, 0.20275778]\n",
      "[0.62281, 0.2, 0.21317403, 0.20145392]\n",
      "[0.61838704, 0.2, 0.20763604, 0.20257096]\n",
      "[0.6230532, 0.2, 0.21110183, 0.2037742]\n",
      "[0.6264546, 0.2, 0.21666159, 0.20161882]\n",
      "[0.62680346, 0.2, 0.21579586, 0.20283557]\n",
      "[0.61332834, 0.2, 0.20295468, 0.20220327]\n",
      "[0.6289671, 0.2, 0.21857218, 0.2022264]\n",
      "[0.6118523, 0.2, 0.20267045, 0.20101629]\n",
      "[0.62748784, 0.2, 0.21846169, 0.20086366]\n",
      "[0.62393355, 0.2, 0.21404456, 0.20172934]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3350 iterations: 1.0667802810668945 mins\n",
      "Train Loss: [0.62393355, 0.2, 0.21404456, 0.20172934]\n",
      "[0.62363243, 0.2, 0.2136864, 0.20178935]\n",
      "[0.6212005, 0.2, 0.21223976, 0.20080695]\n",
      "[0.6232931, 0.2, 0.21380948, 0.20133278]\n",
      "[0.62201464, 0.2, 0.21187486, 0.201992]\n",
      "[0.61062175, 0.2, 0.20149961, 0.2009776]\n",
      "[0.6183308, 0.2, 0.20949271, 0.20069684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62264824, 0.2, 0.21358377, 0.20092662]\n",
      "[0.62454695, 0.2, 0.21635562, 0.20005682]\n",
      "[0.6115, 0.2, 0.20199543, 0.2013738]\n",
      "[0.6129521, 0.2, 0.20466965, 0.20015563]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3360 iterations: 1.0687175671259561 mins\n",
      "Train Loss: [0.6129521, 0.2, 0.20466965, 0.20015563]\n",
      "[0.6146177, 0.2, 0.20511001, 0.20138502]\n",
      "[0.62745976, 0.2, 0.21911845, 0.20022245]\n",
      "[0.6316726, 0.2, 0.22284408, 0.20071349]\n",
      "[0.66197, 0.2, 0.21689478, 0.23696312]\n",
      "[0.62452424, 0.2, 0.2137194, 0.20269449]\n",
      "[0.6103813, 0.2, 0.20141375, 0.20085819]\n",
      "[0.62079215, 0.2, 0.21184315, 0.20084015]\n",
      "[0.61730194, 0.2, 0.20859572, 0.2005979]\n",
      "[0.6145738, 0.2, 0.20665866, 0.19980724]\n",
      "[0.62157595, 0.2, 0.21252087, 0.20094794]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3370 iterations: 1.0705211798350016 mins\n",
      "Train Loss: [0.62157595, 0.2, 0.21252087, 0.20094794]\n",
      "[0.6147102, 0.2, 0.20553763, 0.2010658]\n",
      "[0.6213648, 0.2, 0.21230818, 0.20095073]\n",
      "[0.6227223, 0.2, 0.2141922, 0.20042543]\n",
      "[0.6115129, 0.2, 0.20258324, 0.20082644]\n",
      "[0.6101723, 0.2, 0.2002964, 0.2017744]\n",
      "[0.61779195, 0.2, 0.20807114, 0.20162159]\n",
      "[0.625319, 0.2, 0.2156932, 0.20152898]\n",
      "[0.6226147, 0.2, 0.21318986, 0.20133062]\n",
      "[0.61828876, 0.2, 0.20937797, 0.20081888]\n",
      "[0.6121531, 0.2, 0.20284624, 0.20121744]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3380 iterations: 1.0750899155934652 mins\n",
      "Train Loss: [0.6121531, 0.2, 0.20284624, 0.20121744]\n",
      "[0.61184406, 0.2, 0.20261942, 0.20113772]\n",
      "[0.6197319, 0.2, 0.21098763, 0.20066066]\n",
      "[0.6229198, 0.2, 0.21408011, 0.20075922]\n",
      "[0.61051655, 0.2, 0.20144908, 0.20099013]\n",
      "[0.6232688, 0.2, 0.2144844, 0.20071037]\n",
      "[0.6125165, 0.2, 0.20319203, 0.20125358]\n",
      "[0.65269935, 0.2, 0.24378417, 0.20084721]\n",
      "[0.6393356, 0.2, 0.22996211, 0.20130725]\n",
      "[0.6275482, 0.2, 0.21811663, 0.2013627]\n",
      "[0.6172392, 0.2, 0.20911996, 0.20004568]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3390 iterations: 1.0780379970868428 mins\n",
      "Train Loss: [0.6172392, 0.2, 0.20911996, 0.20004568]\n",
      "[0.61384845, 0.2, 0.20344743, 0.2023219]\n",
      "[0.6144518, 0.2, 0.2053737, 0.20099293]\n",
      "[0.61227906, 0.2, 0.20325585, 0.20093653]\n",
      "[0.6157447, 0.2, 0.20732653, 0.20032932]\n",
      "[0.6171077, 0.2, 0.20812888, 0.20088734]\n",
      "[0.6208876, 0.2, 0.21158606, 0.20120734]\n",
      "[0.66634107, 0.2, 0.2125853, 0.24565865]\n",
      "[0.613762, 0.2, 0.20477399, 0.20088726]\n",
      "[0.6150458, 0.2, 0.2057937, 0.20114768]\n",
      "[0.6131089, 0.2, 0.2034365, 0.20156416]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3400 iterations: 1.0810337821642557 mins\n",
      "Train Loss: [0.6131089, 0.2, 0.2034365, 0.20156416]\n",
      "[0.61102694, 0.2, 0.20242406, 0.20049092]\n",
      "[0.6162133, 0.2, 0.206788, 0.20131032]\n",
      "[0.7183627, 0.2, 0.30961195, 0.20063354]\n",
      "[0.66290617, 0.2, 0.25296554, 0.20181306]\n",
      "[0.6145217, 0.2, 0.20561932, 0.20076007]\n",
      "[0.6136918, 0.2, 0.20412104, 0.20141444]\n",
      "[0.6132085, 0.2, 0.20404665, 0.20099187]\n",
      "[0.62333155, 0.2, 0.21335524, 0.20179367]\n",
      "[0.6241135, 0.2, 0.21419077, 0.20172858]\n",
      "[0.61145693, 0.2, 0.20255566, 0.20069654]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3410 iterations: 1.0835514823595682 mins\n",
      "Train Loss: [0.61145693, 0.2, 0.20255566, 0.20069654]\n",
      "[0.62253106, 0.2, 0.21347353, 0.20084353]\n",
      "[0.61808133, 0.2, 0.20989826, 0.19996104]\n",
      "[0.6134935, 0.2, 0.20373593, 0.2015285]\n",
      "[0.6282371, 0.2, 0.21903452, 0.2009676]\n",
      "[0.6198257, 0.2, 0.2101546, 0.20143102]\n",
      "[0.63617855, 0.2, 0.20250788, 0.22542593]\n",
      "[0.6236538, 0.2, 0.2143178, 0.20108776]\n",
      "[0.62640345, 0.2, 0.21688405, 0.20126775]\n",
      "[0.62491983, 0.2, 0.21409221, 0.2025732]\n",
      "[0.6189642, 0.2, 0.20853946, 0.20216802]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3420 iterations: 1.0859621167182922 mins\n",
      "Train Loss: [0.6189642, 0.2, 0.20853946, 0.20216802]\n",
      "[0.6270991, 0.2, 0.21814054, 0.20070046]\n",
      "[0.61909086, 0.2, 0.20956036, 0.20127289]\n",
      "[0.6129925, 0.2, 0.20424308, 0.20049277]\n",
      "[0.62333214, 0.2, 0.21324359, 0.2018332]\n",
      "[0.61778414, 0.2, 0.20613784, 0.20339334]\n",
      "[0.61881596, 0.2, 0.20982125, 0.2007442]\n",
      "[0.6181801, 0.2, 0.20884146, 0.2010909]\n",
      "[0.615779, 0.2, 0.20703179, 0.20050249]\n",
      "[0.6111595, 0.2, 0.20235167, 0.20056635]\n",
      "[0.61420274, 0.2, 0.2047358, 0.20122902]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3430 iterations: 1.089040466149648 mins\n",
      "Train Loss: [0.61420274, 0.2, 0.2047358, 0.20122902]\n",
      "[0.6111454, 0.2, 0.20203102, 0.2008803]\n",
      "[0.61145145, 0.2, 0.20278344, 0.20043826]\n",
      "[0.6115403, 0.2, 0.20227233, 0.20104308]\n",
      "[0.61751497, 0.2, 0.20909533, 0.20019998]\n",
      "[0.6174504, 0.2, 0.20767407, 0.20156246]\n",
      "[0.62623745, 0.2, 0.21693188, 0.20109804]\n",
      "[0.6320078, 0.2, 0.20454013, 0.21926671]\n",
      "[0.6146225, 0.2, 0.20538348, 0.20104513]\n",
      "[0.6156636, 0.2, 0.20669349, 0.20078176]\n",
      "[0.61566716, 0.2, 0.20640852, 0.20107609]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3440 iterations: 1.0925365169843038 mins\n",
      "Train Loss: [0.61566716, 0.2, 0.20640852, 0.20107609]\n",
      "[0.6176515, 0.2, 0.20832069, 0.20115377]\n",
      "[0.61626303, 0.2, 0.20749085, 0.20060048]\n",
      "[0.60926443, 0.2, 0.20091702, 0.20018126]\n",
      "[0.6161516, 0.2, 0.20737687, 0.20061436]\n",
      "[0.60982186, 0.2, 0.20070575, 0.20096196]\n",
      "[0.6135845, 0.2, 0.20523791, 0.20019881]\n",
      "[0.62546, 0.2, 0.21627721, 0.20104164]\n",
      "[0.61559695, 0.2, 0.20666593, 0.2007961]\n",
      "[0.61202145, 0.2, 0.20278926, 0.20110366]\n",
      "[0.624009, 0.2, 0.21569316, 0.20019326]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3450 iterations: 1.094382898012797 mins\n",
      "Train Loss: [0.624009, 0.2, 0.21569316, 0.20019326]\n",
      "[0.6209666, 0.2, 0.20672539, 0.20612474]\n",
      "[0.61911017, 0.2, 0.21036947, 0.2006302]\n",
      "[0.6376907, 0.2, 0.22881211, 0.20077403]\n",
      "[0.6222402, 0.2, 0.21339948, 0.20074165]\n",
      "[0.6162508, 0.2, 0.20792644, 0.20023076]\n",
      "[0.6140262, 0.2, 0.20416275, 0.20177548]\n",
      "[0.6162981, 0.2, 0.20541477, 0.20280136]\n",
      "[0.6200503, 0.2, 0.2105783, 0.20139861]\n",
      "[0.6146029, 0.2, 0.20626643, 0.20027068]\n",
      "[0.61566395, 0.2, 0.20653543, 0.20106946]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3460 iterations: 1.096450650691986 mins\n",
      "Train Loss: [0.61566395, 0.2, 0.20653543, 0.20106946]\n",
      "[0.61587733, 0.2, 0.20664538, 0.20117928]\n",
      "[0.62779784, 0.2, 0.21881256, 0.20093898]\n",
      "[0.6267421, 0.2, 0.2152198, 0.20348197]\n",
      "[0.6161631, 0.2, 0.20365766, 0.20447098]\n",
      "[0.6236779, 0.2, 0.21433173, 0.20131837]\n",
      "[0.61832356, 0.2, 0.20971923, 0.20058244]\n",
      "[0.61279976, 0.2, 0.20408478, 0.20069918]\n",
      "[0.614028, 0.2, 0.2060055, 0.20001253]\n",
      "[0.6162282, 0.2, 0.20845453, 0.1997697]\n",
      "[0.6142284, 0.2, 0.20589823, 0.20033208]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3470 iterations: 1.100006135304769 mins\n",
      "Train Loss: [0.6142284, 0.2, 0.20589823, 0.20033208]\n",
      "[0.61478, 0.2, 0.20519611, 0.20159113]\n",
      "[0.60942185, 0.2, 0.20102139, 0.2004138]\n",
      "[0.62206537, 0.2, 0.21394104, 0.20014398]\n",
      "[0.61248606, 0.2, 0.20381632, 0.20069556]\n",
      "[0.6204712, 0.2, 0.21200515, 0.2004979]\n",
      "[0.61026824, 0.2, 0.20068425, 0.2016219]\n",
      "[0.6183113, 0.2, 0.20968084, 0.20067434]\n",
      "[0.61071235, 0.2, 0.20240858, 0.20035373]\n",
      "[0.6096093, 0.2, 0.20104443, 0.2006209]\n",
      "[0.61608696, 0.2, 0.20756865, 0.20058058]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3480 iterations: 1.10233416557312 mins\n",
      "Train Loss: [0.61608696, 0.2, 0.20756865, 0.20058058]\n",
      "[0.6557879, 0.2, 0.20140119, 0.24645528]\n",
      "[0.6212774, 0.2, 0.21234564, 0.20100302]\n",
      "[0.6108358, 0.2, 0.20222113, 0.20068689]\n",
      "[0.6188611, 0.2, 0.20935409, 0.20157878]\n",
      "[0.61797184, 0.2, 0.20950215, 0.20053984]\n",
      "[0.62142634, 0.2, 0.21307647, 0.20041661]\n",
      "[0.6169943, 0.2, 0.20851962, 0.20053609]\n",
      "[0.6114472, 0.2, 0.2026346, 0.20086806]\n",
      "[0.61805093, 0.2, 0.20974554, 0.20035416]\n",
      "[0.6176894, 0.2, 0.20912258, 0.20060858]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3490 iterations: 1.104429018497467 mins\n",
      "Train Loss: [0.6176894, 0.2, 0.20912258, 0.20060858]\n",
      "[0.6198184, 0.2, 0.21110334, 0.20074904]\n",
      "[0.6167151, 0.2, 0.20704615, 0.20169477]\n",
      "[0.60947245, 0.2, 0.20107818, 0.20041211]\n",
      "[0.6157069, 0.2, 0.20588624, 0.20183067]\n",
      "[0.6307006, 0.2, 0.2211344, 0.20156944]\n",
      "[0.6263399, 0.2, 0.21740073, 0.20093778]\n",
      "[0.6119052, 0.2, 0.20269449, 0.20120558]\n",
      "[0.61808366, 0.2, 0.20936704, 0.20070925]\n",
      "[0.61040086, 0.2, 0.20170523, 0.20068783]\n",
      "[0.61982566, 0.2, 0.21121125, 0.20060818]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3500 iterations: 1.1065781513849895 mins\n",
      "Train Loss: [0.61982566, 0.2, 0.21121125, 0.20060818]\n",
      "[0.6128707, 0.2, 0.20370968, 0.20115721]\n",
      "[0.6148053, 0.2, 0.20623915, 0.20056503]\n",
      "[0.65357745, 0.2, 0.2008934, 0.24468629]\n",
      "[0.65657425, 0.2, 0.24796408, 0.2006123]\n",
      "[0.6181221, 0.2, 0.20950674, 0.20061576]\n",
      "[0.62307364, 0.2, 0.21490382, 0.20016713]\n",
      "[0.6172149, 0.2, 0.20887892, 0.2003291]\n",
      "[0.6192548, 0.2, 0.2108634, 0.20037974]\n",
      "[0.6493054, 0.2, 0.21211211, 0.22917709]\n",
      "[0.6260596, 0.2, 0.21674076, 0.20129746]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3510 iterations: 1.1098107814788818 mins\n",
      "Train Loss: [0.6260596, 0.2, 0.21674076, 0.20129746]\n",
      "[0.6133162, 0.2, 0.20494801, 0.20034038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6133465, 0.2, 0.20481992, 0.20049201]\n",
      "[0.6169191, 0.2, 0.2083464, 0.20053138]\n",
      "[0.61149913, 0.2, 0.20283869, 0.20061308]\n",
      "[0.62053096, 0.2, 0.21147123, 0.20100692]\n",
      "[0.6590732, 0.2, 0.2181605, 0.2328549]\n",
      "[0.6160896, 0.2, 0.20745566, 0.20057201]\n",
      "[0.6209863, 0.2, 0.21191862, 0.20100169]\n",
      "[0.6136431, 0.2, 0.20514148, 0.20043226]\n",
      "[0.6104561, 0.2, 0.20192301, 0.20046082]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3520 iterations: 1.1131883978843689 mins\n",
      "Train Loss: [0.6104561, 0.2, 0.20192301, 0.20046082]\n",
      "[0.61950326, 0.2, 0.21096201, 0.20046712]\n",
      "[0.61641216, 0.2, 0.20737842, 0.20095776]\n",
      "[0.61705345, 0.2, 0.20793733, 0.20103863]\n",
      "[0.6173374, 0.2, 0.20812026, 0.20113924]\n",
      "[0.62728554, 0.2, 0.21832472, 0.20088317]\n",
      "[0.6198164, 0.2, 0.21137092, 0.20036939]\n",
      "[0.6231685, 0.2, 0.21393551, 0.20115979]\n",
      "[0.6133339, 0.2, 0.20379098, 0.20147264]\n",
      "[0.6137143, 0.2, 0.20489782, 0.20074973]\n",
      "[0.61695915, 0.2, 0.20782511, 0.2010718]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3530 iterations: 1.116114568710327 mins\n",
      "Train Loss: [0.61695915, 0.2, 0.20782511, 0.2010718]\n",
      "[0.6160038, 0.2, 0.20684335, 0.20110337]\n",
      "[0.6109345, 0.2, 0.20211063, 0.2007727]\n",
      "[0.6210656, 0.2, 0.21162249, 0.20139833]\n",
      "[0.6218389, 0.2, 0.21355844, 0.20024236]\n",
      "[0.613589, 0.2, 0.20521978, 0.20033795]\n",
      "[0.6189326, 0.2, 0.21024801, 0.20066044]\n",
      "[0.6199483, 0.2, 0.21083334, 0.20109825]\n",
      "[0.6124005, 0.2, 0.2039273, 0.200464]\n",
      "[0.6204847, 0.2, 0.2120677, 0.20041499]\n",
      "[0.6173342, 0.2, 0.20871677, 0.20062238]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3540 iterations: 1.1185118317604066 mins\n",
      "Train Loss: [0.6173342, 0.2, 0.20871677, 0.20062238]\n",
      "[0.6124324, 0.2, 0.20384516, 0.20059928]\n",
      "[0.61946976, 0.2, 0.2104268, 0.2010625]\n",
      "[0.619932, 0.2, 0.21074854, 0.20121041]\n",
      "[0.6198702, 0.2, 0.21003486, 0.20186862]\n",
      "[0.6123283, 0.2, 0.2031961, 0.2011714]\n",
      "[0.61177355, 0.2, 0.20224014, 0.20157765]\n",
      "[0.6173546, 0.2, 0.20888758, 0.20051539]\n",
      "[0.6210506, 0.2, 0.21109317, 0.20200917]\n",
      "[0.62970537, 0.2, 0.2215047, 0.20025465]\n",
      "[0.6262679, 0.2, 0.21678247, 0.20154175]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3550 iterations: 1.1220722158749898 mins\n",
      "Train Loss: [0.6262679, 0.2, 0.21678247, 0.20154175]\n",
      "[0.6192176, 0.2, 0.2106038, 0.20067218]\n",
      "[0.6146819, 0.2, 0.2050245, 0.20171793]\n",
      "[0.6380756, 0.2, 0.22959398, 0.20054276]\n",
      "[0.6125123, 0.2, 0.20164101, 0.20293349]\n",
      "[0.61784774, 0.2, 0.20668435, 0.20322579]\n",
      "[0.62226105, 0.2, 0.21311362, 0.20121048]\n",
      "[0.6181586, 0.2, 0.20966068, 0.2005625]\n",
      "[0.6248262, 0.2, 0.21672575, 0.20016451]\n",
      "[0.6132287, 0.2, 0.2047543, 0.20053531]\n",
      "[0.616044, 0.2, 0.20671414, 0.20138745]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3560 iterations: 1.126015563805898 mins\n",
      "Train Loss: [0.616044, 0.2, 0.20671414, 0.20138745]\n",
      "[0.6129979, 0.2, 0.20461375, 0.20043771]\n",
      "[0.61847085, 0.2, 0.20842777, 0.20209184]\n",
      "[0.61363167, 0.2, 0.20473301, 0.20094289]\n",
      "[0.61170655, 0.2, 0.20146039, 0.20228633]\n",
      "[0.6132868, 0.2, 0.20530586, 0.20001823]\n",
      "[0.6102627, 0.2, 0.20134509, 0.20095244]\n",
      "[0.6172787, 0.2, 0.2078565, 0.2014553]\n",
      "[0.6388784, 0.2, 0.20143168, 0.22947876]\n",
      "[0.62410885, 0.2, 0.21571137, 0.20042919]\n",
      "[0.6117179, 0.2, 0.20339954, 0.20034905]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3570 iterations: 1.1284441669782004 mins\n",
      "Train Loss: [0.6117179, 0.2, 0.20339954, 0.20034905]\n",
      "[0.6306507, 0.2, 0.22255795, 0.2001226]\n",
      "[0.62519157, 0.2, 0.21560791, 0.20161203]\n",
      "[0.61333996, 0.2, 0.20457445, 0.20079033]\n",
      "[0.6169963, 0.2, 0.20810552, 0.20091158]\n",
      "[0.6139527, 0.2, 0.20516661, 0.20080411]\n",
      "[0.61947304, 0.2, 0.2100496, 0.20143889]\n",
      "[0.6725486, 0.2, 0.2635395, 0.2010224]\n",
      "[0.61864287, 0.2, 0.2074316, 0.20321463]\n",
      "[0.6283495, 0.2, 0.2171293, 0.20321421]\n",
      "[0.6160231, 0.2, 0.20662525, 0.20138349]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3580 iterations: 1.130364481608073 mins\n",
      "Train Loss: [0.6160231, 0.2, 0.20662525, 0.20138349]\n",
      "[0.62031305, 0.2, 0.21021856, 0.20207353]\n",
      "[0.6477954, 0.2, 0.23928693, 0.2004828]\n",
      "[0.6147961, 0.2, 0.20622742, 0.20053995]\n",
      "[0.6225629, 0.2, 0.2096948, 0.20483792]\n",
      "[0.61182094, 0.2, 0.20220985, 0.20158102]\n",
      "[0.617038, 0.2, 0.20659442, 0.2024155]\n",
      "[0.62069666, 0.2, 0.20862663, 0.2040455]\n",
      "[0.6150247, 0.2, 0.20598844, 0.20101753]\n",
      "[0.6310515, 0.2, 0.21665874, 0.20638068]\n",
      "[0.61260897, 0.2, 0.20287843, 0.20172632]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3590 iterations: 1.1335830330848693 mins\n",
      "Train Loss: [0.61260897, 0.2, 0.20287843, 0.20172632]\n",
      "[0.61980206, 0.2, 0.2087184, 0.20308793]\n",
      "[0.6110277, 0.2, 0.20205964, 0.20098098]\n",
      "[0.61113125, 0.2, 0.20002854, 0.20312504]\n",
      "[0.6134401, 0.2, 0.20413677, 0.2013353]\n",
      "[0.62379277, 0.2, 0.21381687, 0.20201801]\n",
      "[0.6560483, 0.2, 0.20495029, 0.24315071]\n",
      "[0.60930467, 0.2, 0.20042548, 0.20094188]\n",
      "[0.61624336, 0.2, 0.20393533, 0.2043806]\n",
      "[0.62310857, 0.2, 0.21215247, 0.20303851]\n",
      "[0.6316146, 0.2, 0.22095233, 0.20275421]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3600 iterations: 1.1362828850746154 mins\n",
      "Train Loss: [0.6316146, 0.2, 0.22095233, 0.20275421]\n",
      "[0.61732894, 0.2, 0.20823334, 0.20119563]\n",
      "[0.62047833, 0.2, 0.21079575, 0.20179021]\n",
      "[0.6260907, 0.2, 0.21675405, 0.20145199]\n",
      "[0.62948966, 0.2, 0.21910278, 0.20251025]\n",
      "[0.61593837, 0.2, 0.2066366, 0.20143427]\n",
      "[0.6166973, 0.2, 0.20682836, 0.20201002]\n",
      "[0.61580205, 0.2, 0.20574853, 0.20220305]\n",
      "[0.6233205, 0.2, 0.21204801, 0.2034308]\n",
      "[0.6435368, 0.2, 0.20753662, 0.2281668]\n",
      "[0.61858207, 0.2, 0.20824444, 0.20250969]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3610 iterations: 1.1391014496485392 mins\n",
      "Train Loss: [0.61858207, 0.2, 0.20824444, 0.20250969]\n",
      "[0.6235491, 0.2, 0.21179137, 0.20393479]\n",
      "[0.6183584, 0.2, 0.20800288, 0.20253746]\n",
      "[0.6287314, 0.2, 0.2186091, 0.20230901]\n",
      "[0.6198063, 0.2, 0.20804805, 0.20394912]\n",
      "[0.6481453, 0.2, 0.23710573, 0.20323433]\n",
      "[0.6206472, 0.2, 0.21118198, 0.20166586]\n",
      "[0.6296118, 0.2, 0.21969457, 0.20212378]\n",
      "[0.62619543, 0.2, 0.21718462, 0.20122255]\n",
      "[0.626799, 0.2, 0.21750043, 0.20151484]\n",
      "[0.62328476, 0.2, 0.21453746, 0.20096776]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3620 iterations: 1.1419973850250245 mins\n",
      "Train Loss: [0.62328476, 0.2, 0.21453746, 0.20096776]\n",
      "[0.6311861, 0.2, 0.22119516, 0.2022154]\n",
      "[0.6232626, 0.2, 0.20991439, 0.20557639]\n",
      "[0.6154304, 0.2, 0.205971, 0.20169169]\n",
      "[0.61692154, 0.2, 0.20773144, 0.20142628]\n",
      "[0.6126945, 0.2, 0.20302914, 0.20190594]\n",
      "[0.6154902, 0.2, 0.20570886, 0.20202605]\n",
      "[0.62147987, 0.2, 0.21240029, 0.20132874]\n",
      "[0.6280372, 0.2, 0.21795516, 0.20233582]\n",
      "[0.61456823, 0.2, 0.20582129, 0.20100464]\n",
      "[0.6161419, 0.2, 0.20768283, 0.20072088]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3630 iterations: 1.1447640140851338 mins\n",
      "Train Loss: [0.6161419, 0.2, 0.20768283, 0.20072088]\n",
      "[0.6151075, 0.2, 0.20567709, 0.2016971]\n",
      "[0.690651, 0.2, 0.28201208, 0.2009108]\n",
      "[0.62208515, 0.2, 0.21323523, 0.20112105]\n",
      "[0.61433417, 0.2, 0.20603156, 0.20057365]\n",
      "[0.6608963, 0.2, 0.20392421, 0.24924323]\n",
      "[0.6135361, 0.2, 0.20515354, 0.20065619]\n",
      "[0.61783403, 0.2, 0.20945387, 0.20065552]\n",
      "[0.6460905, 0.2, 0.21282269, 0.22554494]\n",
      "[0.6224399, 0.2, 0.211153, 0.2035655]\n",
      "[0.61803037, 0.2, 0.20821804, 0.2020909]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3640 iterations: 1.147130799293518 mins\n",
      "Train Loss: [0.61803037, 0.2, 0.20821804, 0.2020909]\n",
      "[0.6624552, 0.2, 0.20801093, 0.24672222]\n",
      "[0.6139454, 0.2, 0.20437084, 0.20185025]\n",
      "[0.619472, 0.2, 0.21038452, 0.20136102]\n",
      "[0.6190083, 0.2, 0.2089652, 0.20231476]\n",
      "[0.61430466, 0.2, 0.20533836, 0.20123653]\n",
      "[0.617198, 0.2, 0.20773655, 0.2017307]\n",
      "[0.6249805, 0.2, 0.21628913, 0.20096013]\n",
      "[0.62552327, 0.2, 0.2133717, 0.20441376]\n",
      "[0.61499137, 0.2, 0.20657088, 0.20067668]\n",
      "[0.6175182, 0.2, 0.20784731, 0.20192164]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3650 iterations: 1.151392968495687 mins\n",
      "Train Loss: [0.6175182, 0.2, 0.20784731, 0.20192164]\n",
      "[0.62231696, 0.2, 0.21411711, 0.20044573]\n",
      "[0.61724126, 0.2, 0.20899841, 0.20048429]\n",
      "[0.6101621, 0.2, 0.20190826, 0.2004916]\n",
      "[0.61751807, 0.2, 0.2085769, 0.20117632]\n",
      "[0.622323, 0.2, 0.2140587, 0.20049742]\n",
      "[0.6172739, 0.2, 0.20900199, 0.20050374]\n",
      "[0.619566, 0.2, 0.21106243, 0.20073533]\n",
      "[0.61014897, 0.2, 0.20228179, 0.20009907]\n",
      "[0.60889125, 0.2, 0.20093961, 0.20018412]\n",
      "[0.62567276, 0.2, 0.2175968, 0.20030947]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3660 iterations: 1.1541538516680399 mins\n",
      "Train Loss: [0.62567276, 0.2, 0.2175968, 0.20030947]\n",
      "[0.6267925, 0.2, 0.21898071, 0.20004635]\n",
      "[0.6151842, 0.2, 0.20693317, 0.20048694]\n",
      "[0.617189, 0.2, 0.20838556, 0.20104079]\n",
      "[0.62515366, 0.2, 0.21637122, 0.20102172]\n",
      "[0.6091091, 0.2, 0.20059367, 0.20075668]\n",
      "[0.60959625, 0.2, 0.2009356, 0.20090389]\n",
      "[0.61286986, 0.2, 0.20423424, 0.20088087]\n",
      "[0.6163426, 0.2, 0.20773728, 0.20085223]\n",
      "[0.6089137, 0.2, 0.2006191, 0.20054242]\n",
      "[0.60887253, 0.2, 0.20063844, 0.20048183]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3670 iterations: 1.1564111471176148 mins\n",
      "Train Loss: [0.60887253, 0.2, 0.20063844, 0.20048183]\n",
      "[0.60840786, 0.2, 0.2002165, 0.20043886]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6127526, 0.2, 0.2036481, 0.2013513]\n",
      "[0.60989594, 0.2, 0.20176312, 0.20037751]\n",
      "[0.6115488, 0.2, 0.20288725, 0.20090352]\n",
      "[0.62061805, 0.2, 0.21270029, 0.20015606]\n",
      "[0.6087569, 0.2, 0.20020086, 0.2007897]\n",
      "[0.6110484, 0.2, 0.20059095, 0.20268385]\n",
      "[0.61068374, 0.2, 0.20133688, 0.20156556]\n",
      "[0.612545, 0.2, 0.20302638, 0.20172572]\n",
      "[0.61343294, 0.2, 0.20350988, 0.20211302]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3680 iterations: 1.1601399858792623 mins\n",
      "Train Loss: [0.61343294, 0.2, 0.20350988, 0.20211302]\n",
      "[0.6312395, 0.2, 0.22181357, 0.20159192]\n",
      "[0.61256546, 0.2, 0.20422617, 0.2004791]\n",
      "[0.6238431, 0.2, 0.2150964, 0.2008584]\n",
      "[0.6095049, 0.2, 0.20183398, 0.19975069]\n",
      "[0.61546344, 0.2, 0.20674478, 0.20077169]\n",
      "[0.6113927, 0.2, 0.20192681, 0.2014966]\n",
      "[0.60905594, 0.2, 0.20022073, 0.20083646]\n",
      "[0.60988784, 0.2, 0.20105107, 0.20080401]\n",
      "[0.61393255, 0.2, 0.20445926, 0.20140715]\n",
      "[0.61305076, 0.2, 0.20131843, 0.20362468]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3690 iterations: 1.164134669303894 mins\n",
      "Train Loss: [0.61305076, 0.2, 0.20131843, 0.20362468]\n",
      "[0.61276394, 0.2, 0.20151456, 0.20310557]\n",
      "[0.6147048, 0.2, 0.2043532, 0.20217396]\n",
      "[0.61558574, 0.2, 0.20300254, 0.20436922]\n",
      "[0.61085284, 0.2, 0.20130618, 0.20129421]\n",
      "[0.61046463, 0.2, 0.20000333, 0.20217767]\n",
      "[0.61143684, 0.2, 0.20236076, 0.2007639]\n",
      "[0.612359, 0.2, 0.20240115, 0.20161545]\n",
      "[0.61250985, 0.2, 0.20198373, 0.20215753]\n",
      "[0.6332729, 0.2, 0.22043025, 0.20444964]\n",
      "[0.6123285, 0.2, 0.20270559, 0.20120741]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3700 iterations: 1.1670045018196107 mins\n",
      "Train Loss: [0.6123285, 0.2, 0.20270559, 0.20120741]\n",
      "[0.6116553, 0.2, 0.2026957, 0.20052192]\n",
      "[0.62160504, 0.2, 0.21171829, 0.20142704]\n",
      "[0.61622447, 0.2, 0.20416717, 0.20357652]\n",
      "[0.61382055, 0.2, 0.2025766, 0.2027459]\n",
      "[0.6181458, 0.2, 0.20283446, 0.20679958]\n",
      "[0.6139549, 0.2, 0.20239292, 0.20303747]\n",
      "[0.62392575, 0.2, 0.21233562, 0.20305677]\n",
      "[0.6127425, 0.2, 0.20004651, 0.20416169]\n",
      "[0.61384046, 0.2, 0.20332779, 0.20197748]\n",
      "[0.6157128, 0.2, 0.20384604, 0.20333235]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3710 iterations: 1.1691497683525085 mins\n",
      "Train Loss: [0.6157128, 0.2, 0.20384604, 0.20333235]\n",
      "[0.6173381, 0.2, 0.20747788, 0.20132439]\n",
      "[0.647733, 0.2, 0.23597012, 0.20322646]\n",
      "[0.62270814, 0.2, 0.20878623, 0.20537804]\n",
      "[0.61574495, 0.2, 0.20253198, 0.20465349]\n",
      "[0.61469924, 0.2, 0.20165147, 0.20446225]\n",
      "[0.6177547, 0.2, 0.20545731, 0.20368078]\n",
      "[0.61535543, 0.2, 0.20486757, 0.201836]\n",
      "[0.6230052, 0.2, 0.21003878, 0.20427662]\n",
      "[0.6195115, 0.2, 0.2070398, 0.20374227]\n",
      "[0.6118284, 0.2, 0.20167011, 0.20139405]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3720 iterations: 1.1712628165880838 mins\n",
      "Train Loss: [0.6118284, 0.2, 0.20167011, 0.20139405]\n",
      "[0.61646247, 0.2, 0.20182556, 0.20584135]\n",
      "[0.62502354, 0.2, 0.21494828, 0.20125253]\n",
      "[0.6197151, 0.2, 0.2065997, 0.20427041]\n",
      "[0.6181836, 0.2, 0.20826614, 0.2010543]\n",
      "[0.6148601, 0.2, 0.20516647, 0.20081708]\n",
      "[0.6283842, 0.2, 0.21719912, 0.20229964]\n",
      "[0.62632364, 0.2, 0.2145933, 0.20283976]\n",
      "[0.6466722, 0.2, 0.21135004, 0.22642978]\n",
      "[0.61435074, 0.2, 0.20399125, 0.20146932]\n",
      "[0.61649823, 0.2, 0.20478138, 0.20283164]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3730 iterations: 1.1737992644309998 mins\n",
      "Train Loss: [0.61649823, 0.2, 0.20478138, 0.20283164]\n",
      "[0.6144569, 0.2, 0.20570518, 0.19987354]\n",
      "[0.61652356, 0.2, 0.20537432, 0.20228018]\n",
      "[0.6108475, 0.2, 0.2005031, 0.20148675]\n",
      "[0.61325735, 0.2, 0.20120212, 0.20321177]\n",
      "[0.6189771, 0.2, 0.20622402, 0.20392531]\n",
      "[0.64224935, 0.2, 0.20999512, 0.2234444]\n",
      "[0.61566526, 0.2, 0.20232768, 0.20454566]\n",
      "[0.61659515, 0.2, 0.20642056, 0.20140171]\n",
      "[0.61528134, 0.2, 0.20327899, 0.2032496]\n",
      "[0.61288893, 0.2, 0.20218356, 0.20197316]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3740 iterations: 1.1763038992881776 mins\n",
      "Train Loss: [0.61288893, 0.2, 0.20218356, 0.20197316]\n",
      "[0.61664516, 0.2, 0.20614046, 0.20179386]\n",
      "[0.6227786, 0.2, 0.21297371, 0.20111568]\n",
      "[0.62282825, 0.2, 0.21172747, 0.20243405]\n",
      "[0.62691534, 0.2, 0.2165284, 0.20174302]\n",
      "[0.6158396, 0.2, 0.20539533, 0.201823]\n",
      "[0.6154502, 0.2, 0.20538206, 0.20146923]\n",
      "[0.6084603, 0.2, 0.19692372, 0.20295979]\n",
      "[0.6289199, 0.2, 0.21868321, 0.20168081]\n",
      "[0.6138899, 0.2, 0.20462209, 0.2007316]\n",
      "[0.6228673, 0.2, 0.21256992, 0.20177986]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3750 iterations: 1.1788226167360942 mins\n",
      "Train Loss: [0.6228673, 0.2, 0.21256992, 0.20177986]\n",
      "[0.61689514, 0.2, 0.2076015, 0.20079486]\n",
      "[0.6185233, 0.2, 0.20948274, 0.20056003]\n",
      "[0.61417615, 0.2, 0.20405112, 0.20166332]\n",
      "[0.6186315, 0.2, 0.2067372, 0.20345174]\n",
      "[0.6187498, 0.2, 0.20670424, 0.20362243]\n",
      "[0.6223146, 0.2, 0.20859423, 0.20531654]\n",
      "[0.6429933, 0.2, 0.20697378, 0.22763556]\n",
      "[0.61787283, 0.2, 0.20728706, 0.20221992]\n",
      "[0.6273729, 0.2, 0.20765541, 0.2113691]\n",
      "[0.68928695, 0.2, 0.24740863, 0.23354594]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3760 iterations: 1.183583382765452 mins\n",
      "Train Loss: [0.68928695, 0.2, 0.24740863, 0.23354594]\n",
      "[0.62249506, 0.2, 0.21119007, 0.2029904]\n",
      "[0.62429565, 0.2, 0.21392061, 0.20207655]\n",
      "[0.62397754, 0.2, 0.21134911, 0.20434467]\n",
      "[0.6206808, 0.2, 0.20644929, 0.20596153]\n",
      "[0.6132359, 0.2, 0.20148838, 0.20348985]\n",
      "[0.6166496, 0.2, 0.20565103, 0.20275271]\n",
      "[0.6155173, 0.2, 0.20653152, 0.20075142]\n",
      "[0.6288996, 0.2, 0.21830928, 0.2023676]\n",
      "[0.62625575, 0.2, 0.21684495, 0.20119971]\n",
      "[0.61694616, 0.2, 0.20611097, 0.20263639]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3770 iterations: 1.1872413635253907 mins\n",
      "Train Loss: [0.61694616, 0.2, 0.20611097, 0.20263639]\n",
      "[0.62911636, 0.2, 0.21526973, 0.20566048]\n",
      "[0.6112753, 0.2, 0.20129102, 0.20181084]\n",
      "[0.6250513, 0.2, 0.21557678, 0.20131318]\n",
      "[0.6449404, 0.2, 0.23402245, 0.20276864]\n",
      "[0.6144406, 0.2, 0.20156261, 0.20474143]\n",
      "[0.6312146, 0.2, 0.20510732, 0.21798317]\n",
      "[0.6178736, 0.2, 0.20791864, 0.20184188]\n",
      "[0.61603594, 0.2, 0.20371357, 0.20422006]\n",
      "[0.6215035, 0.2, 0.21056351, 0.20284772]\n",
      "[0.6245097, 0.2, 0.21259406, 0.20383307]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3780 iterations: 1.1893486857414246 mins\n",
      "Train Loss: [0.6245097, 0.2, 0.21259406, 0.20383307]\n",
      "[0.6183782, 0.2, 0.20738666, 0.20291841]\n",
      "[0.61787105, 0.2, 0.2097753, 0.2000322]\n",
      "[0.62651646, 0.2, 0.21739818, 0.20106444]\n",
      "[0.6213632, 0.2, 0.21122569, 0.20209199]\n",
      "[0.61337936, 0.2, 0.20427744, 0.2010648]\n",
      "[0.6390139, 0.2, 0.22688244, 0.20410343]\n",
      "[0.6163776, 0.2, 0.20520842, 0.20315048]\n",
      "[0.6118303, 0.2, 0.20320828, 0.2006137]\n",
      "[0.60968137, 0.2, 0.20157842, 0.20010552]\n",
      "[0.6719555, 0.2, 0.19991374, 0.26405555]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3790 iterations: 1.1925469636917114 mins\n",
      "Train Loss: [0.6719555, 0.2, 0.19991374, 0.26405555]\n",
      "[0.63704544, 0.2, 0.22630182, 0.20276932]\n",
      "[0.63287574, 0.2, 0.22207858, 0.20283447]\n",
      "[0.6168197, 0.2, 0.20546685, 0.20340078]\n",
      "[0.6306217, 0.2, 0.22210227, 0.20057797]\n",
      "[0.61774147, 0.2, 0.20947276, 0.2003377]\n",
      "[0.6109642, 0.2, 0.20194446, 0.20109901]\n",
      "[0.61649925, 0.2, 0.20739901, 0.20118998]\n",
      "[0.61643094, 0.2, 0.20464028, 0.20389235]\n",
      "[0.6228633, 0.2, 0.21169415, 0.20328213]\n",
      "[0.6125942, 0.2, 0.20140848, 0.20331089]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3800 iterations: 1.19638911485672 mins\n",
      "Train Loss: [0.6125942, 0.2, 0.20140848, 0.20331089]\n",
      "[0.6250636, 0.2, 0.21277371, 0.2044266]\n",
      "[0.61579114, 0.2, 0.20491086, 0.20302778]\n",
      "[0.61165357, 0.2, 0.20255673, 0.20125462]\n",
      "[0.6091631, 0.2, 0.1997468, 0.20158423]\n",
      "[0.64185166, 0.2, 0.2324627, 0.20156667]\n",
      "[0.6264819, 0.2, 0.21136376, 0.20730546]\n",
      "[0.61532557, 0.2, 0.20555183, 0.20197023]\n",
      "[0.61635953, 0.2, 0.20679295, 0.20177223]\n",
      "[0.62254924, 0.2, 0.21431327, 0.20045057]\n",
      "[0.6952935, 0.2, 0.26260528, 0.22491091]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3810 iterations: 1.1993310491243998 mins\n",
      "Train Loss: [0.6952935, 0.2, 0.26260528, 0.22491091]\n",
      "[0.6125231, 0.2, 0.20249774, 0.20225719]\n",
      "[0.6171534, 0.2, 0.20824847, 0.20114455]\n",
      "[0.61295563, 0.2, 0.20381282, 0.2013891]\n",
      "[0.61304003, 0.2, 0.20217545, 0.20311743]\n",
      "[0.6132737, 0.2, 0.20415978, 0.20137292]\n",
      "[0.6097136, 0.2, 0.20147584, 0.20050204]\n",
      "[0.61165434, 0.2, 0.20231216, 0.20161155]\n",
      "[0.6312118, 0.2, 0.22285837, 0.20062774]\n",
      "[0.6235897, 0.2, 0.21513909, 0.20072958]\n",
      "[0.61632174, 0.2, 0.20628326, 0.2023227]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3820 iterations: 1.2017874519030254 mins\n",
      "Train Loss: [0.61632174, 0.2, 0.20628326, 0.2023227]\n",
      "[0.6236646, 0.2, 0.20712915, 0.20882465]\n",
      "[0.61143535, 0.2, 0.20208296, 0.20164661]\n",
      "[0.6425515, 0.2, 0.23381536, 0.20103571]\n",
      "[0.6748065, 0.2, 0.26517949, 0.20193148]\n",
      "[0.6405117, 0.2, 0.23148006, 0.20133646]\n",
      "[0.6204499, 0.2, 0.2106502, 0.20211095]\n",
      "[0.61363405, 0.2, 0.20442563, 0.20152603]\n",
      "[0.6228816, 0.2, 0.212003, 0.20320192]\n",
      "[0.61833996, 0.2, 0.20942892, 0.20123957]\n",
      "[0.61006254, 0.2, 0.20175356, 0.2006421]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3830 iterations: 1.204120401541392 mins\n",
      "Train Loss: [0.61006254, 0.2, 0.20175356, 0.2006421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63704664, 0.2, 0.22492161, 0.20446236]\n",
      "[0.6338263, 0.2, 0.22529046, 0.20087668]\n",
      "[0.6462543, 0.2, 0.23549484, 0.20310344]\n",
      "[0.63774383, 0.2, 0.22843586, 0.20165394]\n",
      "[0.61431676, 0.2, 0.2050715, 0.20159313]\n",
      "[0.6168033, 0.2, 0.20648824, 0.20266455]\n",
      "[0.61653775, 0.2, 0.20742261, 0.20146601]\n",
      "[0.60847294, 0.2, 0.199862, 0.20096299]\n",
      "[0.6251786, 0.2, 0.21242246, 0.2051093]\n",
      "[0.6338246, 0.2, 0.22351994, 0.20265916]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3840 iterations: 1.2065545837084453 mins\n",
      "Train Loss: [0.6338246, 0.2, 0.22351994, 0.20265916]\n",
      "[0.62564486, 0.2, 0.21745162, 0.2005484]\n",
      "[0.61834294, 0.2, 0.20692348, 0.20377529]\n",
      "[0.61850274, 0.2, 0.20890725, 0.20195155]\n",
      "[0.62431633, 0.2, 0.21269996, 0.20397156]\n",
      "[0.6166705, 0.2, 0.20701179, 0.20201276]\n",
      "[0.62225425, 0.2, 0.21235998, 0.20224719]\n",
      "[0.6132401, 0.2, 0.20451039, 0.20108141]\n",
      "[0.61056226, 0.2, 0.20150876, 0.20140414]\n",
      "[0.6179708, 0.2, 0.20685004, 0.20347068]\n",
      "[0.6344283, 0.2, 0.22347407, 0.20330344]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3850 iterations: 1.2103357831637065 mins\n",
      "Train Loss: [0.6344283, 0.2, 0.22347407, 0.20330344]\n",
      "[0.6202495, 0.2, 0.20709844, 0.20549977]\n",
      "[0.6247485, 0.2, 0.21622878, 0.20086789]\n",
      "[0.63691056, 0.2, 0.22812194, 0.20113698]\n",
      "[0.6202796, 0.2, 0.20293477, 0.20969273]\n",
      "[0.6193928, 0.2, 0.20955265, 0.20218687]\n",
      "[0.6253822, 0.2, 0.21685463, 0.20087285]\n",
      "[0.6222641, 0.2, 0.21151051, 0.20309685]\n",
      "[0.6136017, 0.2, 0.20333971, 0.20260355]\n",
      "[0.62044954, 0.2, 0.20990837, 0.20288117]\n",
      "[0.623272, 0.2, 0.21385896, 0.20175134]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3860 iterations: 1.21291188398997 mins\n",
      "Train Loss: [0.623272, 0.2, 0.21385896, 0.20175134]\n",
      "[0.62175256, 0.2, 0.2129389, 0.20115012]\n",
      "[0.61610997, 0.2, 0.20688404, 0.2015604]\n",
      "[0.61503303, 0.2, 0.20628172, 0.20108417]\n",
      "[0.6494863, 0.2, 0.21608394, 0.22573374]\n",
      "[0.61478287, 0.2, 0.2059439, 0.20116852]\n",
      "[0.61672384, 0.2, 0.20633376, 0.2027182]\n",
      "[0.62191856, 0.2, 0.21050346, 0.20374216]\n",
      "[0.61011773, 0.2, 0.20116927, 0.2012734]\n",
      "[0.61621463, 0.2, 0.20446149, 0.20407651]\n",
      "[0.6214311, 0.2, 0.21182445, 0.2019296]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3870 iterations: 1.2149975339571635 mins\n",
      "Train Loss: [0.6214311, 0.2, 0.21182445, 0.2019296]\n",
      "[0.6189755, 0.2, 0.21037863, 0.20091972]\n",
      "[0.6308534, 0.2, 0.21959902, 0.20357779]\n",
      "[0.6515236, 0.2, 0.24203552, 0.20181333]\n",
      "[0.6157009, 0.2, 0.20422047, 0.20380032]\n",
      "[0.6160886, 0.2, 0.20678373, 0.20162046]\n",
      "[0.6127745, 0.2, 0.20322815, 0.20185848]\n",
      "[0.61134744, 0.2, 0.20165546, 0.20200147]\n",
      "[0.6357152, 0.2, 0.20111632, 0.22690667]\n",
      "[0.63368535, 0.2, 0.22342086, 0.20256971]\n",
      "[0.6096044, 0.2, 0.20149204, 0.20041555]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3880 iterations: 1.2173743009567262 mins\n",
      "Train Loss: [0.6096044, 0.2, 0.20149204, 0.20041555]\n",
      "[0.61643183, 0.2, 0.20670389, 0.20202972]\n",
      "[0.61362684, 0.2, 0.20400116, 0.20192656]\n",
      "[0.61932963, 0.2, 0.21132828, 0.20030183]\n",
      "[0.62876666, 0.2, 0.21796921, 0.20309818]\n",
      "[0.6101051, 0.2, 0.1988084, 0.2035982]\n",
      "[0.6208117, 0.2, 0.21179229, 0.20132214]\n",
      "[0.6166492, 0.2, 0.20825325, 0.20070013]\n",
      "[0.62120485, 0.2, 0.21186253, 0.20164849]\n",
      "[0.6380476, 0.2, 0.20005701, 0.23029968]\n",
      "[0.6326532, 0.2, 0.22248115, 0.20248312]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3890 iterations: 1.2191593488057455 mins\n",
      "Train Loss: [0.6326532, 0.2, 0.22248115, 0.20248312]\n",
      "[0.62160987, 0.2, 0.21381533, 0.2001073]\n",
      "[0.61725384, 0.2, 0.207526, 0.20204228]\n",
      "[0.613464, 0.2, 0.20519915, 0.20058113]\n",
      "[0.6106545, 0.2, 0.20047362, 0.20249921]\n",
      "[0.6197783, 0.2, 0.20984632, 0.2022529]\n",
      "[0.6263997, 0.2, 0.21789208, 0.20083162]\n",
      "[0.6524155, 0.2, 0.2440066, 0.20073505]\n",
      "[0.6340527, 0.2, 0.2257447, 0.20064127]\n",
      "[0.6263375, 0.2, 0.21803507, 0.20064174]\n",
      "[0.6208327, 0.2, 0.21206266, 0.20111468]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3900 iterations: 1.2211847146352133 mins\n",
      "Train Loss: [0.6208327, 0.2, 0.21206266, 0.20111468]\n",
      "[0.6201213, 0.2, 0.2108724, 0.20159844]\n",
      "[0.63099736, 0.2, 0.22179766, 0.20155445]\n",
      "[0.6231351, 0.2, 0.21421272, 0.2012814]\n",
      "[0.61683095, 0.2, 0.2070755, 0.20211813]\n",
      "[0.615452, 0.2, 0.20640223, 0.20141622]\n",
      "[0.6229428, 0.2, 0.21289936, 0.20241368]\n",
      "[0.6388244, 0.2, 0.22649814, 0.20470034]\n",
      "[0.6169547, 0.2, 0.20790379, 0.20142922]\n",
      "[0.62633437, 0.2, 0.21764259, 0.20107377]\n",
      "[0.61517954, 0.2, 0.20709495, 0.20047025]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3910 iterations: 1.223443082968394 mins\n",
      "Train Loss: [0.61517954, 0.2, 0.20709495, 0.20047025]\n",
      "[0.6198285, 0.2, 0.21069007, 0.2015281]\n",
      "[0.61590135, 0.2, 0.20856868, 0.19972652]\n",
      "[0.6198004, 0.2, 0.21157613, 0.20062271]\n",
      "[0.61953855, 0.2, 0.21118458, 0.2007561]\n",
      "[0.7080877, 0.2, 0.29777667, 0.20271698]\n",
      "[0.61969125, 0.2, 0.2104699, 0.20162885]\n",
      "[0.621718, 0.2, 0.21050699, 0.20362017]\n",
      "[0.6316832, 0.2, 0.22075765, 0.20333706]\n",
      "[0.61385393, 0.2, 0.20407285, 0.20219502]\n",
      "[0.6105643, 0.2, 0.20337091, 0.19960998]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3920 iterations: 1.227105398972829 mins\n",
      "Train Loss: [0.6105643, 0.2, 0.20337091, 0.19960998]\n",
      "[0.612802, 0.2, 0.20386966, 0.20135154]\n",
      "[0.6281384, 0.2, 0.21791774, 0.20264266]\n",
      "[0.6153985, 0.2, 0.20584653, 0.20197648]\n",
      "[0.630566, 0.2, 0.20867032, 0.21432298]\n",
      "[0.611328, 0.2, 0.20173535, 0.20202407]\n",
      "[0.614663, 0.2, 0.20457736, 0.202521]\n",
      "[0.6318346, 0.2, 0.22190186, 0.20237173]\n",
      "[0.611361, 0.2, 0.2036904, 0.20011327]\n",
      "[0.63156474, 0.2, 0.22208272, 0.20192863]\n",
      "[0.61154896, 0.2, 0.20213644, 0.20186312]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3930 iterations: 1.2303985158602397 mins\n",
      "Train Loss: [0.61154896, 0.2, 0.20213644, 0.20186312]\n",
      "[0.63474005, 0.2, 0.22603215, 0.20116241]\n",
      "[0.61996835, 0.2, 0.21154739, 0.20087928]\n",
      "[0.6178535, 0.2, 0.20662923, 0.20368627]\n",
      "[0.6179854, 0.2, 0.20591801, 0.20453314]\n",
      "[0.61203265, 0.2, 0.20254496, 0.20195748]\n",
      "[0.6151942, 0.2, 0.20652045, 0.20114799]\n",
      "[0.6231737, 0.2, 0.21392182, 0.20173045]\n",
      "[0.6162809, 0.2, 0.20592697, 0.20283668]\n",
      "[0.6153347, 0.2, 0.20845008, 0.1993715]\n",
      "[0.6097999, 0.2, 0.19892216, 0.20336857]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3940 iterations: 1.2342605471611023 mins\n",
      "Train Loss: [0.6097999, 0.2, 0.19892216, 0.20336857]\n",
      "[0.6115199, 0.2, 0.2035741, 0.20044081]\n",
      "[0.61826813, 0.2, 0.20872064, 0.2020472]\n",
      "[0.62743026, 0.2, 0.21825604, 0.20167848]\n",
      "[0.6100097, 0.2, 0.20099002, 0.2015285]\n",
      "[0.6088055, 0.2, 0.20053391, 0.2007852]\n",
      "[0.6073881, 0.2, 0.19921294, 0.20069422]\n",
      "[0.6246582, 0.2, 0.21662527, 0.2005577]\n",
      "[0.614037, 0.2, 0.2063306, 0.20023642]\n",
      "[0.6078199, 0.2, 0.19994152, 0.2004132]\n",
      "[0.6328479, 0.2, 0.22350386, 0.2018833]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3950 iterations: 1.2363920489947 mins\n",
      "Train Loss: [0.6328479, 0.2, 0.22350386, 0.2018833]\n",
      "[0.61043453, 0.2, 0.20141149, 0.20156662]\n",
      "[0.62482727, 0.2, 0.21678883, 0.20058629]\n",
      "[0.61174005, 0.2, 0.20253511, 0.20175676]\n",
      "[0.60945415, 0.2, 0.20080973, 0.20119987]\n",
      "[0.6185891, 0.2, 0.20806955, 0.20307861]\n",
      "[0.61232793, 0.2, 0.20459442, 0.2002956]\n",
      "[0.6095575, 0.2, 0.20153637, 0.2005865]\n",
      "[0.61045814, 0.2, 0.20184815, 0.20117909]\n",
      "[0.6269628, 0.2, 0.21602182, 0.20351395]\n",
      "[0.6298561, 0.2, 0.22122271, 0.20121078]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3960 iterations: 1.2383565187454224 mins\n",
      "Train Loss: [0.6298561, 0.2, 0.22122271, 0.20121078]\n",
      "[0.6275408, 0.2, 0.21885721, 0.20126505]\n",
      "[0.61952007, 0.2, 0.21064715, 0.20145853]\n",
      "[0.6127645, 0.2, 0.20475659, 0.20059867]\n",
      "[0.6081363, 0.2, 0.19968714, 0.20104516]\n",
      "[0.6447841, 0.2, 0.23805638, 0.19932902]\n",
      "[0.6105205, 0.2, 0.2009758, 0.20213977]\n",
      "[0.6234316, 0.2, 0.21460444, 0.20141564]\n",
      "[0.6324615, 0.2, 0.2240152, 0.20102826]\n",
      "[0.62206507, 0.2, 0.21251784, 0.202123]\n",
      "[0.62468964, 0.2, 0.21518207, 0.20207757]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3970 iterations: 1.2402257323265076 mins\n",
      "Train Loss: [0.62468964, 0.2, 0.21518207, 0.20207757]\n",
      "[0.61763823, 0.2, 0.20937638, 0.20082642]\n",
      "[0.6143379, 0.2, 0.20394008, 0.2029575]\n",
      "[0.61064833, 0.2, 0.20266753, 0.20053546]\n",
      "[0.6141343, 0.2, 0.20447184, 0.20221284]\n",
      "[0.6178711, 0.2, 0.20864116, 0.20177718]\n",
      "[0.61687267, 0.2, 0.20731162, 0.20210609]\n",
      "[0.611862, 0.2, 0.20310438, 0.20130034]\n",
      "[0.6476044, 0.2, 0.21197692, 0.2281685]\n",
      "[0.61935973, 0.2, 0.20993829, 0.20196547]\n",
      "[0.6089377, 0.2, 0.20106429, 0.2004194]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3980 iterations: 1.2422452648480733 mins\n",
      "Train Loss: [0.6089377, 0.2, 0.20106429, 0.2004194]\n",
      "[0.6240206, 0.2, 0.21447818, 0.20209025]\n",
      "[0.6220835, 0.2, 0.21450864, 0.20012406]\n",
      "[0.64196914, 0.2, 0.23403956, 0.20047984]\n",
      "[0.6147771, 0.2, 0.20605485, 0.2012717]\n",
      "[0.61540145, 0.2, 0.20749655, 0.20045252]\n",
      "[0.6183396, 0.2, 0.20933957, 0.2015432]\n",
      "[0.6129081, 0.2, 0.20223874, 0.20320776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6375641, 0.2, 0.21109363, 0.21900399]\n",
      "[0.6175653, 0.2, 0.20781454, 0.20228283]\n",
      "[0.61744815, 0.2, 0.20884547, 0.20113175]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3990 iterations: 1.2450690984725952 mins\n",
      "Train Loss: [0.61744815, 0.2, 0.20884547, 0.20113175]\n",
      "[0.6199331, 0.2, 0.21107328, 0.20138484]\n",
      "[0.62017643, 0.2, 0.21260847, 0.20009243]\n",
      "[0.61302525, 0.2, 0.20539813, 0.20014966]\n",
      "[0.61055446, 0.2, 0.20201345, 0.2010608]\n",
      "[0.6115573, 0.2, 0.20398119, 0.20009267]\n",
      "[0.61026984, 0.2, 0.2016817, 0.20110172]\n",
      "[0.6117871, 0.2, 0.20392866, 0.20036939]\n",
      "[0.6283533, 0.2, 0.21884876, 0.20201321]\n",
      "[0.62315077, 0.2, 0.21347238, 0.20218472]\n",
      "[0.6105787, 0.2, 0.20146574, 0.2016176]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4000 iterations: 1.248282500108083 mins\n",
      "Train Loss: [0.6105787, 0.2, 0.20146574, 0.2016176]\n",
      "[0.619937, 0.2, 0.21027026, 0.20217021]\n",
      "[0.61425644, 0.2, 0.20605616, 0.20070285]\n",
      "[0.62819767, 0.2, 0.21930146, 0.20139894]\n",
      "[0.6109566, 0.2, 0.20261224, 0.20084715]\n",
      "[0.61573, 0.2, 0.20641139, 0.2018226]\n",
      "[0.62389356, 0.2, 0.21375507, 0.20264481]\n",
      "[0.6097784, 0.2, 0.20173149, 0.2005558]\n",
      "[0.61818665, 0.2, 0.20876358, 0.20193508]\n",
      "[0.63052505, 0.2, 0.22079328, 0.20224686]\n",
      "[0.61011237, 0.2, 0.2007659, 0.2018644]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4010 iterations: 1.250126047929128 mins\n",
      "Train Loss: [0.61011237, 0.2, 0.2007659, 0.2018644]\n",
      "[0.61839765, 0.2, 0.20951457, 0.20140447]\n",
      "[0.6182284, 0.2, 0.20844845, 0.20230514]\n",
      "[0.6163264, 0.2, 0.2064933, 0.202362]\n",
      "[0.6193674, 0.2, 0.20969126, 0.20220937]\n",
      "[0.62304676, 0.2, 0.21366781, 0.20191675]\n",
      "[0.6182685, 0.2, 0.20930886, 0.20150185]\n",
      "[0.6157464, 0.2, 0.20567703, 0.202616]\n",
      "[0.61636156, 0.2, 0.20839371, 0.20051913]\n",
      "[0.6471499, 0.2, 0.23597702, 0.20372838]\n",
      "[0.6228163, 0.2, 0.21473697, 0.20063956]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4020 iterations: 1.2519956509272256 mins\n",
      "Train Loss: [0.6228163, 0.2, 0.21473697, 0.20063956]\n",
      "[0.618914, 0.2, 0.2111747, 0.20030378]\n",
      "[0.6159554, 0.2, 0.20703264, 0.20149131]\n",
      "[0.62232953, 0.2, 0.213855, 0.20104745]\n",
      "[0.61302227, 0.2, 0.20392852, 0.20167096]\n",
      "[0.62113243, 0.2, 0.21189588, 0.20181829]\n",
      "[0.613978, 0.2, 0.2028754, 0.20369011]\n",
      "[0.61149794, 0.2, 0.20255856, 0.20153284]\n",
      "[0.6263747, 0.2, 0.2181383, 0.2008361]\n",
      "[0.63267595, 0.2, 0.22448838, 0.20079292]\n",
      "[0.6155721, 0.2, 0.2065514, 0.20163132]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4030 iterations: 1.2539168834686278 mins\n",
      "Train Loss: [0.6155721, 0.2, 0.2065514, 0.20163132]\n",
      "[0.61050546, 0.2, 0.20138553, 0.20173593]\n",
      "[0.61285895, 0.2, 0.2040374, 0.2014429]\n",
      "[0.6284886, 0.2, 0.21842365, 0.20269173]\n",
      "[0.6175697, 0.2, 0.20922413, 0.20097828]\n",
      "[0.6332184, 0.2, 0.2245169, 0.2013405]\n",
      "[0.6162115, 0.2, 0.20719579, 0.20166123]\n",
      "[0.62548304, 0.2, 0.21660371, 0.20153168]\n",
      "[0.6198301, 0.2, 0.21130104, 0.20118767]\n",
      "[0.61790794, 0.2, 0.20884553, 0.20172694]\n",
      "[0.62569577, 0.2, 0.21691911, 0.20144688]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4040 iterations: 1.2565786997477213 mins\n",
      "Train Loss: [0.62569577, 0.2, 0.21691911, 0.20144688]\n",
      "[0.62083215, 0.2, 0.21323396, 0.20027389]\n",
      "[0.6141247, 0.2, 0.20622328, 0.20058227]\n",
      "[0.62278444, 0.2, 0.21176618, 0.20370452]\n",
      "[0.62044597, 0.2, 0.21180499, 0.20133252]\n",
      "[0.62133545, 0.2, 0.21267307, 0.2013586]\n",
      "[0.6132209, 0.2, 0.20515443, 0.20076728]\n",
      "[0.6156675, 0.2, 0.20710213, 0.20127061]\n",
      "[0.6283982, 0.2, 0.22004892, 0.20105906]\n",
      "[0.61431104, 0.2, 0.20617838, 0.2008467]\n",
      "[0.6106448, 0.2, 0.2021872, 0.20117566]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4050 iterations: 1.259101382891337 mins\n",
      "Train Loss: [0.6106448, 0.2, 0.2021872, 0.20117566]\n",
      "[0.6201509, 0.2, 0.21266438, 0.20020847]\n",
      "[0.6207664, 0.2, 0.2114302, 0.20206225]\n",
      "[0.609782, 0.2, 0.2019597, 0.20055273]\n",
      "[0.6171841, 0.2, 0.2084856, 0.20143344]\n",
      "[0.6170045, 0.2, 0.20866193, 0.20108105]\n",
      "[0.61070734, 0.2, 0.20280139, 0.20064855]\n",
      "[0.61877674, 0.2, 0.21096826, 0.20055531]\n",
      "[0.61192894, 0.2, 0.20417164, 0.20050856]\n",
      "[0.6503145, 0.2, 0.2019697, 0.24110109]\n",
      "[0.62101775, 0.2, 0.21222083, 0.20155483]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4060 iterations: 1.2609988649686177 mins\n",
      "Train Loss: [0.62101775, 0.2, 0.21222083, 0.20155483]\n",
      "[0.6101112, 0.2, 0.20209308, 0.20077713]\n",
      "[0.61001885, 0.2, 0.20206985, 0.2007088]\n",
      "[0.6215096, 0.2, 0.21342821, 0.20084202]\n",
      "[0.6128295, 0.2, 0.20429538, 0.20129569]\n",
      "[0.61794347, 0.2, 0.21039893, 0.20030718]\n",
      "[0.6132948, 0.2, 0.2050303, 0.20102833]\n",
      "[0.6245205, 0.2, 0.21622142, 0.20106405]\n",
      "[0.61878216, 0.2, 0.21127176, 0.20027679]\n",
      "[0.6172834, 0.2, 0.20937233, 0.20067753]\n",
      "[0.6150653, 0.2, 0.20709671, 0.20073546]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4070 iterations: 1.262986183166504 mins\n",
      "Train Loss: [0.6150653, 0.2, 0.20709671, 0.20073546]\n",
      "[0.6503338, 0.2, 0.21561716, 0.22748418]\n",
      "[0.6228633, 0.2, 0.21493249, 0.20070058]\n",
      "[0.6090181, 0.2, 0.20153353, 0.20025617]\n",
      "[0.621907, 0.2, 0.21413372, 0.2005467]\n",
      "[0.6103142, 0.2, 0.20199224, 0.20109695]\n",
      "[0.64374673, 0.2, 0.20205586, 0.23446794]\n",
      "[0.6276378, 0.2, 0.2203412, 0.20007771]\n",
      "[0.61281806, 0.2, 0.20475008, 0.20085251]\n",
      "[0.6139044, 0.2, 0.2059897, 0.20070262]\n",
      "[0.6091229, 0.2, 0.20120189, 0.2007118]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4080 iterations: 1.2663968165715536 mins\n",
      "Train Loss: [0.6091229, 0.2, 0.20120189, 0.2007118]\n",
      "[0.62172586, 0.2, 0.21355611, 0.20096338]\n",
      "[0.61735827, 0.2, 0.20956513, 0.20058946]\n",
      "[0.61148226, 0.2, 0.20325132, 0.20102996]\n",
      "[0.62708473, 0.2, 0.219206, 0.20068014]\n",
      "[0.6258433, 0.2, 0.2185236, 0.20012341]\n",
      "[0.6222151, 0.2, 0.21469377, 0.20032762]\n",
      "[0.6253973, 0.2, 0.21746187, 0.2007449]\n",
      "[0.612641, 0.2, 0.20506503, 0.20038939]\n",
      "[0.60847634, 0.2, 0.20050113, 0.20079224]\n",
      "[0.60849196, 0.2, 0.20062709, 0.20068574]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4090 iterations: 1.2687626838684083 mins\n",
      "Train Loss: [0.60849196, 0.2, 0.20062709, 0.20068574]\n",
      "[0.610068, 0.2, 0.20126507, 0.20162743]\n",
      "[0.60789436, 0.2, 0.20026457, 0.20045778]\n",
      "[0.607936, 0.2, 0.20071542, 0.2000518]\n",
      "[0.60761094, 0.2, 0.20039187, 0.20005375]\n",
      "[0.607834, 0.2, 0.20056915, 0.20010254]\n",
      "[0.6078727, 0.2, 0.20028533, 0.20042777]\n",
      "[0.60872006, 0.2, 0.20052382, 0.20103928]\n",
      "[0.60839444, 0.2, 0.20059997, 0.20064013]\n",
      "[0.60777, 0.2, 0.2001447, 0.20047341]\n",
      "[0.6074705, 0.2, 0.20010138, 0.20021947]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4100 iterations: 1.2713624993960062 mins\n",
      "Train Loss: [0.6074705, 0.2, 0.20010138, 0.20021947]\n",
      "[0.6078662, 0.2, 0.20045868, 0.20026006]\n",
      "[0.6079447, 0.2, 0.20034605, 0.20045389]\n",
      "[0.62147015, 0.2, 0.21424931, 0.20007907]\n",
      "[0.6077233, 0.2, 0.20037541, 0.20020857]\n",
      "[0.60759854, 0.2, 0.20023657, 0.20022498]\n",
      "[0.60785633, 0.2, 0.20046897, 0.20025238]\n",
      "[0.6076765, 0.2, 0.20024848, 0.20029491]\n",
      "[0.6075796, 0.2, 0.20023663, 0.20021182]\n",
      "[0.607756, 0.2, 0.20016472, 0.20046256]\n",
      "[0.60734934, 0.2, 0.20008016, 0.20014308]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4110 iterations: 1.2736746827761332 mins\n",
      "Train Loss: [0.60734934, 0.2, 0.20008016, 0.20014308]\n",
      "[0.6081558, 0.2, 0.20058262, 0.20044999]\n",
      "[0.6088715, 0.2, 0.20156826, 0.20018354]\n",
      "[0.6078948, 0.2, 0.20045903, 0.2003198]\n",
      "[0.6079204, 0.2, 0.20048451, 0.2003247]\n",
      "[0.6078722, 0.2, 0.20026116, 0.20050533]\n",
      "[0.60749453, 0.2, 0.20030314, 0.20009173]\n",
      "[0.6075981, 0.2, 0.20006512, 0.20043983]\n",
      "[0.60758424, 0.2, 0.2002314, 0.20026654]\n",
      "[0.6074735, 0.2, 0.2001351, 0.2002595]\n",
      "[0.6075707, 0.2, 0.20030749, 0.20019184]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4120 iterations: 1.2767812172571817 mins\n",
      "Train Loss: [0.6075707, 0.2, 0.20030749, 0.20019184]\n",
      "[0.6527786, 0.2, 0.206392, 0.23932298]\n",
      "[0.6077044, 0.2, 0.19995685, 0.20069021]\n",
      "[0.60813785, 0.2, 0.20031357, 0.20077273]\n",
      "[0.60883975, 0.2, 0.20103262, 0.2007607]\n",
      "[0.6072424, 0.2, 0.2004375, 0.19976313]\n",
      "[0.60816073, 0.2, 0.20013523, 0.20098785]\n",
      "[0.6087319, 0.2, 0.20018728, 0.20151049]\n",
      "[0.6076404, 0.2, 0.1996053, 0.2010042]\n",
      "[0.6079637, 0.2, 0.20016643, 0.20076878]\n",
      "[0.6085179, 0.2, 0.20012353, 0.20136711]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4130 iterations: 1.2809787352879842 mins\n",
      "Train Loss: [0.6085179, 0.2, 0.20012353, 0.20136711]\n",
      "[0.60803926, 0.2, 0.20047398, 0.20053728]\n",
      "[0.6100904, 0.2, 0.2014527, 0.20160612]\n",
      "[0.63952684, 0.2, 0.22979663, 0.20269026]\n",
      "[0.6133265, 0.2, 0.20397696, 0.20229931]\n",
      "[0.6114063, 0.2, 0.20175813, 0.20258594]\n",
      "[0.60997516, 0.2, 0.20043023, 0.20246676]\n",
      "[0.6134027, 0.2, 0.20306946, 0.20323385]\n",
      "[0.6142791, 0.2, 0.2047701, 0.20237926]\n",
      "[0.61345714, 0.2, 0.20319267, 0.20309263]\n",
      "[0.6124143, 0.2, 0.20347598, 0.20171528]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4140 iterations: 1.2835470994313558 mins\n",
      "Train Loss: [0.6124143, 0.2, 0.20347598, 0.20171528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61884576, 0.2, 0.20595233, 0.20561005]\n",
      "[0.6155758, 0.2, 0.20534883, 0.20288272]\n",
      "[0.6143061, 0.2, 0.20233399, 0.20456116]\n",
      "[0.6161812, 0.2, 0.2044618, 0.20424242]\n",
      "[0.6573756, 0.2, 0.20238918, 0.24744436]\n",
      "[0.6128032, 0.2, 0.20339109, 0.2018061]\n",
      "[0.62670827, 0.2, 0.2177932, 0.20124675]\n",
      "[0.6327801, 0.2, 0.22412416, 0.20092854]\n",
      "[0.6231459, 0.2, 0.21261874, 0.20273969]\n",
      "[0.6109801, 0.2, 0.2024396, 0.20069961]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4150 iterations: 1.2860806306203207 mins\n",
      "Train Loss: [0.6109801, 0.2, 0.2024396, 0.20069961]\n",
      "[0.62376547, 0.2, 0.21117805, 0.20470014]\n",
      "[0.6128074, 0.2, 0.20187162, 0.20301105]\n",
      "[0.6324973, 0.2, 0.22337924, 0.20116283]\n",
      "[0.6185229, 0.2, 0.20831147, 0.20223166]\n",
      "[0.6161055, 0.2, 0.20741683, 0.20069149]\n",
      "[0.65040904, 0.2, 0.24191795, 0.20048173]\n",
      "[0.6096105, 0.2, 0.20117417, 0.20041287]\n",
      "[0.62117046, 0.2, 0.21089472, 0.20224261]\n",
      "[0.6164435, 0.2, 0.2069124, 0.20149264]\n",
      "[0.61408997, 0.2, 0.20590316, 0.20014675]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4160 iterations: 1.2881481965382895 mins\n",
      "Train Loss: [0.61408997, 0.2, 0.20590316, 0.20014675]\n",
      "[0.6170771, 0.2, 0.20724535, 0.20179345]\n",
      "[0.6189218, 0.2, 0.20923747, 0.2016511]\n",
      "[0.6148263, 0.2, 0.20236182, 0.20443879]\n",
      "[0.6145007, 0.2, 0.20432422, 0.20216094]\n",
      "[0.6115606, 0.2, 0.20100822, 0.20255019]\n",
      "[0.61744535, 0.2, 0.20732749, 0.2021307]\n",
      "[0.61067355, 0.2, 0.2014895, 0.20121364]\n",
      "[0.61296237, 0.2, 0.20179465, 0.20321536]\n",
      "[0.6102175, 0.2, 0.20074123, 0.20154381]\n",
      "[0.63302344, 0.2, 0.22065674, 0.20445503]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4170 iterations: 1.290771730740865 mins\n",
      "Train Loss: [0.63302344, 0.2, 0.22065674, 0.20445503]\n",
      "[0.60995686, 0.2, 0.20081119, 0.20125985]\n",
      "[0.62279195, 0.2, 0.21130829, 0.2036237]\n",
      "[0.62890005, 0.2, 0.21821699, 0.20284833]\n",
      "[0.6197763, 0.2, 0.20978041, 0.20218757]\n",
      "[0.623442, 0.2, 0.21311723, 0.20254321]\n",
      "[0.615271, 0.2, 0.2055733, 0.20194186]\n",
      "[0.6232299, 0.2, 0.21423215, 0.20126696]\n",
      "[0.61891216, 0.2, 0.20961533, 0.20159078]\n",
      "[0.61444974, 0.2, 0.20409074, 0.2026782]\n",
      "[0.61342084, 0.2, 0.20182218, 0.2039437]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4180 iterations: 1.2937872846921286 mins\n",
      "Train Loss: [0.61342084, 0.2, 0.20182218, 0.2039437]\n",
      "[0.6433031, 0.2, 0.23264071, 0.2030324]\n",
      "[0.614511, 0.2, 0.20498829, 0.20191787]\n",
      "[0.61027527, 0.2, 0.20062904, 0.20206568]\n",
      "[0.6166059, 0.2, 0.20686565, 0.20218354]\n",
      "[0.6146414, 0.2, 0.20549025, 0.20161858]\n",
      "[0.61257386, 0.2, 0.20340613, 0.20165847]\n",
      "[0.6225185, 0.2, 0.21414898, 0.20088243]\n",
      "[0.60652953, 0.2, 0.19889766, 0.2001648]\n",
      "[0.6255637, 0.2, 0.20526099, 0.21285488]\n",
      "[0.61044556, 0.2, 0.20102255, 0.20199285]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4190 iterations: 1.2974873344103495 mins\n",
      "Train Loss: [0.61044556, 0.2, 0.20102255, 0.20199285]\n",
      "[0.6252201, 0.2, 0.20382996, 0.21397696]\n",
      "[0.6117341, 0.2, 0.20355295, 0.20078784]\n",
      "[0.61830825, 0.2, 0.20907712, 0.20185596]\n",
      "[0.6189252, 0.2, 0.21129367, 0.20027311]\n",
      "[0.6197587, 0.2, 0.21123274, 0.2011833]\n",
      "[0.6415082, 0.2, 0.23363526, 0.20054547]\n",
      "[0.61287886, 0.2, 0.20399599, 0.201571]\n",
      "[0.62515455, 0.2, 0.21488166, 0.20297594]\n",
      "[0.60922784, 0.2, 0.20149957, 0.20044565]\n",
      "[0.6285426, 0.2, 0.2197, 0.20157407]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4200 iterations: 1.3002811352411905 mins\n",
      "Train Loss: [0.6285426, 0.2, 0.2197, 0.20157407]\n",
      "[0.6549124, 0.2, 0.20335266, 0.24430285]\n",
      "[0.6130814, 0.2, 0.20221277, 0.20362118]\n",
      "[0.6278879, 0.2, 0.22005886, 0.20059097]\n",
      "[0.6201401, 0.2, 0.20726062, 0.20565023]\n",
      "[0.620459, 0.2, 0.21214996, 0.20108855]\n",
      "[0.6202588, 0.2, 0.21179093, 0.20125607]\n",
      "[0.62157893, 0.2, 0.2118873, 0.20248866]\n",
      "[0.6386342, 0.2, 0.20072368, 0.23071651]\n",
      "[0.61700964, 0.2, 0.20887679, 0.20094578]\n",
      "[0.65128326, 0.2, 0.22804774, 0.21605442]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4210 iterations: 1.3028114676475524 mins\n",
      "Train Loss: [0.65128326, 0.2, 0.22804774, 0.21605442]\n",
      "[0.6200674, 0.2, 0.21203443, 0.20085168]\n",
      "[0.62693775, 0.2, 0.21965137, 0.2001044]\n",
      "[0.6123786, 0.2, 0.2041034, 0.2010916]\n",
      "[0.6776013, 0.2, 0.20413147, 0.26628444]\n",
      "[0.6118837, 0.2, 0.20484903, 0.19985104]\n",
      "[0.61691946, 0.2, 0.20927736, 0.20046061]\n",
      "[0.6100674, 0.2, 0.20249254, 0.2003944]\n",
      "[0.61528903, 0.2, 0.20654036, 0.20156898]\n",
      "[0.6073714, 0.2, 0.19943722, 0.200756]\n",
      "[0.60680765, 0.2, 0.1987257, 0.20090559]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4220 iterations: 1.305349918206533 mins\n",
      "Train Loss: [0.60680765, 0.2, 0.1987257, 0.20090559]\n",
      "[0.61170495, 0.2, 0.20331185, 0.20121957]\n",
      "[0.6103686, 0.2, 0.20257518, 0.20062324]\n",
      "[0.6174906, 0.2, 0.20971653, 0.20060775]\n",
      "[0.6765893, 0.2, 0.20406163, 0.26536614]\n",
      "[0.6257585, 0.2, 0.21784978, 0.20075434]\n",
      "[0.6123254, 0.2, 0.20420282, 0.20097536]\n",
      "[0.610746, 0.2, 0.20184961, 0.20175654]\n",
      "[0.61208177, 0.2, 0.20394826, 0.2010011]\n",
      "[0.63355327, 0.2, 0.22598273, 0.20044594]\n",
      "[0.6317445, 0.2, 0.2241909, 0.20043738]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4230 iterations: 1.307620684305827 mins\n",
      "Train Loss: [0.6317445, 0.2, 0.2241909, 0.20043738]\n",
      "[0.62374574, 0.2, 0.21415576, 0.2024819]\n",
      "[0.62895435, 0.2, 0.21961321, 0.20224063]\n",
      "[0.60937876, 0.2, 0.2013167, 0.20096874]\n",
      "[0.6362159, 0.2, 0.22804636, 0.20108317]\n",
      "[0.61932755, 0.2, 0.21165672, 0.20059086]\n",
      "[0.70377654, 0.2, 0.2947652, 0.2019385]\n",
      "[0.6107729, 0.2, 0.20069422, 0.20301622]\n",
      "[0.6136143, 0.2, 0.2027515, 0.20380962]\n",
      "[0.62046224, 0.2, 0.21001515, 0.203402]\n",
      "[0.60994595, 0.2, 0.20102796, 0.20187949]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4240 iterations: 1.309521234035492 mins\n",
      "Train Loss: [0.60994595, 0.2, 0.20102796, 0.20187949]\n",
      "[0.6275288, 0.2, 0.21997239, 0.20052385]\n",
      "[0.6211901, 0.2, 0.21171632, 0.20244767]\n",
      "[0.6283497, 0.2, 0.21970195, 0.201628]\n",
      "[0.6217499, 0.2, 0.21365944, 0.20107625]\n",
      "[0.6427326, 0.2, 0.23491481, 0.20080835]\n",
      "[0.6219546, 0.2, 0.21196151, 0.2029876]\n",
      "[0.6310764, 0.2, 0.22276695, 0.20130731]\n",
      "[0.63888466, 0.2, 0.2292867, 0.20259844]\n",
      "[0.62321514, 0.2, 0.21262515, 0.20359306]\n",
      "[0.6117828, 0.2, 0.2043831, 0.20040485]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4250 iterations: 1.3113287170728047 mins\n",
      "Train Loss: [0.6117828, 0.2, 0.2043831, 0.20040485]\n",
      "[0.6214721, 0.2, 0.21304189, 0.20143725]\n",
      "[0.62004054, 0.2, 0.21170485, 0.20134473]\n",
      "[0.6150986, 0.2, 0.20616636, 0.20194335]\n",
      "[0.60894895, 0.2, 0.20133013, 0.20063198]\n",
      "[0.62600714, 0.2, 0.21708362, 0.20193844]\n",
      "[0.6367871, 0.2, 0.2285122, 0.20129143]\n",
      "[0.6151851, 0.2, 0.20633925, 0.201864]\n",
      "[0.6186201, 0.2, 0.20967384, 0.20196633]\n",
      "[0.6220204, 0.2, 0.21456067, 0.20048206]\n",
      "[0.62597376, 0.2, 0.21830106, 0.20069762]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4260 iterations: 1.313751717408498 mins\n",
      "Train Loss: [0.62597376, 0.2, 0.21830106, 0.20069762]\n",
      "[0.6417697, 0.2, 0.2329396, 0.20185745]\n",
      "[0.61828226, 0.2, 0.21014751, 0.20116378]\n",
      "[0.6154542, 0.2, 0.20841415, 0.20007019]\n",
      "[0.61437076, 0.2, 0.20680399, 0.20059821]\n",
      "[0.6213166, 0.2, 0.21348424, 0.20086485]\n",
      "[0.61874604, 0.2, 0.21106826, 0.20071034]\n",
      "[0.6144292, 0.2, 0.20589283, 0.20156844]\n",
      "[0.60855925, 0.2, 0.20122443, 0.20036648]\n",
      "[0.6243226, 0.2, 0.20207593, 0.21527724]\n",
      "[0.6125574, 0.2, 0.20445582, 0.20113036]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4270 iterations: 1.3168942173322042 mins\n",
      "Train Loss: [0.6125574, 0.2, 0.20445582, 0.20113036]\n",
      "[0.6107462, 0.2, 0.20296767, 0.20080465]\n",
      "[0.61808825, 0.2, 0.20865431, 0.20245668]\n",
      "[0.61008143, 0.2, 0.20261985, 0.2004807]\n",
      "[0.62575895, 0.2, 0.20681003, 0.21196505]\n",
      "[0.6120122, 0.2, 0.20425609, 0.2007694]\n",
      "[0.6459359, 0.2, 0.20136538, 0.23758022]\n",
      "[0.62444705, 0.2, 0.21643922, 0.20101586]\n",
      "[0.6252588, 0.2, 0.21723194, 0.20103268]\n",
      "[0.6227062, 0.2, 0.21388379, 0.20182538]\n",
      "[0.61090094, 0.2, 0.20338942, 0.20051144]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4280 iterations: 1.319418466091156 mins\n",
      "Train Loss: [0.61090094, 0.2, 0.20338942, 0.20051144]\n",
      "[0.6150737, 0.2, 0.20600379, 0.20206724]\n",
      "[0.6432811, 0.2, 0.23574936, 0.20052697]\n",
      "[0.61118007, 0.2, 0.20347257, 0.20070103]\n",
      "[0.6170242, 0.2, 0.20868622, 0.20133065]\n",
      "[0.67279077, 0.2, 0.20349576, 0.26228774]\n",
      "[0.61083376, 0.2, 0.20298193, 0.20084903]\n",
      "[0.6101942, 0.2, 0.20276427, 0.20043147]\n",
      "[0.6164027, 0.2, 0.20830101, 0.20110796]\n",
      "[0.6234748, 0.2, 0.21519731, 0.20128804]\n",
      "[0.6320868, 0.2, 0.22500773, 0.20009395]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4290 iterations: 1.3213229338328043 mins\n",
      "Train Loss: [0.6320868, 0.2, 0.22500773, 0.20009395]\n",
      "[0.61697644, 0.2, 0.20898633, 0.20100932]\n",
      "[0.6181208, 0.2, 0.20952275, 0.20162232]\n",
      "[0.63125557, 0.2, 0.22144486, 0.20284085]\n",
      "[0.60679066, 0.2, 0.19978072, 0.20004562]\n",
      "[0.641219, 0.2, 0.23380633, 0.20045435]\n",
      "[0.6124161, 0.2, 0.20472549, 0.20074162]\n",
      "[0.62207824, 0.2, 0.21355009, 0.20158817]\n",
      "[0.6241682, 0.2, 0.21542539, 0.20181094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62658393, 0.2, 0.21914901, 0.20051035]\n",
      "[0.6172906, 0.2, 0.20885709, 0.20151582]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4300 iterations: 1.3230477968851726 mins\n",
      "Train Loss: [0.6172906, 0.2, 0.20885709, 0.20151582]\n",
      "[0.61056614, 0.2, 0.20298086, 0.20067425]\n",
      "[0.6223421, 0.2, 0.21403424, 0.20140336]\n",
      "[0.6176793, 0.2, 0.20977223, 0.20100911]\n",
      "[0.62713796, 0.2, 0.21947102, 0.20077482]\n",
      "[0.62023807, 0.2, 0.21222432, 0.20112722]\n",
      "[0.61470217, 0.2, 0.20661655, 0.2012041]\n",
      "[0.6155153, 0.2, 0.20780249, 0.20083626]\n",
      "[0.6497437, 0.2, 0.21170253, 0.23116952]\n",
      "[0.6078949, 0.2, 0.20034233, 0.20068817]\n",
      "[0.62921065, 0.2, 0.22139895, 0.20095307]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4310 iterations: 1.3248578151067099 mins\n",
      "Train Loss: [0.62921065, 0.2, 0.22139895, 0.20095307]\n",
      "[0.61974174, 0.2, 0.21264015, 0.20024684]\n",
      "[0.61203766, 0.2, 0.20466022, 0.20052557]\n",
      "[0.6095329, 0.2, 0.20195828, 0.2007251]\n",
      "[0.60787463, 0.2, 0.20085421, 0.20017257]\n",
      "[0.60952955, 0.2, 0.20161545, 0.20106804]\n",
      "[0.60959184, 0.2, 0.200797, 0.20194969]\n",
      "[0.60982853, 0.2, 0.20160231, 0.20138013]\n",
      "[0.60876745, 0.2, 0.20025016, 0.20166737]\n",
      "[0.60857344, 0.2, 0.20125116, 0.20046623]\n",
      "[0.6084779, 0.2, 0.20049214, 0.20112115]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4320 iterations: 1.3269416014353435 mins\n",
      "Train Loss: [0.6084779, 0.2, 0.20049214, 0.20112115]\n",
      "[0.60999244, 0.2, 0.20072637, 0.20239258]\n",
      "[0.60875493, 0.2, 0.20033309, 0.20153873]\n",
      "[0.6088412, 0.2, 0.20130755, 0.20064083]\n",
      "[0.60866886, 0.2, 0.20080131, 0.20096578]\n",
      "[0.60788, 0.2, 0.20029344, 0.20067474]\n",
      "[0.6086773, 0.2, 0.20080407, 0.20095131]\n",
      "[0.6086749, 0.2, 0.20081274, 0.20093015]\n",
      "[0.6076802, 0.2, 0.20053871, 0.20020017]\n",
      "[0.6086411, 0.2, 0.20059617, 0.20109494]\n",
      "[0.6099357, 0.2, 0.20240907, 0.20056872]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4330 iterations: 1.3297685503959655 mins\n",
      "Train Loss: [0.6099357, 0.2, 0.20240907, 0.20056872]\n",
      "[0.60823303, 0.2, 0.20064259, 0.20062661]\n",
      "[0.6079045, 0.2, 0.20053093, 0.20040445]\n",
      "[0.60784954, 0.2, 0.20030943, 0.2005663]\n",
      "[0.6076501, 0.2, 0.20032164, 0.20035087]\n",
      "[0.607886, 0.2, 0.20031768, 0.2005883]\n",
      "[0.60818607, 0.2, 0.20049185, 0.20071238]\n",
      "[0.60754293, 0.2, 0.20026743, 0.20029281]\n",
      "[0.60799694, 0.2, 0.20047495, 0.20053954]\n",
      "[0.608236, 0.2, 0.20072898, 0.20052612]\n",
      "[0.63754994, 0.2, 0.20649314, 0.22407898]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4340 iterations: 1.332675313949585 mins\n",
      "Train Loss: [0.63754994, 0.2, 0.20649314, 0.22407898]\n",
      "[0.60832494, 0.2, 0.20051795, 0.20083214]\n",
      "[0.6084195, 0.2, 0.2007191, 0.2007289]\n",
      "[0.60814303, 0.2, 0.20066255, 0.20051256]\n",
      "[0.60782254, 0.2, 0.20040193, 0.20045683]\n",
      "[0.60812885, 0.2, 0.20067982, 0.2004901]\n",
      "[0.6073687, 0.2, 0.20021303, 0.20020175]\n",
      "[0.6083476, 0.2, 0.2005697, 0.20082885]\n",
      "[0.6080937, 0.2, 0.20076238, 0.20038801]\n",
      "[0.60779446, 0.2, 0.20042694, 0.20043054]\n",
      "[0.6084143, 0.2, 0.20096384, 0.20051935]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4350 iterations: 1.3345271666844687 mins\n",
      "Train Loss: [0.6084143, 0.2, 0.20096384, 0.20051935]\n",
      "[0.60847926, 0.2, 0.20086303, 0.2006922]\n",
      "[0.6075552, 0.2, 0.20029452, 0.20034365]\n",
      "[0.6076295, 0.2, 0.20022509, 0.2004943]\n",
      "[0.60791934, 0.2, 0.20020913, 0.20080678]\n",
      "[0.6078229, 0.2, 0.2003877, 0.20053874]\n",
      "[0.61363465, 0.2, 0.20625797, 0.20048754]\n",
      "[0.6076137, 0.2, 0.20022562, 0.2005056]\n",
      "[0.607488, 0.2, 0.20028259, 0.20032969]\n",
      "[0.6076067, 0.2, 0.20022586, 0.20051214]\n",
      "[0.60761774, 0.2, 0.20025976, 0.20049688]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4360 iterations: 1.336819016933441 mins\n",
      "Train Loss: [0.60761774, 0.2, 0.20025976, 0.20049688]\n",
      "[0.6077531, 0.2, 0.20050089, 0.20039919]\n",
      "[0.6083813, 0.2, 0.20090398, 0.200632]\n",
      "[0.60794574, 0.2, 0.2005522, 0.20055704]\n",
      "[0.60794026, 0.2, 0.2008777, 0.20023409]\n",
      "[0.6089739, 0.2, 0.20097674, 0.20117752]\n",
      "[0.6076186, 0.2, 0.20056179, 0.20024587]\n",
      "[0.6086955, 0.2, 0.20105189, 0.20084028]\n",
      "[0.60764205, 0.2, 0.20057851, 0.20026697]\n",
      "[0.60750604, 0.2, 0.20025241, 0.20046178]\n",
      "[0.6083884, 0.2, 0.20051363, 0.20108567]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4370 iterations: 1.3386214971542358 mins\n",
      "Train Loss: [0.6083884, 0.2, 0.20051363, 0.20108567]\n",
      "[0.6083912, 0.2, 0.20068434, 0.20092016]\n",
      "[0.60866725, 0.2, 0.20054685, 0.20133668]\n",
      "[0.6079291, 0.2, 0.20048511, 0.20066406]\n",
      "[0.60745245, 0.2, 0.200304, 0.20037198]\n",
      "[0.610411, 0.2, 0.20221937, 0.20141815]\n",
      "[0.6075207, 0.2, 0.200298, 0.20045377]\n",
      "[0.60742116, 0.2, 0.20043111, 0.20022479]\n",
      "[0.60799026, 0.2, 0.20036379, 0.2008633]\n",
      "[0.60757536, 0.2, 0.20000115, 0.20081332]\n",
      "[0.60769594, 0.2, 0.20034216, 0.20059577]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4380 iterations: 1.3413462162017822 mins\n",
      "Train Loss: [0.60769594, 0.2, 0.20034216, 0.20059577]\n",
      "[0.60860246, 0.2, 0.20092075, 0.20092703]\n",
      "[0.6091656, 0.2, 0.20099422, 0.20142138]\n",
      "[0.6083566, 0.2, 0.20059223, 0.20101991]\n",
      "[0.6079198, 0.2, 0.20055915, 0.20062295]\n",
      "[0.607918, 0.2, 0.20064116, 0.2005466]\n",
      "[0.6074808, 0.2, 0.20017342, 0.20058519]\n",
      "[0.6078037, 0.2, 0.20074579, 0.20034432]\n",
      "[0.6074678, 0.2, 0.20025213, 0.20051083]\n",
      "[0.6076697, 0.2, 0.20058903, 0.20038477]\n",
      "[0.6079318, 0.2, 0.20049734, 0.20074767]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4390 iterations: 1.3437564849853516 mins\n",
      "Train Loss: [0.6079318, 0.2, 0.20049734, 0.20074767]\n",
      "[0.6075, 0.2, 0.20052758, 0.20029493]\n",
      "[0.6077559, 0.2, 0.20069599, 0.20039226]\n",
      "[0.60735315, 0.2, 0.20020099, 0.20049462]\n",
      "[0.6078443, 0.2, 0.20033067, 0.20086628]\n",
      "[0.60715735, 0.2, 0.20018563, 0.20033512]\n",
      "[0.60723954, 0.2, 0.20030215, 0.20031203]\n",
      "[0.60751265, 0.2, 0.20017074, 0.20072758]\n",
      "[0.6073322, 0.2, 0.20024543, 0.20048383]\n",
      "[0.6073975, 0.2, 0.20025441, 0.2005515]\n",
      "[0.60714877, 0.2, 0.20034967, 0.20021921]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4400 iterations: 1.3455265323321024 mins\n",
      "Train Loss: [0.60714877, 0.2, 0.20034967, 0.20021921]\n",
      "[0.60736734, 0.2, 0.20051408, 0.20028502]\n",
      "[0.60713565, 0.2, 0.2002304, 0.20034862]\n",
      "[0.6075022, 0.2, 0.20037913, 0.20057839]\n",
      "[0.6077, 0.2, 0.20075546, 0.20041187]\n",
      "[0.60791886, 0.2, 0.20064038, 0.20075783]\n",
      "[0.60764164, 0.2, 0.2001881, 0.20094518]\n",
      "[0.6077472, 0.2, 0.2003343, 0.2009168]\n",
      "[0.6074115, 0.2, 0.20029777, 0.20063023]\n",
      "[0.6073741, 0.2, 0.20063062, 0.20027274]\n",
      "[0.60771525, 0.2, 0.20070729, 0.20055005]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4410 iterations: 1.3480735023816426 mins\n",
      "Train Loss: [0.60771525, 0.2, 0.20070729, 0.20055005]\n",
      "[0.60873014, 0.2, 0.20117813, 0.20110661]\n",
      "[0.60735524, 0.2, 0.20054747, 0.20037425]\n",
      "[0.60750383, 0.2, 0.20075017, 0.200332]\n",
      "[0.60717213, 0.2, 0.20025928, 0.20050304]\n",
      "[0.60775447, 0.2, 0.20078613, 0.20057033]\n",
      "[0.6074707, 0.2, 0.20061027, 0.20047408]\n",
      "[0.6071067, 0.2, 0.20015275, 0.20057915]\n",
      "[0.6074641, 0.2, 0.20043598, 0.20066474]\n",
      "[0.6073987, 0.2, 0.20049083, 0.2005562]\n",
      "[0.6072523, 0.2, 0.20051551, 0.20039658]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4420 iterations: 1.350868284702301 mins\n",
      "Train Loss: [0.6072523, 0.2, 0.20051551, 0.20039658]\n",
      "[0.6069434, 0.2, 0.20035416, 0.20026053]\n",
      "[0.6074115, 0.2, 0.20024517, 0.20084877]\n",
      "[0.606726, 0.2, 0.20018607, 0.20023343]\n",
      "[0.60732305, 0.2, 0.2004541, 0.20057333]\n",
      "[0.6073451, 0.2, 0.20053674, 0.2005236]\n",
      "[0.60679287, 0.2, 0.20028365, 0.20023564]\n",
      "[0.60685074, 0.2, 0.20012225, 0.20046592]\n",
      "[0.6068106, 0.2, 0.2002735, 0.20028535]\n",
      "[0.6068358, 0.2, 0.2004001, 0.2001945]\n",
      "[0.60679466, 0.2, 0.20019533, 0.2003687]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4430 iterations: 1.3533159494400024 mins\n",
      "Train Loss: [0.60679466, 0.2, 0.20019533, 0.2003687]\n",
      "[0.6068919, 0.2, 0.20026113, 0.20041062]\n",
      "[0.60689473, 0.2, 0.20019433, 0.20049073]\n",
      "[0.60661983, 0.2, 0.20019498, 0.2002256]\n",
      "[0.6068023, 0.2, 0.20024332, 0.20036997]\n",
      "[0.606679, 0.2, 0.20015931, 0.20034097]\n",
      "[0.60668826, 0.2, 0.20018996, 0.20032957]\n",
      "[0.60671693, 0.2, 0.20025481, 0.20030302]\n",
      "[0.60711634, 0.2, 0.2003241, 0.20064248]\n",
      "[0.606679, 0.2, 0.2001414, 0.20039687]\n",
      "[0.6065469, 0.2, 0.20030095, 0.20011392]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4440 iterations: 1.3552420814832051 mins\n",
      "Train Loss: [0.6065469, 0.2, 0.20030095, 0.20011392]\n",
      "[0.6068546, 0.2, 0.20040649, 0.2003248]\n",
      "[0.6066472, 0.2, 0.20013133, 0.20040111]\n",
      "[0.6063932, 0.2, 0.20018509, 0.20010173]\n",
      "[0.6064966, 0.2, 0.20019941, 0.20019908]\n",
      "[0.6065182, 0.2, 0.20024604, 0.20018218]\n",
      "[0.6064405, 0.2, 0.20019343, 0.20016506]\n",
      "[0.6066845, 0.2, 0.20023741, 0.20037314]\n",
      "[0.6065353, 0.2, 0.20021069, 0.2002584]\n",
      "[0.6065703, 0.2, 0.20028421, 0.20022759]\n",
      "[0.6067249, 0.2, 0.2004142, 0.20025979]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4450 iterations: 1.3569626847902934 mins\n",
      "Train Loss: [0.6067249, 0.2, 0.2004142, 0.20025979]\n",
      "[0.60668, 0.2, 0.20061164, 0.20002514]\n",
      "[0.60627425, 0.2, 0.20010792, 0.20013073]\n",
      "[0.6068198, 0.2, 0.20047584, 0.20031598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60656124, 0.2, 0.20023422, 0.20030658]\n",
      "[0.60663164, 0.2, 0.20037855, 0.20024005]\n",
      "[0.6067647, 0.2, 0.20028988, 0.20046915]\n",
      "[0.6059647, 0.2, 0.20000033, 0.19996613]\n",
      "[0.6076239, 0.2, 0.200614, 0.20101908]\n",
      "[0.6074515, 0.2, 0.20030038, 0.20116782]\n",
      "[0.60665244, 0.2, 0.20031437, 0.20036228]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4460 iterations: 1.3589762489000956 mins\n",
      "Train Loss: [0.60665244, 0.2, 0.20031437, 0.20036228]\n",
      "[0.6064641, 0.2, 0.20022474, 0.200271]\n",
      "[0.60659075, 0.2, 0.20051517, 0.20011471]\n",
      "[0.60644495, 0.2, 0.2002113, 0.20028023]\n",
      "[0.606564, 0.2, 0.20019883, 0.20041928]\n",
      "[0.60617083, 0.2, 0.2001158, 0.20011671]\n",
      "[0.6062734, 0.2, 0.20013987, 0.20020276]\n",
      "[0.60620034, 0.2, 0.2001835, 0.20009354]\n",
      "[0.6062668, 0.2, 0.20008647, 0.2002645]\n",
      "[0.60628575, 0.2, 0.20013604, 0.20024136]\n",
      "[0.6062982, 0.2, 0.200269, 0.20012859]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4470 iterations: 1.3616636315981547 mins\n",
      "Train Loss: [0.6062982, 0.2, 0.200269, 0.20012859]\n",
      "[0.6062126, 0.2, 0.20021021, 0.20010945]\n",
      "[0.60626787, 0.2, 0.2002762, 0.20010641]\n",
      "[0.60649705, 0.2, 0.20011704, 0.20050226]\n",
      "[0.6064673, 0.2, 0.20026717, 0.20033015]\n",
      "[0.60628885, 0.2, 0.20024435, 0.20018226]\n",
      "[0.60619086, 0.2, 0.20016314, 0.20017341]\n",
      "[0.6063406, 0.2, 0.20018387, 0.20031017]\n",
      "[0.6061266, 0.2, 0.20007582, 0.20021227]\n",
      "[0.606254, 0.2, 0.20019352, 0.2002298]\n",
      "[0.60620517, 0.2, 0.20023368, 0.20014867]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4480 iterations: 1.3650823831558228 mins\n",
      "Train Loss: [0.60620517, 0.2, 0.20023368, 0.20014867]\n",
      "[0.6061523, 0.2, 0.20025484, 0.20008236]\n",
      "[0.60638887, 0.2, 0.20028558, 0.20029594]\n",
      "[0.60616547, 0.2, 0.20024858, 0.2001171]\n",
      "[0.6061667, 0.2, 0.20016512, 0.20020927]\n",
      "[0.60611963, 0.2, 0.20019501, 0.2001397]\n",
      "[0.6060714, 0.2, 0.2002234, 0.20007038]\n",
      "[0.6059808, 0.2, 0.2001085, 0.20010199]\n",
      "[0.6060175, 0.2, 0.20007652, 0.20017791]\n",
      "[0.6062511, 0.2, 0.20026344, 0.20023184]\n",
      "[0.60595316, 0.2, 0.2001199, 0.20008461]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4490 iterations: 1.3669315338134767 mins\n",
      "Train Loss: [0.60595316, 0.2, 0.2001199, 0.20008461]\n",
      "[0.6066292, 0.2, 0.20008974, 0.20079792]\n",
      "[0.6062762, 0.2, 0.20019479, 0.20034675]\n",
      "[0.60626894, 0.2, 0.20015614, 0.20038502]\n",
      "[0.6063829, 0.2, 0.20016947, 0.20049262]\n",
      "[0.6061248, 0.2, 0.2, 0.2004109]\n",
      "[0.6061117, 0.2, 0.20006667, 0.20033805]\n",
      "[0.60622877, 0.2, 0.20005412, 0.20047472]\n",
      "[0.6061784, 0.2, 0.20017146, 0.20031402]\n",
      "[0.6075552, 0.2, 0.20007549, 0.20179376]\n",
      "[0.6057509, 0.2, 0.20005496, 0.2000168]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4500 iterations: 1.3686841169993083 mins\n",
      "Train Loss: [0.6057509, 0.2, 0.20005496, 0.2000168]\n",
      "[0.6066112, 0.2, 0.20025101, 0.20068793]\n",
      "[0.6060686, 0.2, 0.20008586, 0.20031744]\n",
      "[0.6061674, 0.2, 0.20018391, 0.20032501]\n",
      "[0.60595113, 0.2, 0.2000672, 0.20023248]\n",
      "[0.60597456, 0.2, 0.2001052, 0.20022489]\n",
      "[0.60611606, 0.2, 0.20011646, 0.20036213]\n",
      "[0.60598844, 0.2, 0.20012149, 0.20023653]\n",
      "[0.60597456, 0.2, 0.20011462, 0.20023645]\n",
      "[0.60596246, 0.2, 0.20018068, 0.20016536]\n",
      "[0.6059289, 0.2, 0.20013654, 0.20018302]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4510 iterations: 1.3704663674036661 mins\n",
      "Train Loss: [0.6059289, 0.2, 0.20013654, 0.20018302]\n",
      "[0.60578656, 0.2, 0.20000002, 0.20018421]\n",
      "[0.6060645, 0.2, 0.20017083, 0.20029846]\n",
      "[0.60602206, 0.2, 0.20018463, 0.20024934]\n",
      "[0.605912, 0.2, 0.20008926, 0.20024176]\n",
      "[0.60585475, 0.2, 0.20008123, 0.20019972]\n",
      "[0.6057996, 0.2, 0.20003378, 0.20019928]\n",
      "[0.60571104, 0.2, 0.20011143, 0.20004034]\n",
      "[0.6058473, 0.2, 0.20016345, 0.20013183]\n",
      "[0.6056642, 0.2, 0.2000477, 0.20007175]\n",
      "[0.6057316, 0.2, 0.200107, 0.20008719]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4520 iterations: 1.3725947817166646 mins\n",
      "Train Loss: [0.6057316, 0.2, 0.200107, 0.20008719]\n",
      "[0.6057653, 0.2, 0.20012185, 0.20011319]\n",
      "[0.6058807, 0.2, 0.20014246, 0.20021516]\n",
      "[0.6056996, 0.2, 0.20008741, 0.20009635]\n",
      "[0.60578126, 0.2, 0.20014371, 0.20012896]\n",
      "[0.60596, 0.2, 0.20026109, 0.20019749]\n",
      "[0.60579383, 0.2, 0.20016746, 0.2001322]\n",
      "[0.60577404, 0.2, 0.20009553, 0.20019159]\n",
      "[0.6056801, 0.2, 0.20006223, 0.20013809]\n",
      "[0.6058908, 0.2, 0.20015791, 0.20026013]\n",
      "[0.605868, 0.2, 0.2001754, 0.20022681]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4530 iterations: 1.375153398513794 mins\n",
      "Train Loss: [0.605868, 0.2, 0.2001754, 0.20022681]\n",
      "[0.60575897, 0.2, 0.20012689, 0.20017327]\n",
      "[0.60561484, 0.2, 0.20006861, 0.20009431]\n",
      "[0.6057755, 0.2, 0.20014463, 0.20018572]\n",
      "[0.60568374, 0.2, 0.20012982, 0.20011553]\n",
      "[0.6056491, 0.2, 0.20009619, 0.20012125]\n",
      "[0.60564977, 0.2, 0.20007215, 0.20015258]\n",
      "[0.6056896, 0.2, 0.20017256, 0.2000987]\n",
      "[0.6056629, 0.2, 0.20012258, 0.20012854]\n",
      "[0.6065444, 0.2, 0.20010102, 0.20103818]\n",
      "[0.60571027, 0.2, 0.20014793, 0.20016351]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4540 iterations: 1.3772308826446533 mins\n",
      "Train Loss: [0.60571027, 0.2, 0.20014793, 0.20016351]\n",
      "[0.605755, 0.2, 0.20020628, 0.20015612]\n",
      "[0.60577816, 0.2, 0.20022802, 0.20016384]\n",
      "[0.60574996, 0.2, 0.20030588, 0.20006412]\n",
      "[0.6055404, 0.2, 0.20011151, 0.20005535]\n",
      "[0.6054943, 0.2, 0.20010638, 0.20002088]\n",
      "[0.6060272, 0.2, 0.20018859, 0.20047776]\n",
      "[0.60613704, 0.2, 0.20049442, 0.20028803]\n",
      "[0.6056575, 0.2, 0.20007992, 0.20022938]\n",
      "[0.60563874, 0.2, 0.20009638, 0.20020038]\n",
      "[0.6055925, 0.2, 0.20011778, 0.2001389]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4550 iterations: 1.378920348485311 mins\n",
      "Train Loss: [0.6055925, 0.2, 0.20011778, 0.2001389]\n",
      "[0.6056497, 0.2, 0.2001439, 0.20017628]\n",
      "[0.6055146, 0.2, 0.20000006, 0.20019141]\n",
      "[0.6055705, 0.2, 0.20011464, 0.2001392]\n",
      "[0.6060121, 0.2, 0.20014952, 0.2005522]\n",
      "[0.60557145, 0.2, 0.20003688, 0.2002304]\n",
      "[0.6056367, 0.2, 0.2002409, 0.20009795]\n",
      "[0.60554785, 0.2, 0.20007136, 0.20018475]\n",
      "[0.6054713, 0.2, 0.20005684, 0.20012894]\n",
      "[0.6056483, 0.2, 0.20033649, 0.2000325]\n",
      "[0.60554594, 0.2, 0.20014979, 0.20012307]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4560 iterations: 1.3813931663831076 mins\n",
      "Train Loss: [0.60554594, 0.2, 0.20014979, 0.20012307]\n",
      "[0.60559344, 0.2, 0.20007096, 0.20025568]\n",
      "[0.60581815, 0.2, 0.20019867, 0.20035896]\n",
      "[0.60563445, 0.2, 0.20016372, 0.20021644]\n",
      "[0.605665, 0.2, 0.20020173, 0.2002152]\n",
      "[0.60575753, 0.2, 0.2001285, 0.20038718]\n",
      "[0.60593903, 0.2, 0.20041063, 0.20029266]\n",
      "[0.605838, 0.2, 0.20017865, 0.20042972]\n",
      "[0.60533935, 0.2, 0.20005886, 0.20005704]\n",
      "[0.60596323, 0.2, 0.20028847, 0.2004574]\n",
      "[0.60557276, 0.2, 0.20016377, 0.20019768]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4570 iterations: 1.3833372473716736 mins\n",
      "Train Loss: [0.60557276, 0.2, 0.20016377, 0.20019768]\n",
      "[0.60581326, 0.2, 0.20025575, 0.20035233]\n",
      "[0.6054532, 0.2, 0.20009845, 0.20015548]\n",
      "[0.6055045, 0.2, 0.2001097, 0.20020157]\n",
      "[0.6053392, 0.2, 0.20006843, 0.20008369]\n",
      "[0.60528165, 0.2, 0.20004626, 0.20005459]\n",
      "[0.60536844, 0.2, 0.20019443, 0.19999942]\n",
      "[0.60535073, 0.2, 0.20004568, 0.20013666]\n",
      "[0.60530156, 0.2, 0.20007002, 0.20006938]\n",
      "[0.60585636, 0.2, 0.20047942, 0.20022099]\n",
      "[0.60541785, 0.2, 0.20009784, 0.20017025]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4580 iterations: 1.3850506822268167 mins\n",
      "Train Loss: [0.60541785, 0.2, 0.20009784, 0.20017025]\n",
      "[0.60544854, 0.2, 0.2001255, 0.2001796]\n",
      "[0.6052964, 0.2, 0.20007212, 0.20008703]\n",
      "[0.6053421, 0.2, 0.20003988, 0.2001712]\n",
      "[0.6052064, 0.2, 0.20005593, 0.20002553]\n",
      "[0.60525787, 0.2, 0.2000281, 0.20011087]\n",
      "[0.6055093, 0.2, 0.20020494, 0.20019136]\n",
      "[0.60527396, 0.2, 0.20000005, 0.20016691]\n",
      "[0.6054135, 0.2, 0.20013784, 0.20017445]\n",
      "[0.6053893, 0.2, 0.20014231, 0.20015164]\n",
      "[0.60565215, 0.2, 0.20013672, 0.20042594]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4590 iterations: 1.3869205832481384 mins\n",
      "Train Loss: [0.60565215, 0.2, 0.20013672, 0.20042594]\n",
      "[0.6055956, 0.2, 0.20014386, 0.2003679]\n",
      "[0.60531, 0.2, 0.2001007, 0.20013137]\n",
      "[0.6055372, 0.2, 0.20026381, 0.2002014]\n",
      "[0.6064855, 0.2, 0.20135276, 0.20006694]\n",
      "[0.60522544, 0.2, 0.20007448, 0.20009096]\n",
      "[0.60568064, 0.2, 0.20037599, 0.2002503]\n",
      "[0.6051792, 0.2, 0.20008145, 0.2000489]\n",
      "[0.6052656, 0.2, 0.20007075, 0.20015155]\n",
      "[0.6051786, 0.2, 0.20001455, 0.20012628]\n",
      "[0.60535705, 0.2, 0.20016313, 0.20016178]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4600 iterations: 1.389043148358663 mins\n",
      "Train Loss: [0.60535705, 0.2, 0.20016313, 0.20016178]\n",
      "[0.6055218, 0.2, 0.20022197, 0.20027323]\n",
      "[0.60522, 0.2, 0.20011899, 0.20008013]\n",
      "[0.60520476, 0.2, 0.20005165, 0.20013796]\n",
      "[0.60519296, 0.2, 0.20010479, 0.20007886]\n",
      "[0.60507345, 0.2, 0.20010202, 0.19996804]\n",
      "[0.6053575, 0.2, 0.20025927, 0.20010073]\n",
      "[0.60525745, 0.2, 0.2002276, 0.2000381]\n",
      "[0.60520256, 0.2, 0.20008695, 0.20012966]\n",
      "[0.60537916, 0.2, 0.20023592, 0.20016305]\n",
      "[0.60515684, 0.2, 0.20006552, 0.20011675]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4610 iterations: 1.3920481999715169 mins\n",
      "Train Loss: [0.60515684, 0.2, 0.20006552, 0.20011675]\n",
      "[0.6052306, 0.2, 0.20010939, 0.20015234]\n",
      "[0.60545105, 0.2, 0.20014618, 0.20034176]\n",
      "[0.60511225, 0.2, 0.200072, 0.20008288]\n",
      "[0.6052153, 0.2, 0.20007865, 0.20018506]\n",
      "[0.6049139, 0.2, 0.20005198, 0.19991599]\n",
      "[0.6051408, 0.2, 0.20009768, 0.20010287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60522276, 0.2, 0.2000736, 0.20021446]\n",
      "[0.6052647, 0.2, 0.20014724, 0.20018822]\n",
      "[0.60513467, 0.2, 0.2001463, 0.20006467]\n",
      "[0.60539526, 0.2, 0.200358, 0.20011917]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4620 iterations: 1.3938535849253337 mins\n",
      "Train Loss: [0.60539526, 0.2, 0.200358, 0.20011917]\n",
      "[0.6051619, 0.2, 0.20010553, 0.20014387]\n",
      "[0.6055371, 0.2, 0.20056589, 0.20006432]\n",
      "[0.6051215, 0.2, 0.2000943, 0.20012581]\n",
      "[0.6050865, 0.2, 0.20004404, 0.2001465]\n",
      "[0.605497, 0.2, 0.20005476, 0.20055185]\n",
      "[0.6051523, 0.2, 0.20006816, 0.20019905]\n",
      "[0.6050851, 0.2, 0.20012374, 0.20008157]\n",
      "[0.60508734, 0.2, 0.20013288, 0.20007996]\n",
      "[0.60519224, 0.2, 0.20010163, 0.20022155]\n",
      "[0.6049983, 0.2, 0.20005988, 0.20007491]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4630 iterations: 1.3961869478225708 mins\n",
      "Train Loss: [0.6049983, 0.2, 0.20005988, 0.20007491]\n",
      "[0.60508835, 0.2, 0.20011535, 0.20011501]\n",
      "[0.6050276, 0.2, 0.20008011, 0.20009509]\n",
      "[0.60501957, 0.2, 0.20009257, 0.20008016]\n",
      "[0.6050892, 0.2, 0.2001551, 0.20009291]\n",
      "[0.6049898, 0.2, 0.2000503, 0.20010404]\n",
      "[0.60524905, 0.2, 0.20017149, 0.20024785]\n",
      "[0.60539186, 0.2, 0.20027058, 0.20029727]\n",
      "[0.60501873, 0.2, 0.20016147, 0.20003892]\n",
      "[0.60521746, 0.2, 0.20030172, 0.20010315]\n",
      "[0.6051989, 0.2, 0.20024917, 0.20014288]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4640 iterations: 1.4003095825513203 mins\n",
      "Train Loss: [0.6051989, 0.2, 0.20024917, 0.20014288]\n",
      "[0.6054367, 0.2, 0.20018569, 0.20044975]\n",
      "[0.6050287, 0.2, 0.20010006, 0.20013295]\n",
      "[0.6050825, 0.2, 0.20005716, 0.20023517]\n",
      "[0.60505843, 0.2, 0.20004949, 0.20022428]\n",
      "[0.60500574, 0.2, 0.20006508, 0.20016173]\n",
      "[0.6049263, 0.2, 0.20005721, 0.20009579]\n",
      "[0.6049475, 0.2, 0.20008941, 0.20009047]\n",
      "[0.60490215, 0.2, 0.20007813, 0.20006216]\n",
      "[0.60497975, 0.2, 0.20007476, 0.20014887]\n",
      "[0.6049856, 0.2, 0.20008335, 0.20015195]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4650 iterations: 1.4027169028917947 mins\n",
      "Train Loss: [0.6049856, 0.2, 0.20008335, 0.20015195]\n",
      "[0.6049994, 0.2, 0.200115, 0.20013995]\n",
      "[0.6049135, 0.2, 0.20005809, 0.20011674]\n",
      "[0.60484415, 0.2, 0.20005779, 0.20005362]\n",
      "[0.6049792, 0.2, 0.20006292, 0.20018946]\n",
      "[0.6048759, 0.2, 0.2000697, 0.20008543]\n",
      "[0.60504496, 0.2, 0.20016824, 0.20016184]\n",
      "[0.6047284, 0.2, 0.20002562, 0.19999386]\n",
      "[0.60497063, 0.2, 0.2000752, 0.20019226]\n",
      "[0.60492164, 0.2, 0.20005539, 0.20016885]\n",
      "[0.6048446, 0.2, 0.20007437, 0.20007858]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4660 iterations: 1.4045599977175394 mins\n",
      "Train Loss: [0.6048446, 0.2, 0.20007437, 0.20007858]\n",
      "[0.60488445, 0.2, 0.20003514, 0.20016338]\n",
      "[0.60500836, 0.2, 0.20008512, 0.20024294]\n",
      "[0.6050177, 0.2, 0.2001146, 0.20022848]\n",
      "[0.60486674, 0.2, 0.20005956, 0.20013817]\n",
      "[0.60489064, 0.2, 0.20011926, 0.20010811]\n",
      "[0.6048219, 0.2, 0.20006599, 0.20009848]\n",
      "[0.60506916, 0.2, 0.20008399, 0.20033346]\n",
      "[0.6049543, 0.2, 0.20006055, 0.20024776]\n",
      "[0.6047683, 0.2, 0.20006043, 0.20006754]\n",
      "[0.60479546, 0.2, 0.20007585, 0.20008494]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4670 iterations: 1.4068777163823445 mins\n",
      "Train Loss: [0.60479546, 0.2, 0.20007585, 0.20008494]\n",
      "[0.6047901, 0.2, 0.20001894, 0.2001422]\n",
      "[0.6047265, 0.2, 0.2, 0.20010315]\n",
      "[0.6049385, 0.2, 0.20020357, 0.2001172]\n",
      "[0.6047343, 0.2, 0.20005621, 0.20006612]\n",
      "[0.60476327, 0.2, 0.20006654, 0.20009042]\n",
      "[0.6049979, 0.2, 0.20028529, 0.20011191]\n",
      "[0.6046921, 0.2, 0.20006263, 0.20003457]\n",
      "[0.6048864, 0.2, 0.2000634, 0.20023377]\n",
      "[0.60476, 0.2, 0.2000469, 0.20012951]\n",
      "[0.60475856, 0.2, 0.20008314, 0.20009753]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4680 iterations: 1.4100434184074402 mins\n",
      "Train Loss: [0.60475856, 0.2, 0.20008314, 0.20009753]\n",
      "[0.6047269, 0.2, 0.2000886, 0.20006599]\n",
      "[0.60478914, 0.2, 0.20012286, 0.20009959]\n",
      "[0.6046607, 0.2, 0.2000576, 0.20004207]\n",
      "[0.60469127, 0.2, 0.20010765, 0.20002821]\n",
      "[0.6047089, 0.2, 0.20006417, 0.20009492]\n",
      "[0.6047048, 0.2, 0.2000856, 0.200075]\n",
      "[0.6047702, 0.2, 0.20011708, 0.2001144]\n",
      "[0.6047574, 0.2, 0.20013943, 0.20008495]\n",
      "[0.60465, 0.2, 0.20003527, 0.20008725]\n",
      "[0.6046479, 0.2, 0.20005095, 0.20007505]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4690 iterations: 1.4122993667920432 mins\n",
      "Train Loss: [0.6046479, 0.2, 0.20005095, 0.20007505]\n",
      "[0.6046926, 0.2, 0.2000687, 0.20010749]\n",
      "[0.6046213, 0.2, 0.2, 0.20011055]\n",
      "[0.60465276, 0.2, 0.20008805, 0.20005949]\n",
      "[0.60461134, 0.2, 0.20006895, 0.20004264]\n",
      "[0.6046868, 0.2, 0.20009382, 0.20009877]\n",
      "[0.60466135, 0.2, 0.20008242, 0.20009016]\n",
      "[0.6046288, 0.2, 0.20005663, 0.20008898]\n",
      "[0.6045636, 0.2, 0.20005776, 0.20002812]\n",
      "[0.6046441, 0.2, 0.2000851, 0.20008673]\n",
      "[0.6045978, 0.2, 0.20006289, 0.20006801]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4700 iterations: 1.4149590492248536 mins\n",
      "Train Loss: [0.6045978, 0.2, 0.20006289, 0.20006801]\n",
      "[0.6045855, 0.2, 0.20004196, 0.20008203]\n",
      "[0.6045822, 0.2, 0.20004869, 0.20007731]\n",
      "[0.6045708, 0.2, 0.20005172, 0.20006825]\n",
      "[0.60457975, 0.2, 0.20006773, 0.20006646]\n",
      "[0.60460156, 0.2, 0.20007604, 0.20008525]\n",
      "[0.6046091, 0.2, 0.2000853, 0.20008884]\n",
      "[0.60459673, 0.2, 0.20009217, 0.20007496]\n",
      "[0.604483, 0.2, 0.20003496, 0.20002383]\n",
      "[0.6045337, 0.2, 0.20005733, 0.20005748]\n",
      "[0.60448337, 0.2, 0.20000002, 0.20006992]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4710 iterations: 1.4172413984934489 mins\n",
      "Train Loss: [0.60448337, 0.2, 0.20000002, 0.20006992]\n",
      "[0.60453445, 0.2, 0.20003317, 0.20009321]\n",
      "[0.60447496, 0.2, 0.20003524, 0.20003708]\n",
      "[0.6044848, 0.2, 0.2000625, 0.20002502]\n",
      "[0.6045272, 0.2, 0.200066, 0.20006928]\n",
      "[0.6045872, 0.2, 0.20011407, 0.20008673]\n",
      "[0.6045266, 0.2, 0.20005488, 0.20009074]\n",
      "[0.6045062, 0.2, 0.20005412, 0.20007655]\n",
      "[0.604513, 0.2, 0.20007999, 0.20006295]\n",
      "[0.60445166, 0.2, 0.2000228, 0.20006423]\n",
      "[0.6044652, 0.2, 0.20002423, 0.20008181]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4720 iterations: 1.4192719181378683 mins\n",
      "Train Loss: [0.6044652, 0.2, 0.20002423, 0.20008181]\n",
      "[0.6044747, 0.2, 0.20006028, 0.20006074]\n",
      "[0.60445756, 0.2, 0.20004702, 0.20006235]\n",
      "[0.6044242, 0.2, 0.20006151, 0.2000199]\n",
      "[0.60454345, 0.2, 0.20009181, 0.20011438]\n",
      "[0.604835, 0.2, 0.200383, 0.20012024]\n",
      "[0.6044767, 0.2, 0.20006941, 0.20008075]\n",
      "[0.60462636, 0.2, 0.20010677, 0.20019835]\n",
      "[0.6044654, 0.2, 0.20010793, 0.20004156]\n",
      "[0.60444033, 0.2, 0.20006526, 0.20006442]\n",
      "[0.60443866, 0.2, 0.20000426, 0.20012893]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4730 iterations: 1.421127231915792 mins\n",
      "Train Loss: [0.60443866, 0.2, 0.20000426, 0.20012893]\n",
      "[0.6044669, 0.2, 0.2000376, 0.20012902]\n",
      "[0.60452676, 0.2, 0.20008421, 0.20014745]\n",
      "[0.6044579, 0.2, 0.20008424, 0.20008361]\n",
      "[0.6043745, 0.2, 0.2000586, 0.20003097]\n",
      "[0.6043885, 0.2, 0.20002803, 0.2000805]\n",
      "[0.6044123, 0.2, 0.20007725, 0.20006022]\n",
      "[0.60440236, 0.2, 0.20010883, 0.20002373]\n",
      "[0.6044094, 0.2, 0.20003855, 0.20010616]\n",
      "[0.6043698, 0.2, 0.20004596, 0.20006424]\n",
      "[0.60437787, 0.2, 0.20003471, 0.20008849]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4740 iterations: 1.4233340819676716 mins\n",
      "Train Loss: [0.60437787, 0.2, 0.20003471, 0.20008849]\n",
      "[0.60445946, 0.2, 0.20013921, 0.20007065]\n",
      "[0.6043874, 0.2, 0.20007715, 0.20006555]\n",
      "[0.6044132, 0.2, 0.2000932, 0.2000803]\n",
      "[0.60439354, 0.2, 0.20008413, 0.20007455]\n",
      "[0.60434705, 0.2, 0.20005699, 0.20006013]\n",
      "[0.6043489, 0.2, 0.20008364, 0.20004024]\n",
      "[0.6043086, 0.2, 0.20005053, 0.20003794]\n",
      "[0.60429865, 0.2, 0.20002979, 0.20005368]\n",
      "[0.6043667, 0.2, 0.20007938, 0.20007713]\n",
      "[0.6044177, 0.2, 0.2000944, 0.200118]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4750 iterations: 1.4272873838742575 mins\n",
      "Train Loss: [0.6044177, 0.2, 0.2000944, 0.200118]\n",
      "[0.6043777, 0.2, 0.20006198, 0.20011544]\n",
      "[0.6043218, 0.2, 0.20003252, 0.2000939]\n",
      "[0.6045562, 0.2, 0.20006809, 0.20029758]\n",
      "[0.60433435, 0.2, 0.20007153, 0.2000773]\n",
      "[0.6046562, 0.2, 0.20016485, 0.20031074]\n",
      "[0.60429263, 0.2, 0.20002103, 0.20009579]\n",
      "[0.60433316, 0.2, 0.20005, 0.20011221]\n",
      "[0.6042979, 0.2, 0.20003372, 0.20009807]\n",
      "[0.6042428, 0.2, 0.20004433, 0.2000372]\n",
      "[0.6043987, 0.2, 0.20019232, 0.2000499]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4760 iterations: 1.4293421824773154 mins\n",
      "Train Loss: [0.6043987, 0.2, 0.20019232, 0.2000499]\n",
      "[0.60441333, 0.2, 0.20014484, 0.20011681]\n",
      "[0.6042575, 0.2, 0.20005725, 0.20005344]\n",
      "[0.60427046, 0.2, 0.20006649, 0.20006199]\n",
      "[0.60436094, 0.2, 0.20013374, 0.20009011]\n",
      "[0.60452104, 0.2, 0.20016603, 0.2002228]\n",
      "[0.6043124, 0.2, 0.20011766, 0.20006743]\n",
      "[0.6042344, 0.2, 0.20005922, 0.20005268]\n",
      "[0.6042445, 0.2, 0.20006388, 0.20006296]\n",
      "[0.6042867, 0.2, 0.20006195, 0.200112]\n",
      "[0.60428536, 0.2, 0.20001765, 0.20015989]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4770 iterations: 1.4315424998601278 mins\n",
      "Train Loss: [0.60428536, 0.2, 0.20001765, 0.20015989]\n",
      "[0.6042439, 0.2, 0.20011002, 0.200031]\n",
      "[0.6042175, 0.2, 0.20009886, 0.20002069]\n",
      "[0.6042338, 0.2, 0.20004953, 0.20009118]\n",
      "[0.6042097, 0.2, 0.20005561, 0.20006585]\n",
      "[0.60418063, 0.2, 0.2000479, 0.20004933]\n",
      "[0.60420585, 0.2, 0.20008415, 0.20004313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60418415, 0.2, 0.20004794, 0.20006235]\n",
      "[0.6042341, 0.2, 0.20006244, 0.20010257]\n",
      "[0.6041707, 0.2, 0.20003253, 0.2000737]\n",
      "[0.60425735, 0.2, 0.20007533, 0.20012228]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4780 iterations: 1.434445865948995 mins\n",
      "Train Loss: [0.60425735, 0.2, 0.20007533, 0.20012228]\n",
      "[0.6041545, 0.2, 0.20003174, 0.2000677]\n",
      "[0.60420895, 0.2, 0.20004727, 0.20011117]\n",
      "[0.60416895, 0.2, 0.20008658, 0.20003648]\n",
      "[0.60423803, 0.2, 0.2000451, 0.20015153]\n",
      "[0.60416883, 0.2, 0.20007609, 0.20005581]\n",
      "[0.604147, 0.2, 0.2000715, 0.20004311]\n",
      "[0.6041506, 0.2, 0.20002836, 0.20009436]\n",
      "[0.60487473, 0.2, 0.2008165, 0.20003493]\n",
      "[0.60432994, 0.2, 0.20010503, 0.20020607]\n",
      "[0.6042111, 0.2, 0.20013168, 0.20006499]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4790 iterations: 1.4375429511070252 mins\n",
      "Train Loss: [0.6042111, 0.2, 0.20013168, 0.20006499]\n",
      "[0.6040844, 0.2, 0.200039, 0.20003547]\n",
      "[0.6041294, 0.2, 0.20007183, 0.20005217]\n",
      "[0.60417557, 0.2, 0.2001286, 0.2000462]\n",
      "[0.60423815, 0.2, 0.20014656, 0.20009544]\n",
      "[0.6040924, 0.2, 0.20005454, 0.20004645]\n",
      "[0.60430473, 0.2, 0.2001271, 0.20019089]\n",
      "[0.60418016, 0.2, 0.20014209, 0.2000562]\n",
      "[0.6041245, 0.2, 0.20001264, 0.20013474]\n",
      "[0.60409856, 0.2, 0.20007232, 0.20005386]\n",
      "[0.6041688, 0.2, 0.20010352, 0.20009771]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4800 iterations: 1.4394032835960389 mins\n",
      "Train Loss: [0.6041688, 0.2, 0.20010352, 0.20009771]\n",
      "[0.6041926, 0.2, 0.20008424, 0.20014557]\n",
      "[0.6041175, 0.2, 0.20010862, 0.20005088]\n",
      "[0.60415095, 0.2, 0.20009387, 0.20010392]\n",
      "[0.6042086, 0.2, 0.20017736, 0.20008296]\n",
      "[0.6041631, 0.2, 0.20005521, 0.20016444]\n",
      "[0.6041326, 0.2, 0.20008297, 0.20011085]\n",
      "[0.6042114, 0.2, 0.20009, 0.20018739]\n",
      "[0.6040936, 0.2, 0.20005599, 0.20010835]\n",
      "[0.6040934, 0.2, 0.20009583, 0.20007294]\n",
      "[0.6041082, 0.2, 0.2000795, 0.20010883]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4810 iterations: 1.4413784662882487 mins\n",
      "Train Loss: [0.6041082, 0.2, 0.2000795, 0.20010883]\n",
      "[0.60404134, 0.2, 0.20006703, 0.20005913]\n",
      "[0.603997, 0.2, 0.20003918, 0.20004725]\n",
      "[0.60395885, 0.2, 0.20000002, 0.20005302]\n",
      "[0.6041457, 0.2, 0.20011702, 0.20012762]\n",
      "[0.6039727, 0.2, 0.20005722, 0.20001908]\n",
      "[0.6039724, 0.2, 0.20009883, 0.19998194]\n",
      "[0.6039325, 0.2, 0.20001402, 0.20003156]\n",
      "[0.6039757, 0.2, 0.20004795, 0.20004557]\n",
      "[0.60397124, 0.2, 0.20005548, 0.20003828]\n",
      "[0.60398394, 0.2, 0.20003104, 0.20008002]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4820 iterations: 1.4432268500328065 mins\n",
      "Train Loss: [0.60398394, 0.2, 0.20003104, 0.20008002]\n",
      "[0.6039802, 0.2, 0.2000776, 0.2000344]\n",
      "[0.6040371, 0.2, 0.200023, 0.20015049]\n",
      "[0.6039607, 0.2, 0.20005295, 0.20004866]\n",
      "[0.6040045, 0.2, 0.20006037, 0.20008959]\n",
      "[0.6039584, 0.2, 0.20005655, 0.20005187]\n",
      "[0.6039571, 0.2, 0.20005299, 0.20005868]\n",
      "[0.60392696, 0.2, 0.20003888, 0.20004718]\n",
      "[0.6039687, 0.2, 0.20006947, 0.20006293]\n",
      "[0.60395586, 0.2, 0.2000462, 0.20007797]\n",
      "[0.6038806, 0.2, 0.20002922, 0.20002426]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4830 iterations: 1.4458953976631164 mins\n",
      "Train Loss: [0.6038806, 0.2, 0.20002922, 0.20002426]\n",
      "[0.603956, 0.2, 0.20006357, 0.20006986]\n",
      "[0.60401416, 0.2, 0.20010751, 0.2000887]\n",
      "[0.6039203, 0.2, 0.20005195, 0.20005499]\n",
      "[0.6039236, 0.2, 0.20005462, 0.20006028]\n",
      "[0.60392904, 0.2, 0.20005956, 0.20006554]\n",
      "[0.603894, 0.2, 0.20002851, 0.2000663]\n",
      "[0.60393447, 0.2, 0.20003928, 0.20010069]\n",
      "[0.6038716, 0.2, 0.20002732, 0.2000544]\n",
      "[0.60390615, 0.2, 0.20007487, 0.2000461]\n",
      "[0.60388505, 0.2, 0.20004967, 0.20005481]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4840 iterations: 1.4484700997670492 mins\n",
      "Train Loss: [0.60388505, 0.2, 0.20004967, 0.20005481]\n",
      "[0.60386485, 0.2, 0.20005184, 0.20003712]\n",
      "[0.60387194, 0.2, 0.20004675, 0.20005393]\n",
      "[0.60385615, 0.2, 0.20005427, 0.20003535]\n",
      "[0.6038828, 0.2, 0.2000534, 0.20006749]\n",
      "[0.6038646, 0.2, 0.20005858, 0.20004879]\n",
      "[0.6039542, 0.2, 0.20003036, 0.20017116]\n",
      "[0.60388315, 0.2, 0.20005275, 0.20008224]\n",
      "[0.6038343, 0.2, 0.20005408, 0.20003648]\n",
      "[0.6038529, 0.2, 0.20006439, 0.20004928]\n",
      "[0.6038171, 0.2, 0.20004426, 0.20003803]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4850 iterations: 1.4511561354001363 mins\n",
      "Train Loss: [0.6038171, 0.2, 0.20004426, 0.20003803]\n",
      "[0.60377175, 0.2, 0.20002724, 0.2000141]\n",
      "[0.6037883, 0.2, 0.20002127, 0.20004097]\n",
      "[0.6038167, 0.2, 0.20003448, 0.2000604]\n",
      "[0.60383314, 0.2, 0.20004293, 0.20007278]\n",
      "[0.60378134, 0.2, 0.20002201, 0.20004642]\n",
      "[0.6037947, 0.2, 0.20005715, 0.20002908]\n",
      "[0.60372955, 0.2, 0.20002374, 0.20000166]\n",
      "[0.6038131, 0.2, 0.2000444, 0.20006892]\n",
      "[0.6037723, 0.2, 0.20003536, 0.20004134]\n",
      "[0.6037801, 0.2, 0.20004077, 0.20004803]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4860 iterations: 1.4531355500221252 mins\n",
      "Train Loss: [0.6037801, 0.2, 0.20004077, 0.20004803]\n",
      "[0.60380477, 0.2, 0.20003901, 0.20007886]\n",
      "[0.6038428, 0.2, 0.20009053, 0.20006971]\n",
      "[0.6037955, 0.2, 0.2000516, 0.20006566]\n",
      "[0.6038172, 0.2, 0.20002179, 0.20012155]\n",
      "[0.603723, 0.2, 0.20001954, 0.20003387]\n",
      "[0.60376066, 0.2, 0.20004499, 0.20005052]\n",
      "[0.603787, 0.2, 0.20006345, 0.2000628]\n",
      "[0.60380095, 0.2, 0.20005731, 0.20008732]\n",
      "[0.6037329, 0.2, 0.20004626, 0.20003468]\n",
      "[0.6037323, 0.2, 0.2000346, 0.20005022]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4870 iterations: 1.4561956644058227 mins\n",
      "Train Loss: [0.6037323, 0.2, 0.2000346, 0.20005022]\n",
      "[0.60377336, 0.2, 0.20005704, 0.20007327]\n",
      "[0.6037582, 0.2, 0.20004877, 0.20007084]\n",
      "[0.60377556, 0.2, 0.20008147, 0.20005997]\n",
      "[0.60373104, 0.2, 0.20006791, 0.20003335]\n",
      "[0.60391253, 0.2, 0.20019381, 0.20009343]\n",
      "[0.6037102, 0.2, 0.20003363, 0.20005563]\n",
      "[0.603721, 0.2, 0.20003724, 0.20006734]\n",
      "[0.6037211, 0.2, 0.20008266, 0.20002647]\n",
      "[0.6036778, 0.2, 0.20003664, 0.20003362]\n",
      "[0.6037081, 0.2, 0.20003393, 0.20007104]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4880 iterations: 1.4588788191477458 mins\n",
      "Train Loss: [0.6037081, 0.2, 0.20003393, 0.20007104]\n",
      "[0.60372853, 0.2, 0.20004664, 0.20008312]\n",
      "[0.6037048, 0.2, 0.20003496, 0.20007549]\n",
      "[0.60366386, 0.2, 0.20006157, 0.20001231]\n",
      "[0.6036537, 0.2, 0.2, 0.20006812]\n",
      "[0.6037703, 0.2, 0.20014654, 0.20004247]\n",
      "[0.60370106, 0.2, 0.20002365, 0.2001005]\n",
      "[0.60373724, 0.2, 0.20007291, 0.2000917]\n",
      "[0.6036811, 0.2, 0.20004568, 0.20006715]\n",
      "[0.60363674, 0.2, 0.20001742, 0.20005547]\n",
      "[0.6037522, 0.2, 0.20009223, 0.20010039]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4890 iterations: 1.4613997658093771 mins\n",
      "Train Loss: [0.6037522, 0.2, 0.20009223, 0.20010039]\n",
      "[0.6036849, 0.2, 0.20007849, 0.20005132]\n",
      "[0.60368985, 0.2, 0.20006791, 0.20007125]\n",
      "[0.603656, 0.2, 0.20005971, 0.20005007]\n",
      "[0.60365194, 0.2, 0.20003363, 0.20007654]\n",
      "[0.6036368, 0.2, 0.20005111, 0.20004839]\n",
      "[0.6038113, 0.2, 0.20006022, 0.2002182]\n",
      "[0.6036133, 0.2, 0.20003474, 0.2000499]\n",
      "[0.60454047, 0.2, 0.2000436, 0.20097241]\n",
      "[0.6035558, 0.2, 0.20006669, 0.19996876]\n",
      "[0.6037207, 0.2, 0.20002553, 0.20017882]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4900 iterations: 1.4645184675852458 mins\n",
      "Train Loss: [0.6037207, 0.2, 0.20002553, 0.20017882]\n",
      "[0.6035927, 0.2, 0.20008351, 0.19999686]\n",
      "[0.6042165, 0.2, 0.20006111, 0.20064715]\n",
      "[0.605775, 0.2, 0.20214197, 0.2001287]\n",
      "[0.60372263, 0.2, 0.20011286, 0.20010956]\n",
      "[0.6037785, 0.2, 0.2002051, 0.20007692]\n",
      "[0.6044601, 0.2, 0.20042622, 0.20054097]\n",
      "[0.6042754, 0.2, 0.20042357, 0.20036209]\n",
      "[0.6046325, 0.2, 0.20046107, 0.20068473]\n",
      "[0.6040118, 0.2, 0.20046979, 0.20005822]\n",
      "[0.60411555, 0.2, 0.2003662, 0.2002682]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4910 iterations: 1.4676167329152425 mins\n",
      "Train Loss: [0.60411555, 0.2, 0.2003662, 0.2002682]\n",
      "[0.6060114, 0.2, 0.20113236, 0.20140013]\n",
      "[0.60449296, 0.2, 0.20006336, 0.20095252]\n",
      "[0.60367644, 0.2, 0.20022765, 0.19997296]\n",
      "[0.6042008, 0.2, 0.20035808, 0.20036784]\n",
      "[0.6048459, 0.2, 0.200967, 0.20040385]\n",
      "[0.60415614, 0.2, 0.20009597, 0.20058367]\n",
      "[0.60457754, 0.2, 0.20090507, 0.2001926]\n",
      "[0.6049851, 0.2, 0.20059882, 0.20090283]\n",
      "[0.60462797, 0.2, 0.20041525, 0.20072387]\n",
      "[0.6051373, 0.2, 0.20126748, 0.20037462]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4920 iterations: 1.4698081294695535 mins\n",
      "Train Loss: [0.6051373, 0.2, 0.20126748, 0.20037462]\n",
      "[0.6046553, 0.2, 0.20029686, 0.20085767]\n",
      "[0.6043525, 0.2, 0.2002773, 0.20056833]\n",
      "[0.60506994, 0.2, 0.20082863, 0.20072794]\n",
      "[0.6045005, 0.2, 0.20032455, 0.20065597]\n",
      "[0.6049408, 0.2, 0.2008862, 0.200528]\n",
      "[0.6049202, 0.2, 0.20104507, 0.2003428]\n",
      "[0.6049485, 0.2, 0.20079574, 0.20061572]\n",
      "[0.6053068, 0.2, 0.2011224, 0.20064314]\n",
      "[0.6045498, 0.2, 0.20036143, 0.20064333]\n",
      "[0.60371834, 0.2, 0.20000008, 0.20017058]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4930 iterations: 1.4719988505045574 mins\n",
      "Train Loss: [0.60371834, 0.2, 0.20000008, 0.20017058]\n",
      "[0.6043075, 0.2, 0.20051698, 0.20024069]\n",
      "[0.6039153, 0.2, 0.20000608, 0.20035772]\n",
      "[0.60408676, 0.2, 0.20031281, 0.20022142]\n",
      "[0.6041703, 0.2, 0.20027341, 0.2003438]\n",
      "[0.6049054, 0.2, 0.2007111, 0.20064095]\n",
      "[0.6040673, 0.2, 0.20026475, 0.2002498]\n",
      "[0.6044439, 0.2, 0.20052132, 0.20037054]\n",
      "[0.60427445, 0.2, 0.20055416, 0.20016925]\n",
      "[0.6041905, 0.2, 0.20030321, 0.2003382]\n",
      "[0.603915, 0.2, 0.20014803, 0.20021994]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4940 iterations: 1.4738530794779459 mins\n",
      "Train Loss: [0.603915, 0.2, 0.20014803, 0.20021994]\n",
      "[0.6039577, 0.2, 0.20020966, 0.2002034]\n",
      "[0.6043153, 0.2, 0.20042168, 0.20035154]\n",
      "[0.604044, 0.2, 0.20032318, 0.20018151]\n",
      "[0.6656094, 0.2, 0.26200897, 0.20006423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6041487, 0.2, 0.2003688, 0.200224]\n",
      "[0.6038846, 0.2, 0.20013624, 0.20013098]\n",
      "[0.6043243, 0.2, 0.20036563, 0.20025092]\n",
      "[0.60436225, 0.2, 0.20041594, 0.20012964]\n",
      "[0.6044174, 0.2, 0.20025176, 0.2002289]\n",
      "[0.6044767, 0.2, 0.2000002, 0.20041443]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4950 iterations: 1.4764654517173768 mins\n",
      "Train Loss: [0.6044767, 0.2, 0.2000002, 0.20041443]\n",
      "[0.6050251, 0.2, 0.20034677, 0.2004907]\n",
      "[0.60453814, 0.2, 0.20017244, 0.20005536]\n",
      "[0.60497594, 0.2, 0.20021184, 0.20033649]\n",
      "[0.60471195, 0.2, 0.2000001, 0.2001739]\n",
      "[0.60497105, 0.2, 0.2001313, 0.20019947]\n",
      "[0.6051643, 0.2, 0.20018889, 0.20024146]\n",
      "[0.60555583, 0.2, 0.2001579, 0.20057946]\n",
      "[0.60530746, 0.2, 0.20007673, 0.20033638]\n",
      "[0.60544837, 0.2, 0.2001631, 0.2003241]\n",
      "[0.60596347, 0.2, 0.20031735, 0.20062698]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4960 iterations: 1.4782735308011372 mins\n",
      "Train Loss: [0.60596347, 0.2, 0.20031735, 0.20062698]\n",
      "[0.6057954, 0.2, 0.2004371, 0.20028976]\n",
      "[0.60582954, 0.2, 0.20020317, 0.2005162]\n",
      "[0.60563195, 0.2, 0.20018871, 0.20029852]\n",
      "[0.6057616, 0.2, 0.20021015, 0.20037876]\n",
      "[0.60575795, 0.2, 0.20040226, 0.20016102]\n",
      "[0.6058645, 0.2, 0.20036042, 0.20029315]\n",
      "[0.6058759, 0.2, 0.20014398, 0.20050986]\n",
      "[0.606401, 0.2, 0.20057015, 0.20060243]\n",
      "[0.6059519, 0.2, 0.20019557, 0.20052579]\n",
      "[0.6065711, 0.2, 0.20116536, 0.20017673]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4970 iterations: 1.4803584655125936 mins\n",
      "Train Loss: [0.6065711, 0.2, 0.20116536, 0.20017673]\n",
      "[0.60582817, 0.2, 0.20009592, 0.20050812]\n",
      "[0.60552186, 0.2, 0.20014733, 0.20015807]\n",
      "[0.6064241, 0.2, 0.20055197, 0.20066549]\n",
      "[0.6062597, 0.2, 0.20017493, 0.20088995]\n",
      "[0.6061839, 0.2, 0.20000051, 0.20100227]\n",
      "[0.6058492, 0.2, 0.20022884, 0.20045456]\n",
      "[0.6062, 0.2, 0.20023173, 0.20081899]\n",
      "[0.60558933, 0.2, 0.20004275, 0.20041524]\n",
      "[0.60539025, 0.2, 0.20015079, 0.20012699]\n",
      "[0.6054588, 0.2, 0.20023775, 0.20012838]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4980 iterations: 1.4832825183868408 mins\n",
      "Train Loss: [0.6054588, 0.2, 0.20023775, 0.20012838]\n",
      "[0.60569906, 0.2, 0.20032413, 0.2003028]\n",
      "[0.60559434, 0.2, 0.20011231, 0.20043121]\n",
      "[0.60671496, 0.2, 0.20159572, 0.20009005]\n",
      "[0.6066421, 0.2, 0.20008004, 0.20155506]\n",
      "[0.60707444, 0.2, 0.2003065, 0.20178348]\n",
      "[0.60617644, 0.2, 0.20067857, 0.20053639]\n",
      "[0.60632586, 0.2, 0.20017879, 0.20120868]\n",
      "[0.6059928, 0.2, 0.20102254, 0.2000551]\n",
      "[0.60683477, 0.2, 0.20127815, 0.20066477]\n",
      "[0.6054155, 0.2, 0.20019281, 0.20035453]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4990 iterations: 1.4869914491971334 mins\n",
      "Train Loss: [0.6054155, 0.2, 0.20019281, 0.20035453]\n",
      "[0.6054266, 0.2, 0.20035134, 0.20023046]\n",
      "[0.6067382, 0.2, 0.201606, 0.20031054]\n",
      "[0.605064, 0.2, 0.20021637, 0.20004863]\n",
      "[0.60578746, 0.2, 0.20035432, 0.20065653]\n",
      "[0.6069594, 0.2, 0.20052116, 0.20168313]\n",
      "[0.6068462, 0.2, 0.2016258, 0.20048647]\n",
      "[0.60516655, 0.2, 0.20015895, 0.20029464]\n",
      "[0.6052705, 0.2, 0.20022716, 0.20035084]\n",
      "[0.60755503, 0.2, 0.20186327, 0.20101932]\n",
      "[0.60548586, 0.2, 0.2002742, 0.20055942]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5000 iterations: 1.489564633369446 mins\n",
      "Train Loss: [0.60548586, 0.2, 0.2002742, 0.20055942]\n",
      "[0.60505956, 0.2, 0.20019697, 0.20023037]\n",
      "[0.6054117, 0.2, 0.20067476, 0.20012426]\n",
      "[0.60791093, 0.2, 0.20244333, 0.20087394]\n",
      "[0.60480326, 0.2, 0.20015284, 0.20007572]\n",
      "[0.6050857, 0.2, 0.20010582, 0.20042382]\n",
      "[0.60499394, 0.2, 0.20023428, 0.20022193]\n",
      "[0.6050394, 0.2, 0.20020603, 0.20031358]\n",
      "[0.60551506, 0.2, 0.20056666, 0.20044616]\n",
      "[0.60506886, 0.2, 0.20010151, 0.20048255]\n",
      "[0.6052448, 0.2, 0.20012915, 0.2006479]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5010 iterations: 1.4927608331044515 mins\n",
      "Train Loss: [0.6052448, 0.2, 0.20012915, 0.2006479]\n",
      "[0.60497046, 0.2, 0.20009267, 0.20042685]\n",
      "[0.6052538, 0.2, 0.20014222, 0.20067734]\n",
      "[0.60694027, 0.2, 0.20168518, 0.20083769]\n",
      "[0.60464185, 0.2, 0.2000992, 0.2001421]\n",
      "[0.6050337, 0.2, 0.20007646, 0.2005733]\n",
      "[0.60466015, 0.2, 0.20024638, 0.20004618]\n",
      "[0.6046973, 0.2, 0.20006204, 0.20028396]\n",
      "[0.60531116, 0.2, 0.2004733, 0.20050259]\n",
      "[0.60574055, 0.2, 0.20089857, 0.20052268]\n",
      "[0.6051953, 0.2, 0.20008065, 0.20081127]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5020 iterations: 1.4947790503501892 mins\n",
      "Train Loss: [0.6051953, 0.2, 0.20008065, 0.20081127]\n",
      "[0.605005, 0.2, 0.20052499, 0.20019265]\n",
      "[0.6045529, 0.2, 0.20023778, 0.2000435]\n",
      "[0.6045781, 0.2, 0.2002033, 0.2001188]\n",
      "[0.60607743, 0.2, 0.20047446, 0.20136233]\n",
      "[0.60466063, 0.2, 0.2001566, 0.20027861]\n",
      "[0.60446626, 0.2, 0.20020878, 0.20004718]\n",
      "[0.6048667, 0.2, 0.2007066, 0.19996464]\n",
      "[0.6048401, 0.2, 0.20041539, 0.20024385]\n",
      "[0.6047365, 0.2, 0.20028742, 0.2002825]\n",
      "[0.60454637, 0.2, 0.20029627, 0.20009744]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5030 iterations: 1.4967536171277365 mins\n",
      "Train Loss: [0.60454637, 0.2, 0.20029627, 0.20009744]\n",
      "[0.60447156, 0.2, 0.20004962, 0.20028311]\n",
      "[0.60451716, 0.2, 0.20009474, 0.20029718]\n",
      "[0.60514987, 0.2, 0.20079373, 0.20024419]\n",
      "[0.60580033, 0.2, 0.20078419, 0.20091753]\n",
      "[0.60556585, 0.2, 0.20041898, 0.20106143]\n",
      "[0.6069125, 0.2, 0.20095603, 0.20188417]\n",
      "[0.60469186, 0.2, 0.20033827, 0.2002945]\n",
      "[0.60527617, 0.2, 0.20105705, 0.20017312]\n",
      "[0.6043022, 0.2, 0.20006898, 0.20020033]\n",
      "[0.6059315, 0.2, 0.20093329, 0.20097812]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5040 iterations: 1.4998753468195598 mins\n",
      "Train Loss: [0.6059315, 0.2, 0.20093329, 0.20097812]\n",
      "[0.60558826, 0.2, 0.20024127, 0.20133957]\n",
      "[0.6067981, 0.2, 0.20251477, 0.20028852]\n",
      "[0.60395783, 0.2, 0.20013016, 0.19984545]\n",
      "[0.60556716, 0.2, 0.20116267, 0.20043463]\n",
      "[0.6043991, 0.2, 0.2002785, 0.20016275]\n",
      "[0.6051643, 0.2, 0.20010203, 0.20111628]\n",
      "[0.60441226, 0.2, 0.2001767, 0.20030124]\n",
      "[0.6044619, 0.2, 0.20011139, 0.20042764]\n",
      "[0.6041307, 0.2, 0.20014021, 0.20007898]\n",
      "[0.6042994, 0.2, 0.20017661, 0.20022249]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5050 iterations: 1.5020829637845357 mins\n",
      "Train Loss: [0.6042994, 0.2, 0.20017661, 0.20022249]\n",
      "[0.60413355, 0.2, 0.20010746, 0.20013678]\n",
      "[0.60450006, 0.2, 0.20027004, 0.2003517]\n",
      "[0.6041524, 0.2, 0.20008433, 0.20020063]\n",
      "[0.6041718, 0.2, 0.2001105, 0.2002046]\n",
      "[0.6042423, 0.2, 0.20014688, 0.20024925]\n",
      "[0.6052225, 0.2, 0.20099148, 0.20039532]\n",
      "[0.60411423, 0.2, 0.20004465, 0.20024401]\n",
      "[0.60499895, 0.2, 0.20071368, 0.20046952]\n",
      "[0.6043018, 0.2, 0.20008336, 0.20041253]\n",
      "[0.60451454, 0.2, 0.20052293, 0.2001953]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5060 iterations: 1.504193381468455 mins\n",
      "Train Loss: [0.60451454, 0.2, 0.20052293, 0.2001953]\n",
      "[0.6040537, 0.2, 0.20020182, 0.20006514]\n",
      "[0.6040811, 0.2, 0.20015775, 0.200146]\n",
      "[0.6055055, 0.2, 0.20018667, 0.2015509]\n",
      "[0.60499805, 0.2, 0.20039214, 0.20084715]\n",
      "[0.60426766, 0.2, 0.20016523, 0.20035289]\n",
      "[0.60460746, 0.2, 0.20010209, 0.20076504]\n",
      "[0.6046123, 0.2, 0.2007239, 0.20015712]\n",
      "[0.6047327, 0.2, 0.20093128, 0.20007919]\n",
      "[0.60394865, 0.2, 0.20004494, 0.20019054]\n",
      "[0.6040769, 0.2, 0.20008126, 0.20029145]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5070 iterations: 1.5060768683751424 mins\n",
      "Train Loss: [0.6040769, 0.2, 0.20008126, 0.20029145]\n",
      "[0.6040374, 0.2, 0.2000039, 0.20033827]\n",
      "[0.6046001, 0.2, 0.20056711, 0.2003465]\n",
      "[0.60391027, 0.2, 0.2000792, 0.20015343]\n",
      "[0.6041555, 0.2, 0.20016971, 0.20031683]\n",
      "[0.6040793, 0.2, 0.20025565, 0.20016348]\n",
      "[0.6039926, 0.2, 0.20011087, 0.20023023]\n",
      "[0.60460764, 0.2, 0.20081699, 0.20014773]\n",
      "[0.60440797, 0.2, 0.20059134, 0.2001822]\n",
      "[0.6039274, 0.2, 0.20016876, 0.20013276]\n",
      "[0.60466343, 0.2, 0.20013267, 0.20091334]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5080 iterations: 1.5088052988052367 mins\n",
      "Train Loss: [0.60466343, 0.2, 0.20013267, 0.20091334]\n",
      "[0.60411406, 0.2, 0.20016892, 0.20033602]\n",
      "[0.6040501, 0.2, 0.20018603, 0.20026317]\n",
      "[0.60385674, 0.2, 0.20011492, 0.20014906]\n",
      "[0.60396135, 0.2, 0.20034146, 0.20003513]\n",
      "[0.60477793, 0.2, 0.2009389, 0.20026223]\n",
      "[0.60428745, 0.2, 0.2004472, 0.20027137]\n",
      "[0.60394865, 0.2, 0.20017079, 0.20021681]\n",
      "[0.6038921, 0.2, 0.200147, 0.20019184]\n",
      "[0.60450333, 0.2, 0.20073523, 0.20022257]\n",
      "[0.60395026, 0.2, 0.20016204, 0.20025033]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5090 iterations: 1.5112156669298809 mins\n",
      "Train Loss: [0.60395026, 0.2, 0.20016204, 0.20025033]\n",
      "[0.60380137, 0.2, 0.20009676, 0.20017402]\n",
      "[0.6039797, 0.2, 0.20000029, 0.20045613]\n",
      "[0.60407376, 0.2, 0.20014167, 0.20041583]\n",
      "[0.60447335, 0.2, 0.200287, 0.20067714]\n",
      "[0.60385555, 0.2, 0.20016724, 0.20018585]\n",
      "[0.60396004, 0.2, 0.20013744, 0.20032689]\n",
      "[0.60404515, 0.2, 0.20025213, 0.20030397]\n",
      "[0.60340637, 0.2, 0.19996355, 0.19996054]\n",
      "[0.60364884, 0.2, 0.20018058, 0.19999266]\n",
      "[0.60404885, 0.2, 0.2002273, 0.2003526]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5100 iterations: 1.5142678022384644 mins\n",
      "Train Loss: [0.60404885, 0.2, 0.2002273, 0.2003526]\n",
      "[0.60378593, 0.2, 0.20018043, 0.20014337]\n",
      "[0.6040849, 0.2, 0.20010306, 0.20052637]\n",
      "[0.6038372, 0.2, 0.20016791, 0.2002204]\n",
      "[0.6049927, 0.2, 0.20034976, 0.20120052]\n",
      "[0.6036467, 0.2, 0.20013535, 0.20007537]\n",
      "[0.6038191, 0.2, 0.20014283, 0.20024669]\n",
      "[0.6045091, 0.2, 0.20009623, 0.20098966]\n",
      "[0.6039656, 0.2, 0.20015559, 0.20039296]\n",
      "[0.60378695, 0.2, 0.20034033, 0.20003586]\n",
      "[0.6038359, 0.2, 0.20022382, 0.20020749]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5110 iterations: 1.5161953806877135 mins\n",
      "Train Loss: [0.6038359, 0.2, 0.20022382, 0.20020749]\n",
      "[0.60377884, 0.2, 0.20012559, 0.20025492]\n",
      "[0.6040149, 0.2, 0.20048745, 0.2001353]\n",
      "[0.6035474, 0.2, 0.20009835, 0.20006321]\n",
      "[0.60371894, 0.2, 0.2001257, 0.20021358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6037893, 0.2, 0.20005412, 0.20036171]\n",
      "[0.6035799, 0.2, 0.20007865, 0.20013393]\n",
      "[0.60363024, 0.2, 0.20009474, 0.20017436]\n",
      "[0.60434234, 0.2, 0.20085153, 0.2001357]\n",
      "[0.6038478, 0.2, 0.20039065, 0.20010832]\n",
      "[0.6036737, 0.2, 0.20004548, 0.20028564]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5120 iterations: 1.518731951713562 mins\n",
      "Train Loss: [0.6036737, 0.2, 0.20004548, 0.20028564]\n",
      "[0.6040301, 0.2, 0.20006907, 0.20062466]\n",
      "[0.6036622, 0.2, 0.20016192, 0.20017008]\n",
      "[0.60378337, 0.2, 0.20017378, 0.20028558]\n",
      "[0.6041815, 0.2, 0.20076057, 0.200103]\n",
      "[0.6046007, 0.2, 0.20009793, 0.20119087]\n",
      "[0.60462224, 0.2, 0.20127359, 0.20004268]\n",
      "[0.60358256, 0.2, 0.20001027, 0.20027214]\n",
      "[0.60370195, 0.2, 0.20014925, 0.20025826]\n",
      "[0.6036027, 0.2, 0.20013617, 0.20017767]\n",
      "[0.60351175, 0.2, 0.20014092, 0.20008752]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5130 iterations: 1.5210865497589112 mins\n",
      "Train Loss: [0.60351175, 0.2, 0.20014092, 0.20008752]\n",
      "[0.60454136, 0.2, 0.20073491, 0.20052873]\n",
      "[0.60375875, 0.2, 0.20046364, 0.20002303]\n",
      "[0.60343474, 0.2, 0.20009474, 0.20007348]\n",
      "[0.6035478, 0.2, 0.20000239, 0.20028454]\n",
      "[0.6037474, 0.2, 0.20034605, 0.20014621]\n",
      "[0.6052364, 0.2, 0.20137088, 0.20061615]\n",
      "[0.60362947, 0.2, 0.20013526, 0.20025048]\n",
      "[0.60469955, 0.2, 0.20022333, 0.20123833]\n",
      "[0.60434824, 0.2, 0.20008492, 0.2010313]\n",
      "[0.6033451, 0.2, 0.20009975, 0.20001914]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5140 iterations: 1.5232096314430237 mins\n",
      "Train Loss: [0.6033451, 0.2, 0.20009975, 0.20001914]\n",
      "[0.6035283, 0.2, 0.20017138, 0.2001366]\n",
      "[0.6035211, 0.2, 0.20006742, 0.20023936]\n",
      "[0.60343105, 0.2, 0.20013694, 0.20008588]\n",
      "[0.6038226, 0.2, 0.2001783, 0.20044214]\n",
      "[0.6046081, 0.2, 0.20127012, 0.20014174]\n",
      "[0.60340756, 0.2, 0.20012811, 0.20008908]\n",
      "[0.6044222, 0.2, 0.20006637, 0.20117128]\n",
      "[0.6032583, 0.2, 0.2000231, 0.2000563]\n",
      "[0.60365784, 0.2, 0.20000012, 0.2004844]\n",
      "[0.60451686, 0.2, 0.20000005, 0.20134905]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5150 iterations: 1.5261961181958517 mins\n",
      "Train Loss: [0.60451686, 0.2, 0.20000005, 0.20134905]\n",
      "[0.6034217, 0.2, 0.2000956, 0.20016393]\n",
      "[0.6033184, 0.2, 0.20009416, 0.20006776]\n",
      "[0.6041493, 0.2, 0.20071465, 0.20028369]\n",
      "[0.60401434, 0.2, 0.20058893, 0.20028001]\n",
      "[0.60352576, 0.2, 0.20012513, 0.20026074]\n",
      "[0.6034079, 0.2, 0.20010917, 0.20016444]\n",
      "[0.604254, 0.2, 0.20012397, 0.20100129]\n",
      "[0.6033378, 0.2, 0.20013525, 0.20007938]\n",
      "[0.6037777, 0.2, 0.2001448, 0.20051514]\n",
      "[0.60368586, 0.2, 0.20034526, 0.20022842]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5160 iterations: 1.5287273486455282 mins\n",
      "Train Loss: [0.60368586, 0.2, 0.20034526, 0.20022842]\n",
      "[0.6032842, 0.2, 0.2000753, 0.20010224]\n",
      "[0.60324675, 0.2, 0.20007443, 0.20007116]\n",
      "[0.6038445, 0.2, 0.20059304, 0.20015565]\n",
      "[0.6033601, 0.2, 0.20014364, 0.20012575]\n",
      "[0.60322493, 0.2, 0.2000488, 0.20009062]\n",
      "[0.60381216, 0.2, 0.20061743, 0.20011425]\n",
      "[0.6034735, 0.2, 0.20014514, 0.20025277]\n",
      "[0.6037447, 0.2, 0.2003693, 0.2003046]\n",
      "[0.6033643, 0.2, 0.20003386, 0.20026438]\n",
      "[0.6036608, 0.2, 0.20036983, 0.20022956]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5170 iterations: 1.5312711159388224 mins\n",
      "Train Loss: [0.6036608, 0.2, 0.20036983, 0.20022956]\n",
      "[0.60343146, 0.2, 0.20009051, 0.20028412]\n",
      "[0.6034305, 0.2, 0.20008165, 0.20029667]\n",
      "[0.6031449, 0.2, 0.20011674, 0.19998045]\n",
      "[0.6036131, 0.2, 0.20008597, 0.20048401]\n",
      "[0.60338444, 0.2, 0.20003015, 0.20031576]\n",
      "[0.60358256, 0.2, 0.20050678, 0.20004173]\n",
      "[0.603363, 0.2, 0.20004931, 0.20028408]\n",
      "[0.60313344, 0.2, 0.200053, 0.2000553]\n",
      "[0.6035642, 0.2, 0.20036301, 0.20018056]\n",
      "[0.6033338, 0.2, 0.20024411, 0.20007366]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5180 iterations: 1.5334985494613647 mins\n",
      "Train Loss: [0.6033338, 0.2, 0.20024411, 0.20007366]\n",
      "[0.60333997, 0.2, 0.2000872, 0.20024148]\n",
      "[0.60333145, 0.2, 0.2002689, 0.2000561]\n",
      "[0.6034126, 0.2, 0.2001689, 0.20024215]\n",
      "[0.6033069, 0.2, 0.20009659, 0.20021364]\n",
      "[0.6031147, 0.2, 0.20006108, 0.20006183]\n",
      "[0.6030857, 0.2, 0.20003888, 0.20005997]\n",
      "[0.6030656, 0.2, 0.20008361, 0.20000017]\n",
      "[0.60313416, 0.2, 0.20009162, 0.20006573]\n",
      "[0.6032207, 0.2, 0.20007527, 0.20017372]\n",
      "[0.6030085, 0.2, 0.20005144, 0.19999057]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5190 iterations: 1.535898001988729 mins\n",
      "Train Loss: [0.6030085, 0.2, 0.20005144, 0.19999057]\n",
      "[0.6031887, 0.2, 0.20009938, 0.20012797]\n",
      "[0.60308987, 0.2, 0.2000496, 0.20008412]\n",
      "[0.60361385, 0.2, 0.20063153, 0.20003128]\n",
      "[0.6034948, 0.2, 0.20045212, 0.2000968]\n",
      "[0.60311335, 0.2, 0.2000512, 0.20012128]\n",
      "[0.603703, 0.2, 0.2000447, 0.20072256]\n",
      "[0.6031497, 0.2, 0.20007473, 0.20014425]\n",
      "[0.6031873, 0.2, 0.20007426, 0.20018733]\n",
      "[0.6032958, 0.2, 0.20033956, 0.20003548]\n",
      "[0.60335195, 0.2, 0.20031679, 0.20011944]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5200 iterations: 1.5382607181866963 mins\n",
      "Train Loss: [0.60335195, 0.2, 0.20031679, 0.20011944]\n",
      "[0.60358644, 0.2, 0.20008215, 0.20059364]\n",
      "[0.6031167, 0.2, 0.2001374, 0.2000737]\n",
      "[0.60305864, 0.2, 0.20007396, 0.20008405]\n",
      "[0.6033504, 0.2, 0.20007518, 0.20037937]\n",
      "[0.6030905, 0.2, 0.20004326, 0.20015626]\n",
      "[0.6036653, 0.2, 0.20009133, 0.20068763]\n",
      "[0.60311645, 0.2, 0.20010604, 0.20012884]\n",
      "[0.6033835, 0.2, 0.20044829, 0.20005831]\n",
      "[0.60309976, 0.2, 0.2000665, 0.20016111]\n",
      "[0.6038601, 0.2, 0.20024805, 0.20074454]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5210 iterations: 1.540125068028768 mins\n",
      "Train Loss: [0.6038601, 0.2, 0.20024805, 0.20074454]\n",
      "[0.60329235, 0.2, 0.2000921, 0.20033723]\n",
      "[0.603108, 0.2, 0.20007536, 0.20017418]\n",
      "[0.6032405, 0.2, 0.20004195, 0.20034462]\n",
      "[0.60362244, 0.2, 0.20063707, 0.20013593]\n",
      "[0.60468304, 0.2, 0.20164819, 0.20018996]\n",
      "[0.60299534, 0.2, 0.20012525, 0.20002972]\n",
      "[0.60307956, 0.2, 0.20009413, 0.20014976]\n",
      "[0.60300773, 0.2, 0.20006686, 0.20010999]\n",
      "[0.6045714, 0.2, 0.2011929, 0.2005523]\n",
      "[0.6030334, 0.2, 0.20011532, 0.20009653]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5220 iterations: 1.5432068506876628 mins\n",
      "Train Loss: [0.6030334, 0.2, 0.20011532, 0.20009653]\n",
      "[0.6031571, 0.2, 0.20001726, 0.20032273]\n",
      "[0.60347825, 0.2, 0.20053865, 0.20012681]\n",
      "[0.6038246, 0.2, 0.20016737, 0.20084864]\n",
      "[0.6048547, 0.2, 0.20181826, 0.20023207]\n",
      "[0.60351384, 0.2, 0.20009091, 0.20062281]\n",
      "[0.60358304, 0.2, 0.20061529, 0.20017192]\n",
      "[0.60314053, 0.2, 0.20008914, 0.2002597]\n",
      "[0.60306215, 0.2, 0.20018466, 0.20009014]\n",
      "[0.603241, 0.2, 0.20025948, 0.20019844]\n",
      "[0.6028549, 0.2, 0.2000925, 0.19998349]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5230 iterations: 1.5448902289072672 mins\n",
      "Train Loss: [0.6028549, 0.2, 0.2000925, 0.19998349]\n",
      "[0.60312694, 0.2, 0.20023334, 0.20011874]\n",
      "[0.6034957, 0.2, 0.20046207, 0.20026276]\n",
      "[0.603339, 0.2, 0.20054981, 0.20002224]\n",
      "[0.60300094, 0.2, 0.20005637, 0.2001815]\n",
      "[0.60320586, 0.2, 0.20007186, 0.20037484]\n",
      "[0.60305655, 0.2, 0.20002231, 0.20027903]\n",
      "[0.60310084, 0.2, 0.20002003, 0.20032959]\n",
      "[0.60330826, 0.2, 0.20040573, 0.20015524]\n",
      "[0.60404253, 0.2, 0.20011652, 0.20118263]\n",
      "[0.60351366, 0.2, 0.20054036, 0.20023395]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5240 iterations: 1.5472856322924295 mins\n",
      "Train Loss: [0.60351366, 0.2, 0.20054036, 0.20023395]\n",
      "[0.60379684, 0.2, 0.20068327, 0.20037805]\n",
      "[0.60339886, 0.2, 0.20064208, 0.20002517]\n",
      "[0.603141, 0.2, 0.20010145, 0.20031181]\n",
      "[0.60356706, 0.2, 0.20064595, 0.20019734]\n",
      "[0.60283715, 0.2, 0.2000899, 0.20002748]\n",
      "[0.603897, 0.2, 0.20021094, 0.20097025]\n",
      "[0.60298616, 0.2, 0.20019913, 0.20007539]\n",
      "[0.6037056, 0.2, 0.20019877, 0.20079927]\n",
      "[0.60353017, 0.2, 0.20009845, 0.20072842]\n",
      "[0.6041989, 0.2, 0.20000096, 0.20149869]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5250 iterations: 1.550096829732259 mins\n",
      "Train Loss: [0.6041989, 0.2, 0.20000096, 0.20149869]\n",
      "[0.60382485, 0.2, 0.20006707, 0.20106259]\n",
      "[0.6028627, 0.2, 0.20006712, 0.20010431]\n",
      "[0.6029485, 0.2, 0.20005149, 0.20020963]\n",
      "[0.6028698, 0.2, 0.20006664, 0.20011967]\n",
      "[0.60330987, 0.2, 0.20021756, 0.20041274]\n",
      "[0.6035174, 0.2, 0.20011222, 0.20072941]\n",
      "[0.6033284, 0.2, 0.20009516, 0.20056131]\n",
      "[0.6032742, 0.2, 0.20022048, 0.20038567]\n",
      "[0.6030474, 0.2, 0.20004767, 0.20033549]\n",
      "[0.6027974, 0.2, 0.20006204, 0.20007503]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5260 iterations: 1.5520578980445863 mins\n",
      "Train Loss: [0.6027974, 0.2, 0.20006204, 0.20007503]\n",
      "[0.6032541, 0.2, 0.20014694, 0.2004507]\n",
      "[0.60280246, 0.2, 0.20005257, 0.20009726]\n",
      "[0.6027632, 0.2, 0.2000448, 0.20006979]\n",
      "[0.6038902, 0.2, 0.20106943, 0.20017609]\n",
      "[0.6032906, 0.2, 0.20044847, 0.20020135]\n",
      "[0.60302776, 0.2, 0.20008938, 0.20030156]\n",
      "[0.60378546, 0.2, 0.20082213, 0.2003304]\n",
      "[0.6033827, 0.2, 0.20057826, 0.20017546]\n",
      "[0.6029321, 0.2, 0.20013587, 0.20017111]\n",
      "[0.60295063, 0.2, 0.20020363, 0.20012581]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5270 iterations: 1.5545624653498331 mins\n",
      "Train Loss: [0.60295063, 0.2, 0.20020363, 0.20012581]\n",
      "[0.60331887, 0.2, 0.20027636, 0.20042522]\n",
      "[0.6034191, 0.2, 0.2002181, 0.20058766]\n",
      "[0.6028888, 0.2, 0.20015667, 0.20012279]\n",
      "[0.6026639, 0.2, 0.2000183, 0.20004018]\n",
      "[0.60297453, 0.2, 0.200138, 0.20023508]\n",
      "[0.60315377, 0.2, 0.20017117, 0.20038514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6035704, 0.2, 0.20077938, 0.20019759]\n",
      "[0.60284114, 0.2, 0.2001678, 0.20008373]\n",
      "[0.6029074, 0.2, 0.20022883, 0.20009302]\n",
      "[0.60306644, 0.2, 0.20024957, 0.2002352]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5280 iterations: 1.5568724513053893 mins\n",
      "Train Loss: [0.60306644, 0.2, 0.20024957, 0.2002352]\n",
      "[0.6028962, 0.2, 0.20012642, 0.20019206]\n",
      "[0.6027336, 0.2, 0.20008399, 0.20007585]\n",
      "[0.6031635, 0.2, 0.20029707, 0.20029652]\n",
      "[0.6027496, 0.2, 0.20005912, 0.20012443]\n",
      "[0.60256517, 0.2, 0.2000413, 0.19996169]\n",
      "[0.60270524, 0.2, 0.20005797, 0.20008898]\n",
      "[0.6027325, 0.2, 0.20015495, 0.20002304]\n",
      "[0.6026367, 0.2, 0.20010635, 0.19997968]\n",
      "[0.6028843, 0.2, 0.20021684, 0.20012055]\n",
      "[0.6026867, 0.2, 0.20010987, 0.20003365]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5290 iterations: 1.559515380859375 mins\n",
      "Train Loss: [0.6026867, 0.2, 0.20010987, 0.20003365]\n",
      "[0.6030239, 0.2, 0.20016852, 0.20031586]\n",
      "[0.602824, 0.2, 0.1999902, 0.20029785]\n",
      "[0.6028366, 0.2, 0.20010139, 0.20020281]\n",
      "[0.60303926, 0.2, 0.20019896, 0.20031147]\n",
      "[0.60263735, 0.2, 0.19998296, 0.20012914]\n",
      "[0.60316527, 0.2, 0.20048961, 0.20015383]\n",
      "[0.60264397, 0.2, 0.20003265, 0.20009299]\n",
      "[0.6028457, 0.2, 0.20022269, 0.20010813]\n",
      "[0.60278565, 0.2, 0.20013976, 0.20013452]\n",
      "[0.6030494, 0.2, 0.20039025, 0.20015126]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5300 iterations: 1.5616657495498658 mins\n",
      "Train Loss: [0.6030494, 0.2, 0.20039025, 0.20015126]\n",
      "[0.60276824, 0.2, 0.2000908, 0.20017308]\n",
      "[0.6035092, 0.2, 0.2004504, 0.20055798]\n",
      "[0.6029617, 0.2, 0.20009398, 0.20037052]\n",
      "[0.6033035, 0.2, 0.2002302, 0.20057963]\n",
      "[0.6027649, 0.2, 0.20015855, 0.20011617]\n",
      "[0.6028484, 0.2, 0.20012987, 0.20023198]\n",
      "[0.6027058, 0.2, 0.20001687, 0.20020589]\n",
      "[0.6028513, 0.2, 0.20033185, 0.20003998]\n",
      "[0.60350156, 0.2, 0.20092057, 0.20010513]\n",
      "[0.60305536, 0.2, 0.2003611, 0.20022196]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5310 iterations: 1.563975699742635 mins\n",
      "Train Loss: [0.60305536, 0.2, 0.2003611, 0.20022196]\n",
      "[0.6030082, 0.2, 0.20006773, 0.20047182]\n",
      "[0.60272634, 0.2, 0.20012139, 0.20014001]\n",
      "[0.6027055, 0.2, 0.20025614, 0.199988]\n",
      "[0.6026933, 0.2, 0.20012036, 0.20011525]\n",
      "[0.6030252, 0.2, 0.20033772, 0.2002335]\n",
      "[0.6026638, 0.2, 0.20008309, 0.20013031]\n",
      "[0.60292476, 0.2, 0.20012058, 0.2003574]\n",
      "[0.60272545, 0.2, 0.20019694, 0.20008534]\n",
      "[0.6026372, 0.2, 0.200105, 0.20009257]\n",
      "[0.6034413, 0.2, 0.20040467, 0.20060052]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5320 iterations: 1.5660677512486776 mins\n",
      "Train Loss: [0.6034413, 0.2, 0.20040467, 0.20060052]\n",
      "[0.60263234, 0.2, 0.20015629, 0.20004332]\n",
      "[0.6027353, 0.2, 0.20011802, 0.20018777]\n",
      "[0.6031953, 0.2, 0.20012312, 0.20064598]\n",
      "[0.60343826, 0.2, 0.20078517, 0.20023032]\n",
      "[0.6029876, 0.2, 0.20038578, 0.2001824]\n",
      "[0.6041029, 0.2, 0.20116393, 0.2005228]\n",
      "[0.6036697, 0.2, 0.20109804, 0.20015863]\n",
      "[0.60330105, 0.2, 0.20079663, 0.20009452]\n",
      "[0.603357, 0.2, 0.20083177, 0.20011842]\n",
      "[0.6034867, 0.2, 0.20058708, 0.20049585]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5330 iterations: 1.568458648522695 mins\n",
      "Train Loss: [0.6034867, 0.2, 0.20058708, 0.20049585]\n",
      "[0.60283077, 0.2, 0.2003522, 0.20007777]\n",
      "[0.6026357, 0.2, 0.20021482, 0.20002322]\n",
      "[0.60337806, 0.2, 0.20082791, 0.20015562]\n",
      "[0.6030183, 0.2, 0.20007211, 0.20055482]\n",
      "[0.6029842, 0.2, 0.20018134, 0.20041472]\n",
      "[0.6027155, 0.2, 0.20011961, 0.20021103]\n",
      "[0.602925, 0.2, 0.2001784, 0.20036511]\n",
      "[0.60265166, 0.2, 0.20010184, 0.20017162]\n",
      "[0.60333806, 0.2, 0.20085113, 0.2001121]\n",
      "[0.60259765, 0.2, 0.20009531, 0.20013084]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5340 iterations: 1.570571498076121 mins\n",
      "Train Loss: [0.60259765, 0.2, 0.20009531, 0.20013084]\n",
      "[0.6032448, 0.2, 0.20065513, 0.20022146]\n",
      "[0.60348463, 0.2, 0.20073089, 0.20038888]\n",
      "[0.60253376, 0.2, 0.20001017, 0.20016202]\n",
      "[0.60258424, 0.2, 0.20002235, 0.2002036]\n",
      "[0.6025889, 0.2, 0.20018041, 0.20005345]\n",
      "[0.6025587, 0.2, 0.20009987, 0.20010701]\n",
      "[0.60384536, 0.2, 0.20093916, 0.20055749]\n",
      "[0.60300833, 0.2, 0.2005308, 0.20013198]\n",
      "[0.602443, 0.2, 0.2000133, 0.20008737]\n",
      "[0.6026001, 0.2, 0.20004576, 0.2002153]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5350 iterations: 1.5726880828539531 mins\n",
      "Train Loss: [0.6026001, 0.2, 0.20004576, 0.2002153]\n",
      "[0.6025273, 0.2, 0.20004904, 0.20014247]\n",
      "[0.6025133, 0.2, 0.20001832, 0.20016235]\n",
      "[0.602401, 0.2, 0.20003346, 0.20003824]\n",
      "[0.6030078, 0.2, 0.20046417, 0.20021755]\n",
      "[0.60242796, 0.2, 0.20007022, 0.20003475]\n",
      "[0.6025983, 0.2, 0.20006397, 0.20021449]\n",
      "[0.60245216, 0.2, 0.2000168, 0.20011856]\n",
      "[0.60266036, 0.2, 0.20020728, 0.20013922]\n",
      "[0.6024232, 0.2, 0.20008144, 0.20003076]\n",
      "[0.6025341, 0.2, 0.2000675, 0.2001584]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5360 iterations: 1.5757135470708212 mins\n",
      "Train Loss: [0.6025341, 0.2, 0.2000675, 0.2001584]\n",
      "[0.6025108, 0.2, 0.20008744, 0.20011795]\n",
      "[0.6025534, 0.2, 0.20007959, 0.20017126]\n",
      "[0.6024403, 0.2, 0.20007731, 0.20006333]\n",
      "[0.60257924, 0.2, 0.20004743, 0.20023507]\n",
      "[0.6025404, 0.2, 0.20014012, 0.20010638]\n",
      "[0.60279614, 0.2, 0.20011868, 0.20038648]\n",
      "[0.6023762, 0.2, 0.20008391, 0.20000434]\n",
      "[0.6027494, 0.2, 0.20003605, 0.20042846]\n",
      "[0.6027821, 0.2, 0.2003522, 0.20014796]\n",
      "[0.60241824, 0.2, 0.20006429, 0.20007516]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5370 iterations: 1.5779578646024068 mins\n",
      "Train Loss: [0.60241824, 0.2, 0.20006429, 0.20007516]\n",
      "[0.602636, 0.2, 0.20029241, 0.20006786]\n",
      "[0.6024872, 0.2, 0.20010464, 0.20011015]\n",
      "[0.60245425, 0.2, 0.20009533, 0.20008966]\n",
      "[0.6024449, 0.2, 0.20006372, 0.2001151]\n",
      "[0.6025415, 0.2, 0.2002218, 0.20005687]\n",
      "[0.6023356, 0.2, 0.20005096, 0.20002507]\n",
      "[0.60240895, 0.2, 0.20005733, 0.20009542]\n",
      "[0.6023547, 0.2, 0.20001826, 0.20008352]\n",
      "[0.6025074, 0.2, 0.2001574, 0.20010036]\n",
      "[0.6023484, 0.2, 0.2000818, 0.20002027]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5380 iterations: 1.5798566818237305 mins\n",
      "Train Loss: [0.6023484, 0.2, 0.2000818, 0.20002027]\n",
      "[0.60252726, 0.2, 0.20008966, 0.20019451]\n",
      "[0.6023767, 0.2, 0.20004173, 0.20009524]\n",
      "[0.6026099, 0.2, 0.20024842, 0.20012508]\n",
      "[0.6028716, 0.2, 0.2002084, 0.20043023]\n",
      "[0.6023305, 0.2, 0.20004542, 0.20005552]\n",
      "[0.602797, 0.2, 0.20029476, 0.20027597]\n",
      "[0.602321, 0.2, 0.20004067, 0.20005752]\n",
      "[0.6023012, 0.2, 0.20000002, 0.20008162]\n",
      "[0.60245234, 0.2, 0.20010483, 0.20013142]\n",
      "[0.60240734, 0.2, 0.20011188, 0.20008281]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5390 iterations: 1.5835048317909242 mins\n",
      "Train Loss: [0.60240734, 0.2, 0.20011188, 0.20008281]\n",
      "[0.6029573, 0.2, 0.20039661, 0.20035152]\n",
      "[0.6023284, 0.2, 0.20005898, 0.20006374]\n",
      "[0.6027723, 0.2, 0.200475, 0.20009509]\n",
      "[0.60220206, 0.2, 0.20001824, 0.19998512]\n",
      "[0.6022671, 0.2, 0.20007643, 0.19999546]\n",
      "[0.60231566, 0.2, 0.20006792, 0.20005615]\n",
      "[0.602728, 0.2, 0.20024204, 0.20029789]\n",
      "[0.6024015, 0.2, 0.2, 0.20021696]\n",
      "[0.6025823, 0.2, 0.20005989, 0.20034134]\n",
      "[0.6023171, 0.2, 0.20010927, 0.20003028]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5400 iterations: 1.5859880328178406 mins\n",
      "Train Loss: [0.6023171, 0.2, 0.20010927, 0.20003028]\n",
      "[0.6024375, 0.2, 0.20011006, 0.20015338]\n",
      "[0.602191, 0.2, 0.200024, 0.19999635]\n",
      "[0.6023951, 0.2, 0.20007789, 0.2001501]\n",
      "[0.60228133, 0.2, 0.20005807, 0.2000595]\n",
      "[0.6023226, 0.2, 0.20006683, 0.2000953]\n",
      "[0.6023643, 0.2, 0.20012696, 0.20008022]\n",
      "[0.6024147, 0.2, 0.200024, 0.20023695]\n",
      "[0.60232854, 0.2, 0.20005253, 0.20012552]\n",
      "[0.60227805, 0.2, 0.20005253, 0.20007838]\n",
      "[0.6022327, 0.2, 0.20000002, 0.2000888]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5410 iterations: 1.5880884965260824 mins\n",
      "Train Loss: [0.6022327, 0.2, 0.20000002, 0.2000888]\n",
      "[0.60243994, 0.2, 0.2000714, 0.20022798]\n",
      "[0.60223246, 0.2, 0.20005178, 0.20004342]\n",
      "[0.6022466, 0.2, 0.20006609, 0.20004663]\n",
      "[0.6022526, 0.2, 0.20003612, 0.20008592]\n",
      "[0.60230297, 0.2, 0.20007928, 0.20009638]\n",
      "[0.60266054, 0.2, 0.20015836, 0.20037822]\n",
      "[0.6022646, 0.2, 0.20005174, 0.20009215]\n",
      "[0.6024924, 0.2, 0.20005302, 0.2003219]\n",
      "[0.6024801, 0.2, 0.20003577, 0.20033012]\n",
      "[0.60269403, 0.2, 0.20039593, 0.2001871]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5420 iterations: 1.5899385849634806 mins\n",
      "Train Loss: [0.60269403, 0.2, 0.20039593, 0.2001871]\n",
      "[0.6022878, 0.2, 0.20003745, 0.2001425]\n",
      "[0.602191, 0.2, 0.20002243, 0.20006385]\n",
      "[0.60229546, 0.2, 0.20011942, 0.20007458]\n",
      "[0.602201, 0.2, 0.20004639, 0.20005623]\n",
      "[0.602503, 0.2, 0.20030813, 0.20009975]\n",
      "[0.602219, 0.2, 0.200034, 0.20009302]\n",
      "[0.60243833, 0.2, 0.20031098, 0.20003857]\n",
      "[0.6022143, 0.2, 0.2000389, 0.2000896]\n",
      "[0.60228413, 0.2, 0.20017047, 0.20003101]\n",
      "[0.60219425, 0.2, 0.20002554, 0.20008911]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5430 iterations: 1.5923303325970968 mins\n",
      "Train Loss: [0.60219425, 0.2, 0.20002554, 0.20008911]\n",
      "[0.6022624, 0.2, 0.2001214, 0.20006442]\n",
      "[0.60219526, 0.2, 0.20003688, 0.2000849]\n",
      "[0.60251915, 0.2, 0.20035186, 0.20009676]\n",
      "[0.6025885, 0.2, 0.20039767, 0.20012328]\n",
      "[0.6022072, 0.2, 0.20007485, 0.20006791]\n",
      "[0.60249275, 0.2, 0.20034105, 0.20009048]\n",
      "[0.60254437, 0.2, 0.20046477, 0.20002145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6023224, 0.2, 0.20006691, 0.20020042]\n",
      "[0.6021383, 0.2, 0.20006275, 0.20002358]\n",
      "[0.6025418, 0.2, 0.20004843, 0.20044446]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5440 iterations: 1.5952545483907064 mins\n",
      "Train Loss: [0.6025418, 0.2, 0.20004843, 0.20044446]\n",
      "[0.6022611, 0.2, 0.20013471, 0.20008041]\n",
      "[0.60255915, 0.2, 0.20004879, 0.20046723]\n",
      "[0.60232866, 0.2, 0.20020683, 0.20008153]\n",
      "[0.60211337, 0.2, 0.20005059, 0.2000253]\n",
      "[0.60230696, 0.2, 0.20015074, 0.20012157]\n",
      "[0.60211754, 0.2, 0.2000151, 0.20007063]\n",
      "[0.6024794, 0.2, 0.20020352, 0.20024687]\n",
      "[0.60217667, 0.2, 0.20011216, 0.20003831]\n",
      "[0.6021756, 0.2, 0.2000893, 0.20006295]\n",
      "[0.60247344, 0.2, 0.20006226, 0.20039079]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5450 iterations: 1.5975905656814575 mins\n",
      "Train Loss: [0.60247344, 0.2, 0.20006226, 0.20039079]\n",
      "[0.6022961, 0.2, 0.20002632, 0.20025228]\n",
      "[0.60234636, 0.2, 0.20027658, 0.20005521]\n",
      "[0.60209185, 0.2, 0.20002979, 0.20005043]\n",
      "[0.6025177, 0.2, 0.20040685, 0.20010217]\n",
      "[0.6026218, 0.2, 0.20038804, 0.20022798]\n",
      "[0.60279614, 0.2, 0.20021364, 0.20057964]\n",
      "[0.6020952, 0.2, 0.20005634, 0.20003891]\n",
      "[0.60209936, 0.2, 0.20003313, 0.20006931]\n",
      "[0.60224736, 0.2, 0.20016038, 0.20009317]\n",
      "[0.60207146, 0.2, 0.2000267, 0.20005389]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5460 iterations: 1.5996633172035217 mins\n",
      "Train Loss: [0.60207146, 0.2, 0.2000267, 0.20005389]\n",
      "[0.6023374, 0.2, 0.20007661, 0.20027287]\n",
      "[0.60210043, 0.2, 0.2000767, 0.20003869]\n",
      "[0.6021508, 0.2, 0.2000576, 0.2001109]\n",
      "[0.60209066, 0.2, 0.20004296, 0.20006819]\n",
      "[0.60210496, 0.2, 0.20006791, 0.20006025]\n",
      "[0.6020535, 0.2, 0.20002961, 0.20004988]\n",
      "[0.6021495, 0.2, 0.20014256, 0.20003565]\n",
      "[0.6020899, 0.2, 0.2000208, 0.20010044]\n",
      "[0.6024411, 0.2, 0.2000245, 0.20045072]\n",
      "[0.6021824, 0.2, 0.20012015, 0.20009908]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5470 iterations: 1.6018317659695944 mins\n",
      "Train Loss: [0.6021824, 0.2, 0.20012015, 0.20009908]\n",
      "[0.6020781, 0.2, 0.20003706, 0.20008062]\n",
      "[0.6021679, 0.2, 0.20003864, 0.20017162]\n",
      "[0.6019989, 0.2, 0.2000437, 0.20000039]\n",
      "[0.60229987, 0.2, 0.20027436, 0.20007336]\n",
      "[0.60224044, 0.2, 0.20003657, 0.20025457]\n",
      "[0.6021957, 0.2, 0.20003626, 0.20021288]\n",
      "[0.6020147, 0.2, 0.2000141, 0.20005682]\n",
      "[0.60215634, 0.2, 0.20004386, 0.20017153]\n",
      "[0.60201323, 0.2, 0.2000428, 0.20003235]\n",
      "[0.6021545, 0.2, 0.20006114, 0.20015815]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5480 iterations: 1.60396093527476 mins\n",
      "Train Loss: [0.6021545, 0.2, 0.20006114, 0.20015815]\n",
      "[0.60218847, 0.2, 0.20023045, 0.20002565]\n",
      "[0.6020568, 0.2, 0.2000422, 0.20008516]\n",
      "[0.60211843, 0.2, 0.20004487, 0.20014703]\n",
      "[0.6021489, 0.2, 0.2000521, 0.20017327]\n",
      "[0.60207516, 0.2, 0.20004238, 0.20011231]\n",
      "[0.60229534, 0.2, 0.20024054, 0.20013735]\n",
      "[0.60213447, 0.2, 0.20008965, 0.20013042]\n",
      "[0.6020901, 0.2, 0.20003396, 0.20014474]\n",
      "[0.6021226, 0.2, 0.20002103, 0.20019318]\n",
      "[0.60237944, 0.2, 0.2002727, 0.20020123]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5490 iterations: 1.6058162490526835 mins\n",
      "Train Loss: [0.60237944, 0.2, 0.2002727, 0.20020123]\n",
      "[0.6020035, 0.2, 0.20003533, 0.20006567]\n",
      "[0.6019629, 0.2, 0.20002507, 0.20003821]\n",
      "[0.6025793, 0.2, 0.20053916, 0.20014347]\n",
      "[0.60213166, 0.2, 0.20012261, 0.20011522]\n",
      "[0.60308444, 0.2, 0.2006447, 0.20054872]\n",
      "[0.6019972, 0.2, 0.2000542, 0.20005465]\n",
      "[0.60204285, 0.2, 0.20009789, 0.20005912]\n",
      "[0.6023383, 0.2, 0.20042872, 0.20002624]\n",
      "[0.6025748, 0.2, 0.20038652, 0.20030716]\n",
      "[0.60284954, 0.2, 0.20053217, 0.2004384]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5500 iterations: 1.6076545317967732 mins\n",
      "Train Loss: [0.60284954, 0.2, 0.20053217, 0.2004384]\n",
      "[0.6033561, 0.2, 0.20071016, 0.20076902]\n",
      "[0.6019634, 0.2, 0.20004274, 0.20004568]\n",
      "[0.60230434, 0.2, 0.20033169, 0.20009965]\n",
      "[0.60199445, 0.2, 0.20006213, 0.20006134]\n",
      "[0.6019656, 0.2, 0.20006175, 0.20003492]\n",
      "[0.60235393, 0.2, 0.20042753, 0.20005974]\n",
      "[0.6021571, 0.2, 0.20005395, 0.20023873]\n",
      "[0.6019698, 0.2, 0.20005472, 0.20005296]\n",
      "[0.602502, 0.2, 0.20004776, 0.20059459]\n",
      "[0.6019866, 0.2, 0.20004979, 0.20007965]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5510 iterations: 1.6096834977467855 mins\n",
      "Train Loss: [0.6019866, 0.2, 0.20004979, 0.20007965]\n",
      "[0.60312986, 0.2, 0.20087472, 0.20040044]\n",
      "[0.60328066, 0.2, 0.20087512, 0.20055325]\n",
      "[0.6023857, 0.2, 0.20047624, 0.20005946]\n",
      "[0.60188127, 0.2, 0.20000347, 0.20003006]\n",
      "[0.60214776, 0.2, 0.20018332, 0.20011896]\n",
      "[0.6023321, 0.2, 0.20005435, 0.20043463]\n",
      "[0.6019946, 0.2, 0.2000284, 0.2001253]\n",
      "[0.6018681, 0.2, 0.20001672, 0.2000128]\n",
      "[0.6022153, 0.2, 0.20002201, 0.20035703]\n",
      "[0.6020626, 0.2, 0.20014125, 0.20008743]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5520 iterations: 1.611504900455475 mins\n",
      "Train Loss: [0.6020626, 0.2, 0.20014125, 0.20008743]\n",
      "[0.60177886, 0.2, 0.20000015, 0.19994718]\n",
      "[0.60218334, 0.2, 0.20014627, 0.20020789]\n",
      "[0.6018933, 0.2, 0.20004477, 0.20002176]\n",
      "[0.6018846, 0.2, 0.20008668, 0.19997358]\n",
      "[0.60246074, 0.2, 0.20046154, 0.20017736]\n",
      "[0.60189426, 0.2, 0.20000005, 0.20007487]\n",
      "[0.6020028, 0.2, 0.20013386, 0.200052]\n",
      "[0.6019383, 0.2, 0.20005734, 0.20006643]\n",
      "[0.6021559, 0.2, 0.20016263, 0.20018114]\n",
      "[0.6020011, 0.2, 0.2000319, 0.20015939]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5530 iterations: 1.6134790301322937 mins\n",
      "Train Loss: [0.6020011, 0.2, 0.2000319, 0.20015939]\n",
      "[0.6019551, 0.2, 0.20006534, 0.20008239]\n",
      "[0.60185146, 0.2, 0.20000002, 0.20004645]\n",
      "[0.6018999, 0.2, 0.20006329, 0.20003422]\n",
      "[0.60209906, 0.2, 0.20004086, 0.20025818]\n",
      "[0.6020201, 0.2, 0.20003559, 0.20018692]\n",
      "[0.6020758, 0.2, 0.20012581, 0.20015484]\n",
      "[0.6019055, 0.2, 0.20006606, 0.20004687]\n",
      "[0.60263735, 0.2, 0.200065, 0.20078227]\n",
      "[0.6027234, 0.2, 0.20074533, 0.20019045]\n",
      "[0.60193473, 0.2, 0.20005403, 0.20009549]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5540 iterations: 1.6152201970418294 mins\n",
      "Train Loss: [0.60193473, 0.2, 0.20005403, 0.20009549]\n",
      "[0.60211104, 0.2, 0.20004466, 0.20028353]\n",
      "[0.60190517, 0.2, 0.20005779, 0.20006694]\n",
      "[0.601821, 0.2, 0.20004584, 0.19999714]\n",
      "[0.6019695, 0.2, 0.2000469, 0.20014694]\n",
      "[0.6018485, 0.2, 0.20002174, 0.20005357]\n",
      "[0.6021079, 0.2, 0.20034024, 0.19999687]\n",
      "[0.602081, 0.2, 0.20024231, 0.20007041]\n",
      "[0.6023003, 0.2, 0.20042184, 0.20011254]\n",
      "[0.60194427, 0.2, 0.20006782, 0.20011295]\n",
      "[0.6021086, 0.2, 0.20014384, 0.20020361]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5550 iterations: 1.6176657478014629 mins\n",
      "Train Loss: [0.6021086, 0.2, 0.20014384, 0.20020361]\n",
      "[0.60193646, 0.2, 0.2001031, 0.20007461]\n",
      "[0.60202533, 0.2, 0.20004639, 0.20022252]\n",
      "[0.60216534, 0.2, 0.20032388, 0.20008752]\n",
      "[0.60182863, 0.2, 0.20002621, 0.20005098]\n",
      "[0.60180384, 0.2, 0.20002584, 0.20002887]\n",
      "[0.60220295, 0.2, 0.20008066, 0.2003756]\n",
      "[0.60252833, 0.2, 0.20048787, 0.20029616]\n",
      "[0.6017447, 0.2, 0.20004024, 0.19996245]\n",
      "[0.6021094, 0.2, 0.20003603, 0.20033367]\n",
      "[0.6023627, 0.2, 0.20021814, 0.20040713]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5560 iterations: 1.619526465733846 mins\n",
      "Train Loss: [0.6023627, 0.2, 0.20021814, 0.20040713]\n",
      "[0.60191727, 0.2, 0.20006347, 0.20011863]\n",
      "[0.60178596, 0.2, 0.20002946, 0.20002356]\n",
      "[0.6019052, 0.2, 0.20010051, 0.20007409]\n",
      "[0.6019773, 0.2, 0.2000752, 0.2001737]\n",
      "[0.6021451, 0.2, 0.20033345, 0.20008549]\n",
      "[0.60183215, 0.2, 0.20007096, 0.20003718]\n",
      "[0.60188645, 0.2, 0.20003368, 0.20013098]\n",
      "[0.60184747, 0.2, 0.20006874, 0.20005901]\n",
      "[0.60214204, 0.2, 0.20036697, 0.20005752]\n",
      "[0.6023907, 0.2, 0.20056033, 0.20011494]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5570 iterations: 1.6214438637097677 mins\n",
      "Train Loss: [0.6023907, 0.2, 0.20056033, 0.20011494]\n",
      "[0.6022904, 0.2, 0.20002678, 0.20055026]\n",
      "[0.60237217, 0.2, 0.20040476, 0.20025621]\n",
      "[0.6022949, 0.2, 0.20018336, 0.20040257]\n",
      "[0.601957, 0.2, 0.20020527, 0.20004502]\n",
      "[0.60180205, 0.2, 0.20004801, 0.20004952]\n",
      "[0.6017633, 0.2, 0.20004475, 0.20001638]\n",
      "[0.6018955, 0.2, 0.20003444, 0.2001612]\n",
      "[0.602088, 0.2, 0.20006984, 0.2003206]\n",
      "[0.60206115, 0.2, 0.20011976, 0.20024614]\n",
      "[0.6018296, 0.2, 0.20003133, 0.20010538]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5580 iterations: 1.6234100818634034 mins\n",
      "Train Loss: [0.6018296, 0.2, 0.20003133, 0.20010538]\n",
      "[0.60176635, 0.2, 0.20003894, 0.20003676]\n",
      "[0.6021791, 0.2, 0.20032991, 0.20016088]\n",
      "[0.601807, 0.2, 0.20005159, 0.2000694]\n",
      "[0.601779, 0.2, 0.20005965, 0.20003565]\n",
      "[0.6017764, 0.2, 0.20006654, 0.20002842]\n",
      "[0.6019099, 0.2, 0.20019545, 0.20003529]\n",
      "[0.6017264, 0.2, 0.20002167, 0.20002781]\n",
      "[0.6017358, 0.2, 0.20000944, 0.20005156]\n",
      "[0.6017522, 0.2, 0.20006557, 0.20001404]\n",
      "[0.60199827, 0.2, 0.20010595, 0.20022185]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5590 iterations: 1.6254031976064047 mins\n",
      "Train Loss: [0.60199827, 0.2, 0.20010595, 0.20022185]\n",
      "[0.6020743, 0.2, 0.20004535, 0.2003607]\n",
      "[0.60171276, 0.2, 0.20002538, 0.20002133]\n",
      "[0.60176414, 0.2, 0.20002101, 0.20007934]\n",
      "[0.60176927, 0.2, 0.20006722, 0.20004061]\n",
      "[0.60179716, 0.2, 0.2000468, 0.20009132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6020729, 0.2, 0.20002483, 0.20039153]\n",
      "[0.6018219, 0.2, 0.20006135, 0.20010644]\n",
      "[0.6017327, 0.2, 0.20002618, 0.20005482]\n",
      "[0.6017464, 0.2, 0.20001736, 0.20007978]\n",
      "[0.60183203, 0.2, 0.20003873, 0.20014648]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5600 iterations: 1.6273393670717875 mins\n",
      "Train Loss: [0.60183203, 0.2, 0.20003873, 0.20014648]\n",
      "[0.60197425, 0.2, 0.20028245, 0.2000475]\n",
      "[0.60173047, 0.2, 0.20005038, 0.20003822]\n",
      "[0.6018386, 0.2, 0.20018375, 0.20001549]\n",
      "[0.6017782, 0.2, 0.20004183, 0.2000995]\n",
      "[0.60176134, 0.2, 0.20004378, 0.20008309]\n",
      "[0.6017243, 0.2, 0.20003907, 0.20005323]\n",
      "[0.6017443, 0.2, 0.20007272, 0.20004198]\n",
      "[0.60186005, 0.2, 0.2001757, 0.20005716]\n",
      "[0.6017715, 0.2, 0.20003766, 0.20010908]\n",
      "[0.6017872, 0.2, 0.20005241, 0.20011234]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5610 iterations: 1.6291454156239829 mins\n",
      "Train Loss: [0.6017872, 0.2, 0.20005241, 0.20011234]\n",
      "[0.6016963, 0.2, 0.2000504, 0.2000258]\n",
      "[0.60177046, 0.2, 0.2000544, 0.20009828]\n",
      "[0.6018939, 0.2, 0.20006378, 0.2002147]\n",
      "[0.6019364, 0.2, 0.20010594, 0.20021735]\n",
      "[0.6018802, 0.2, 0.2001114, 0.20015797]\n",
      "[0.6017418, 0.2, 0.20002958, 0.2001036]\n",
      "[0.60181814, 0.2, 0.20010139, 0.20011042]\n",
      "[0.601876, 0.2, 0.20025529, 0.2000167]\n",
      "[0.60188085, 0.2, 0.2000205, 0.20025852]\n",
      "[0.6017514, 0.2, 0.20009205, 0.20005967]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5620 iterations: 1.6314454992612204 mins\n",
      "Train Loss: [0.6017514, 0.2, 0.20009205, 0.20005967]\n",
      "[0.60171694, 0.2, 0.20004381, 0.20007567]\n",
      "[0.60188097, 0.2, 0.20003176, 0.20025395]\n",
      "[0.6017828, 0.2, 0.2000941, 0.2000957]\n",
      "[0.6016562, 0.2, 0.20003384, 0.2000317]\n",
      "[0.6017924, 0.2, 0.20004168, 0.20016241]\n",
      "[0.60171235, 0.2, 0.20005353, 0.20007282]\n",
      "[0.60175806, 0.2, 0.2000342, 0.20014021]\n",
      "[0.6018621, 0.2, 0.20016482, 0.20011598]\n",
      "[0.601684, 0.2, 0.20003289, 0.20007221]\n",
      "[0.60177594, 0.2, 0.20017749, 0.20002195]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5630 iterations: 1.6334844668706259 mins\n",
      "Train Loss: [0.60177594, 0.2, 0.20017749, 0.20002195]\n",
      "[0.60177654, 0.2, 0.20007654, 0.20012589]\n",
      "[0.60170877, 0.2, 0.2000348, 0.20010224]\n",
      "[0.60190237, 0.2, 0.20021194, 0.20012107]\n",
      "[0.60201454, 0.2, 0.2001106, 0.20033695]\n",
      "[0.60172874, 0.2, 0.2000696, 0.20009439]\n",
      "[0.60181993, 0.2, 0.20002502, 0.20023237]\n",
      "[0.6018147, 0.2, 0.20004486, 0.20020956]\n",
      "[0.60165673, 0.2, 0.20005225, 0.20004643]\n",
      "[0.6016334, 0.2, 0.20004776, 0.2000297]\n",
      "[0.6016735, 0.2, 0.20002341, 0.20009638]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5640 iterations: 1.6353213349978128 mins\n",
      "Train Loss: [0.6016735, 0.2, 0.20002341, 0.20009638]\n",
      "[0.6016682, 0.2, 0.2000447, 0.20007186]\n",
      "[0.60173416, 0.2, 0.20010409, 0.20008053]\n",
      "[0.6015728, 0.2, 0.20003647, 0.19998887]\n",
      "[0.60164195, 0.2, 0.20005849, 0.20003799]\n",
      "[0.6021174, 0.2, 0.20005883, 0.20051506]\n",
      "[0.60178983, 0.2, 0.2000833, 0.20016499]\n",
      "[0.6017877, 0.2, 0.20005018, 0.20019792]\n",
      "[0.60163283, 0.2, 0.20003495, 0.20006026]\n",
      "[0.601757, 0.2, 0.20002489, 0.20019644]\n",
      "[0.60166836, 0.2, 0.20006989, 0.20006475]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5650 iterations: 1.6371969819068908 mins\n",
      "Train Loss: [0.60166836, 0.2, 0.20006989, 0.20006475]\n",
      "[0.6018935, 0.2, 0.20027104, 0.2000906]\n",
      "[0.60228163, 0.2, 0.20063603, 0.20011558]\n",
      "[0.6021095, 0.2, 0.20035988, 0.20022137]\n",
      "[0.60204214, 0.2, 0.20007843, 0.20043723]\n",
      "[0.6016352, 0.2, 0.20004334, 0.20006727]\n",
      "[0.60166204, 0.2, 0.20008515, 0.20005424]\n",
      "[0.6018521, 0.2, 0.2000971, 0.2002343]\n",
      "[0.6022987, 0.2, 0.20035678, 0.20042324]\n",
      "[0.60171014, 0.2, 0.2000643, 0.20012915]\n",
      "[0.6016424, 0.2, 0.20007566, 0.200052]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5660 iterations: 1.6389389991760255 mins\n",
      "Train Loss: [0.6016424, 0.2, 0.20007566, 0.200052]\n",
      "[0.60155493, 0.2, 0.20002502, 0.20001732]\n",
      "[0.6018032, 0.2, 0.20004296, 0.20024969]\n",
      "[0.6015416, 0.2, 0.2, 0.20003305]\n",
      "[0.6016616, 0.2, 0.2000763, 0.20007889]\n",
      "[0.60199785, 0.2, 0.20029728, 0.20019616]\n",
      "[0.60161513, 0.2, 0.20003706, 0.20007578]\n",
      "[0.6016399, 0.2, 0.20007104, 0.2000686]\n",
      "[0.6015993, 0.2, 0.2000446, 0.20005645]\n",
      "[0.60156643, 0.2, 0.20003498, 0.20003533]\n",
      "[0.60152495, 0.2, 0.20003755, 0.19999333]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5670 iterations: 1.6408851822217305 mins\n",
      "Train Loss: [0.60152495, 0.2, 0.20003755, 0.19999333]\n",
      "[0.6016176, 0.2, 0.20009764, 0.20002805]\n",
      "[0.6015927, 0.2, 0.20003052, 0.20007244]\n",
      "[0.60156137, 0.2, 0.20005734, 0.20001645]\n",
      "[0.601768, 0.2, 0.20022595, 0.20005673]\n",
      "[0.6015494, 0.2, 0.2000484, 0.20001772]\n",
      "[0.60153323, 0.2, 0.20007108, 0.19998108]\n",
      "[0.6017062, 0.2, 0.20021434, 0.20001297]\n",
      "[0.6015162, 0.2, 0.2000536, 0.1999858]\n",
      "[0.6014682, 0.2, 0.20001465, 0.19997892]\n",
      "[0.601563, 0.2, 0.20007585, 0.20001452]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5680 iterations: 1.642735203107198 mins\n",
      "Train Loss: [0.601563, 0.2, 0.20007585, 0.20001452]\n",
      "[0.6016047, 0.2, 0.20002964, 0.20010448]\n",
      "[0.60164285, 0.2, 0.20013486, 0.20003939]\n",
      "[0.6016157, 0.2, 0.20005684, 0.2000922]\n",
      "[0.60164624, 0.2, 0.20003736, 0.20014408]\n",
      "[0.60152584, 0.2, 0.20004581, 0.2000171]\n",
      "[0.60164714, 0.2, 0.20005594, 0.20013015]\n",
      "[0.6015745, 0.2, 0.20003788, 0.20007743]\n",
      "[0.60163355, 0.2, 0.20004864, 0.2001276]\n",
      "[0.60165787, 0.2, 0.20002815, 0.20017421]\n",
      "[0.6015562, 0.2, 0.20003548, 0.20006701]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5690 iterations: 1.6447423497835796 mins\n",
      "Train Loss: [0.6015562, 0.2, 0.20003548, 0.20006701]\n",
      "[0.60163295, 0.2, 0.2000734, 0.20010781]\n",
      "[0.6016458, 0.2, 0.20009223, 0.20010383]\n",
      "[0.6016015, 0.2, 0.20007193, 0.20008177]\n",
      "[0.60168, 0.2, 0.20019844, 0.20003568]\n",
      "[0.6015377, 0.2, 0.200023, 0.20007087]\n",
      "[0.60170287, 0.2, 0.20014212, 0.20011884]\n",
      "[0.60161763, 0.2, 0.20018369, 0.19999403]\n",
      "[0.6015324, 0.2, 0.20003015, 0.20006429]\n",
      "[0.60157907, 0.2, 0.20011202, 0.20003104]\n",
      "[0.6015874, 0.2, 0.20003447, 0.20011896]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5700 iterations: 1.6467182517051697 mins\n",
      "Train Loss: [0.6015874, 0.2, 0.20003447, 0.20011896]\n",
      "[0.6016513, 0.2, 0.2001223, 0.20009708]\n",
      "[0.6018613, 0.2, 0.20025434, 0.20017703]\n",
      "[0.6015909, 0.2, 0.20005424, 0.20010874]\n",
      "[0.601481, 0.2, 0.20002843, 0.20002677]\n",
      "[0.6015255, 0.2, 0.20005186, 0.20004998]\n",
      "[0.6015306, 0.2, 0.20004456, 0.2000645]\n",
      "[0.601622, 0.2, 0.20002694, 0.20017558]\n",
      "[0.60155135, 0.2, 0.20007078, 0.20006327]\n",
      "[0.6015816, 0.2, 0.20013386, 0.20003258]\n",
      "[0.6015522, 0.2, 0.20012276, 0.20001635]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5710 iterations: 1.6490697344144185 mins\n",
      "Train Loss: [0.6015522, 0.2, 0.20012276, 0.20001635]\n",
      "[0.60153764, 0.2, 0.20001724, 0.2001095]\n",
      "[0.60158944, 0.2, 0.2000544, 0.20012622]\n",
      "[0.6015124, 0.2, 0.20001131, 0.20009434]\n",
      "[0.6014691, 0.2, 0.2000135, 0.20005094]\n",
      "[0.60151476, 0.2, 0.2000171, 0.20009504]\n",
      "[0.60148937, 0.2, 0.20001675, 0.20007211]\n",
      "[0.60147953, 0.2, 0.20004828, 0.2000328]\n",
      "[0.6014667, 0.2, 0.20003735, 0.20003308]\n",
      "[0.6014484, 0.2, 0.20002085, 0.20003335]\n",
      "[0.6015589, 0.2, 0.20004061, 0.2001262]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5720 iterations: 1.652002763748169 mins\n",
      "Train Loss: [0.6015589, 0.2, 0.20004061, 0.2001262]\n",
      "[0.6015428, 0.2, 0.20004776, 0.20010497]\n",
      "[0.60160875, 0.2, 0.20006678, 0.20015396]\n",
      "[0.6015192, 0.2, 0.20010382, 0.20002943]\n",
      "[0.60153437, 0.2, 0.2000525, 0.20009787]\n",
      "[0.60154057, 0.2, 0.20005083, 0.20010768]\n",
      "[0.60144454, 0.2, 0.20000005, 0.2000644]\n",
      "[0.60147756, 0.2, 0.20004228, 0.20005716]\n",
      "[0.6016296, 0.2, 0.20022286, 0.2000305]\n",
      "[0.60142875, 0.2, 0.20002173, 0.20003268]\n",
      "[0.60156614, 0.2, 0.20015948, 0.20003422]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5730 iterations: 1.653725016117096 mins\n",
      "Train Loss: [0.60156614, 0.2, 0.20015948, 0.20003422]\n",
      "[0.60166776, 0.2, 0.2001586, 0.20013854]\n",
      "[0.6014481, 0.2, 0.20004767, 0.20003162]\n",
      "[0.60182047, 0.2, 0.20032871, 0.20012467]\n",
      "[0.6014201, 0.2, 0.20001146, 0.20004341]\n",
      "[0.601651, 0.2, 0.20008586, 0.2002017]\n",
      "[0.6015407, 0.2, 0.20000903, 0.20016994]\n",
      "[0.601658, 0.2, 0.2002512, 0.20004685]\n",
      "[0.6014066, 0.2, 0.20002678, 0.20002161]\n",
      "[0.60144216, 0.2, 0.20002082, 0.20006508]\n",
      "[0.60158104, 0.2, 0.20005319, 0.20017351]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5740 iterations: 1.6557220180829366 mins\n",
      "Train Loss: [0.60158104, 0.2, 0.20005319, 0.20017351]\n",
      "[0.6014528, 0.2, 0.2000572, 0.20004325]\n",
      "[0.6017092, 0.2, 0.20024976, 0.20010902]\n",
      "[0.6014049, 0.2, 0.2, 0.20005645]\n",
      "[0.60178125, 0.2, 0.20010707, 0.20032759]\n",
      "[0.6014332, 0.2, 0.20003852, 0.20004998]\n",
      "[0.60151047, 0.2, 0.20011732, 0.20005026]\n",
      "[0.6015706, 0.2, 0.20017013, 0.20005941]\n",
      "[0.601492, 0.2, 0.20008057, 0.2000721]\n",
      "[0.601519, 0.2, 0.20010021, 0.2000812]\n",
      "[0.60141516, 0.2, 0.20004447, 0.20003492]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5750 iterations: 1.657680130004883 mins\n",
      "Train Loss: [0.60141516, 0.2, 0.20004447, 0.20003492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60154974, 0.2, 0.20015177, 0.20006394]\n",
      "[0.6014864, 0.2, 0.20003378, 0.20012033]\n",
      "[0.6015021, 0.2, 0.20003484, 0.20013674]\n",
      "[0.60140103, 0.2, 0.20001924, 0.20005292]\n",
      "[0.6014629, 0.2, 0.20002939, 0.20010631]\n",
      "[0.6014368, 0.2, 0.20006394, 0.20004728]\n",
      "[0.6015345, 0.2, 0.20015652, 0.20005414]\n",
      "[0.601476, 0.2, 0.20004377, 0.20011005]\n",
      "[0.60141486, 0.2, 0.20002559, 0.20006874]\n",
      "[0.6014695, 0.2, 0.2000579, 0.20009273]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5760 iterations: 1.6597460508346558 mins\n",
      "Train Loss: [0.6014695, 0.2, 0.2000579, 0.20009273]\n",
      "[0.6014916, 0.2, 0.20010881, 0.2000655]\n",
      "[0.6014125, 0.2, 0.20005058, 0.20004629]\n",
      "[0.6013818, 0.2, 0.20003897, 0.20002887]\n",
      "[0.60157657, 0.2, 0.2000211, 0.20024328]\n",
      "[0.6013686, 0.2, 0.20001839, 0.20003961]\n",
      "[0.6013732, 0.2, 0.20003165, 0.20003262]\n",
      "[0.6017506, 0.2, 0.20011787, 0.20032546]\n",
      "[0.60145456, 0.2, 0.2001397, 0.20000921]\n",
      "[0.60152346, 0.2, 0.20009436, 0.20012498]\n",
      "[0.6015208, 0.2, 0.20010485, 0.20011348]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5770 iterations: 1.6616289496421814 mins\n",
      "Train Loss: [0.6015208, 0.2, 0.20010485, 0.20011348]\n",
      "[0.60149175, 0.2, 0.20012909, 0.20006183]\n",
      "[0.6015187, 0.2, 0.20012727, 0.20009214]\n",
      "[0.60145044, 0.2, 0.20007782, 0.20007493]\n",
      "[0.6014553, 0.2, 0.20008397, 0.20007522]\n",
      "[0.6014088, 0.2, 0.20005855, 0.20005566]\n",
      "[0.6015526, 0.2, 0.2001563, 0.20010331]\n",
      "[0.60152704, 0.2, 0.20010512, 0.20013055]\n",
      "[0.60136735, 0.2, 0.20002659, 0.20005104]\n",
      "[0.6015517, 0.2, 0.20006852, 0.20019507]\n",
      "[0.6013734, 0.2, 0.20010206, 0.19998482]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5780 iterations: 1.6638463656107585 mins\n",
      "Train Loss: [0.6013734, 0.2, 0.20010206, 0.19998482]\n",
      "[0.6013493, 0.2, 0.20000002, 0.20006461]\n",
      "[0.60136455, 0.2, 0.20006189, 0.20001964]\n",
      "[0.60144114, 0.2, 0.20004861, 0.20011123]\n",
      "[0.6013099, 0.2, 0.2000644, 0.1999659]\n",
      "[0.6014394, 0.2, 0.20004475, 0.20011671]\n",
      "[0.60150623, 0.2, 0.20008993, 0.20013998]\n",
      "[0.6018976, 0.2, 0.20051351, 0.20010933]\n",
      "[0.6015111, 0.2, 0.2000905, 0.20014748]\n",
      "[0.6014034, 0.2, 0.20000757, 0.2001243]\n",
      "[0.6014789, 0.2, 0.20007524, 0.20013367]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5790 iterations: 1.6658020178476969 mins\n",
      "Train Loss: [0.6014789, 0.2, 0.20007524, 0.20013367]\n",
      "[0.60167176, 0.2, 0.20018752, 0.20021595]\n",
      "[0.60143024, 0.2, 0.20007244, 0.20009114]\n",
      "[0.60151255, 0.2, 0.20005514, 0.20019256]\n",
      "[0.60133, 0.2, 0.20004942, 0.20001747]\n",
      "[0.60147977, 0.2, 0.20008495, 0.20013349]\n",
      "[0.6014089, 0.2, 0.20008342, 0.20006602]\n",
      "[0.6018152, 0.2, 0.20016657, 0.20039101]\n",
      "[0.6013631, 0.2, 0.2000696, 0.20003778]\n",
      "[0.601363, 0.2, 0.20001394, 0.20009519]\n",
      "[0.6014062, 0.2, 0.20009059, 0.20006359]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5800 iterations: 1.6676443179448446 mins\n",
      "Train Loss: [0.6014062, 0.2, 0.20009059, 0.20006359]\n",
      "[0.60130394, 0.2, 0.20001227, 0.20004144]\n",
      "[0.60134816, 0.2, 0.2000486, 0.20005108]\n",
      "[0.60153353, 0.2, 0.20005488, 0.20023194]\n",
      "[0.6014068, 0.2, 0.2000355, 0.20012641]\n",
      "[0.6013502, 0.2, 0.20003565, 0.20007136]\n",
      "[0.6014637, 0.2, 0.2001293, 0.20009294]\n",
      "[0.6013967, 0.2, 0.20007554, 0.2000815]\n",
      "[0.60138154, 0.2, 0.20005524, 0.20008852]\n",
      "[0.6014883, 0.2, 0.20010236, 0.20014983]\n",
      "[0.60130966, 0.2, 0.20002988, 0.20004554]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5810 iterations: 1.6695534825325011 mins\n",
      "Train Loss: [0.60130966, 0.2, 0.20002988, 0.20004554]\n",
      "[0.60137016, 0.2, 0.20007817, 0.20005946]\n",
      "[0.6013425, 0.2, 0.20002915, 0.20008245]\n",
      "[0.6013259, 0.2, 0.20004478, 0.20005171]\n",
      "[0.6013149, 0.2, 0.20005219, 0.20003489]\n",
      "[0.60133415, 0.2, 0.20005368, 0.20005406]\n",
      "[0.6013069, 0.2, 0.20005281, 0.20002916]\n",
      "[0.60127085, 0.2, 0.20002998, 0.2000174]\n",
      "[0.60136247, 0.2, 0.20002246, 0.20011793]\n",
      "[0.6013167, 0.2, 0.20003867, 0.20005742]\n",
      "[0.60137606, 0.2, 0.20005919, 0.20009793]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5820 iterations: 1.671317998568217 mins\n",
      "Train Loss: [0.60137606, 0.2, 0.20005919, 0.20009793]\n",
      "[0.601356, 0.2, 0.20003718, 0.20010161]\n",
      "[0.6013531, 0.2, 0.20004493, 0.2000926]\n",
      "[0.6012558, 0.2, 0.20001805, 0.20002389]\n",
      "[0.60137737, 0.2, 0.20004946, 0.20011586]\n",
      "[0.6013215, 0.2, 0.20002407, 0.20008737]\n",
      "[0.60129786, 0.2, 0.20005138, 0.20003834]\n",
      "[0.60145146, 0.2, 0.20015657, 0.20008875]\n",
      "[0.6014588, 0.2, 0.20019495, 0.20005968]\n",
      "[0.60144055, 0.2, 0.20002614, 0.2002123]\n",
      "[0.60133857, 0.2, 0.20008007, 0.20005843]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5830 iterations: 1.6731703519821166 mins\n",
      "Train Loss: [0.60133857, 0.2, 0.20008007, 0.20005843]\n",
      "[0.601296, 0.2, 0.20005824, 0.20003977]\n",
      "[0.6013021, 0.2, 0.20005728, 0.20004888]\n",
      "[0.6013555, 0.2, 0.20006628, 0.2000954]\n",
      "[0.60125184, 0.2, 0.20003189, 0.2000282]\n",
      "[0.60130066, 0.2, 0.20008712, 0.20002382]\n",
      "[0.6013831, 0.2, 0.20011334, 0.20008191]\n",
      "[0.6013978, 0.2, 0.20009743, 0.20011443]\n",
      "[0.6013214, 0.2, 0.20004772, 0.20008968]\n",
      "[0.60129005, 0.2, 0.20005046, 0.20005758]\n",
      "[0.60132223, 0.2, 0.20002744, 0.2001148]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5840 iterations: 1.6749231179555257 mins\n",
      "Train Loss: [0.60132223, 0.2, 0.20002744, 0.2001148]\n",
      "[0.60163754, 0.2, 0.20003748, 0.20042202]\n",
      "[0.6014004, 0.2, 0.2001555, 0.2000685]\n",
      "[0.60134596, 0.2, 0.20006862, 0.20010264]\n",
      "[0.6013679, 0.2, 0.20002945, 0.20016555]\n",
      "[0.6020281, 0.2, 0.20077856, 0.20007822]\n",
      "[0.6014061, 0.2, 0.20003842, 0.20019768]\n",
      "[0.6014893, 0.2, 0.20019946, 0.20012094]\n",
      "[0.60226256, 0.2, 0.20084004, 0.20025443]\n",
      "[0.60197777, 0.2, 0.20054254, 0.20026754]\n",
      "[0.6019415, 0.2, 0.200344, 0.20043011]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5850 iterations: 1.676977781454722 mins\n",
      "Train Loss: [0.6019415, 0.2, 0.200344, 0.20043011]\n",
      "[0.60211194, 0.2, 0.20069897, 0.20024568]\n",
      "[0.6017191, 0.2, 0.20041169, 0.2001394]\n",
      "[0.602123, 0.2, 0.20051412, 0.20043899]\n",
      "[0.6041826, 0.2, 0.20119807, 0.20181033]\n",
      "[0.6039655, 0.2, 0.20192637, 0.20085663]\n",
      "[0.6077606, 0.2, 0.20208871, 0.20447198]\n",
      "[0.61139107, 0.2, 0.2060637, 0.2040953]\n",
      "[0.6089233, 0.2, 0.20166402, 0.2059528]\n",
      "[0.6080081, 0.2, 0.20009683, 0.2065254]\n",
      "[0.62540644, 0.2, 0.21390176, 0.21002026]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5860 iterations: 1.6787901798884073 mins\n",
      "Train Loss: [0.62540644, 0.2, 0.21390176, 0.21002026]\n",
      "[0.61938804, 0.2, 0.20981544, 0.20804486]\n",
      "[0.6149731, 0.2, 0.20872788, 0.20466648]\n",
      "[0.6296927, 0.2, 0.20968914, 0.21833426]\n",
      "[0.61267936, 0.2, 0.20005426, 0.21082926]\n",
      "[0.6252694, 0.2, 0.20847322, 0.21484585]\n",
      "[0.6271717, 0.2, 0.20964128, 0.21543139]\n",
      "[0.64624786, 0.2, 0.23786032, 0.20611094]\n",
      "[0.6322444, 0.2, 0.2192414, 0.21062392]\n",
      "[0.62346643, 0.2, 0.20864733, 0.21239366]\n",
      "[0.6144404, 0.2, 0.20109949, 0.21089529]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5870 iterations: 1.6812870303789775 mins\n",
      "Train Loss: [0.6144404, 0.2, 0.20109949, 0.21089529]\n",
      "[0.60752106, 0.2, 0.20265393, 0.20239817]\n",
      "[0.6076757, 0.2, 0.20159252, 0.20357935]\n",
      "[0.6075161, 0.2, 0.20339166, 0.20157911]\n",
      "[0.6089872, 0.2, 0.20276374, 0.20363396]\n",
      "[0.60480547, 0.2, 0.20116228, 0.20101014]\n",
      "[0.6056513, 0.2, 0.20130564, 0.2016715]\n",
      "[0.6064019, 0.2, 0.20153554, 0.20215534]\n",
      "[0.60368407, 0.2, 0.20000459, 0.2009357]\n",
      "[0.6055194, 0.2, 0.2019539, 0.20079301]\n",
      "[0.605059, 0.2, 0.20087469, 0.2013872]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5880 iterations: 1.6831659515698751 mins\n",
      "Train Loss: [0.605059, 0.2, 0.20087469, 0.2013872]\n",
      "[0.6040234, 0.2, 0.20029423, 0.20091271]\n",
      "[0.6084916, 0.2, 0.20301624, 0.2026444]\n",
      "[0.60599923, 0.2, 0.20173809, 0.20142071]\n",
      "[0.60693717, 0.2, 0.20168138, 0.20240885]\n",
      "[0.6062735, 0.2, 0.20175688, 0.20166531]\n",
      "[0.6064842, 0.2, 0.20089698, 0.20273423]\n",
      "[0.6061945, 0.2, 0.20123552, 0.20210668]\n",
      "[0.6067838, 0.2, 0.20192857, 0.20200591]\n",
      "[0.6085356, 0.2, 0.20170245, 0.20398813]\n",
      "[0.60484785, 0.2, 0.20070483, 0.2013037]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5890 iterations: 1.685157330830892 mins\n",
      "Train Loss: [0.60484785, 0.2, 0.20070483, 0.2013037]\n",
      "[0.6068398, 0.2, 0.20218533, 0.20182121]\n",
      "[0.6045564, 0.2, 0.20083624, 0.20089403]\n",
      "[0.6065298, 0.2, 0.20266926, 0.20104226]\n",
      "[0.60619295, 0.2, 0.20204481, 0.20133783]\n",
      "[0.60667783, 0.2, 0.20217979, 0.20169649]\n",
      "[0.60370475, 0.2, 0.20085147, 0.20006111]\n",
      "[0.6063379, 0.2, 0.2014813, 0.20207442]\n",
      "[0.60695696, 0.2, 0.20151481, 0.20267028]\n",
      "[0.6039712, 0.2, 0.20053117, 0.20067917]\n",
      "[0.6064872, 0.2, 0.201806, 0.2019315]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5900 iterations: 1.6870620489120483 mins\n",
      "Train Loss: [0.6064872, 0.2, 0.201806, 0.2019315]\n",
      "[0.6046853, 0.2, 0.20055905, 0.20138834]\n",
      "[0.604134, 0.2, 0.20108828, 0.2003195]\n",
      "[0.60473645, 0.2, 0.20125207, 0.20076986]\n",
      "[0.60397846, 0.2, 0.20083432, 0.20044152]\n",
      "[0.60378313, 0.2, 0.20081592, 0.20027654]\n",
      "[0.60326684, 0.2, 0.20020908, 0.20037971]\n",
      "[0.6030268, 0.2, 0.20000176, 0.20036009]\n",
      "[0.6046717, 0.2, 0.20146888, 0.20055088]\n",
      "[0.6043304, 0.2, 0.20074591, 0.20094627]\n",
      "[0.6044015, 0.2, 0.20046958, 0.20130783]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5910 iterations: 1.6888962825139364 mins\n",
      "Train Loss: [0.6044015, 0.2, 0.20046958, 0.20130783]\n",
      "[0.60391647, 0.2, 0.2004557, 0.20085143]\n",
      "[0.6034741, 0.2, 0.20022224, 0.20065734]\n",
      "[0.6037501, 0.2, 0.20021728, 0.20095313]\n",
      "[0.60375524, 0.2, 0.20050254, 0.2006881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6029408, 0.2, 0.2, 0.20039114]\n",
      "[0.6039359, 0.2, 0.20089711, 0.20050384]\n",
      "[0.60338014, 0.2, 0.20047516, 0.20038493]\n",
      "[0.6030969, 0.2, 0.20015104, 0.2004406]\n",
      "[0.6040457, 0.2, 0.20070322, 0.20085162]\n",
      "[0.60318327, 0.2, 0.20052034, 0.20018694]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5920 iterations: 1.690856365362803 mins\n",
      "Train Loss: [0.60318327, 0.2, 0.20052034, 0.20018694]\n",
      "[0.60312366, 0.2, 0.20017202, 0.20049013]\n",
      "[0.60307586, 0.2, 0.20034575, 0.2002828]\n",
      "[0.6025946, 0.2, 0.200226, 0.199935]\n",
      "[0.60376656, 0.2, 0.20086622, 0.20048028]\n",
      "[0.6030568, 0.2, 0.20038815, 0.20026222]\n",
      "[0.603455, 0.2, 0.20000088, 0.20106137]\n",
      "[0.6031376, 0.2, 0.2002923, 0.2004659]\n",
      "[0.6033528, 0.2, 0.20028348, 0.20070313]\n",
      "[0.6034077, 0.2, 0.2003483, 0.20070611]\n",
      "[0.60299635, 0.2, 0.20023365, 0.20042259]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5930 iterations: 1.6927843332290649 mins\n",
      "Train Loss: [0.60299635, 0.2, 0.20023365, 0.20042259]\n",
      "[0.60332996, 0.2, 0.20016311, 0.20083973]\n",
      "[0.602946, 0.2, 0.20034352, 0.20028791]\n",
      "[0.60297364, 0.2, 0.20048107, 0.20019059]\n",
      "[0.6028138, 0.2, 0.20013455, 0.20038964]\n",
      "[0.602868, 0.2, 0.2003837, 0.20020692]\n",
      "[0.6032778, 0.2, 0.20066041, 0.20035209]\n",
      "[0.6037658, 0.2, 0.20039423, 0.20111834]\n",
      "[0.6029055, 0.2, 0.20045654, 0.20020758]\n",
      "[0.6024845, 0.2, 0.20011851, 0.20013642]\n",
      "[0.60369587, 0.2, 0.20052487, 0.200953]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5940 iterations: 1.6946933309237162 mins\n",
      "Train Loss: [0.60369587, 0.2, 0.20052487, 0.200953]\n",
      "[0.6031122, 0.2, 0.20046008, 0.20044531]\n",
      "[0.6034514, 0.2, 0.20060827, 0.20064726]\n",
      "[0.6032352, 0.2, 0.20053563, 0.20051473]\n",
      "[0.60347706, 0.2, 0.20040205, 0.20090109]\n",
      "[0.60429925, 0.2, 0.20141801, 0.200718]\n",
      "[0.6030023, 0.2, 0.2003582, 0.2004917]\n",
      "[0.60294193, 0.2, 0.20049962, 0.20030029]\n",
      "[0.60256046, 0.2, 0.2000304, 0.20039842]\n",
      "[0.60293365, 0.2, 0.20009854, 0.20071349]\n",
      "[0.60273415, 0.2, 0.20044498, 0.20017764]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5950 iterations: 1.6965006669362386 mins\n",
      "Train Loss: [0.60273415, 0.2, 0.20044498, 0.20017764]\n",
      "[0.6026537, 0.2, 0.20039771, 0.20015405]\n",
      "[0.6033848, 0.2, 0.20076835, 0.20052391]\n",
      "[0.6026121, 0.2, 0.20025367, 0.20027503]\n",
      "[0.60323465, 0.2, 0.20045249, 0.20070782]\n",
      "[0.60266274, 0.2, 0.20060827, 0.19998893]\n",
      "[0.60288495, 0.2, 0.20040013, 0.20042816]\n",
      "[0.6032454, 0.2, 0.20042357, 0.20077373]\n",
      "[0.60254204, 0.2, 0.20013134, 0.20037125]\n",
      "[0.6027812, 0.2, 0.20046669, 0.20028389]\n",
      "[0.6026997, 0.2, 0.20052855, 0.2001492]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5960 iterations: 1.6988553325335185 mins\n",
      "Train Loss: [0.6026997, 0.2, 0.20052855, 0.2001492]\n",
      "[0.6030361, 0.2, 0.20048189, 0.20054099]\n",
      "[0.6033401, 0.2, 0.20115466, 0.20018075]\n",
      "[0.6029776, 0.2, 0.2002624, 0.20071918]\n",
      "[0.6032749, 0.2, 0.20046985, 0.2008178]\n",
      "[0.60268354, 0.2, 0.20020252, 0.20050238]\n",
      "[0.6024265, 0.2, 0.20022587, 0.20023084]\n",
      "[0.6021674, 0.2, 0.20024838, 0.19995807]\n",
      "[0.602789, 0.2, 0.2003753, 0.20046137]\n",
      "[0.6026914, 0.2, 0.2005257, 0.20022191]\n",
      "[0.6022691, 0.2, 0.20033023, 0.20000318]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5970 iterations: 1.70066796541214 mins\n",
      "Train Loss: [0.6022691, 0.2, 0.20033023, 0.20000318]\n",
      "[0.60333294, 0.2, 0.20068848, 0.20071663]\n",
      "[0.6023825, 0.2, 0.20040214, 0.20006016]\n",
      "[0.60226446, 0.2, 0.20014846, 0.20020336]\n",
      "[0.6029559, 0.2, 0.20059638, 0.20045418]\n",
      "[0.6023717, 0.2, 0.20019919, 0.20027445]\n",
      "[0.6029061, 0.2, 0.20013265, 0.20088263]\n",
      "[0.6024569, 0.2, 0.20049083, 0.20008251]\n",
      "[0.60227627, 0.2, 0.20013493, 0.20026499]\n",
      "[0.6023766, 0.2, 0.20034246, 0.20016502]\n",
      "[0.6024836, 0.2, 0.20036885, 0.2002527]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5980 iterations: 1.7026210347811381 mins\n",
      "Train Loss: [0.6024836, 0.2, 0.20036885, 0.2002527]\n",
      "[0.6022658, 0.2, 0.20003371, 0.20037735]\n",
      "[0.60265285, 0.2, 0.20011552, 0.20068972]\n",
      "[0.6020402, 0.2, 0.20021035, 0.19998933]\n",
      "[0.60264534, 0.2, 0.20042327, 0.20038882]\n",
      "[0.60220337, 0.2, 0.20018515, 0.20019226]\n",
      "[0.6022739, 0.2, 0.20019989, 0.20025538]\n",
      "[0.6020798, 0.2, 0.20017311, 0.20009534]\n",
      "[0.6020693, 0.2, 0.200162, 0.20010301]\n",
      "[0.60213774, 0.2, 0.20023425, 0.20010598]\n",
      "[0.6027603, 0.2, 0.20022537, 0.200744]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5990 iterations: 1.7044469316800435 mins\n",
      "Train Loss: [0.6027603, 0.2, 0.20022537, 0.200744]\n",
      "[0.6036206, 0.2, 0.20098667, 0.20084958]\n",
      "[0.6024025, 0.2, 0.20021865, 0.20040597]\n",
      "[0.6020805, 0.2, 0.20006113, 0.200248]\n",
      "[0.6024033, 0.2, 0.20028111, 0.20035715]\n",
      "[0.60226077, 0.2, 0.20016654, 0.20033562]\n",
      "[0.6022254, 0.2, 0.20010017, 0.20037295]\n",
      "[0.6025157, 0.2, 0.2002019, 0.2005679]\n",
      "[0.6020886, 0.2, 0.200174, 0.20017512]\n",
      "[0.6017806, 0.2, 0.2000841, 0.19996355]\n",
      "[0.6019991, 0.2, 0.20014356, 0.20012903]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6000 iterations: 1.7064213156700134 mins\n",
      "Train Loss: [0.6019991, 0.2, 0.20014356, 0.20012903]\n",
      "[0.60251486, 0.2, 0.20019528, 0.20059952]\n",
      "[0.60219854, 0.2, 0.20017491, 0.20030999]\n",
      "[0.6022239, 0.2, 0.20038302, 0.20013356]\n",
      "[0.6024649, 0.2, 0.20021544, 0.20054822]\n",
      "[0.6018344, 0.2, 0.20018338, 0.19995603]\n",
      "[0.60207534, 0.2, 0.20031244, 0.20007399]\n",
      "[0.60205907, 0.2, 0.20020653, 0.20016941]\n",
      "[0.6027285, 0.2, 0.20014209, 0.20090902]\n",
      "[0.6027851, 0.2, 0.20043272, 0.20068055]\n",
      "[0.6020454, 0.2, 0.20017299, 0.20020632]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6010 iterations: 1.7084611813227335 mins\n",
      "Train Loss: [0.6020454, 0.2, 0.20017299, 0.20020632]\n",
      "[0.60249776, 0.2, 0.20014344, 0.20069404]\n",
      "[0.60254645, 0.2, 0.20029792, 0.20059389]\n",
      "[0.60266197, 0.2, 0.20085621, 0.20015684]\n",
      "[0.60263664, 0.2, 0.20066509, 0.20032862]\n",
      "[0.60311115, 0.2, 0.20081292, 0.20066136]\n",
      "[0.6025435, 0.2, 0.20059237, 0.20031998]\n",
      "[0.601936, 0.2, 0.20013402, 0.2001765]\n",
      "[0.6020587, 0.2, 0.20003544, 0.20040369]\n",
      "[0.602111, 0.2, 0.20020048, 0.20029631]\n",
      "[0.60207045, 0.2, 0.20005712, 0.20040433]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6020 iterations: 1.71107519865036 mins\n",
      "Train Loss: [0.60207045, 0.2, 0.20005712, 0.20040433]\n",
      "[0.6018433, 0.2, 0.200186, 0.20005336]\n",
      "[0.6018567, 0.2, 0.20013618, 0.20012172]\n",
      "[0.6018709, 0.2, 0.20011042, 0.20016669]\n",
      "[0.60204875, 0.2, 0.20037474, 0.20008512]\n",
      "[0.6020238, 0.2, 0.20033379, 0.20010602]\n",
      "[0.6022048, 0.2, 0.20008735, 0.20053832]\n",
      "[0.6022611, 0.2, 0.20006979, 0.20061676]\n",
      "[0.60222924, 0.2, 0.20026368, 0.20039555]\n",
      "[0.6018893, 0.2, 0.2002963, 0.20002736]\n",
      "[0.60207415, 0.2, 0.2002026, 0.20031029]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6030 iterations: 1.715205446879069 mins\n",
      "Train Loss: [0.60207415, 0.2, 0.2002026, 0.20031029]\n",
      "[0.6021103, 0.2, 0.20042038, 0.20013289]\n",
      "[0.60192794, 0.2, 0.20021856, 0.20015669]\n",
      "[0.60184467, 0.2, 0.20013143, 0.2001647]\n",
      "[0.6018982, 0.2, 0.2001741, 0.20017974]\n",
      "[0.6019306, 0.2, 0.2001913, 0.20019898]\n",
      "[0.60196096, 0.2, 0.20020223, 0.2002225]\n",
      "[0.6021041, 0.2, 0.20013407, 0.20043802]\n",
      "[0.6018015, 0.2, 0.2001435, 0.20013012]\n",
      "[0.6018562, 0.2, 0.20015042, 0.20018204]\n",
      "[0.6019429, 0.2, 0.20016778, 0.20025551]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6040 iterations: 1.7180281321207682 mins\n",
      "Train Loss: [0.6019429, 0.2, 0.20016778, 0.20025551]\n",
      "[0.6017936, 0.2, 0.20019634, 0.20008184]\n",
      "[0.60219663, 0.2, 0.20044518, 0.20024043]\n",
      "[0.6018543, 0.2, 0.20006083, 0.20028718]\n",
      "[0.6018451, 0.2, 0.20008181, 0.20026155]\n",
      "[0.6018282, 0.2, 0.2001244, 0.20020668]\n",
      "[0.6019516, 0.2, 0.20009929, 0.20035964]\n",
      "[0.6019385, 0.2, 0.20020323, 0.20024706]\n",
      "[0.60175794, 0.2, 0.20006251, 0.2002117]\n",
      "[0.6018497, 0.2, 0.20023043, 0.2001399]\n",
      "[0.60175174, 0.2, 0.20007879, 0.2001982]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6050 iterations: 1.7204405824343363 mins\n",
      "Train Loss: [0.60175174, 0.2, 0.20007879, 0.2001982]\n",
      "[0.60194665, 0.2, 0.20016073, 0.20031577]\n",
      "[0.6017535, 0.2, 0.200114, 0.2001738]\n",
      "[0.6017473, 0.2, 0.20014368, 0.20014243]\n",
      "[0.60183954, 0.2, 0.20017257, 0.20021035]\n",
      "[0.60173845, 0.2, 0.20019288, 0.20009342]\n",
      "[0.60172486, 0.2, 0.20017241, 0.20010492]\n",
      "[0.6015367, 0.2, 0.20006296, 0.20003055]\n",
      "[0.60174996, 0.2, 0.20019637, 0.20011477]\n",
      "[0.60180724, 0.2, 0.20014799, 0.20022473]\n",
      "[0.6018757, 0.2, 0.20029102, 0.20015424]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6060 iterations: 1.722206981976827 mins\n",
      "Train Loss: [0.6018757, 0.2, 0.20029102, 0.20015424]\n",
      "[0.6016273, 0.2, 0.20018396, 0.20001699]\n",
      "[0.60155773, 0.2, 0.20007966, 0.2000557]\n",
      "[0.60148954, 0.2, 0.2000602, 0.200011]\n",
      "[0.60159504, 0.2, 0.20011124, 0.20006938]\n",
      "[0.6017546, 0.2, 0.20017233, 0.20017175]\n",
      "[0.6015976, 0.2, 0.20023355, 0.19995749]\n",
      "[0.60176337, 0.2, 0.20027506, 0.20008564]\n",
      "[0.60173804, 0.2, 0.20010474, 0.20023444]\n",
      "[0.6015493, 0.2, 0.20006768, 0.20008655]\n",
      "[0.6017251, 0.2, 0.2001343, 0.20019941]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6070 iterations: 1.7241844495137533 mins\n",
      "Train Loss: [0.6017251, 0.2, 0.2001343, 0.20019941]\n",
      "[0.60152334, 0.2, 0.20009823, 0.20003751]\n",
      "[0.6017391, 0.2, 0.20013992, 0.20021531]\n",
      "[0.6015612, 0.2, 0.2001059, 0.20007546]\n",
      "[0.6019137, 0.2, 0.20034216, 0.20019554]\n",
      "[0.6017275, 0.2, 0.2002709, 0.2000843]\n",
      "[0.6016593, 0.2, 0.20020883, 0.2000818]\n",
      "[0.6017036, 0.2, 0.20028469, 0.20005381]\n",
      "[0.6015891, 0.2, 0.2001678, 0.20005976]\n",
      "[0.6017593, 0.2, 0.20014697, 0.20025449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6015159, 0.2, 0.20015179, 0.20000981]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6080 iterations: 1.7261265993118287 mins\n",
      "Train Loss: [0.6015159, 0.2, 0.20015179, 0.20000981]\n",
      "[0.6016032, 0.2, 0.20019452, 0.20005788]\n",
      "[0.60152423, 0.2, 0.2002368, 0.19994012]\n",
      "[0.6019261, 0.2, 0.20022064, 0.20036156]\n",
      "[0.6015625, 0.2, 0.20006655, 0.20015535]\n",
      "[0.60176826, 0.2, 0.20034091, 0.20008992]\n",
      "[0.60149086, 0.2, 0.20006262, 0.20009409]\n",
      "[0.6017468, 0.2, 0.20019309, 0.20022282]\n",
      "[0.60187465, 0.2, 0.20026232, 0.20028462]\n",
      "[0.6019086, 0.2, 0.20006227, 0.20052171]\n",
      "[0.6016682, 0.2, 0.20019104, 0.20015544]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6090 iterations: 1.728061314423879 mins\n",
      "Train Loss: [0.6016682, 0.2, 0.20019104, 0.20015544]\n",
      "[0.6017138, 0.2, 0.20005135, 0.20034364]\n",
      "[0.60175264, 0.2, 0.20014672, 0.20029001]\n",
      "[0.601632, 0.2, 0.20021607, 0.20010322]\n",
      "[0.6018672, 0.2, 0.20008574, 0.20047188]\n",
      "[0.60200506, 0.2, 0.20022959, 0.20046888]\n",
      "[0.60151595, 0.2, 0.2001791, 0.20003295]\n",
      "[0.6014689, 0.2, 0.20012204, 0.20004566]\n",
      "[0.6017102, 0.2, 0.20013778, 0.2002739]\n",
      "[0.60167676, 0.2, 0.20008625, 0.20029454]\n",
      "[0.60166377, 0.2, 0.20012908, 0.20024109]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6100 iterations: 1.7305222312609354 mins\n",
      "Train Loss: [0.60166377, 0.2, 0.20012908, 0.20024109]\n",
      "[0.60160923, 0.2, 0.20006667, 0.20025125]\n",
      "[0.6015923, 0.2, 0.2001823, 0.20012096]\n",
      "[0.60141695, 0.2, 0.20011504, 0.20001522]\n",
      "[0.6016836, 0.2, 0.20011161, 0.20028773]\n",
      "[0.60154694, 0.2, 0.20013808, 0.20012726]\n",
      "[0.6016489, 0.2, 0.20005603, 0.20031378]\n",
      "[0.6014546, 0.2, 0.20001598, 0.200162]\n",
      "[0.6014335, 0.2, 0.2001486, 0.20001063]\n",
      "[0.6017139, 0.2, 0.20039721, 0.20004475]\n",
      "[0.60139877, 0.2, 0.20007734, 0.20005202]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6110 iterations: 1.7323424180348714 mins\n",
      "Train Loss: [0.60139877, 0.2, 0.20007734, 0.20005202]\n",
      "[0.6016588, 0.2, 0.20024218, 0.20014961]\n",
      "[0.6015162, 0.2, 0.20023213, 0.20001955]\n",
      "[0.60160714, 0.2, 0.2000981, 0.2002469]\n",
      "[0.6016798, 0.2, 0.20016791, 0.20025206]\n",
      "[0.6014771, 0.2, 0.20009212, 0.20012733]\n",
      "[0.6014779, 0.2, 0.20017627, 0.2000464]\n",
      "[0.60187006, 0.2, 0.20019169, 0.20042531]\n",
      "[0.60161257, 0.2, 0.20007421, 0.2002873]\n",
      "[0.60177237, 0.2, 0.20008585, 0.20043743]\n",
      "[0.601518, 0.2, 0.20020394, 0.20006676]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6120 iterations: 1.734325349330902 mins\n",
      "Train Loss: [0.601518, 0.2, 0.20020394, 0.20006676]\n",
      "[0.60134053, 0.2, 0.20008323, 0.20001191]\n",
      "[0.60197794, 0.2, 0.20035192, 0.20038277]\n",
      "[0.6017055, 0.2, 0.20012069, 0.20034373]\n",
      "[0.6013737, 0.2, 0.20014633, 0.19998817]\n",
      "[0.60164225, 0.2, 0.20010212, 0.2003029]\n",
      "[0.6015066, 0.2, 0.20006621, 0.2002051]\n",
      "[0.6013067, 0.2, 0.20013987, 0.19993342]\n",
      "[0.60175484, 0.2, 0.20017634, 0.20034707]\n",
      "[0.6015998, 0.2, 0.20004696, 0.20032345]\n",
      "[0.6015705, 0.2, 0.20009938, 0.20024374]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6130 iterations: 1.7360621333122253 mins\n",
      "Train Loss: [0.6015705, 0.2, 0.20009938, 0.20024374]\n",
      "[0.6014377, 0.2, 0.20004973, 0.20016253]\n",
      "[0.6014819, 0.2, 0.20020083, 0.20005766]\n",
      "[0.60148805, 0.2, 0.20007263, 0.20019412]\n",
      "[0.6015203, 0.2, 0.20023039, 0.2000708]\n",
      "[0.6018161, 0.2, 0.20034489, 0.2002542]\n",
      "[0.6013921, 0.2, 0.20005903, 0.20011802]\n",
      "[0.6014608, 0.2, 0.20013137, 0.20011622]\n",
      "[0.60208863, 0.2, 0.20068988, 0.20018743]\n",
      "[0.60171646, 0.2, 0.2001469, 0.20036098]\n",
      "[0.60169166, 0.2, 0.20037284, 0.20011266]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6140 iterations: 1.7379516323407491 mins\n",
      "Train Loss: [0.60169166, 0.2, 0.20037284, 0.20011266]\n",
      "[0.60165566, 0.2, 0.20031011, 0.200142]\n",
      "[0.6015228, 0.2, 0.20018496, 0.20013674]\n",
      "[0.6016688, 0.2, 0.20024346, 0.20022658]\n",
      "[0.6018281, 0.2, 0.2000827, 0.2005489]\n",
      "[0.6015035, 0.2, 0.20011164, 0.20019738]\n",
      "[0.6016051, 0.2, 0.20030549, 0.200107]\n",
      "[0.6017166, 0.2, 0.20027766, 0.20024832]\n",
      "[0.6013945, 0.2, 0.20008697, 0.2001189]\n",
      "[0.6016178, 0.2, 0.20012295, 0.20030838]\n",
      "[0.60137314, 0.2, 0.20012932, 0.20005947]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6150 iterations: 1.7397265990575155 mins\n",
      "Train Loss: [0.60137314, 0.2, 0.20012932, 0.20005947]\n",
      "[0.60125315, 0.2, 0.20008256, 0.19998851]\n",
      "[0.601518, 0.2, 0.20008893, 0.20024931]\n",
      "[0.60152644, 0.2, 0.20009948, 0.20024952]\n",
      "[0.60127157, 0.2, 0.20012087, 0.19997577]\n",
      "[0.6016759, 0.2, 0.20009442, 0.20040922]\n",
      "[0.60149056, 0.2, 0.20025864, 0.20006213]\n",
      "[0.6013612, 0.2, 0.20016, 0.20003405]\n",
      "[0.601376, 0.2, 0.20015673, 0.20005482]\n",
      "[0.6016724, 0.2, 0.20013331, 0.20037727]\n",
      "[0.6011763, 0.2, 0.20010044, 0.19991653]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6160 iterations: 1.7416532993316651 mins\n",
      "Train Loss: [0.6011763, 0.2, 0.20010044, 0.19991653]\n",
      "[0.6013068, 0.2, 0.20010085, 0.20004886]\n",
      "[0.60157365, 0.2, 0.20006104, 0.2003579]\n",
      "[0.6015387, 0.2, 0.20023333, 0.200153]\n",
      "[0.60153, 0.2, 0.20027411, 0.20010597]\n",
      "[0.6014224, 0.2, 0.20006984, 0.20020528]\n",
      "[0.6013183, 0.2, 0.20004104, 0.20013253]\n",
      "[0.60156506, 0.2, 0.20017329, 0.20024972]\n",
      "[0.60131717, 0.2, 0.20012589, 0.20005202]\n",
      "[0.6014846, 0.2, 0.20028235, 0.20006569]\n",
      "[0.60160655, 0.2, 0.20012896, 0.2003437]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6170 iterations: 1.7434802333513895 mins\n",
      "Train Loss: [0.60160655, 0.2, 0.20012896, 0.2003437]\n",
      "[0.6018391, 0.2, 0.20020865, 0.20049913]\n",
      "[0.6016595, 0.2, 0.20021312, 0.20031753]\n",
      "[0.6018367, 0.2, 0.20030408, 0.20040621]\n",
      "[0.60160905, 0.2, 0.20010737, 0.20037787]\n",
      "[0.60170746, 0.2, 0.200214, 0.2003722]\n",
      "[0.6015125, 0.2, 0.20009261, 0.20030142]\n",
      "[0.6015484, 0.2, 0.20017679, 0.20025565]\n",
      "[0.6013665, 0.2, 0.2000718, 0.20018156]\n",
      "[0.60121423, 0.2, 0.20004623, 0.20005755]\n",
      "[0.6012005, 0.2, 0.20000005, 0.20009251]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6180 iterations: 1.7454421997070313 mins\n",
      "Train Loss: [0.6012005, 0.2, 0.20000005, 0.20009251]\n",
      "[0.6011668, 0.2, 0.20005378, 0.20000732]\n",
      "[0.6014142, 0.2, 0.20013967, 0.20017104]\n",
      "[0.60128576, 0.2, 0.20019546, 0.19998893]\n",
      "[0.6016374, 0.2, 0.20021085, 0.20032726]\n",
      "[0.60171175, 0.2, 0.20009056, 0.2005239]\n",
      "[0.6013985, 0.2, 0.20011911, 0.2001842]\n",
      "[0.60151744, 0.2, 0.20016663, 0.20025747]\n",
      "[0.6010566, 0.2, 0.20005554, 0.19990954]\n",
      "[0.60148215, 0.2, 0.20011112, 0.20028117]\n",
      "[0.6014651, 0.2, 0.2000947, 0.20028219]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6190 iterations: 1.7479040503501893 mins\n",
      "Train Loss: [0.6014651, 0.2, 0.2000947, 0.20028219]\n",
      "[0.60132164, 0.2, 0.20013174, 0.20010309]\n",
      "[0.6013172, 0.2, 0.20007858, 0.20015332]\n",
      "[0.6012557, 0.2, 0.200226, 0.19994585]\n",
      "[0.6013096, 0.2, 0.20014897, 0.20007825]\n",
      "[0.6014564, 0.2, 0.20011364, 0.20026208]\n",
      "[0.6012994, 0.2, 0.20021398, 0.20000663]\n",
      "[0.60150087, 0.2, 0.20006438, 0.20035958]\n",
      "[0.601202, 0.2, 0.20008144, 0.20004542]\n",
      "[0.6016534, 0.2, 0.20016758, 0.20041254]\n",
      "[0.60168946, 0.2, 0.20023486, 0.20038326]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6200 iterations: 1.7499029994010926 mins\n",
      "Train Loss: [0.60168946, 0.2, 0.20023486, 0.20038326]\n",
      "[0.6013754, 0.2, 0.2002123, 0.2000938]\n",
      "[0.601753, 0.2, 0.20032154, 0.20036416]\n",
      "[0.60139996, 0.2, 0.200256, 0.20007895]\n",
      "[0.60129035, 0.2, 0.2001463, 0.20008132]\n",
      "[0.60152507, 0.2, 0.20007727, 0.20038727]\n",
      "[0.6015618, 0.2, 0.20034932, 0.20015426]\n",
      "[0.6013707, 0.2, 0.20018192, 0.20013298]\n",
      "[0.60119885, 0.2, 0.200053, 0.20009229]\n",
      "[0.6015844, 0.2, 0.2003271, 0.20020603]\n",
      "[0.6016365, 0.2, 0.20029968, 0.20028779]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6210 iterations: 1.7519057154655457 mins\n",
      "Train Loss: [0.6016365, 0.2, 0.20029968, 0.20028779]\n",
      "[0.60127354, 0.2, 0.2001353, 0.20009163]\n",
      "[0.6015316, 0.2, 0.20019934, 0.2002882]\n",
      "[0.60117066, 0.2, 0.20007554, 0.20005369]\n",
      "[0.60134757, 0.2, 0.20027122, 0.20003748]\n",
      "[0.601344, 0.2, 0.20013666, 0.20017108]\n",
      "[0.6011716, 0.2, 0.20000008, 0.2001378]\n",
      "[0.6014763, 0.2, 0.20007943, 0.20036562]\n",
      "[0.6014696, 0.2, 0.20018612, 0.2002545]\n",
      "[0.6014673, 0.2, 0.20043486, 0.20000586]\n",
      "[0.60153216, 0.2, 0.20003079, 0.2004773]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6220 iterations: 1.753766083717346 mins\n",
      "Train Loss: [0.60153216, 0.2, 0.20003079, 0.2004773]\n",
      "[0.6015229, 0.2, 0.200083, 0.20041811]\n",
      "[0.6012257, 0.2, 0.20018134, 0.20002459]\n",
      "[0.60112673, 0.2, 0.20006527, 0.20004372]\n",
      "[0.6013689, 0.2, 0.20012157, 0.2002316]\n",
      "[0.601413, 0.2, 0.20009504, 0.20030433]\n",
      "[0.60117334, 0.2, 0.2001898, 0.19997196]\n",
      "[0.60132444, 0.2, 0.20017865, 0.20013626]\n",
      "[0.6012983, 0.2, 0.20013112, 0.20015948]\n",
      "[0.6013772, 0.2, 0.20015037, 0.200221]\n",
      "[0.6016163, 0.2, 0.20029724, 0.2003152]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6230 iterations: 1.7557660500208536 mins\n",
      "Train Loss: [0.6016163, 0.2, 0.20029724, 0.2003152]\n",
      "[0.6011659, 0.2, 0.20008014, 0.20008378]\n",
      "[0.6011724, 0.2, 0.20007563, 0.2000968]\n",
      "[0.60122335, 0.2, 0.20006664, 0.20015869]\n",
      "[0.60122126, 0.2, 0.20011029, 0.20011488]\n",
      "[0.6011325, 0.2, 0.20005283, 0.2000855]\n",
      "[0.6013647, 0.2, 0.20014499, 0.20022744]\n",
      "[0.6012879, 0.2, 0.2001354, 0.20016214]\n",
      "[0.60118794, 0.2, 0.20007172, 0.20012788]\n",
      "[0.6013457, 0.2, 0.20014767, 0.20021163]\n",
      "[0.6013847, 0.2, 0.20019668, 0.20020345]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6240 iterations: 1.7576057990392049 mins\n",
      "Train Loss: [0.6013847, 0.2, 0.20019668, 0.20020345]\n",
      "[0.6012245, 0.2, 0.20011456, 0.20012705]\n",
      "[0.6011165, 0.2, 0.20015791, 0.19997753]\n",
      "[0.6011621, 0.2, 0.20024113, 0.19994175]\n",
      "[0.60113376, 0.2, 0.20006908, 0.20008725]\n",
      "[0.6014837, 0.2, 0.20043224, 0.20007578]\n",
      "[0.60265285, 0.2, 0.20041744, 0.2012613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60156566, 0.2, 0.20029537, 0.20029758]\n",
      "[0.60111463, 0.2, 0.20004742, 0.20009589]\n",
      "[0.601234, 0.2, 0.20033668, 0.19992754]\n",
      "[0.6010169, 0.2, 0.20009224, 0.19995615]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6250 iterations: 1.7596025149027505 mins\n",
      "Train Loss: [0.6010169, 0.2, 0.20009224, 0.19995615]\n",
      "[0.6011806, 0.2, 0.20018637, 0.20002703]\n",
      "[0.60174406, 0.2, 0.20021597, 0.20056197]\n",
      "[0.60127383, 0.2, 0.2001557, 0.20015301]\n",
      "[0.60147613, 0.2, 0.20003967, 0.20047227]\n",
      "[0.6017963, 0.2, 0.2001143, 0.20071855]\n",
      "[0.60164845, 0.2, 0.20016997, 0.20051558]\n",
      "[0.601153, 0.2, 0.20008709, 0.20010367]\n",
      "[0.6012965, 0.2, 0.20000008, 0.20033468]\n",
      "[0.60140467, 0.2, 0.20008692, 0.20035642]\n",
      "[0.6017686, 0.2, 0.20013657, 0.20067132]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6260 iterations: 1.761428133646647 mins\n",
      "Train Loss: [0.6017686, 0.2, 0.20013657, 0.20067132]\n",
      "[0.6011943, 0.2, 0.20003924, 0.20019518]\n",
      "[0.6011665, 0.2, 0.20007701, 0.20013046]\n",
      "[0.60128736, 0.2, 0.20018943, 0.20013988]\n",
      "[0.6010574, 0.2, 0.20005023, 0.20005019]\n",
      "[0.6013355, 0.2, 0.20013751, 0.20024212]\n",
      "[0.6016413, 0.2, 0.20008302, 0.20060353]\n",
      "[0.6011489, 0.2, 0.2000526, 0.2001425]\n",
      "[0.60143185, 0.2, 0.2000376, 0.20044139]\n",
      "[0.601958, 0.2, 0.20045237, 0.20055376]\n",
      "[0.6017119, 0.2, 0.20053455, 0.20022643]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6270 iterations: 1.7638642986615498 mins\n",
      "Train Loss: [0.6017119, 0.2, 0.20053455, 0.20022643]\n",
      "[0.6011399, 0.2, 0.20013085, 0.20005895]\n",
      "[0.601259, 0.2, 0.20000148, 0.20030817]\n",
      "[0.60137856, 0.2, 0.20032202, 0.20010787]\n",
      "[0.60145485, 0.2, 0.20011444, 0.2003927]\n",
      "[0.6017962, 0.2, 0.20026752, 0.20058192]\n",
      "[0.60174596, 0.2, 0.20045842, 0.20034178]\n",
      "[0.6013353, 0.2, 0.2002078, 0.20018297]\n",
      "[0.60152453, 0.2, 0.20020905, 0.20037241]\n",
      "[0.60143644, 0.2, 0.20029236, 0.20020229]\n",
      "[0.6015118, 0.2, 0.20021933, 0.20035161]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6280 iterations: 1.7657429655392964 mins\n",
      "Train Loss: [0.6015118, 0.2, 0.20021933, 0.20035161]\n",
      "[0.60135996, 0.2, 0.2001124, 0.20030758]\n",
      "[0.60128826, 0.2, 0.20018859, 0.20016047]\n",
      "[0.60135514, 0.2, 0.20008738, 0.20032918]\n",
      "[0.601076, 0.2, 0.20010498, 0.20003301]\n",
      "[0.6013241, 0.2, 0.20018049, 0.20020612]\n",
      "[0.6013172, 0.2, 0.20021845, 0.20016178]\n",
      "[0.6016501, 0.2, 0.20038787, 0.20032583]\n",
      "[0.60128, 0.2, 0.20030205, 0.20004216]\n",
      "[0.60130227, 0.2, 0.20036137, 0.20000549]\n",
      "[0.6013109, 0.2, 0.20005982, 0.20031577]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6290 iterations: 1.7677823980649312 mins\n",
      "Train Loss: [0.6013109, 0.2, 0.20005982, 0.20031577]\n",
      "[0.60187, 0.2, 0.20026386, 0.2006709]\n",
      "[0.6016045, 0.2, 0.20026448, 0.2004046]\n",
      "[0.6011764, 0.2, 0.20011657, 0.20012428]\n",
      "[0.6013052, 0.2, 0.2002034, 0.20016642]\n",
      "[0.60121566, 0.2, 0.20005992, 0.20022056]\n",
      "[0.60109127, 0.2, 0.20012811, 0.20002846]\n",
      "[0.60128945, 0.2, 0.20017613, 0.20017943]\n",
      "[0.6011762, 0.2, 0.2001552, 0.20008788]\n",
      "[0.6010019, 0.2, 0.20005368, 0.20001608]\n",
      "[0.6011672, 0.2, 0.20011698, 0.20011908]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6300 iterations: 1.769720717271169 mins\n",
      "Train Loss: [0.6011672, 0.2, 0.20011698, 0.20011908]\n",
      "[0.60141635, 0.2, 0.20021768, 0.20026873]\n",
      "[0.6011285, 0.2, 0.2000669, 0.20013289]\n",
      "[0.6009705, 0.2, 0.20005454, 0.19998862]\n",
      "[0.60110676, 0.2, 0.20004176, 0.20013927]\n",
      "[0.60109, 0.2, 0.20016354, 0.20000249]\n",
      "[0.6009782, 0.2, 0.20010294, 0.19995308]\n",
      "[0.6011039, 0.2, 0.2001168, 0.2000668]\n",
      "[0.60108465, 0.2, 0.20009969, 0.20006675]\n",
      "[0.60116976, 0.2, 0.20013657, 0.20011713]\n",
      "[0.601299, 0.2, 0.20019543, 0.20018959]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6310 iterations: 1.7718025962511699 mins\n",
      "Train Loss: [0.601299, 0.2, 0.20019543, 0.20018959]\n",
      "[0.6013149, 0.2, 0.20026308, 0.20013982]\n",
      "[0.60145, 0.2, 0.2001773, 0.2003628]\n",
      "[0.6016478, 0.2, 0.20017838, 0.20056145]\n",
      "[0.60112023, 0.2, 0.20014551, 0.20006882]\n",
      "[0.6010743, 0.2, 0.20009144, 0.20007868]\n",
      "[0.6011044, 0.2, 0.20011269, 0.20008904]\n",
      "[0.6014682, 0.2, 0.20013344, 0.20043325]\n",
      "[0.60134584, 0.2, 0.20014194, 0.20030348]\n",
      "[0.6011334, 0.2, 0.20012191, 0.20011215]\n",
      "[0.6010556, 0.2, 0.20004654, 0.20011088]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6320 iterations: 1.7737785498301188 mins\n",
      "Train Loss: [0.6010556, 0.2, 0.20004654, 0.20011088]\n",
      "[0.6011614, 0.2, 0.20014259, 0.20012161]\n",
      "[0.60107225, 0.2, 0.20009404, 0.20008199]\n",
      "[0.6012028, 0.2, 0.20017695, 0.2001306]\n",
      "[0.60093576, 0.2, 0.2, 0.2000415]\n",
      "[0.60119027, 0.2, 0.20009065, 0.20020643]\n",
      "[0.60146224, 0.2, 0.20010738, 0.2004628]\n",
      "[0.6011723, 0.2, 0.20008515, 0.2001964]\n",
      "[0.6011077, 0.2, 0.20000002, 0.200218]\n",
      "[0.6012047, 0.2, 0.20012811, 0.20018819]\n",
      "[0.6010955, 0.2, 0.20016976, 0.20003864]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6330 iterations: 1.7757096330324809 mins\n",
      "Train Loss: [0.6010955, 0.2, 0.20016976, 0.20003864]\n",
      "[0.6013164, 0.2, 0.20026365, 0.20016699]\n",
      "[0.60108197, 0.2, 0.20019583, 0.20000197]\n",
      "[0.60113883, 0.2, 0.20005465, 0.20020169]\n",
      "[0.60179216, 0.2, 0.20018499, 0.20072626]\n",
      "[0.6011771, 0.2, 0.2002399, 0.20005783]\n",
      "[0.6011739, 0.2, 0.20000002, 0.20029606]\n",
      "[0.60099286, 0.2, 0.20010103, 0.20001534]\n",
      "[0.6012017, 0.2, 0.2000865, 0.20024006]\n",
      "[0.6011737, 0.2, 0.2000996, 0.20020027]\n",
      "[0.6012353, 0.2, 0.20012856, 0.20023422]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6340 iterations: 1.7776635964711507 mins\n",
      "Train Loss: [0.6012353, 0.2, 0.20012856, 0.20023422]\n",
      "[0.6012104, 0.2, 0.20017916, 0.20016003]\n",
      "[0.6012859, 0.2, 0.20018008, 0.20023578]\n",
      "[0.6011642, 0.2, 0.20013443, 0.20016098]\n",
      "[0.6012345, 0.2, 0.20012328, 0.20024353]\n",
      "[0.6012339, 0.2, 0.20013365, 0.20023377]\n",
      "[0.60101706, 0.2, 0.20008738, 0.20006436]\n",
      "[0.60107094, 0.2, 0.20015661, 0.20005012]\n",
      "[0.6013678, 0.2, 0.20009755, 0.20040709]\n",
      "[0.6009716, 0.2, 0.20009196, 0.20001751]\n",
      "[0.6010353, 0.2, 0.20013599, 0.20003833]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6350 iterations: 1.7794607639312745 mins\n",
      "Train Loss: [0.6010353, 0.2, 0.20013599, 0.20003833]\n",
      "[0.60112643, 0.2, 0.20016178, 0.20010476]\n",
      "[0.6011361, 0.2, 0.20020156, 0.20007586]\n",
      "[0.6010659, 0.2, 0.20008929, 0.20011918]\n",
      "[0.60109293, 0.2, 0.20017265, 0.20006423]\n",
      "[0.6009827, 0.2, 0.20011413, 0.20001394]\n",
      "[0.60127443, 0.2, 0.20010631, 0.20031483]\n",
      "[0.6010921, 0.2, 0.20003888, 0.20020132]\n",
      "[0.60131156, 0.2, 0.20014258, 0.20031843]\n",
      "[0.60103947, 0.2, 0.20007583, 0.2001142]\n",
      "[0.6009421, 0.2, 0.20011163, 0.19998224]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6360 iterations: 1.7818607807159423 mins\n",
      "Train Loss: [0.6009421, 0.2, 0.20011163, 0.19998224]\n",
      "[0.6013693, 0.2, 0.20014483, 0.20037743]\n",
      "[0.6014962, 0.2, 0.20030998, 0.20034026]\n",
      "[0.6011176, 0.2, 0.20006001, 0.20021272]\n",
      "[0.60122645, 0.2, 0.20016818, 0.2002144]\n",
      "[0.60113376, 0.2, 0.20022346, 0.2000675]\n",
      "[0.601307, 0.2, 0.20037825, 0.2000868]\n",
      "[0.6015841, 0.2, 0.20040315, 0.20033962]\n",
      "[0.60150605, 0.2, 0.20028594, 0.20037946]\n",
      "[0.60103804, 0.2, 0.20016734, 0.20003088]\n",
      "[0.6012945, 0.2, 0.20019944, 0.20025586]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6370 iterations: 1.7837561170260112 mins\n",
      "Train Loss: [0.6012945, 0.2, 0.20019944, 0.20025586]\n",
      "[0.60131204, 0.2, 0.2002192, 0.20025402]\n",
      "[0.60109097, 0.2, 0.2001238, 0.20012863]\n",
      "[0.601161, 0.2, 0.20017442, 0.20014827]\n",
      "[0.6013379, 0.2, 0.20020969, 0.20029019]\n",
      "[0.60105044, 0.2, 0.20009811, 0.20011455]\n",
      "[0.6011658, 0.2, 0.20016432, 0.20016402]\n",
      "[0.60125977, 0.2, 0.20026818, 0.20015447]\n",
      "[0.60119116, 0.2, 0.20014736, 0.20020717]\n",
      "[0.60103565, 0.2, 0.20017497, 0.20002463]\n",
      "[0.6012504, 0.2, 0.2002056, 0.2002093]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6380 iterations: 1.7856735984484355 mins\n",
      "Train Loss: [0.6012504, 0.2, 0.2002056, 0.2002093]\n",
      "[0.6010114, 0.2, 0.20012072, 0.20005582]\n",
      "[0.60113704, 0.2, 0.20015891, 0.20014401]\n",
      "[0.60108817, 0.2, 0.20010234, 0.20015271]\n",
      "[0.60119474, 0.2, 0.20007233, 0.20029049]\n",
      "[0.6007506, 0.2, 0.20005004, 0.19986969]\n",
      "[0.60131276, 0.2, 0.20012353, 0.20035948]\n",
      "[0.601176, 0.2, 0.20012368, 0.20022365]\n",
      "[0.6018166, 0.2, 0.20048276, 0.20050627]\n",
      "[0.6012478, 0.2, 0.20005351, 0.20036806]\n",
      "[0.60133463, 0.2, 0.20007272, 0.2004369]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6390 iterations: 1.7874842484792073 mins\n",
      "Train Loss: [0.60133463, 0.2, 0.20007272, 0.2004369]\n",
      "[0.6011238, 0.2, 0.20027278, 0.20002726]\n",
      "[0.60117865, 0.2, 0.20027287, 0.20008327]\n",
      "[0.6011021, 0.2, 0.20019864, 0.20008239]\n",
      "[0.6011096, 0.2, 0.2002657, 0.20002419]\n",
      "[0.6011968, 0.2, 0.20026581, 0.2001129]\n",
      "[0.6013107, 0.2, 0.20009136, 0.200403]\n",
      "[0.6010095, 0.2, 0.20013377, 0.2000611]\n",
      "[0.60122687, 0.2, 0.20013073, 0.20028332]\n",
      "[0.6010931, 0.2, 0.20020764, 0.20007436]\n",
      "[0.60122025, 0.2, 0.200219, 0.2001917]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6400 iterations: 1.7910520990689596 mins\n",
      "Train Loss: [0.60122025, 0.2, 0.200219, 0.2001917]\n",
      "[0.6008668, 0.2, 0.20000002, 0.20005883]\n",
      "[0.60107625, 0.2, 0.20022228, 0.20004755]\n",
      "[0.6011933, 0.2, 0.2001573, 0.20023113]\n",
      "[0.60090274, 0.2, 0.20011996, 0.19997944]\n",
      "[0.60123515, 0.2, 0.20031548, 0.20011781]\n",
      "[0.60093313, 0.2, 0.20010257, 0.20003031]\n",
      "[0.6009279, 0.2, 0.20026517, 0.19986409]\n",
      "[0.6011774, 0.2, 0.20012878, 0.20025147]\n",
      "[0.6014512, 0.2, 0.20012516, 0.20053044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6014071, 0.2, 0.20027113, 0.2003418]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6410 iterations: 1.7930221637090047 mins\n",
      "Train Loss: [0.6014071, 0.2, 0.20027113, 0.2003418]\n",
      "[0.60113627, 0.2, 0.20042984, 0.19991367]\n",
      "[0.6015323, 0.2, 0.20009711, 0.2006438]\n",
      "[0.60113317, 0.2, 0.200197, 0.2001463]\n",
      "[0.60075474, 0.2, 0.2000646, 0.19990163]\n",
      "[0.6013284, 0.2, 0.20006968, 0.20047142]\n",
      "[0.6007209, 0.2, 0.20007452, 0.19986007]\n",
      "[0.6012255, 0.2, 0.20028518, 0.20015506]\n",
      "[0.6012103, 0.2, 0.20020677, 0.20021932]\n",
      "[0.6016006, 0.2, 0.20048226, 0.20033501]\n",
      "[0.6010052, 0.2, 0.20021118, 0.20001145]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6420 iterations: 1.7948490818341574 mins\n",
      "Train Loss: [0.6010052, 0.2, 0.20021118, 0.20001145]\n",
      "[0.60127926, 0.2, 0.20037684, 0.20012052]\n",
      "[0.6008491, 0.2, 0.20006292, 0.20000501]\n",
      "[0.600945, 0.2, 0.20008649, 0.20007785]\n",
      "[0.60133094, 0.2, 0.20011891, 0.20043166]\n",
      "[0.6008009, 0.2, 0.20023829, 0.19978249]\n",
      "[0.6012136, 0.2, 0.20030516, 0.20012857]\n",
      "[0.6013996, 0.2, 0.20012677, 0.20049319]\n",
      "[0.6019817, 0.2, 0.20054796, 0.20065397]\n",
      "[0.6009255, 0.2, 0.20002212, 0.20012371]\n",
      "[0.6011204, 0.2, 0.20020792, 0.20013273]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6430 iterations: 1.7969045996665955 mins\n",
      "Train Loss: [0.6011204, 0.2, 0.20020792, 0.20013273]\n",
      "[0.601135, 0.2, 0.20026256, 0.20009261]\n",
      "[0.6012116, 0.2, 0.20039152, 0.20004003]\n",
      "[0.6017809, 0.2, 0.20022886, 0.20077182]\n",
      "[0.601434, 0.2, 0.20008972, 0.20056377]\n",
      "[0.6012201, 0.2, 0.20020403, 0.20023538]\n",
      "[0.6013384, 0.2, 0.20012498, 0.20043267]\n",
      "[0.601302, 0.2, 0.20022902, 0.20029211]\n",
      "[0.60135555, 0.2, 0.20013233, 0.20044243]\n",
      "[0.6010928, 0.2, 0.20019656, 0.20011571]\n",
      "[0.6016848, 0.2, 0.20048706, 0.20041744]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6440 iterations: 1.7992905696233115 mins\n",
      "Train Loss: [0.6016848, 0.2, 0.20048706, 0.20041744]\n",
      "[0.6012501, 0.2, 0.2001992, 0.20027079]\n",
      "[0.6006381, 0.2, 0.20013851, 0.19971997]\n",
      "[0.60100466, 0.2, 0.20005207, 0.20017363]\n",
      "[0.6014848, 0.2, 0.20029318, 0.20041312]\n",
      "[0.6011618, 0.2, 0.20028694, 0.2000968]\n",
      "[0.6011324, 0.2, 0.20034873, 0.20000614]\n",
      "[0.6013832, 0.2, 0.20035647, 0.2002496]\n",
      "[0.60109353, 0.2, 0.20005788, 0.20025891]\n",
      "[0.6012456, 0.2, 0.20010224, 0.20036666]\n",
      "[0.6013728, 0.2, 0.20041491, 0.20018129]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6450 iterations: 1.801270882288615 mins\n",
      "Train Loss: [0.6013728, 0.2, 0.20041491, 0.20018129]\n",
      "[0.6011552, 0.2, 0.20015445, 0.20022425]\n",
      "[0.6015068, 0.2, 0.20010816, 0.20062222]\n",
      "[0.60107374, 0.2, 0.20010062, 0.20019673]\n",
      "[0.6010069, 0.2, 0.20019557, 0.20003504]\n",
      "[0.6012696, 0.2, 0.20023999, 0.2002533]\n",
      "[0.60103166, 0.2, 0.20012842, 0.20012699]\n",
      "[0.60100216, 0.2, 0.2002126, 0.20001358]\n",
      "[0.6009898, 0.2, 0.20013018, 0.2000838]\n",
      "[0.6013966, 0.2, 0.20021012, 0.20041062]\n",
      "[0.60109085, 0.2, 0.2002411, 0.20007375]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6460 iterations: 1.8031298001607259 mins\n",
      "Train Loss: [0.60109085, 0.2, 0.2002411, 0.20007375]\n",
      "[0.6010014, 0.2, 0.20009497, 0.20013016]\n",
      "[0.60092217, 0.2, 0.20012173, 0.20002382]\n",
      "[0.6016179, 0.2, 0.200195, 0.2006457]\n",
      "[0.6009088, 0.2, 0.20012522, 0.20000586]\n",
      "[0.601309, 0.2, 0.20013735, 0.2003937]\n",
      "[0.6011066, 0.2, 0.20012902, 0.20019938]\n",
      "[0.6016807, 0.2, 0.2003835, 0.20051871]\n",
      "[0.6008142, 0.2, 0.20011728, 0.19991814]\n",
      "[0.6013622, 0.2, 0.20014268, 0.20044042]\n",
      "[0.6011469, 0.2, 0.2002521, 0.20011516]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6470 iterations: 1.8052526156107584 mins\n",
      "Train Loss: [0.6011469, 0.2, 0.2002521, 0.20011516]\n",
      "[0.60080266, 0.2, 0.20000008, 0.2000225]\n",
      "[0.6020548, 0.2, 0.20008169, 0.2011927]\n",
      "[0.6013061, 0.2, 0.2003066, 0.20021893]\n",
      "[0.60132337, 0.2, 0.20018718, 0.2003557]\n",
      "[0.6011519, 0.2, 0.20041423, 0.19995752]\n",
      "[0.6010984, 0.2, 0.20020922, 0.20010926]\n",
      "[0.6010956, 0.2, 0.20016351, 0.20015253]\n",
      "[0.60124326, 0.2, 0.2003042, 0.20015985]\n",
      "[0.60170895, 0.2, 0.20020527, 0.20072494]\n",
      "[0.601216, 0.2, 0.20025873, 0.20017952]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6480 iterations: 1.8071271657943726 mins\n",
      "Train Loss: [0.601216, 0.2, 0.20025873, 0.20017952]\n",
      "[0.6011006, 0.2, 0.20011806, 0.20020556]\n",
      "[0.6010854, 0.2, 0.20012367, 0.2001855]\n",
      "[0.6017471, 0.2, 0.2007941, 0.20017743]\n",
      "[0.601121, 0.2, 0.20016348, 0.20018277]\n",
      "[0.6012176, 0.2, 0.20007129, 0.20037234]\n",
      "[0.60127985, 0.2, 0.20017438, 0.20033215]\n",
      "[0.6009435, 0.2, 0.20014511, 0.20002593]\n",
      "[0.6010749, 0.2, 0.20010078, 0.20020238]\n",
      "[0.6014932, 0.2, 0.20035124, 0.20037122]\n",
      "[0.6011746, 0.2, 0.20022978, 0.20017512]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6490 iterations: 1.8091657519340516 mins\n",
      "Train Loss: [0.6011746, 0.2, 0.20022978, 0.20017512]\n",
      "[0.601185, 0.2, 0.20014668, 0.20026954]\n",
      "[0.6010633, 0.2, 0.2001888, 0.2001062]\n",
      "[0.601189, 0.2, 0.20025645, 0.20016459]\n",
      "[0.60135484, 0.2, 0.20043205, 0.20015524]\n",
      "[0.601095, 0.2, 0.20022526, 0.2001029]\n",
      "[0.60100406, 0.2, 0.20007613, 0.20016176]\n",
      "[0.6012963, 0.2, 0.20012443, 0.20040648]\n",
      "[0.60124016, 0.2, 0.20022175, 0.2002538]\n",
      "[0.6012099, 0.2, 0.20019059, 0.20025551]\n",
      "[0.60103166, 0.2, 0.20013374, 0.200135]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6500 iterations: 1.811224635442098 mins\n",
      "Train Loss: [0.60103166, 0.2, 0.20013374, 0.200135]\n",
      "[0.60094476, 0.2, 0.20011435, 0.20006828]\n",
      "[0.6011737, 0.2, 0.20016426, 0.20024829]\n",
      "[0.60151917, 0.2, 0.20034896, 0.20041037]\n",
      "[0.601196, 0.2, 0.20019153, 0.20024616]\n",
      "[0.6014376, 0.2, 0.2003421, 0.20033899]\n",
      "[0.6015222, 0.2, 0.20012285, 0.20064448]\n",
      "[0.6014106, 0.2, 0.20020501, 0.20045254]\n",
      "[0.60090214, 0.2, 0.20000005, 0.20015067]\n",
      "[0.6010285, 0.2, 0.20000003, 0.2002784]\n",
      "[0.60137826, 0.2, 0.20017383, 0.20045564]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6510 iterations: 1.8130334496498108 mins\n",
      "Train Loss: [0.60137826, 0.2, 0.20017383, 0.20045564]\n",
      "[0.601182, 0.2, 0.2002489, 0.20018545]\n",
      "[0.6008996, 0.2, 0.20013641, 0.20001669]\n",
      "[0.6012073, 0.2, 0.20009764, 0.20036437]\n",
      "[0.6009465, 0.2, 0.20004396, 0.20015858]\n",
      "[0.60104334, 0.2, 0.20013575, 0.20016496]\n",
      "[0.60105616, 0.2, 0.20010167, 0.20021312]\n",
      "[0.6023318, 0.2, 0.2012824, 0.20030923]\n",
      "[0.60101193, 0.2, 0.20022269, 0.20005047]\n",
      "[0.6013029, 0.2, 0.20038465, 0.20018086]\n",
      "[0.60115165, 0.2, 0.20023553, 0.20018004]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6520 iterations: 1.8153931498527527 mins\n",
      "Train Loss: [0.60115165, 0.2, 0.20023553, 0.20018004]\n",
      "[0.6010054, 0.2, 0.2001481, 0.20012255]\n",
      "[0.601251, 0.2, 0.20011757, 0.20039994]\n",
      "[0.60086536, 0.2, 0.20004392, 0.20008919]\n",
      "[0.6013196, 0.2, 0.20024644, 0.20034204]\n",
      "[0.60110563, 0.2, 0.2002681, 0.20010771]\n",
      "[0.6011641, 0.2, 0.20008847, 0.20034719]\n",
      "[0.60122484, 0.2, 0.20038119, 0.20011653]\n",
      "[0.6009524, 0.2, 0.20014839, 0.20007794]\n",
      "[0.60097396, 0.2, 0.20010766, 0.20014139]\n",
      "[0.6010332, 0.2, 0.20010972, 0.20019977]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6530 iterations: 1.8172340830167135 mins\n",
      "Train Loss: [0.6010332, 0.2, 0.20010972, 0.20019977]\n",
      "[0.60093063, 0.2, 0.20007262, 0.20013562]\n",
      "[0.6009592, 0.2, 0.20014417, 0.20009397]\n",
      "[0.6011317, 0.2, 0.2001277, 0.20028424]\n",
      "[0.6011194, 0.2, 0.20014663, 0.20025425]\n",
      "[0.6012542, 0.2, 0.20023783, 0.20029895]\n",
      "[0.60112476, 0.2, 0.2001952, 0.20021346]\n",
      "[0.601155, 0.2, 0.20017548, 0.2002647]\n",
      "[0.6010562, 0.2, 0.20016207, 0.20018068]\n",
      "[0.60096407, 0.2, 0.20009722, 0.20015459]\n",
      "[0.6011404, 0.2, 0.20024072, 0.20018855]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6540 iterations: 1.8192885835965475 mins\n",
      "Train Loss: [0.6011404, 0.2, 0.20024072, 0.20018855]\n",
      "[0.60122174, 0.2, 0.20019482, 0.2003169]\n",
      "[0.60099846, 0.2, 0.20016149, 0.20012793]\n",
      "[0.6011022, 0.2, 0.20016119, 0.200233]\n",
      "[0.6008825, 0.2, 0.20010506, 0.20007037]\n",
      "[0.60112095, 0.2, 0.20007588, 0.20033902]\n",
      "[0.60108066, 0.2, 0.20022011, 0.20015542]\n",
      "[0.60080916, 0.2, 0.2000363, 0.20006873]\n",
      "[0.6013206, 0.2, 0.20026793, 0.20034957]\n",
      "[0.60106283, 0.2, 0.20023938, 0.2001213]\n",
      "[0.6013243, 0.2, 0.20037435, 0.20024869]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6550 iterations: 1.821078117688497 mins\n",
      "Train Loss: [0.6013243, 0.2, 0.20037435, 0.20024869]\n",
      "[0.60141087, 0.2, 0.20022048, 0.20048995]\n",
      "[0.60146594, 0.2, 0.20066118, 0.20010534]\n",
      "[0.60137767, 0.2, 0.2002267, 0.2004525]\n",
      "[0.6013668, 0.2, 0.20043224, 0.20023672]\n",
      "[0.6017096, 0.2, 0.20034409, 0.20066789]\n",
      "[0.60083795, 0.2, 0.20016433, 0.19997624]\n",
      "[0.6015358, 0.2, 0.2003879, 0.20045058]\n",
      "[0.6014292, 0.2, 0.20027424, 0.20045765]\n",
      "[0.60139406, 0.2, 0.20033653, 0.20036006]\n",
      "[0.6012553, 0.2, 0.20040497, 0.20015246]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6560 iterations: 1.8230712493260701 mins\n",
      "Train Loss: [0.6012553, 0.2, 0.20040497, 0.20015246]\n",
      "[0.60143965, 0.2, 0.20019469, 0.20054673]\n",
      "[0.60117096, 0.2, 0.2002368, 0.20023544]\n",
      "[0.6013342, 0.2, 0.20009282, 0.20054206]\n",
      "[0.6012704, 0.2, 0.20019908, 0.20037147]\n",
      "[0.6013488, 0.2, 0.20033523, 0.20031323]\n",
      "[0.6015987, 0.2, 0.20025635, 0.20064166]\n",
      "[0.60131663, 0.2, 0.20024332, 0.2003727]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60118246, 0.2, 0.20042051, 0.20006125]\n",
      "[0.60143006, 0.2, 0.20036244, 0.20036677]\n",
      "[0.6012851, 0.2, 0.20028223, 0.20030192]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6570 iterations: 1.8252626180648803 mins\n",
      "Train Loss: [0.6012851, 0.2, 0.20028223, 0.20030192]\n",
      "[0.6016368, 0.2, 0.20029438, 0.20064141]\n",
      "[0.60122436, 0.2, 0.20027511, 0.2002481]\n",
      "[0.600864, 0.2, 0.20003013, 0.2001328]\n",
      "[0.6014275, 0.2, 0.20023791, 0.20048855]\n",
      "[0.60135347, 0.2, 0.20042758, 0.20022526]\n",
      "[0.600817, 0.2, 0.20013218, 0.19998461]\n",
      "[0.60142285, 0.2, 0.20031282, 0.20041026]\n",
      "[0.6012027, 0.2, 0.20037149, 0.20013197]\n",
      "[0.60145044, 0.2, 0.20019785, 0.20055366]\n",
      "[0.60102564, 0.2, 0.20032196, 0.20000514]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6580 iterations: 1.8271462162335714 mins\n",
      "Train Loss: [0.60102564, 0.2, 0.20032196, 0.20000514]\n",
      "[0.601105, 0.2, 0.20011939, 0.20028739]\n",
      "[0.60153925, 0.2, 0.20018016, 0.20066114]\n",
      "[0.6010676, 0.2, 0.20001864, 0.20035149]\n",
      "[0.6014912, 0.2, 0.2004379, 0.20035599]\n",
      "[0.60130715, 0.2, 0.2000002, 0.20060962]\n",
      "[0.60106415, 0.2, 0.20025595, 0.20011076]\n",
      "[0.6009113, 0.2, 0.20008014, 0.20013337]\n",
      "[0.6012645, 0.2, 0.20023486, 0.20033124]\n",
      "[0.60138655, 0.2, 0.20037231, 0.20031522]\n",
      "[0.60109884, 0.2, 0.20029303, 0.20010597]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6590 iterations: 1.8290730992952982 mins\n",
      "Train Loss: [0.60109884, 0.2, 0.20029303, 0.20010597]\n",
      "[0.6015184, 0.2, 0.2004095, 0.20040819]\n",
      "[0.6011832, 0.2, 0.20012066, 0.20036112]\n",
      "[0.6012727, 0.2, 0.20043492, 0.20013584]\n",
      "[0.601653, 0.2, 0.20060672, 0.20034364]\n",
      "[0.60160387, 0.2, 0.20064244, 0.20025836]\n",
      "[0.60093004, 0.2, 0.20011275, 0.20011401]\n",
      "[0.6016116, 0.2, 0.20060816, 0.20029981]\n",
      "[0.6011594, 0.2, 0.2003249, 0.20013069]\n",
      "[0.6014695, 0.2, 0.20029457, 0.2004708]\n",
      "[0.60141075, 0.2, 0.20053817, 0.20016795]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6600 iterations: 1.8313352147738138 mins\n",
      "Train Loss: [0.60141075, 0.2, 0.20053817, 0.20016795]\n",
      "[0.60114676, 0.2, 0.20017256, 0.2002691]\n",
      "[0.6013789, 0.2, 0.20027155, 0.20040172]\n",
      "[0.6016171, 0.2, 0.2004116, 0.2004992]\n",
      "[0.6009769, 0.2, 0.20018448, 0.20008501]\n",
      "[0.6019032, 0.2, 0.20089522, 0.2002994]\n",
      "[0.6011761, 0.2, 0.20029673, 0.20017028]\n",
      "[0.60125613, 0.2, 0.20023905, 0.20030741]\n",
      "[0.60141575, 0.2, 0.20049194, 0.20021363]\n",
      "[0.6012403, 0.2, 0.20027047, 0.20025915]\n",
      "[0.60125816, 0.2, 0.20037366, 0.2001731]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6610 iterations: 1.8332502484321593 mins\n",
      "Train Loss: [0.60125816, 0.2, 0.20037366, 0.2001731]\n",
      "[0.6010961, 0.2, 0.2001006, 0.20028333]\n",
      "[0.6013521, 0.2, 0.20017904, 0.20046006]\n",
      "[0.60119873, 0.2, 0.2001882, 0.2002968]\n",
      "[0.60099596, 0.2, 0.2001543, 0.20012738]\n",
      "[0.60116374, 0.2, 0.20016892, 0.20027989]\n",
      "[0.6011536, 0.2, 0.2001406, 0.20029758]\n",
      "[0.60128176, 0.2, 0.20005514, 0.20051067]\n",
      "[0.6012154, 0.2, 0.20031351, 0.20018563]\n",
      "[0.60109276, 0.2, 0.20027643, 0.20009975]\n",
      "[0.60128003, 0.2, 0.20031583, 0.20024748]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6620 iterations: 1.8351650794347127 mins\n",
      "Train Loss: [0.60128003, 0.2, 0.20031583, 0.20024748]\n",
      "[0.60131603, 0.2, 0.20019844, 0.20040067]\n",
      "[0.60135615, 0.2, 0.20033516, 0.20030393]\n",
      "[0.6012289, 0.2, 0.20013449, 0.20037729]\n",
      "[0.60120875, 0.2, 0.20020773, 0.20028387]\n",
      "[0.6009984, 0.2, 0.20021488, 0.2000662]\n",
      "[0.6011281, 0.2, 0.20029816, 0.20011243]\n",
      "[0.6010427, 0.2, 0.2000478, 0.20027733]\n",
      "[0.6016613, 0.2, 0.20021453, 0.20072901]\n",
      "[0.6013612, 0.2, 0.20045596, 0.20018773]\n",
      "[0.6012824, 0.2, 0.2001042, 0.2004611]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6630 iterations: 1.8370178500811258 mins\n",
      "Train Loss: [0.6012824, 0.2, 0.2001042, 0.2004611]\n",
      "[0.6012265, 0.2, 0.20023629, 0.20027362]\n",
      "[0.6011888, 0.2, 0.20007949, 0.2003933]\n",
      "[0.60093564, 0.2, 0.20011097, 0.20010956]\n",
      "[0.60130346, 0.2, 0.20012364, 0.20046546]\n",
      "[0.6011331, 0.2, 0.20023225, 0.20018731]\n",
      "[0.60145664, 0.2, 0.2002784, 0.20046532]\n",
      "[0.6016739, 0.2, 0.2003407, 0.200621]\n",
      "[0.6010305, 0.2, 0.20020534, 0.20011395]\n",
      "[0.6010095, 0.2, 0.2001612, 0.20013796]\n",
      "[0.6012057, 0.2, 0.20023534, 0.2002611]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6640 iterations: 1.8390244007110597 mins\n",
      "Train Loss: [0.6012057, 0.2, 0.20023534, 0.2002611]\n",
      "[0.6022405, 0.2, 0.20013705, 0.2013953]\n",
      "[0.6011905, 0.2, 0.2000263, 0.20045713]\n",
      "[0.60190016, 0.2, 0.200314, 0.20088011]\n",
      "[0.6019882, 0.2, 0.20107453, 0.20020871]\n",
      "[0.60142255, 0.2, 0.20023468, 0.20048374]\n",
      "[0.60103965, 0.2, 0.20014541, 0.20019075]\n",
      "[0.6013327, 0.2, 0.20031922, 0.20031038]\n",
      "[0.60197294, 0.2, 0.20056456, 0.20070565]\n",
      "[0.60156286, 0.2, 0.2006973, 0.20016314]\n",
      "[0.6013653, 0.2, 0.20016956, 0.20049345]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6650 iterations: 1.8408563137054443 mins\n",
      "Train Loss: [0.6013653, 0.2, 0.20016956, 0.20049345]\n",
      "[0.6011668, 0.2, 0.20019701, 0.2002673]\n",
      "[0.6012722, 0.2, 0.20044073, 0.20012891]\n",
      "[0.60124207, 0.2, 0.20023225, 0.20030728]\n",
      "[0.6020561, 0.2, 0.2007752, 0.2005786]\n",
      "[0.6022649, 0.2, 0.20098914, 0.20057356]\n",
      "[0.60158145, 0.2, 0.2002631, 0.20061645]\n",
      "[0.60154295, 0.2, 0.20036791, 0.20047337]\n",
      "[0.60138583, 0.2, 0.20024066, 0.20044371]\n",
      "[0.60129917, 0.2, 0.20002925, 0.2005686]\n",
      "[0.6013853, 0.2, 0.20037517, 0.20030911]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6660 iterations: 1.8430499156316122 mins\n",
      "Train Loss: [0.6013853, 0.2, 0.20037517, 0.20030911]\n",
      "[0.6010077, 0.2, 0.20010625, 0.20020077]\n",
      "[0.6011121, 0.2, 0.20014748, 0.20026417]\n",
      "[0.6010068, 0.2, 0.20022233, 0.2000843]\n",
      "[0.601412, 0.2, 0.20019688, 0.20051536]\n",
      "[0.6009882, 0.2, 0.20008788, 0.20020093]\n",
      "[0.60146636, 0.2, 0.20043175, 0.20033556]\n",
      "[0.60116166, 0.2, 0.20020449, 0.20025863]\n",
      "[0.60125756, 0.2, 0.20032033, 0.20023909]\n",
      "[0.6011334, 0.2, 0.20026027, 0.2001757]\n",
      "[0.60116863, 0.2, 0.20000014, 0.20047145]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6670 iterations: 1.8448661327362061 mins\n",
      "Train Loss: [0.60116863, 0.2, 0.20000014, 0.20047145]\n",
      "[0.6012117, 0.2, 0.20022368, 0.20029144]\n",
      "[0.601258, 0.2, 0.20037928, 0.20018242]\n",
      "[0.6014159, 0.2, 0.20055242, 0.20016761]\n",
      "[0.60119927, 0.2, 0.20026657, 0.20023744]\n",
      "[0.6009823, 0.2, 0.20000893, 0.20027874]\n",
      "[0.6011763, 0.2, 0.20029461, 0.2001877]\n",
      "[0.6013381, 0.2, 0.20021822, 0.20042646]\n",
      "[0.60119396, 0.2, 0.20018072, 0.20032059]\n",
      "[0.6011623, 0.2, 0.20023583, 0.20023456]\n",
      "[0.60100543, 0.2, 0.20010678, 0.20020768]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6680 iterations: 1.8472570657730103 mins\n",
      "Train Loss: [0.60100543, 0.2, 0.20010678, 0.20020768]\n",
      "[0.60116184, 0.2, 0.2002024, 0.20026962]\n",
      "[0.60126555, 0.2, 0.200472, 0.20010485]\n",
      "[0.60125387, 0.2, 0.20021948, 0.20034692]\n",
      "[0.6012853, 0.2, 0.20030065, 0.2002983]\n",
      "[0.6014185, 0.2, 0.20020868, 0.20052451]\n",
      "[0.6010309, 0.2, 0.20022145, 0.20012522]\n",
      "[0.6011491, 0.2, 0.20023017, 0.2002358]\n",
      "[0.6012096, 0.2, 0.20024036, 0.20028736]\n",
      "[0.60109013, 0.2, 0.20016742, 0.20024209]\n",
      "[0.6014371, 0.2, 0.2002559, 0.20050183]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6690 iterations: 1.8493424971898398 mins\n",
      "Train Loss: [0.6014371, 0.2, 0.2002559, 0.20050183]\n",
      "[0.60134876, 0.2, 0.20010215, 0.20056848]\n",
      "[0.6011774, 0.2, 0.20024064, 0.20025988]\n",
      "[0.6009279, 0.2, 0.20009157, 0.2001605]\n",
      "[0.60116374, 0.2, 0.20035508, 0.20013374]\n",
      "[0.601216, 0.2, 0.20040475, 0.20013721]\n",
      "[0.60110646, 0.2, 0.2001542, 0.20027903]\n",
      "[0.6011628, 0.2, 0.20021771, 0.20027259]\n",
      "[0.6015531, 0.2, 0.2001861, 0.20069537]\n",
      "[0.60108304, 0.2, 0.20040193, 0.20001015]\n",
      "[0.60108817, 0.2, 0.2001277, 0.20029008]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6700 iterations: 1.8511558492978415 mins\n",
      "Train Loss: [0.60108817, 0.2, 0.2001277, 0.20029008]\n",
      "[0.60113657, 0.2, 0.2004194, 0.20004727]\n",
      "[0.6015625, 0.2, 0.20040938, 0.20048364]\n",
      "[0.60113806, 0.2, 0.20020702, 0.20026205]\n",
      "[0.60100794, 0.2, 0.20013402, 0.20020519]\n",
      "[0.60098994, 0.2, 0.20012529, 0.20019591]\n",
      "[0.6013754, 0.2, 0.20032156, 0.20038468]\n",
      "[0.6011341, 0.2, 0.20018628, 0.20027803]\n",
      "[0.6012122, 0.2, 0.20015185, 0.20038983]\n",
      "[0.60117984, 0.2, 0.20017003, 0.2003386]\n",
      "[0.6014688, 0.2, 0.20042369, 0.20037325]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6710 iterations: 1.8531365156173707 mins\n",
      "Train Loss: [0.6014688, 0.2, 0.20042369, 0.20037325]\n",
      "[0.6012587, 0.2, 0.20036705, 0.20021914]\n",
      "[0.6011418, 0.2, 0.20002604, 0.20044258]\n",
      "[0.60128033, 0.2, 0.20030668, 0.20029972]\n",
      "[0.6013171, 0.2, 0.20018384, 0.20045887]\n",
      "[0.6014338, 0.2, 0.20048438, 0.2002748]\n",
      "[0.60117906, 0.2, 0.2001546, 0.20034958]\n",
      "[0.6014933, 0.2, 0.2002493, 0.20056884]\n",
      "[0.6017329, 0.2, 0.20014907, 0.20090859]\n",
      "[0.60137683, 0.2, 0.20046939, 0.20023265]\n",
      "[0.601908, 0.2, 0.20098788, 0.20024583]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6720 iterations: 1.855032479763031 mins\n",
      "Train Loss: [0.601908, 0.2, 0.20098788, 0.20024583]\n",
      "[0.6012202, 0.2, 0.20057797, 0.19996794]\n",
      "[0.6015574, 0.2, 0.20048451, 0.20039897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6011932, 0.2, 0.2002266, 0.2002927]\n",
      "[0.60131556, 0.2, 0.2003744, 0.20026693]\n",
      "[0.60147184, 0.2, 0.20043842, 0.20035836]\n",
      "[0.6012901, 0.2, 0.20027031, 0.20034386]\n",
      "[0.6012907, 0.2, 0.20027179, 0.20034182]\n",
      "[0.6009116, 0.2, 0.20007311, 0.20016009]\n",
      "[0.60141534, 0.2, 0.2006948, 0.20004062]\n",
      "[0.60256696, 0.2, 0.20137714, 0.20050861]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6730 iterations: 1.8569973150889079 mins\n",
      "Train Loss: [0.60256696, 0.2, 0.20137714, 0.20050861]\n",
      "[0.60176176, 0.2, 0.20031708, 0.20076217]\n",
      "[0.60213536, 0.2, 0.20122379, 0.20022795]\n",
      "[0.6012695, 0.2, 0.2005012, 0.20008399]\n",
      "[0.6017245, 0.2, 0.20028077, 0.20075835]\n",
      "[0.6014866, 0.2, 0.20044383, 0.2003559]\n",
      "[0.6010128, 0.2, 0.20027827, 0.20004606]\n",
      "[0.60117656, 0.2, 0.2002735, 0.20021285]\n",
      "[0.6017405, 0.2, 0.20060496, 0.20044336]\n",
      "[0.6011713, 0.2, 0.20012636, 0.20035148]\n",
      "[0.60187477, 0.2, 0.20031807, 0.20086138]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6740 iterations: 1.85885009765625 mins\n",
      "Train Loss: [0.60187477, 0.2, 0.20031807, 0.20086138]\n",
      "[0.6015337, 0.2, 0.20000035, 0.20083638]\n",
      "[0.6014593, 0.2, 0.20014383, 0.2006169]\n",
      "[0.60181653, 0.2, 0.2002145, 0.2009016]\n",
      "[0.60190547, 0.2, 0.20027453, 0.20092884]\n",
      "[0.60125387, 0.2, 0.20035249, 0.20019728]\n",
      "[0.6019144, 0.2, 0.20053157, 0.20067644]\n",
      "[0.6017456, 0.2, 0.20069721, 0.20033978]\n",
      "[0.6008765, 0.2, 0.20003054, 0.20013505]\n",
      "[0.602229, 0.2, 0.20083977, 0.20067589]\n",
      "[0.60219187, 0.2, 0.20044807, 0.20102799]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6750 iterations: 1.8608193000157673 mins\n",
      "Train Loss: [0.60219187, 0.2, 0.20044807, 0.20102799]\n",
      "[0.6016864, 0.2, 0.20026632, 0.20070171]\n",
      "[0.6018302, 0.2, 0.20030141, 0.20080782]\n",
      "[0.6022674, 0.2, 0.20051368, 0.20102987]\n",
      "[0.6014587, 0.2, 0.20033865, 0.20039324]\n",
      "[0.6016052, 0.2, 0.20026189, 0.20061365]\n",
      "[0.60158205, 0.2, 0.20053588, 0.20031369]\n",
      "[0.6015035, 0.2, 0.2006188, 0.20014969]\n",
      "[0.6016392, 0.2, 0.20078345, 0.20011833]\n",
      "[0.60195524, 0.2, 0.2005549, 0.2006607]\n",
      "[0.6018999, 0.2, 0.20013003, 0.2010282]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6760 iterations: 1.862912384668986 mins\n",
      "Train Loss: [0.6018999, 0.2, 0.20013003, 0.2010282]\n",
      "[0.60167605, 0.2, 0.20030819, 0.20062444]\n",
      "[0.6023011, 0.2, 0.20082384, 0.20073229]\n",
      "[0.60186213, 0.2, 0.2002588, 0.20085727]\n",
      "[0.60168594, 0.2, 0.20078465, 0.2001542]\n",
      "[0.601537, 0.2, 0.20056644, 0.20022257]\n",
      "[0.601598, 0.2, 0.20032544, 0.20052393]\n",
      "[0.6022473, 0.2, 0.2006416, 0.20085666]\n",
      "[0.60169286, 0.2, 0.20056099, 0.20038271]\n",
      "[0.60136545, 0.2, 0.20026395, 0.20035265]\n",
      "[0.602126, 0.2, 0.20082204, 0.20055558]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6770 iterations: 1.865251934528351 mins\n",
      "Train Loss: [0.602126, 0.2, 0.20082204, 0.20055558]\n",
      "[0.60236394, 0.2, 0.201017, 0.2005995]\n",
      "[0.6013926, 0.2, 0.20003416, 0.20061235]\n",
      "[0.6009555, 0.2, 0.20000063, 0.20021003]\n",
      "[0.60160005, 0.2, 0.20034169, 0.20051467]\n",
      "[0.60210145, 0.2, 0.20056106, 0.20079778]\n",
      "[0.6020998, 0.2, 0.20051722, 0.20084095]\n",
      "[0.60170215, 0.2, 0.20039178, 0.20056973]\n",
      "[0.6011598, 0.2, 0.20004368, 0.2003764]\n",
      "[0.6010611, 0.2, 0.20027082, 0.20005123]\n",
      "[0.60154825, 0.2, 0.2004282, 0.20038167]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6780 iterations: 1.8671455025672912 mins\n",
      "Train Loss: [0.60154825, 0.2, 0.2004282, 0.20038167]\n",
      "[0.60122323, 0.2, 0.20032342, 0.20016213]\n",
      "[0.6012527, 0.2, 0.20014147, 0.20037432]\n",
      "[0.60125357, 0.2, 0.20028219, 0.20023528]\n",
      "[0.60159993, 0.2, 0.2005343, 0.20033042]\n",
      "[0.6013542, 0.2, 0.20023069, 0.20038947]\n",
      "[0.60141784, 0.2, 0.20038003, 0.20030524]\n",
      "[0.6016288, 0.2, 0.2003109, 0.20058689]\n",
      "[0.60187733, 0.2, 0.20047235, 0.2006757]\n",
      "[0.6013431, 0.2, 0.20043302, 0.20018227]\n",
      "[0.60199326, 0.2, 0.20092216, 0.20034479]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6790 iterations: 1.8689688841501872 mins\n",
      "Train Loss: [0.60199326, 0.2, 0.20092216, 0.20034479]\n",
      "[0.60191065, 0.2, 0.20062663, 0.20055945]\n",
      "[0.60149634, 0.2, 0.20073713, 0.2000363]\n",
      "[0.6018769, 0.2, 0.20050013, 0.20065537]\n",
      "[0.6010284, 0.2, 0.20018566, 0.20012282]\n",
      "[0.6014615, 0.2, 0.20034714, 0.20039578]\n",
      "[0.60137516, 0.2, 0.2004192, 0.20023859]\n",
      "[0.6012035, 0.2, 0.20028612, 0.20020126]\n",
      "[0.6013052, 0.2, 0.20014949, 0.20044076]\n",
      "[0.60149145, 0.2, 0.20018607, 0.20059149]\n",
      "[0.60144216, 0.2, 0.20042685, 0.20030247]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6800 iterations: 1.8709440151850383 mins\n",
      "Train Loss: [0.60144216, 0.2, 0.20042685, 0.20030247]\n",
      "[0.6019607, 0.2, 0.20117244, 0.20007643]\n",
      "[0.6010005, 0.2, 0.2002783, 0.20001152]\n",
      "[0.60153365, 0.2, 0.20045629, 0.20036753]\n",
      "[0.6011192, 0.2, 0.20020847, 0.20020162]\n",
      "[0.60109335, 0.2, 0.200147, 0.2002378]\n",
      "[0.6011735, 0.2, 0.20016514, 0.20030044]\n",
      "[0.6012921, 0.2, 0.20018789, 0.2003968]\n",
      "[0.60128486, 0.2, 0.20025848, 0.20031935]\n",
      "[0.60156935, 0.2, 0.20040539, 0.20045713]\n",
      "[0.60157007, 0.2, 0.20016514, 0.2006982]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6810 iterations: 1.8728121320406597 mins\n",
      "Train Loss: [0.60157007, 0.2, 0.20016514, 0.2006982]\n",
      "[0.60136205, 0.2, 0.2003509, 0.2003044]\n",
      "[0.6010714, 0.2, 0.20024998, 0.20011492]\n",
      "[0.600984, 0.2, 0.20023552, 0.20004226]\n",
      "[0.60155356, 0.2, 0.20030463, 0.20054306]\n",
      "[0.600989, 0.2, 0.20013852, 0.20014492]\n",
      "[0.6016601, 0.2, 0.20009032, 0.20086446]\n",
      "[0.6011249, 0.2, 0.20023204, 0.20018812]\n",
      "[0.601423, 0.2, 0.20026463, 0.20045437]\n",
      "[0.60136205, 0.2, 0.20020312, 0.20045595]\n",
      "[0.6010167, 0.2, 0.2001887, 0.20012604]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6820 iterations: 1.874763548374176 mins\n",
      "Train Loss: [0.6010167, 0.2, 0.2001887, 0.20012604]\n",
      "[0.60148865, 0.2, 0.20018266, 0.20060506]\n",
      "[0.60117877, 0.2, 0.2002589, 0.20022018]\n",
      "[0.6010601, 0.2, 0.20019534, 0.20016627]\n",
      "[0.60106057, 0.2, 0.20020343, 0.20016006]\n",
      "[0.6016657, 0.2, 0.20016596, 0.20080395]\n",
      "[0.60129887, 0.2, 0.20037243, 0.2002319]\n",
      "[0.60160714, 0.2, 0.20017046, 0.20074336]\n",
      "[0.6009941, 0.2, 0.20009449, 0.20020737]\n",
      "[0.60128623, 0.2, 0.20030077, 0.20029436]\n",
      "[0.60092175, 0.2, 0.20011888, 0.2001129]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6830 iterations: 1.8766234318415325 mins\n",
      "Train Loss: [0.60092175, 0.2, 0.20011888, 0.2001129]\n",
      "[0.60120475, 0.2, 0.20022479, 0.20029116]\n",
      "[0.6010519, 0.2, 0.20016688, 0.20019753]\n",
      "[0.6011878, 0.2, 0.20016149, 0.20033999]\n",
      "[0.601166, 0.2, 0.20045038, 0.20003027]\n",
      "[0.6010129, 0.2, 0.20020427, 0.20012417]\n",
      "[0.6014755, 0.2, 0.20039976, 0.20039219]\n",
      "[0.60135716, 0.2, 0.20030963, 0.20036484]\n",
      "[0.6013506, 0.2, 0.20032884, 0.20033996]\n",
      "[0.60155606, 0.2, 0.20054135, 0.20033364]\n",
      "[0.6014301, 0.2, 0.2005286, 0.20022129]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6840 iterations: 1.878685430685679 mins\n",
      "Train Loss: [0.6014301, 0.2, 0.2005286, 0.20022129]\n",
      "[0.60139996, 0.2, 0.20000677, 0.20071399]\n",
      "[0.60110426, 0.2, 0.20014863, 0.20027754]\n",
      "[0.6012913, 0.2, 0.20020168, 0.20041268]\n",
      "[0.60126776, 0.2, 0.20032059, 0.20027146]\n",
      "[0.6011154, 0.2, 0.2002503, 0.20019051]\n",
      "[0.6011074, 0.2, 0.20015389, 0.20028012]\n",
      "[0.6014796, 0.2, 0.20030658, 0.20050068]\n",
      "[0.6010545, 0.2, 0.20012204, 0.20026119]\n",
      "[0.60106087, 0.2, 0.20027333, 0.20011725]\n",
      "[0.60127527, 0.2, 0.20006557, 0.2005402]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6850 iterations: 1.8816985686620076 mins\n",
      "Train Loss: [0.60127527, 0.2, 0.20006557, 0.2005402]\n",
      "[0.601311, 0.2, 0.2003228, 0.20031963]\n",
      "[0.6014191, 0.2, 0.20031552, 0.20043616]\n",
      "[0.60172135, 0.2, 0.20065281, 0.20040214]\n",
      "[0.60098946, 0.2, 0.20005624, 0.20026794]\n",
      "[0.6012899, 0.2, 0.20042601, 0.20019954]\n",
      "[0.60126203, 0.2, 0.20019779, 0.20040081]\n",
      "[0.6009953, 0.2, 0.20012444, 0.2002086]\n",
      "[0.6016859, 0.2, 0.200578, 0.20044674]\n",
      "[0.60101867, 0.2, 0.20027572, 0.20008309]\n",
      "[0.6017804, 0.2, 0.20057714, 0.20054458]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6860 iterations: 1.885452930132548 mins\n",
      "Train Loss: [0.6017804, 0.2, 0.20057714, 0.20054458]\n",
      "[0.60123295, 0.2, 0.20018588, 0.20038973]\n",
      "[0.60141784, 0.2, 0.20023018, 0.20053177]\n",
      "[0.60110635, 0.2, 0.20018935, 0.20026249]\n",
      "[0.60105336, 0.2, 0.20010984, 0.20029013]\n",
      "[0.6011794, 0.2, 0.20015441, 0.20037256]\n",
      "[0.60115993, 0.2, 0.2003035, 0.2002049]\n",
      "[0.6017058, 0.2, 0.2005048, 0.20055015]\n",
      "[0.60122216, 0.2, 0.20030896, 0.20026313]\n",
      "[0.60128945, 0.2, 0.20013775, 0.20050238]\n",
      "[0.6014861, 0.2, 0.20033509, 0.20050235]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6870 iterations: 1.8875072677930196 mins\n",
      "Train Loss: [0.6014861, 0.2, 0.20033509, 0.20050235]\n",
      "[0.6023206, 0.2, 0.2006698, 0.20100267]\n",
      "[0.6012207, 0.2, 0.20008428, 0.20048903]\n",
      "[0.6010436, 0.2, 0.2001432, 0.20025338]\n",
      "[0.60089546, 0.2, 0.20010181, 0.2001467]\n",
      "[0.60290235, 0.2, 0.20108028, 0.20117487]\n",
      "[0.60119975, 0.2, 0.20032129, 0.20023113]\n",
      "[0.60199577, 0.2, 0.20064254, 0.20070547]\n",
      "[0.6013512, 0.2, 0.20045319, 0.20024984]\n",
      "[0.6018312, 0.2, 0.20072122, 0.20046125]\n",
      "[0.6011668, 0.2, 0.20021497, 0.20030266]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6880 iterations: 1.889726750055949 mins\n",
      "Train Loss: [0.6011668, 0.2, 0.20021497, 0.20030266]\n",
      "[0.60143125, 0.2, 0.20044452, 0.20033696]\n",
      "[0.60184866, 0.2, 0.20054168, 0.2006565]\n",
      "[0.6016345, 0.2, 0.20036204, 0.20062141]\n",
      "[0.60112387, 0.2, 0.20025449, 0.20021771]\n",
      "[0.60127205, 0.2, 0.20023693, 0.20038265]\n",
      "[0.60156655, 0.2, 0.20041153, 0.2005017]\n",
      "[0.6016286, 0.2, 0.2006137, 0.20036067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6013397, 0.2, 0.20019396, 0.20049044]\n",
      "[0.6012486, 0.2, 0.20043789, 0.2001544]\n",
      "[0.6014509, 0.2, 0.20025022, 0.20054328]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6890 iterations: 1.8937268654505413 mins\n",
      "Train Loss: [0.6014509, 0.2, 0.20025022, 0.20054328]\n",
      "[0.60166395, 0.2, 0.20045248, 0.20055309]\n",
      "[0.6015566, 0.2, 0.200295, 0.20060222]\n",
      "[0.6013166, 0.2, 0.20029831, 0.20035782]\n",
      "[0.602147, 0.2, 0.20053093, 0.20095429]\n",
      "[0.6015714, 0.2, 0.20028329, 0.200625]\n",
      "[0.6013355, 0.2, 0.20052554, 0.20014548]\n",
      "[0.60154504, 0.2, 0.20055705, 0.20032196]\n",
      "[0.60233736, 0.2, 0.20095684, 0.20071287]\n",
      "[0.601532, 0.2, 0.200329, 0.20053382]\n",
      "[0.6013422, 0.2, 0.20034528, 0.20032601]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6900 iterations: 1.896233566602071 mins\n",
      "Train Loss: [0.6013422, 0.2, 0.20034528, 0.20032601]\n",
      "[0.6016025, 0.2, 0.20028552, 0.20064422]\n",
      "[0.60151917, 0.2, 0.2003861, 0.20045845]\n",
      "[0.60103136, 0.2, 0.2003445, 0.20001043]\n",
      "[0.6014769, 0.2, 0.20020097, 0.20059766]\n",
      "[0.60101336, 0.2, 0.20018268, 0.2001506]\n",
      "[0.6015889, 0.2, 0.20011663, 0.20079054]\n",
      "[0.6014142, 0.2, 0.20025004, 0.2004809]\n",
      "[0.60153764, 0.2, 0.2003321, 0.20052099]\n",
      "[0.60136354, 0.2, 0.2002827, 0.20039512]\n",
      "[0.6011078, 0.2, 0.20018606, 0.20023504]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6910 iterations: 1.8985076506932577 mins\n",
      "Train Loss: [0.6011078, 0.2, 0.20018606, 0.20023504]\n",
      "[0.6012568, 0.2, 0.20032957, 0.2002399]\n",
      "[0.6016701, 0.2, 0.2004245, 0.20055783]\n",
      "[0.6012641, 0.2, 0.20026398, 0.20031203]\n",
      "[0.6012005, 0.2, 0.20022202, 0.20029005]\n",
      "[0.60121095, 0.2, 0.20039593, 0.20012629]\n",
      "[0.6015882, 0.2, 0.20050927, 0.20039004]\n",
      "[0.60140955, 0.2, 0.20034899, 0.20037185]\n",
      "[0.6011668, 0.2, 0.20022063, 0.20025752]\n",
      "[0.60092825, 0.2, 0.20011377, 0.20012611]\n",
      "[0.6011331, 0.2, 0.20030318, 0.20014183]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6920 iterations: 1.9005051016807557 mins\n",
      "Train Loss: [0.6011331, 0.2, 0.20030318, 0.20014183]\n",
      "[0.6027817, 0.2, 0.20160086, 0.20049314]\n",
      "[0.60122, 0.2, 0.20026202, 0.20027089]\n",
      "[0.6015128, 0.2, 0.20039436, 0.20043178]\n",
      "[0.60147065, 0.2, 0.20032507, 0.20045952]\n",
      "[0.601207, 0.2, 0.20022789, 0.20029368]\n",
      "[0.6012841, 0.2, 0.20024112, 0.2003582]\n",
      "[0.6016478, 0.2, 0.20033042, 0.20063327]\n",
      "[0.6012786, 0.2, 0.20037983, 0.20021553]\n",
      "[0.6012154, 0.2, 0.20028806, 0.2002451]\n",
      "[0.6012985, 0.2, 0.2003793, 0.20023802]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6930 iterations: 1.9025127172470093 mins\n",
      "Train Loss: [0.6012985, 0.2, 0.2003793, 0.20023802]\n",
      "[0.601114, 0.2, 0.20026283, 0.20017114]\n",
      "[0.6010696, 0.2, 0.20019358, 0.20019718]\n",
      "[0.6013059, 0.2, 0.20024575, 0.20038244]\n",
      "[0.6013719, 0.2, 0.2003428, 0.20035268]\n",
      "[0.60115445, 0.2, 0.20016138, 0.20031802]\n",
      "[0.60121995, 0.2, 0.20036682, 0.20017956]\n",
      "[0.6016214, 0.2, 0.20034608, 0.20060334]\n",
      "[0.60103405, 0.2, 0.20008329, 0.20028068]\n",
      "[0.601384, 0.2, 0.20051855, 0.20019718]\n",
      "[0.6012943, 0.2, 0.20010753, 0.20052032]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6940 iterations: 1.9045754154523213 mins\n",
      "Train Loss: [0.6012943, 0.2, 0.20010753, 0.20052032]\n",
      "[0.60138726, 0.2, 0.20058747, 0.20013519]\n",
      "[0.6010278, 0.2, 0.20008686, 0.2002781]\n",
      "[0.6008708, 0.2, 0.20004365, 0.20016582]\n",
      "[0.60102296, 0.2, 0.20026046, 0.20010237]\n",
      "[0.60100245, 0.2, 0.20016709, 0.20017637]\n",
      "[0.6011791, 0.2, 0.20031168, 0.20020956]\n",
      "[0.60111964, 0.2, 0.20037152, 0.2000912]\n",
      "[0.6009605, 0.2, 0.20013241, 0.20017214]\n",
      "[0.60085505, 0.2, 0.20000012, 0.20019996]\n",
      "[0.6009045, 0.2, 0.20000005, 0.20025033]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6950 iterations: 1.9064178665479024 mins\n",
      "Train Loss: [0.6009045, 0.2, 0.20000005, 0.20025033]\n",
      "[0.6014494, 0.2, 0.20039998, 0.20039593]\n",
      "[0.60143465, 0.2, 0.2003698, 0.20041224]\n",
      "[0.6011529, 0.2, 0.2003882, 0.2001127]\n",
      "[0.60111916, 0.2, 0.2001871, 0.20028052]\n",
      "[0.6016959, 0.2, 0.20030044, 0.20074442]\n",
      "[0.60162663, 0.2, 0.20015574, 0.20082039]\n",
      "[0.6008697, 0.2, 0.20004995, 0.2001696]\n",
      "[0.6009995, 0.2, 0.20004573, 0.20030381]\n",
      "[0.6010098, 0.2, 0.20037471, 0.19998533]\n",
      "[0.60083055, 0.2, 0.20015788, 0.20002319]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6960 iterations: 1.9084761182467143 mins\n",
      "Train Loss: [0.60083055, 0.2, 0.20015788, 0.20002319]\n",
      "[0.6011849, 0.2, 0.20022534, 0.20031027]\n",
      "[0.6020361, 0.2, 0.20045884, 0.20092835]\n",
      "[0.6019753, 0.2, 0.20063038, 0.20069653]\n",
      "[0.60138834, 0.2, 0.20006144, 0.20067911]\n",
      "[0.6010778, 0.2, 0.20014833, 0.2002823]\n",
      "[0.6009303, 0.2, 0.20008615, 0.20019773]\n",
      "[0.60095155, 0.2, 0.20018911, 0.20011671]\n",
      "[0.601164, 0.2, 0.20027976, 0.20023905]\n",
      "[0.60141075, 0.2, 0.20051207, 0.20025428]\n",
      "[0.6013139, 0.2, 0.20026638, 0.20040394]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6970 iterations: 1.9103099981943765 mins\n",
      "Train Loss: [0.6013139, 0.2, 0.20026638, 0.20040394]\n",
      "[0.6013821, 0.2, 0.20031074, 0.20042874]\n",
      "[0.60133266, 0.2, 0.20039895, 0.20029218]\n",
      "[0.60142154, 0.2, 0.20032232, 0.20045884]\n",
      "[0.6017376, 0.2, 0.20029804, 0.20080027]\n",
      "[0.60136133, 0.2, 0.20028365, 0.2004391]\n",
      "[0.60165703, 0.2, 0.20033996, 0.20067912]\n",
      "[0.6013618, 0.2, 0.20030884, 0.20041579]\n",
      "[0.60122746, 0.2, 0.20034555, 0.2002455]\n",
      "[0.60119945, 0.2, 0.20030352, 0.20026043]\n",
      "[0.60110146, 0.2, 0.20024903, 0.2002179]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6980 iterations: 1.9123070001602174 mins\n",
      "Train Loss: [0.60110146, 0.2, 0.20024903, 0.2002179]\n",
      "[0.6009623, 0.2, 0.20027012, 0.20005874]\n",
      "[0.60190254, 0.2, 0.20022126, 0.2010489]\n",
      "[0.60108674, 0.2, 0.20024072, 0.20021512]\n",
      "[0.6023044, 0.2, 0.20032702, 0.20134774]\n",
      "[0.60136956, 0.2, 0.20032309, 0.20041803]\n",
      "[0.6011071, 0.2, 0.20029713, 0.20018245]\n",
      "[0.6014363, 0.2, 0.20052063, 0.20028895]\n",
      "[0.6010446, 0.2, 0.20032974, 0.2000886]\n",
      "[0.60194224, 0.2, 0.2002812, 0.20103505]\n",
      "[0.6010208, 0.2, 0.200112, 0.20028336]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6990 iterations: 1.914113982518514 mins\n",
      "Train Loss: [0.6010208, 0.2, 0.200112, 0.20028336]\n",
      "[0.60197496, 0.2, 0.20091482, 0.20043513]\n",
      "[0.60188717, 0.2, 0.200204, 0.20105879]\n",
      "[0.6013264, 0.2, 0.20023653, 0.20046607]\n",
      "[0.60083985, 0.2, 0.20000017, 0.20021623]\n",
      "[0.60137147, 0.2, 0.20026137, 0.20048653]\n",
      "[0.60212713, 0.2, 0.20089082, 0.20061225]\n",
      "[0.6020174, 0.2, 0.20049872, 0.20089397]\n",
      "[0.60120124, 0.2, 0.20040703, 0.20016846]\n",
      "[0.6012171, 0.2, 0.20030154, 0.20028809]\n",
      "[0.6015204, 0.2, 0.20031993, 0.20057084]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7000 iterations: 1.9167430639266967 mins\n",
      "Train Loss: [0.6015204, 0.2, 0.20031993, 0.20057084]\n",
      "[0.6010556, 0.2, 0.20033956, 0.20008406]\n",
      "[0.6011828, 0.2, 0.20034735, 0.20020087]\n",
      "[0.6014354, 0.2, 0.20020668, 0.20059153]\n",
      "[0.6014912, 0.2, 0.20059848, 0.20025305]\n",
      "[0.6024639, 0.2, 0.20059702, 0.20122476]\n",
      "[0.60147196, 0.2, 0.20054373, 0.20028393]\n",
      "[0.6012775, 0.2, 0.2003873, 0.20024401]\n",
      "[0.6010353, 0.2, 0.2001166, 0.20027082]\n",
      "[0.60110384, 0.2, 0.20025657, 0.20019783]\n",
      "[0.6012223, 0.2, 0.2000003, 0.20057122]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7010 iterations: 1.9187804341316224 mins\n",
      "Train Loss: [0.6012223, 0.2, 0.2000003, 0.20057122]\n",
      "[0.60101694, 0.2, 0.20019028, 0.20017499]\n",
      "[0.60139805, 0.2, 0.20003341, 0.20071225]\n",
      "[0.6010966, 0.2, 0.2001162, 0.20032771]\n",
      "[0.60294, 0.2, 0.20178467, 0.20050262]\n",
      "[0.60122174, 0.2, 0.20031539, 0.20025389]\n",
      "[0.60180944, 0.2, 0.20021963, 0.2009377]\n",
      "[0.6012764, 0.2, 0.20016332, 0.20046131]\n",
      "[0.60141736, 0.2, 0.20049515, 0.20027074]\n",
      "[0.6011832, 0.2, 0.20033257, 0.20019965]\n",
      "[0.60126096, 0.2, 0.2002283, 0.20038205]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7020 iterations: 1.9206558823585511 mins\n",
      "Train Loss: [0.60126096, 0.2, 0.2002283, 0.20038205]\n",
      "[0.60084033, 0.2, 0.2001628, 0.20002729]\n",
      "[0.60128284, 0.2, 0.20020272, 0.20043035]\n",
      "[0.6011718, 0.2, 0.20044969, 0.20007308]\n",
      "[0.6019881, 0.2, 0.20043524, 0.20090467]\n",
      "[0.6026274, 0.2, 0.20027582, 0.20170447]\n",
      "[0.60149527, 0.2, 0.20028178, 0.2005676]\n",
      "[0.602173, 0.2, 0.20087987, 0.20064819]\n",
      "[0.60110563, 0.2, 0.20018722, 0.20027451]\n",
      "[0.60146403, 0.2, 0.20023808, 0.20058301]\n",
      "[0.6019999, 0.2, 0.20069347, 0.20066446]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7030 iterations: 1.9226427356402078 mins\n",
      "Train Loss: [0.6019999, 0.2, 0.20069347, 0.20066446]\n",
      "[0.60144943, 0.2, 0.200244, 0.2005647]\n",
      "[0.6016779, 0.2, 0.20026119, 0.20077729]\n",
      "[0.6012294, 0.2, 0.20009734, 0.20049377]\n",
      "[0.6007933, 0.2, 0.2, 0.20015615]\n",
      "[0.6017099, 0.2, 0.20084974, 0.2002242]\n",
      "[0.6010166, 0.2, 0.20025593, 0.20012623]\n",
      "[0.60125893, 0.2, 0.20045076, 0.20017537]\n",
      "[0.60123533, 0.2, 0.20013738, 0.2004668]\n",
      "[0.60128605, 0.2, 0.20014383, 0.20051275]\n",
      "[0.60107154, 0.2, 0.2003117, 0.20013179]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7040 iterations: 1.924492100874583 mins\n",
      "Train Loss: [0.60107154, 0.2, 0.2003117, 0.20013179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6013083, 0.2, 0.20032409, 0.20035736]\n",
      "[0.6011334, 0.2, 0.20027606, 0.2002317]\n",
      "[0.6014322, 0.2, 0.20029059, 0.20051692]\n",
      "[0.6011767, 0.2, 0.2003493, 0.20020387]\n",
      "[0.6010717, 0.2, 0.20021777, 0.20023152]\n",
      "[0.60156757, 0.2, 0.20023887, 0.20070757]\n",
      "[0.6011979, 0.2, 0.20018493, 0.2003932]\n",
      "[0.6010207, 0.2, 0.20019312, 0.20020908]\n",
      "[0.6009009, 0.2, 0.20013757, 0.20014623]\n",
      "[0.6009661, 0.2, 0.20013966, 0.20021072]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7050 iterations: 1.9265654802322387 mins\n",
      "Train Loss: [0.6009661, 0.2, 0.20013966, 0.20021072]\n",
      "[0.6010444, 0.2, 0.20022774, 0.20020242]\n",
      "[0.6008028, 0.2, 0.20010568, 0.20008434]\n",
      "[0.6012801, 0.2, 0.20032717, 0.20034175]\n",
      "[0.60120904, 0.2, 0.20031266, 0.20028697]\n",
      "[0.6008387, 0.2, 0.20018995, 0.20004123]\n",
      "[0.6009094, 0.2, 0.20011102, 0.20019275]\n",
      "[0.6008738, 0.2, 0.20016298, 0.20010711]\n",
      "[0.60093087, 0.2, 0.20010495, 0.20022412]\n",
      "[0.60113317, 0.2, 0.20045021, 0.20008314]\n",
      "[0.60092074, 0.2, 0.20008296, 0.20024]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7060 iterations: 1.9285985986391703 mins\n",
      "Train Loss: [0.60092074, 0.2, 0.20008296, 0.20024]\n",
      "[0.6007812, 0.2, 0.20010354, 0.20008168]\n",
      "[0.6008285, 0.2, 0.20015669, 0.20007761]\n",
      "[0.60103214, 0.2, 0.20018274, 0.20025676]\n",
      "[0.60095817, 0.2, 0.2001375, 0.20022957]\n",
      "[0.6008304, 0.2, 0.20021084, 0.20002992]\n",
      "[0.6010066, 0.2, 0.20013481, 0.2002836]\n",
      "[0.6009283, 0.2, 0.20022522, 0.20011598]\n",
      "[0.6008207, 0.2, 0.20010476, 0.20012991]\n",
      "[0.60109794, 0.2, 0.20023185, 0.20028107]\n",
      "[0.6006949, 0.2, 0.20012055, 0.19999033]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7070 iterations: 1.9308692495028177 mins\n",
      "Train Loss: [0.6006949, 0.2, 0.20012055, 0.19999033]\n",
      "[0.60124946, 0.2, 0.20044689, 0.20021965]\n",
      "[0.60104316, 0.2, 0.20031011, 0.20015126]\n",
      "[0.6010453, 0.2, 0.20009916, 0.2003655]\n",
      "[0.6008885, 0.2, 0.20013514, 0.20017372]\n",
      "[0.600877, 0.2, 0.20009746, 0.20020099]\n",
      "[0.6011592, 0.2, 0.20026664, 0.20031501]\n",
      "[0.6011172, 0.2, 0.20032705, 0.20021358]\n",
      "[0.6007406, 0.2, 0.20013754, 0.20002751]\n",
      "[0.6007556, 0.2, 0.20006442, 0.20011657]\n",
      "[0.60080636, 0.2, 0.20009945, 0.20013334]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7080 iterations: 1.9328936020533243 mins\n",
      "Train Loss: [0.60080636, 0.2, 0.20009945, 0.20013334]\n",
      "[0.6011915, 0.2, 0.2004232, 0.20019571]\n",
      "[0.6015624, 0.2, 0.20047507, 0.20051566]\n",
      "[0.6007747, 0.2, 0.20009397, 0.20011038]\n",
      "[0.6027725, 0.2, 0.20173034, 0.20047297]\n",
      "[0.6008217, 0.2, 0.2000636, 0.20019026]\n",
      "[0.6007855, 0.2, 0.20013256, 0.20008636]\n",
      "[0.60112256, 0.2, 0.20034382, 0.2002132]\n",
      "[0.60105264, 0.2, 0.2002112, 0.20027703]\n",
      "[0.60117126, 0.2, 0.20031294, 0.20029506]\n",
      "[0.60105354, 0.2, 0.20018315, 0.20030826]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7090 iterations: 1.934701418876648 mins\n",
      "Train Loss: [0.60105354, 0.2, 0.20018315, 0.20030826]\n",
      "[0.601002, 0.2, 0.20016782, 0.20027316]\n",
      "[0.6009896, 0.2, 0.20017567, 0.20025396]\n",
      "[0.60093296, 0.2, 0.200201, 0.20017324]\n",
      "[0.60081273, 0.2, 0.20008887, 0.20016643]\n",
      "[0.60083467, 0.2, 0.20010397, 0.20017445]\n",
      "[0.6006804, 0.2, 0.20003958, 0.2000857]\n",
      "[0.60112107, 0.2, 0.20023164, 0.20033543]\n",
      "[0.6008572, 0.2, 0.20012374, 0.20018056]\n",
      "[0.60088044, 0.2, 0.20015447, 0.20017415]\n",
      "[0.6007891, 0.2, 0.20006019, 0.20017819]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7100 iterations: 1.9368189970652263 mins\n",
      "Train Loss: [0.6007891, 0.2, 0.20006019, 0.20017819]\n",
      "[0.6007684, 0.2, 0.20002128, 0.20019741]\n",
      "[0.60124147, 0.2, 0.20035551, 0.20033732]\n",
      "[0.6011488, 0.2, 0.20034252, 0.20025876]\n",
      "[0.6008986, 0.2, 0.20014903, 0.20020321]\n",
      "[0.6007574, 0.2, 0.20012212, 0.20008992]\n",
      "[0.60084534, 0.2, 0.20011337, 0.20018756]\n",
      "[0.60100293, 0.2, 0.20021948, 0.20023982]\n",
      "[0.6009043, 0.2, 0.20016278, 0.20019877]\n",
      "[0.6010069, 0.2, 0.20012105, 0.200344]\n",
      "[0.6007899, 0.2, 0.2001712, 0.20007764]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7110 iterations: 1.9386693000793458 mins\n",
      "Train Loss: [0.6007899, 0.2, 0.2001712, 0.20007764]\n",
      "[0.60093707, 0.2, 0.20029777, 0.20009908]\n",
      "[0.60108405, 0.2, 0.20007876, 0.20046584]\n",
      "[0.6008632, 0.2, 0.20017907, 0.20014532]\n",
      "[0.60096496, 0.2, 0.20013453, 0.20029216]\n",
      "[0.6010448, 0.2, 0.20014086, 0.20036614]\n",
      "[0.60096484, 0.2, 0.20017375, 0.20025375]\n",
      "[0.60089767, 0.2, 0.20015751, 0.20020328]\n",
      "[0.6009219, 0.2, 0.20021912, 0.20016651]\n",
      "[0.60081017, 0.2, 0.20007686, 0.20019773]\n",
      "[0.6008898, 0.2, 0.20028174, 0.2000732]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7120 iterations: 1.9405480821927388 mins\n",
      "Train Loss: [0.6008898, 0.2, 0.20028174, 0.2000732]\n",
      "[0.60098153, 0.2, 0.2000821, 0.20036526]\n",
      "[0.60102075, 0.2, 0.20016173, 0.20032568]\n",
      "[0.6011587, 0.2, 0.20046467, 0.20016152]\n",
      "[0.60091203, 0.2, 0.20019206, 0.20018831]\n",
      "[0.6008301, 0.2, 0.20015441, 0.20014498]\n",
      "[0.6007863, 0.2, 0.20008752, 0.20016897]\n",
      "[0.6008271, 0.2, 0.20011547, 0.20018262]\n",
      "[0.6008013, 0.2, 0.20015451, 0.20011877]\n",
      "[0.6010157, 0.2, 0.2002356, 0.2002532]\n",
      "[0.6010598, 0.2, 0.20023845, 0.20029563]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7130 iterations: 1.9426704009373983 mins\n",
      "Train Loss: [0.6010598, 0.2, 0.20023845, 0.20029563]\n",
      "[0.60088074, 0.2, 0.20011738, 0.20023881]\n",
      "[0.60100424, 0.2, 0.20030837, 0.20017257]\n",
      "[0.600875, 0.2, 0.20016623, 0.20018668]\n",
      "[0.6008994, 0.2, 0.20020854, 0.20016988]\n",
      "[0.6009544, 0.2, 0.20015022, 0.20028433]\n",
      "[0.60090834, 0.2, 0.20006339, 0.20032607]\n",
      "[0.60077393, 0.2, 0.20005806, 0.20019801]\n",
      "[0.6011622, 0.2, 0.20025869, 0.20038658]\n",
      "[0.600853, 0.2, 0.20026867, 0.20006856]\n",
      "[0.6010095, 0.2, 0.20022981, 0.20026502]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7140 iterations: 1.9444627324740091 mins\n",
      "Train Loss: [0.6010095, 0.2, 0.20022981, 0.20026502]\n",
      "[0.6010516, 0.2, 0.20019092, 0.20034724]\n",
      "[0.6005896, 0.2, 0.20000002, 0.200077]\n",
      "[0.6009321, 0.2, 0.20010157, 0.20031895]\n",
      "[0.60089666, 0.2, 0.20006153, 0.20032443]\n",
      "[0.6009417, 0.2, 0.20012233, 0.20030949]\n",
      "[0.601201, 0.2, 0.20035514, 0.20033668]\n",
      "[0.6008138, 0.2, 0.20013711, 0.20016852]\n",
      "[0.6013307, 0.2, 0.2003399, 0.20048374]\n",
      "[0.6009213, 0.2, 0.20013796, 0.20027722]\n",
      "[0.601006, 0.2, 0.20023565, 0.20026504]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7150 iterations: 1.9464395999908448 mins\n",
      "Train Loss: [0.601006, 0.2, 0.20023565, 0.20026504]\n",
      "[0.6007964, 0.2, 0.20012744, 0.20016445]\n",
      "[0.60091966, 0.2, 0.2003142, 0.20010161]\n",
      "[0.6009576, 0.2, 0.20021449, 0.20023979]\n",
      "[0.60075957, 0.2, 0.20013635, 0.20012046]\n",
      "[0.60079235, 0.2, 0.20000003, 0.20029008]\n",
      "[0.6006514, 0.2, 0.2, 0.20014977]\n",
      "[0.60134125, 0.2, 0.20040007, 0.20044014]\n",
      "[0.60086966, 0.2, 0.2001082, 0.20026124]\n",
      "[0.60091317, 0.2, 0.20020632, 0.20020752]\n",
      "[0.60092956, 0.2, 0.20015097, 0.2002803]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7160 iterations: 1.9488080143928528 mins\n",
      "Train Loss: [0.60092956, 0.2, 0.20015097, 0.2002803]\n",
      "[0.60090375, 0.2, 0.20025034, 0.20015606]\n",
      "[0.6010019, 0.2, 0.20026448, 0.20024107]\n",
      "[0.6006214, 0.2, 0.20009723, 0.20002891]\n",
      "[0.6008496, 0.2, 0.20018575, 0.20016968]\n",
      "[0.6008635, 0.2, 0.2002168, 0.2001536]\n",
      "[0.6007109, 0.2, 0.2001684, 0.20005058]\n",
      "[0.60091966, 0.2, 0.2001216, 0.20030726]\n",
      "[0.60082775, 0.2, 0.20012417, 0.2002138]\n",
      "[0.60121113, 0.2, 0.20041247, 0.20030986]\n",
      "[0.6010233, 0.2, 0.20020947, 0.20032609]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7170 iterations: 1.9507934172948203 mins\n",
      "Train Loss: [0.6010233, 0.2, 0.20020947, 0.20032609]\n",
      "[0.6007956, 0.2, 0.20020245, 0.20010652]\n",
      "[0.6006232, 0.2, 0.20000006, 0.20013747]\n",
      "[0.6008494, 0.2, 0.20012459, 0.20024003]\n",
      "[0.60070676, 0.2, 0.20008905, 0.20013385]\n",
      "[0.600731, 0.2, 0.20016061, 0.20008737]\n",
      "[0.60078096, 0.2, 0.20017825, 0.20012058]\n",
      "[0.6006894, 0.2, 0.2001095, 0.2000986]\n",
      "[0.60075456, 0.2, 0.20012386, 0.20015016]\n",
      "[0.6007793, 0.2, 0.2001642, 0.20013537]\n",
      "[0.60100746, 0.2, 0.20014484, 0.20038362]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7180 iterations: 1.9526852011680602 mins\n",
      "Train Loss: [0.60100746, 0.2, 0.20014484, 0.20038362]\n",
      "[0.6011813, 0.2, 0.20025058, 0.20045269]\n",
      "[0.60078, 0.2, 0.20013696, 0.20016572]\n",
      "[0.6008033, 0.2, 0.2002471, 0.20007974]\n",
      "[0.6007555, 0.2, 0.20012742, 0.20015244]\n",
      "[0.6007755, 0.2, 0.2000957, 0.20020492]\n",
      "[0.6006578, 0.2, 0.20008168, 0.20010197]\n",
      "[0.6007987, 0.2, 0.20013468, 0.20019053]\n",
      "[0.60082656, 0.2, 0.20012157, 0.2002322]\n",
      "[0.60142606, 0.2, 0.20012891, 0.20082511]\n",
      "[0.60091573, 0.2, 0.2003009, 0.20014308]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7190 iterations: 1.9545990188916524 mins\n",
      "Train Loss: [0.60091573, 0.2, 0.2003009, 0.20014308]\n",
      "[0.600671, 0.2, 0.20006995, 0.20012982]\n",
      "[0.6007598, 0.2, 0.20005666, 0.20023239]\n",
      "[0.6010284, 0.2, 0.20026675, 0.20029148]\n",
      "[0.6015053, 0.2, 0.20018378, 0.20085213]\n",
      "[0.60063607, 0.2, 0.20010673, 0.20006055]\n",
      "[0.6011785, 0.2, 0.20029111, 0.20041929]\n",
      "[0.6009537, 0.2, 0.200247, 0.20023917]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60082793, 0.2, 0.20012978, 0.20023124]\n",
      "[0.60078245, 0.2, 0.2001509, 0.20016526]\n",
      "[0.60086495, 0.2, 0.20026058, 0.20013884]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7200 iterations: 1.9566557168960572 mins\n",
      "Train Loss: [0.60086495, 0.2, 0.20026058, 0.20013884]\n",
      "[0.6008316, 0.2, 0.20013782, 0.20022881]\n",
      "[0.60068846, 0.2, 0.2000327, 0.20019129]\n",
      "[0.6006398, 0.2, 0.20021921, 0.19995672]\n",
      "[0.60086685, 0.2, 0.20019008, 0.20021325]\n",
      "[0.60063857, 0.2, 0.20008352, 0.20009199]\n",
      "[0.6010079, 0.2, 0.20014906, 0.20039621]\n",
      "[0.60094637, 0.2, 0.20019576, 0.20028861]\n",
      "[0.601025, 0.2, 0.2003131, 0.20025046]\n",
      "[0.60083324, 0.2, 0.20014454, 0.20022805]\n",
      "[0.6006359, 0.2, 0.20012058, 0.2000554]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7210 iterations: 1.958478319644928 mins\n",
      "Train Loss: [0.6006359, 0.2, 0.20012058, 0.2000554]\n",
      "[0.6009064, 0.2, 0.20022607, 0.20022109]\n",
      "[0.60083437, 0.2, 0.20011446, 0.20026141]\n",
      "[0.6009891, 0.2, 0.20021442, 0.20031694]\n",
      "[0.60065806, 0.2, 0.20006275, 0.20013814]\n",
      "[0.6011911, 0.2, 0.20026217, 0.20047233]\n",
      "[0.6009358, 0.2, 0.20022453, 0.20025533]\n",
      "[0.60074985, 0.2, 0.20007089, 0.20022362]\n",
      "[0.60094285, 0.2, 0.20030983, 0.20017838]\n",
      "[0.60080504, 0.2, 0.20018867, 0.20016238]\n",
      "[0.6005846, 0.2, 0.20005612, 0.20007516]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7220 iterations: 1.9605357329050699 mins\n",
      "Train Loss: [0.6005846, 0.2, 0.20005612, 0.20007516]\n",
      "[0.60100806, 0.2, 0.20029475, 0.20026061]\n",
      "[0.60114855, 0.2, 0.20038223, 0.20031424]\n",
      "[0.60083395, 0.2, 0.20011906, 0.20026344]\n",
      "[0.60095096, 0.2, 0.20012037, 0.20037985]\n",
      "[0.6009643, 0.2, 0.2003815, 0.2001328]\n",
      "[0.6006095, 0.2, 0.2001185, 0.20004174]\n",
      "[0.6006198, 0.2, 0.20008892, 0.20008229]\n",
      "[0.6014828, 0.2, 0.20014057, 0.2008942]\n",
      "[0.6012654, 0.2, 0.2, 0.20081775]\n",
      "[0.60080475, 0.2, 0.2002184, 0.20013887]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7230 iterations: 1.9623069008191427 mins\n",
      "Train Loss: [0.60080475, 0.2, 0.2002184, 0.20013887]\n",
      "[0.6007681, 0.2, 0.20007725, 0.20024331]\n",
      "[0.60073525, 0.2, 0.20008893, 0.20019837]\n",
      "[0.60129905, 0.2, 0.2002295, 0.2006208]\n",
      "[0.6009215, 0.2, 0.20037626, 0.20009585]\n",
      "[0.6007639, 0.2, 0.20014511, 0.20016886]\n",
      "[0.60077107, 0.2, 0.20017979, 0.20014068]\n",
      "[0.60107034, 0.2, 0.20049813, 0.20012093]\n",
      "[0.6008284, 0.2, 0.20022932, 0.20014726]\n",
      "[0.60093796, 0.2, 0.20015796, 0.20032753]\n",
      "[0.6010908, 0.2, 0.20051283, 0.20012484]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7240 iterations: 1.9648467818895976 mins\n",
      "Train Loss: [0.6010908, 0.2, 0.20051283, 0.20012484]\n",
      "[0.6007281, 0.2, 0.20009139, 0.20018311]\n",
      "[0.60114735, 0.2, 0.20036978, 0.20032339]\n",
      "[0.602507, 0.2, 0.20176034, 0.20029213]\n",
      "[0.600868, 0.2, 0.20012794, 0.20028527]\n",
      "[0.60103333, 0.2, 0.20019759, 0.20038052]\n",
      "[0.60087746, 0.2, 0.20033252, 0.20008937]\n",
      "[0.60094947, 0.2, 0.2003563, 0.20013724]\n",
      "[0.6009029, 0.2, 0.20008814, 0.20035864]\n",
      "[0.6008649, 0.2, 0.20010322, 0.20030536]\n",
      "[0.6008673, 0.2, 0.20036401, 0.20004672]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7250 iterations: 1.96675994793574 mins\n",
      "Train Loss: [0.6008673, 0.2, 0.20036401, 0.20004672]\n",
      "[0.6006269, 0.2, 0.20007586, 0.20009436]\n",
      "[0.6010109, 0.2, 0.20030943, 0.20024449]\n",
      "[0.60082656, 0.2, 0.20017302, 0.20019634]\n",
      "[0.6013332, 0.2, 0.20042334, 0.20045231]\n",
      "[0.6010676, 0.2, 0.20025301, 0.20035678]\n",
      "[0.6007256, 0.2, 0.20020433, 0.20006302]\n",
      "[0.60096866, 0.2, 0.2002759, 0.20023406]\n",
      "[0.60094243, 0.2, 0.20037349, 0.20010965]\n",
      "[0.6012371, 0.2, 0.20048621, 0.2002909]\n",
      "[0.60140485, 0.2, 0.20065385, 0.20029043]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7260 iterations: 1.9686657985051472 mins\n",
      "Train Loss: [0.60140485, 0.2, 0.20065385, 0.20029043]\n",
      "[0.601568, 0.2, 0.20080103, 0.20030591]\n",
      "[0.60087436, 0.2, 0.20019212, 0.20022084]\n",
      "[0.60087913, 0.2, 0.20015822, 0.2002592]\n",
      "[0.60088795, 0.2, 0.2002542, 0.20017193]\n",
      "[0.6009964, 0.2, 0.20018439, 0.20034999]\n",
      "[0.6008006, 0.2, 0.20013869, 0.20019963]\n",
      "[0.60083145, 0.2, 0.20014518, 0.20022373]\n",
      "[0.6008432, 0.2, 0.20009886, 0.20028143]\n",
      "[0.600826, 0.2, 0.20017487, 0.20018779]\n",
      "[0.60059726, 0.2, 0.2000687, 0.2000649]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7270 iterations: 1.970645582675934 mins\n",
      "Train Loss: [0.60059726, 0.2, 0.2000687, 0.2000649]\n",
      "[0.6008308, 0.2, 0.20003322, 0.20033364]\n",
      "[0.6009368, 0.2, 0.20027372, 0.20019896]\n",
      "[0.60108286, 0.2, 0.20032631, 0.20029242]\n",
      "[0.60123736, 0.2, 0.20051976, 0.20025375]\n",
      "[0.60127276, 0.2, 0.20027855, 0.20053059]\n",
      "[0.6009512, 0.2, 0.20027551, 0.20021223]\n",
      "[0.60150003, 0.2, 0.20038678, 0.20065008]\n",
      "[0.6009024, 0.2, 0.20013416, 0.20030524]\n",
      "[0.60082793, 0.2, 0.20014659, 0.20021859]\n",
      "[0.60064113, 0.2, 0.20003958, 0.20013906]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7280 iterations: 1.972476633389791 mins\n",
      "Train Loss: [0.60064113, 0.2, 0.20003958, 0.20013906]\n",
      "[0.60106045, 0.2, 0.2002155, 0.20038274]\n",
      "[0.600954, 0.2, 0.20022602, 0.2002661]\n",
      "[0.6007729, 0.2, 0.20011947, 0.20019203]\n",
      "[0.60097504, 0.2, 0.20023036, 0.20028365]\n",
      "[0.60092396, 0.2, 0.20015217, 0.2003111]\n",
      "[0.60095453, 0.2, 0.2002265, 0.20026761]\n",
      "[0.60069627, 0.2, 0.20016605, 0.20007023]\n",
      "[0.6007771, 0.2, 0.20016031, 0.20015736]\n",
      "[0.60079193, 0.2, 0.20018204, 0.20015109]\n",
      "[0.60072064, 0.2, 0.20012157, 0.20014076]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7290 iterations: 1.9745208978652955 mins\n",
      "Train Loss: [0.60072064, 0.2, 0.20012157, 0.20014076]\n",
      "[0.60064006, 0.2, 0.20013516, 0.20004696]\n",
      "[0.60068, 0.2, 0.20007059, 0.20015159]\n",
      "[0.6011475, 0.2, 0.20019868, 0.2004912]\n",
      "[0.6008846, 0.2, 0.20009063, 0.20033659]\n",
      "[0.601617, 0.2, 0.20060313, 0.20055647]\n",
      "[0.6009516, 0.2, 0.20028426, 0.2002101]\n",
      "[0.601034, 0.2, 0.2002407, 0.20033602]\n",
      "[0.6006385, 0.2, 0.20009042, 0.20009084]\n",
      "[0.6010228, 0.2, 0.20016299, 0.20040253]\n",
      "[0.60077304, 0.2, 0.20025581, 0.20006014]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7300 iterations: 1.9764843344688416 mins\n",
      "Train Loss: [0.60077304, 0.2, 0.20025581, 0.20006014]\n",
      "[0.60088915, 0.2, 0.20007677, 0.20035543]\n",
      "[0.60090506, 0.2, 0.20028435, 0.20016415]\n",
      "[0.6012316, 0.2, 0.20015255, 0.20062289]\n",
      "[0.6007776, 0.2, 0.20015036, 0.20017143]\n",
      "[0.60080093, 0.2, 0.20026185, 0.20008345]\n",
      "[0.6008298, 0.2, 0.2000927, 0.20028175]\n",
      "[0.601006, 0.2, 0.20021911, 0.20033188]\n",
      "[0.60069895, 0.2, 0.20015556, 0.20008881]\n",
      "[0.6007099, 0.2, 0.20010853, 0.20014723]\n",
      "[0.600899, 0.2, 0.20021723, 0.20022793]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7310 iterations: 1.978538183371226 mins\n",
      "Train Loss: [0.600899, 0.2, 0.20021723, 0.20022793]\n",
      "[0.60110986, 0.2, 0.20024952, 0.20040673]\n",
      "[0.60078824, 0.2, 0.20008771, 0.20024744]\n",
      "[0.601084, 0.2, 0.20022252, 0.20040892]\n",
      "[0.6006873, 0.2, 0.2000684, 0.2001671]\n",
      "[0.60070884, 0.2, 0.20016186, 0.2000959]\n",
      "[0.60067856, 0.2, 0.20016913, 0.20005903]\n",
      "[0.600727, 0.2, 0.20009515, 0.20018223]\n",
      "[0.6009126, 0.2, 0.20010902, 0.20035474]\n",
      "[0.6007016, 0.2, 0.20009828, 0.2001552]\n",
      "[0.6006399, 0.2, 0.20015164, 0.20004088]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7320 iterations: 1.9811541318893433 mins\n",
      "Train Loss: [0.6006399, 0.2, 0.20015164, 0.20004088]\n",
      "[0.6007151, 0.2, 0.20008144, 0.20018709]\n",
      "[0.60079694, 0.2, 0.20017968, 0.20017153]\n",
      "[0.60087013, 0.2, 0.2000819, 0.20034331]\n",
      "[0.6009457, 0.2, 0.20031042, 0.20019142]\n",
      "[0.600847, 0.2, 0.20015588, 0.20024836]\n",
      "[0.60105515, 0.2, 0.20030157, 0.20031199]\n",
      "[0.6007806, 0.2, 0.20023523, 0.20010509]\n",
      "[0.6011549, 0.2, 0.20029818, 0.2004176]\n",
      "[0.60097927, 0.2, 0.20038415, 0.20015717]\n",
      "[0.60076404, 0.2, 0.20011558, 0.20021167]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7330 iterations: 1.9829734325408936 mins\n",
      "Train Loss: [0.60076404, 0.2, 0.20011558, 0.20021167]\n",
      "[0.60080636, 0.2, 0.20005858, 0.20031218]\n",
      "[0.6005847, 0.2, 0.200058, 0.20009226]\n",
      "[0.60088116, 0.2, 0.20024471, 0.20020291]\n",
      "[0.60075706, 0.2, 0.20016551, 0.20015894]\n",
      "[0.6008718, 0.2, 0.20020878, 0.20023112]\n",
      "[0.6010101, 0.2, 0.20007287, 0.20050597]\n",
      "[0.6011037, 0.2, 0.20026994, 0.2004031]\n",
      "[0.6007992, 0.2, 0.20016962, 0.20019937]\n",
      "[0.6013414, 0.2, 0.20043138, 0.20048021]\n",
      "[0.6012411, 0.2, 0.20039418, 0.20041762]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7340 iterations: 1.984974217414856 mins\n",
      "Train Loss: [0.6012411, 0.2, 0.20039418, 0.20041762]\n",
      "[0.6010339, 0.2, 0.20044656, 0.2001585]\n",
      "[0.6008756, 0.2, 0.20016445, 0.20028248]\n",
      "[0.6015406, 0.2, 0.20039152, 0.20072025]\n",
      "[0.6009392, 0.2, 0.20021039, 0.20029959]\n",
      "[0.601201, 0.2, 0.20023298, 0.20053817]\n",
      "[0.60082746, 0.2, 0.20018966, 0.20020726]\n",
      "[0.60120565, 0.2, 0.2002612, 0.2005132]\n",
      "[0.6007244, 0.2, 0.2002575, 0.20003486]\n",
      "[0.6008504, 0.2, 0.20019813, 0.20021945]\n",
      "[0.60116875, 0.2, 0.20074229, 0.19999273]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7350 iterations: 1.9867948333422343 mins\n",
      "Train Loss: [0.60116875, 0.2, 0.20074229, 0.19999273]\n",
      "[0.60204726, 0.2, 0.2005259, 0.20108674]\n",
      "[0.60166603, 0.2, 0.20058466, 0.20064574]\n",
      "[0.6011, 0.2, 0.2003885, 0.20027487]\n",
      "[0.6010369, 0.2, 0.2002836, 0.20031567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6012012, 0.2, 0.2001969, 0.20056564]\n",
      "[0.60062844, 0.2, 0.2001255, 0.20006317]\n",
      "[0.6011533, 0.2, 0.2003934, 0.200319]\n",
      "[0.60095584, 0.2, 0.20041448, 0.20009932]\n",
      "[0.60146743, 0.2, 0.20061411, 0.20041023]\n",
      "[0.6009207, 0.2, 0.20019652, 0.20028023]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7360 iterations: 1.9888305823008219 mins\n",
      "Train Loss: [0.6009207, 0.2, 0.20019652, 0.20028023]\n",
      "[0.6010015, 0.2, 0.20037529, 0.2001814]\n",
      "[0.60086733, 0.2, 0.20022361, 0.20019801]\n",
      "[0.6008052, 0.2, 0.20008336, 0.20027532]\n",
      "[0.6008907, 0.2, 0.20034385, 0.2000995]\n",
      "[0.6010494, 0.2, 0.20027085, 0.20033053]\n",
      "[0.6010149, 0.2, 0.20033316, 0.20023313]\n",
      "[0.6010088, 0.2, 0.2003885, 0.20017104]\n",
      "[0.60076964, 0.2, 0.2001175, 0.20020242]\n",
      "[0.6008613, 0.2, 0.20010987, 0.20030127]\n",
      "[0.6008737, 0.2, 0.20025536, 0.20016788]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7370 iterations: 1.9906568328539531 mins\n",
      "Train Loss: [0.6008737, 0.2, 0.20025536, 0.20016788]\n",
      "[0.6007819, 0.2, 0.20017384, 0.20015737]\n",
      "[0.6011545, 0.2, 0.20046303, 0.20024036]\n",
      "[0.60115093, 0.2, 0.20055626, 0.20014325]\n",
      "[0.6011664, 0.2, 0.2002778, 0.20043716]\n",
      "[0.60079527, 0.2, 0.2001254, 0.20021835]\n",
      "[0.60076785, 0.2, 0.20026408, 0.20005223]\n",
      "[0.60087246, 0.2, 0.20017599, 0.20024498]\n",
      "[0.60098165, 0.2, 0.2002739, 0.20025627]\n",
      "[0.60136855, 0.2, 0.20078744, 0.2001297]\n",
      "[0.60112184, 0.2, 0.20020323, 0.20046732]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7380 iterations: 1.993120050430298 mins\n",
      "Train Loss: [0.60112184, 0.2, 0.20020323, 0.20046732]\n",
      "[0.6012305, 0.2, 0.2004166, 0.20036288]\n",
      "[0.60084796, 0.2, 0.2002834, 0.20011385]\n",
      "[0.60090786, 0.2, 0.20031153, 0.20014578]\n",
      "[0.6008604, 0.2, 0.20032665, 0.20008323]\n",
      "[0.60069704, 0.2, 0.20004424, 0.20020214]\n",
      "[0.60100436, 0.2, 0.20024303, 0.20031065]\n",
      "[0.6012552, 0.2, 0.2004906, 0.20031394]\n",
      "[0.6009622, 0.2, 0.20028843, 0.20022307]\n",
      "[0.6009796, 0.2, 0.20017871, 0.20035028]\n",
      "[0.6007161, 0.2, 0.20011249, 0.20015326]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7390 iterations: 1.9970595677693685 mins\n",
      "Train Loss: [0.6007161, 0.2, 0.20011249, 0.20015326]\n",
      "[0.6008704, 0.2, 0.20028359, 0.20013653]\n",
      "[0.60087466, 0.2, 0.20033684, 0.20008768]\n",
      "[0.6008994, 0.2, 0.20027265, 0.20017679]\n",
      "[0.6009929, 0.2, 0.20034154, 0.20020172]\n",
      "[0.6010505, 0.2, 0.20019336, 0.20040795]\n",
      "[0.60143065, 0.2, 0.20031573, 0.20066619]\n",
      "[0.6008403, 0.2, 0.20010877, 0.20028341]\n",
      "[0.6012441, 0.2, 0.2003755, 0.200421]\n",
      "[0.6011912, 0.2, 0.2004006, 0.20034352]\n",
      "[0.60098946, 0.2, 0.20021923, 0.20032369]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7400 iterations: 1.9998955686887105 mins\n",
      "Train Loss: [0.60098946, 0.2, 0.20021923, 0.20032369]\n",
      "[0.6009114, 0.2, 0.20032401, 0.2001412]\n",
      "[0.6006297, 0.2, 0.2001255, 0.20005837]\n",
      "[0.60083747, 0.2, 0.20032562, 0.20006625]\n",
      "[0.6013721, 0.2, 0.20036049, 0.20056644]\n",
      "[0.60102814, 0.2, 0.20024341, 0.20034005]\n",
      "[0.6011169, 0.2, 0.200072, 0.20060065]\n",
      "[0.60067546, 0.2, 0.20025504, 0.19997644]\n",
      "[0.6010202, 0.2, 0.20023544, 0.20034087]\n",
      "[0.6008915, 0.2, 0.20037077, 0.20007664]\n",
      "[0.6015705, 0.2, 0.2002679, 0.20085841]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7410 iterations: 2.002057433128357 mins\n",
      "Train Loss: [0.6015705, 0.2, 0.2002679, 0.20085841]\n",
      "[0.6014185, 0.2, 0.20031714, 0.20065664]\n",
      "[0.60112727, 0.2, 0.20024179, 0.20044024]\n",
      "[0.60122454, 0.2, 0.2003643, 0.20041427]\n",
      "[0.6015052, 0.2, 0.20023166, 0.20082702]\n",
      "[0.60108125, 0.2, 0.20027845, 0.20035543]\n",
      "[0.601122, 0.2, 0.20042418, 0.20024975]\n",
      "[0.6010304, 0.2, 0.20028108, 0.20030043]\n",
      "[0.6013497, 0.2, 0.20022091, 0.20067899]\n",
      "[0.6010003, 0.2, 0.20017873, 0.20037088]\n",
      "[0.6011402, 0.2, 0.20009756, 0.2005911]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7420 iterations: 2.0042407313982644 mins\n",
      "Train Loss: [0.6011402, 0.2, 0.20009756, 0.2005911]\n",
      "[0.6007624, 0.2, 0.20010248, 0.20020756]\n",
      "[0.6009044, 0.2, 0.2003528, 0.20009845]\n",
      "[0.6008321, 0.2, 0.20024332, 0.2001348]\n",
      "[0.6013109, 0.2, 0.20053704, 0.20031925]\n",
      "[0.6010377, 0.2, 0.20021285, 0.20036966]\n",
      "[0.60082763, 0.2, 0.20022097, 0.20015089]\n",
      "[0.60076725, 0.2, 0.20014897, 0.200162]\n",
      "[0.600882, 0.2, 0.20025648, 0.20016873]\n",
      "[0.6007101, 0.2, 0.20010097, 0.200152]\n",
      "[0.6005884, 0.2, 0.20008257, 0.2000484]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7430 iterations: 2.007074264685313 mins\n",
      "Train Loss: [0.6005884, 0.2, 0.20008257, 0.2000484]\n",
      "[0.60107124, 0.2, 0.20032471, 0.2002889]\n",
      "[0.6009741, 0.2, 0.20023242, 0.20028399]\n",
      "[0.6007627, 0.2, 0.20017664, 0.20012848]\n",
      "[0.6010508, 0.2, 0.200162, 0.20043136]\n",
      "[0.60088426, 0.2, 0.20013778, 0.20028919]\n",
      "[0.60147226, 0.2, 0.20023565, 0.20077951]\n",
      "[0.6011955, 0.2, 0.20031637, 0.20042242]\n",
      "[0.60108405, 0.2, 0.20017989, 0.20044759]\n",
      "[0.60120773, 0.2, 0.20027305, 0.20047836]\n",
      "[0.60084295, 0.2, 0.20010649, 0.20028012]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7440 iterations: 2.0093464652697244 mins\n",
      "Train Loss: [0.60084295, 0.2, 0.20010649, 0.20028012]\n",
      "[0.60092646, 0.2, 0.20020935, 0.20026077]\n",
      "[0.6010781, 0.2, 0.20029694, 0.20032483]\n",
      "[0.60058606, 0.2, 0.20000008, 0.20012958]\n",
      "[0.601175, 0.2, 0.20032912, 0.20038946]\n",
      "[0.6011808, 0.2, 0.20049667, 0.20022775]\n",
      "[0.60123485, 0.2, 0.20028189, 0.20049681]\n",
      "[0.60092473, 0.2, 0.20026197, 0.20020685]\n",
      "[0.60096973, 0.2, 0.20013893, 0.20037502]\n",
      "[0.60131013, 0.2, 0.20056188, 0.20029259]\n",
      "[0.6007548, 0.2, 0.20015022, 0.20014933]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7450 iterations: 2.0112173636754354 mins\n",
      "Train Loss: [0.6007548, 0.2, 0.20015022, 0.20014933]\n",
      "[0.6007954, 0.2, 0.20018576, 0.20015486]\n",
      "[0.6008713, 0.2, 0.20020185, 0.20021506]\n",
      "[0.60101265, 0.2, 0.20037034, 0.20018826]\n",
      "[0.60103345, 0.2, 0.20035905, 0.20022091]\n",
      "[0.6009643, 0.2, 0.20025145, 0.20026003]\n",
      "[0.6010596, 0.2, 0.20032035, 0.2002869]\n",
      "[0.6008092, 0.2, 0.20006607, 0.20029116]\n",
      "[0.6008771, 0.2, 0.20015997, 0.20026547]\n",
      "[0.60090387, 0.2, 0.20019715, 0.20025529]\n",
      "[0.60108125, 0.2, 0.2003448, 0.20028529]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7460 iterations: 2.013217302163442 mins\n",
      "Train Loss: [0.60108125, 0.2, 0.2003448, 0.20028529]\n",
      "[0.6008818, 0.2, 0.20012198, 0.20030887]\n",
      "[0.60089606, 0.2, 0.20000005, 0.20044531]\n",
      "[0.6015058, 0.2, 0.20044416, 0.20061117]\n",
      "[0.6007093, 0.2, 0.20007479, 0.20018446]\n",
      "[0.60083467, 0.2, 0.20000005, 0.20038494]\n",
      "[0.6008225, 0.2, 0.20013636, 0.20023689]\n",
      "[0.6008146, 0.2, 0.20019639, 0.20016947]\n",
      "[0.6007846, 0.2, 0.20013866, 0.20019779]\n",
      "[0.6007594, 0.2, 0.20013791, 0.20017378]\n",
      "[0.60092944, 0.2, 0.20039932, 0.20008284]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7470 iterations: 2.015451129277547 mins\n",
      "Train Loss: [0.60092944, 0.2, 0.20039932, 0.20008284]\n",
      "[0.60111916, 0.2, 0.20038797, 0.20028435]\n",
      "[0.60090923, 0.2, 0.20037441, 0.20008834]\n",
      "[0.60081404, 0.2, 0.20022278, 0.20014517]\n",
      "[0.60118556, 0.2, 0.20061083, 0.20012915]\n",
      "[0.6007176, 0.2, 0.2001363, 0.2001363]\n",
      "[0.60084915, 0.2, 0.20028472, 0.20011976]\n",
      "[0.6013222, 0.2, 0.20068458, 0.20019342]\n",
      "[0.60067284, 0.2, 0.20010297, 0.20012642]\n",
      "[0.60091764, 0.2, 0.20014974, 0.20032498]\n",
      "[0.6009439, 0.2, 0.20031692, 0.20018478]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7480 iterations: 2.0174076159795127 mins\n",
      "Train Loss: [0.6009439, 0.2, 0.20031692, 0.20018478]\n",
      "[0.6006795, 0.2, 0.20014684, 0.20009102]\n",
      "[0.600693, 0.2, 0.20010298, 0.20014884]\n",
      "[0.6006693, 0.2, 0.20011416, 0.20011441]\n",
      "[0.6006087, 0.2, 0.200056, 0.2001125]\n",
      "[0.60079145, 0.2, 0.20014805, 0.20020373]\n",
      "[0.6006365, 0.2, 0.20015264, 0.20004463]\n",
      "[0.6010131, 0.2, 0.20005067, 0.20052372]\n",
      "[0.6008955, 0.2, 0.20017104, 0.20028627]\n",
      "[0.60108083, 0.2, 0.20024574, 0.20039748]\n",
      "[0.6006127, 0.2, 0.20000002, 0.20017557]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7490 iterations: 2.0193745652834574 mins\n",
      "Train Loss: [0.6006127, 0.2, 0.20000002, 0.20017557]\n",
      "[0.6009259, 0.2, 0.20027612, 0.20021327]\n",
      "[0.6008676, 0.2, 0.200173, 0.20025885]\n",
      "[0.60057867, 0.2, 0.2, 0.20014362]\n",
      "[0.6008234, 0.2, 0.20011829, 0.20027079]\n",
      "[0.60076743, 0.2, 0.20010392, 0.2002299]\n",
      "[0.6007947, 0.2, 0.20006382, 0.20029809]\n",
      "[0.6007851, 0.2, 0.20018454, 0.20016862]\n",
      "[0.60071725, 0.2, 0.2001443, 0.20014197]\n",
      "[0.60094917, 0.2, 0.20032386, 0.2001952]\n",
      "[0.60102254, 0.2, 0.2003077, 0.20028566]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7500 iterations: 2.021273346741994 mins\n",
      "Train Loss: [0.60102254, 0.2, 0.2003077, 0.20028566]\n",
      "[0.6006845, 0.2, 0.20012906, 0.20012735]\n",
      "[0.6008441, 0.2, 0.20013238, 0.2002845]\n",
      "[0.6010647, 0.2, 0.2002425, 0.20039575]\n",
      "[0.6006841, 0.2, 0.20013286, 0.20012553]\n",
      "[0.60084045, 0.2, 0.20026529, 0.20015013]\n",
      "[0.6008169, 0.2, 0.20020668, 0.20018591]\n",
      "[0.6009094, 0.2, 0.20036042, 0.2001253]\n",
      "[0.60088396, 0.2, 0.20022333, 0.20023769]\n",
      "[0.60072434, 0.2, 0.20010483, 0.20019728]\n",
      "[0.60064185, 0.2, 0.20003499, 0.20018521]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7510 iterations: 2.0233356674512226 mins\n",
      "Train Loss: [0.60064185, 0.2, 0.20003499, 0.20018521]\n",
      "[0.6011951, 0.2, 0.20024177, 0.20053212]\n",
      "[0.6007208, 0.2, 0.20023473, 0.20006539]\n",
      "[0.60065556, 0.2, 0.20009527, 0.20014013]\n",
      "[0.6007419, 0.2, 0.2002289, 0.20009333]\n",
      "[0.6009333, 0.2, 0.20016932, 0.20034486]\n",
      "[0.6006675, 0.2, 0.2001845, 0.20006439]\n",
      "[0.6009176, 0.2, 0.20025653, 0.2002432]\n",
      "[0.6007243, 0.2, 0.20007962, 0.20022747]\n",
      "[0.6010184, 0.2, 0.20032631, 0.20027564]\n",
      "[0.60099393, 0.2, 0.20022324, 0.2003552]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7520 iterations: 2.025295281410217 mins\n",
      "Train Loss: [0.60099393, 0.2, 0.20022324, 0.2003552]\n",
      "[0.6007302, 0.2, 0.2001605, 0.20015518]\n",
      "[0.600703, 0.2, 0.20010361, 0.20018591]\n",
      "[0.6007925, 0.2, 0.20018893, 0.20019111]\n",
      "[0.60061336, 0.2, 0.20008434, 0.20011765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6005819, 0.2, 0.20011331, 0.20005825]\n",
      "[0.60057855, 0.2, 0.20007366, 0.20009564]\n",
      "[0.60050553, 0.2, 0.20003033, 0.20006707]\n",
      "[0.6008458, 0.2, 0.20020743, 0.20023137]\n",
      "[0.60063374, 0.2, 0.20007402, 0.20015402]\n",
      "[0.6006101, 0.2, 0.20014723, 0.20005843]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7530 iterations: 2.027329150835673 mins\n",
      "Train Loss: [0.6006101, 0.2, 0.20014723, 0.20005843]\n",
      "[0.6006824, 0.2, 0.20007919, 0.2002]\n",
      "[0.6006593, 0.2, 0.2000561, 0.2002012]\n",
      "[0.6006178, 0.2, 0.20009826, 0.20011874]\n",
      "[0.6006906, 0.2, 0.20013806, 0.2001528]\n",
      "[0.6007929, 0.2, 0.20016822, 0.200226]\n",
      "[0.60094905, 0.2, 0.20020811, 0.20034337]\n",
      "[0.6005847, 0.2, 0.20002633, 0.20016192]\n",
      "[0.60056305, 0.2, 0.2000807, 0.20008697]\n",
      "[0.6005811, 0.2, 0.20003481, 0.20015176]\n",
      "[0.6009482, 0.2, 0.20034222, 0.20021228]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7540 iterations: 2.0292264660199484 mins\n",
      "Train Loss: [0.6009482, 0.2, 0.20034222, 0.20021228]\n",
      "[0.60080415, 0.2, 0.20016247, 0.2002487]\n",
      "[0.60084593, 0.2, 0.20022008, 0.2002335]\n",
      "[0.6011403, 0.2, 0.20054838, 0.20020016]\n",
      "[0.6007196, 0.2, 0.20015778, 0.20017049]\n",
      "[0.6006501, 0.2, 0.20014092, 0.2001183]\n",
      "[0.6005655, 0.2, 0.20001563, 0.20015943]\n",
      "[0.6010441, 0.2, 0.20037653, 0.2002775]\n",
      "[0.6007954, 0.2, 0.20011857, 0.20028704]\n",
      "[0.60067683, 0.2, 0.2000774, 0.20020996]\n",
      "[0.60094583, 0.2, 0.20037523, 0.20018144]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7550 iterations: 2.0318350315093996 mins\n",
      "Train Loss: [0.60094583, 0.2, 0.20037523, 0.20018144]\n",
      "[0.6006931, 0.2, 0.20011, 0.20019434]\n",
      "[0.6006378, 0.2, 0.20013444, 0.200115]\n",
      "[0.6005818, 0.2, 0.20010549, 0.20008829]\n",
      "[0.6007475, 0.2, 0.20011796, 0.2002417]\n",
      "[0.60076827, 0.2, 0.20009987, 0.20028076]\n",
      "[0.60074335, 0.2, 0.20014736, 0.20020844]\n",
      "[0.6006891, 0.2, 0.20012833, 0.20017317]\n",
      "[0.60079575, 0.2, 0.20031026, 0.20009741]\n",
      "[0.60106665, 0.2, 0.20039625, 0.20028171]\n",
      "[0.60078925, 0.2, 0.20018508, 0.2002149]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7560 iterations: 2.03476718266805 mins\n",
      "Train Loss: [0.60078925, 0.2, 0.20018508, 0.2002149]\n",
      "[0.601846, 0.2, 0.20005743, 0.20139866]\n",
      "[0.6006721, 0.2, 0.20015186, 0.20012976]\n",
      "[0.6010873, 0.2, 0.2002379, 0.200458]\n",
      "[0.6008099, 0.2, 0.20023897, 0.20017868]\n",
      "[0.6008551, 0.2, 0.20014985, 0.20031226]\n",
      "[0.6007301, 0.2, 0.20021428, 0.20012197]\n",
      "[0.6009679, 0.2, 0.20024952, 0.20032355]\n",
      "[0.6010258, 0.2, 0.20047748, 0.20015244]\n",
      "[0.60085386, 0.2, 0.20038795, 0.20006914]\n",
      "[0.60086995, 0.2, 0.200164, 0.20030826]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7570 iterations: 2.0365742842356362 mins\n",
      "Train Loss: [0.60086995, 0.2, 0.200164, 0.20030826]\n",
      "[0.600898, 0.2, 0.20016679, 0.20033246]\n",
      "[0.6008009, 0.2, 0.20016122, 0.20023982]\n",
      "[0.6007351, 0.2, 0.20023708, 0.200097]\n",
      "[0.6008525, 0.2, 0.20004724, 0.2004029]\n",
      "[0.60094285, 0.2, 0.20016736, 0.20037186]\n",
      "[0.6016889, 0.2, 0.20098037, 0.20030363]\n",
      "[0.6007375, 0.2, 0.20004801, 0.20028356]\n",
      "[0.60063255, 0.2, 0.2001264, 0.20009929]\n",
      "[0.600852, 0.2, 0.2001432, 0.200301]\n",
      "[0.60128534, 0.2, 0.20017615, 0.20070033]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7580 iterations: 2.038627882798513 mins\n",
      "Train Loss: [0.60128534, 0.2, 0.20017615, 0.20070033]\n",
      "[0.60121506, 0.2, 0.20017189, 0.20063351]\n",
      "[0.6017829, 0.2, 0.20064221, 0.20073056]\n",
      "[0.60096735, 0.2, 0.2002119, 0.20034482]\n",
      "[0.6010043, 0.2, 0.2002853, 0.20030789]\n",
      "[0.60073775, 0.2, 0.20021138, 0.20011479]\n",
      "[0.6009047, 0.2, 0.20022362, 0.20026903]\n",
      "[0.6007047, 0.2, 0.20010632, 0.20018594]\n",
      "[0.60263413, 0.2, 0.20056948, 0.20165177]\n",
      "[0.60080093, 0.2, 0.20022036, 0.20016733]\n",
      "[0.6009698, 0.2, 0.2002205, 0.20033555]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7590 iterations: 2.0409444332122804 mins\n",
      "Train Loss: [0.6009698, 0.2, 0.2002205, 0.20033555]\n",
      "[0.6009514, 0.2, 0.20016274, 0.20037456]\n",
      "[0.60089517, 0.2, 0.20021297, 0.20026748]\n",
      "[0.60069996, 0.2, 0.20008673, 0.20019792]\n",
      "[0.600863, 0.2, 0.20018156, 0.20026554]\n",
      "[0.60072803, 0.2, 0.20013803, 0.2001737]\n",
      "[0.60128355, 0.2, 0.2003513, 0.20051563]\n",
      "[0.6008163, 0.2, 0.20022605, 0.20017345]\n",
      "[0.6012293, 0.2, 0.20040981, 0.20040247]\n",
      "[0.6012591, 0.2, 0.20048715, 0.20035501]\n",
      "[0.6010043, 0.2, 0.20023045, 0.20035708]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7600 iterations: 2.0429279168446857 mins\n",
      "Train Loss: [0.6010043, 0.2, 0.20023045, 0.20035708]\n",
      "[0.6006708, 0.2, 0.20012213, 0.200132]\n",
      "[0.6006113, 0.2, 0.20007737, 0.20011714]\n",
      "[0.60085696, 0.2, 0.20017451, 0.20026538]\n",
      "[0.60079515, 0.2, 0.20025787, 0.20011987]\n",
      "[0.6012277, 0.2, 0.20018576, 0.20062433]\n",
      "[0.6006629, 0.2, 0.20015378, 0.2000916]\n",
      "[0.60062134, 0.2, 0.20012577, 0.2000781]\n",
      "[0.60107803, 0.2, 0.20042448, 0.20023607]\n",
      "[0.60067844, 0.2, 0.20004398, 0.2002172]\n",
      "[0.6008122, 0.2, 0.20016436, 0.20023057]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7610 iterations: 2.044976015885671 mins\n",
      "Train Loss: [0.6008122, 0.2, 0.20016436, 0.20023057]\n",
      "[0.6011106, 0.2, 0.20039214, 0.20030138]\n",
      "[0.6012363, 0.2, 0.20015259, 0.20066701]\n",
      "[0.60105675, 0.2, 0.20039181, 0.2002488]\n",
      "[0.6008194, 0.2, 0.20013012, 0.20027363]\n",
      "[0.6009529, 0.2, 0.20020899, 0.20032878]\n",
      "[0.6008752, 0.2, 0.20025, 0.20021059]\n",
      "[0.6009931, 0.2, 0.2003603, 0.20021884]\n",
      "[0.60084915, 0.2, 0.20014907, 0.20028688]\n",
      "[0.60057205, 0.2, 0.2000001, 0.20015955]\n",
      "[0.60081005, 0.2, 0.20028153, 0.20011677]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7620 iterations: 2.0473883628845213 mins\n",
      "Train Loss: [0.60081005, 0.2, 0.20028153, 0.20011677]\n",
      "[0.60150707, 0.2, 0.20081821, 0.20027767]\n",
      "[0.6008113, 0.2, 0.20019513, 0.20020561]\n",
      "[0.6006614, 0.2, 0.20010693, 0.20014441]\n",
      "[0.6007146, 0.2, 0.20011532, 0.2001896]\n",
      "[0.6026943, 0.2, 0.20199548, 0.20028928]\n",
      "[0.60143095, 0.2, 0.20094371, 0.20007807]\n",
      "[0.60175383, 0.2, 0.2012464, 0.20009865]\n",
      "[0.60072106, 0.2, 0.2002511, 0.20006149]\n",
      "[0.60086775, 0.2, 0.20021339, 0.20024599]\n",
      "[0.60074115, 0.2, 0.20016713, 0.20016575]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7630 iterations: 2.0494189461072287 mins\n",
      "Train Loss: [0.60074115, 0.2, 0.20016713, 0.20016575]\n",
      "[0.6008586, 0.2, 0.2002973, 0.20015286]\n",
      "[0.60103047, 0.2, 0.20014903, 0.20047279]\n",
      "[0.601035, 0.2, 0.2003041, 0.200322]\n",
      "[0.60154974, 0.2, 0.20088044, 0.20025991]\n",
      "[0.60104966, 0.2, 0.2003655, 0.20027423]\n",
      "[0.60095197, 0.2, 0.20017193, 0.20036943]\n",
      "[0.60102016, 0.2, 0.20005137, 0.2005576]\n",
      "[0.6009031, 0.2, 0.20007432, 0.20041701]\n",
      "[0.6007148, 0.2, 0.20012754, 0.20017463]\n",
      "[0.60072243, 0.2, 0.200041, 0.20026809]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7640 iterations: 2.051270119349162 mins\n",
      "Train Loss: [0.60072243, 0.2, 0.200041, 0.20026809]\n",
      "[0.6005868, 0.2, 0.20004551, 0.20012726]\n",
      "[0.60114676, 0.2, 0.20038176, 0.20035046]\n",
      "[0.6007241, 0.2, 0.20008457, 0.2002247]\n",
      "[0.6005048, 0.2, 0.20003359, 0.20005599]\n",
      "[0.6012852, 0.2, 0.20031032, 0.20055912]\n",
      "[0.6008485, 0.2, 0.20032567, 0.20010678]\n",
      "[0.60103565, 0.2, 0.20037758, 0.20024176]\n",
      "[0.6014477, 0.2, 0.200321, 0.20071007]\n",
      "[0.60097915, 0.2, 0.20021838, 0.2003441]\n",
      "[0.60066754, 0.2, 0.20000012, 0.20025057]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7650 iterations: 2.0532286326090494 mins\n",
      "Train Loss: [0.60066754, 0.2, 0.20000012, 0.20025057]\n",
      "[0.6008165, 0.2, 0.20021643, 0.20018297]\n",
      "[0.6008661, 0.2, 0.20024183, 0.2002069]\n",
      "[0.60077375, 0.2, 0.20017135, 0.20018484]\n",
      "[0.60079044, 0.2, 0.20026478, 0.20010786]\n",
      "[0.60122234, 0.2, 0.20062655, 0.20017785]\n",
      "[0.60082877, 0.2, 0.20003207, 0.20037879]\n",
      "[0.60119706, 0.2, 0.20032163, 0.20045778]\n",
      "[0.6008886, 0.2, 0.2002893, 0.20018202]\n",
      "[0.6012325, 0.2, 0.20055728, 0.20025834]\n",
      "[0.60101175, 0.2, 0.2002915, 0.2003038]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7660 iterations: 2.0553011496861777 mins\n",
      "Train Loss: [0.60101175, 0.2, 0.2002915, 0.2003038]\n",
      "[0.6007007, 0.2, 0.20007621, 0.20020843]\n",
      "[0.6008963, 0.2, 0.20022872, 0.20025185]\n",
      "[0.6008067, 0.2, 0.20017497, 0.20021623]\n",
      "[0.60076535, 0.2, 0.2002624, 0.20008773]\n",
      "[0.60077417, 0.2, 0.20014484, 0.2002144]\n",
      "[0.6007855, 0.2, 0.20008843, 0.20028245]\n",
      "[0.6008878, 0.2, 0.20023017, 0.20024338]\n",
      "[0.6009362, 0.2, 0.2001131, 0.200409]\n",
      "[0.6006738, 0.2, 0.20009933, 0.20016053]\n",
      "[0.60090107, 0.2, 0.20026776, 0.20021941]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7670 iterations: 2.0571513175964355 mins\n",
      "Train Loss: [0.60090107, 0.2, 0.20026776, 0.20021941]\n",
      "[0.60062456, 0.2, 0.20010172, 0.20010914]\n",
      "[0.6008852, 0.2, 0.20021081, 0.2002609]\n",
      "[0.6008135, 0.2, 0.20026278, 0.20013762]\n",
      "[0.60067844, 0.2, 0.20002969, 0.20023602]\n",
      "[0.6009437, 0.2, 0.20019853, 0.20033282]\n",
      "[0.6012058, 0.2, 0.20010778, 0.20068617]\n",
      "[0.6010823, 0.2, 0.20025954, 0.20041147]\n",
      "[0.6010953, 0.2, 0.20024392, 0.20044073]\n",
      "[0.6011351, 0.2, 0.20032597, 0.20039909]\n",
      "[0.6007522, 0.2, 0.20013712, 0.20020565]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7680 iterations: 2.0593063672383627 mins\n",
      "Train Loss: [0.6007522, 0.2, 0.20013712, 0.20020565]\n",
      "[0.60074425, 0.2, 0.20013493, 0.20020056]\n",
      "[0.60071355, 0.2, 0.20022793, 0.2000774]\n",
      "[0.6012019, 0.2, 0.20019372, 0.20060046]\n",
      "[0.60131437, 0.2, 0.20069991, 0.20020753]\n",
      "[0.6010964, 0.2, 0.20018236, 0.20050792]\n",
      "[0.6007538, 0.2, 0.20015885, 0.20018981]\n",
      "[0.60069376, 0.2, 0.20023155, 0.20005794]\n",
      "[0.60058314, 0.2, 0.20007873, 0.20010093]\n",
      "[0.6008537, 0.2, 0.20010078, 0.20035024]\n",
      "[0.6009409, 0.2, 0.20024425, 0.20029481]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7690 iterations: 2.0612097144126893 mins\n",
      "Train Loss: [0.6009409, 0.2, 0.20024425, 0.20029481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6008329, 0.2, 0.2002943, 0.20013765]\n",
      "[0.60078615, 0.2, 0.20028368, 0.20010248]\n",
      "[0.60084736, 0.2, 0.20022242, 0.2002258]\n",
      "[0.60105824, 0.2, 0.20039381, 0.20026617]\n",
      "[0.6006853, 0.2, 0.20010471, 0.20018317]\n",
      "[0.60061216, 0.2, 0.20007683, 0.2001386]\n",
      "[0.60060525, 0.2, 0.20007823, 0.20013091]\n",
      "[0.6006191, 0.2, 0.20016333, 0.20006017]\n",
      "[0.6008827, 0.2, 0.20021592, 0.20027182]\n",
      "[0.60058683, 0.2, 0.20000006, 0.20019226]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7700 iterations: 2.063573630650838 mins\n",
      "Train Loss: [0.60058683, 0.2, 0.20000006, 0.20019226]\n",
      "[0.6008019, 0.2, 0.20025751, 0.20015031]\n",
      "[0.6010689, 0.2, 0.2003616, 0.20031384]\n",
      "[0.60084087, 0.2, 0.20028254, 0.20016545]\n",
      "[0.600829, 0.2, 0.20016637, 0.20027041]\n",
      "[0.6007508, 0.2, 0.20015891, 0.20020023]\n",
      "[0.6007867, 0.2, 0.20030247, 0.20009294]\n",
      "[0.6009097, 0.2, 0.20040151, 0.20011729]\n",
      "[0.6006476, 0.2, 0.20017898, 0.20007817]\n",
      "[0.6006606, 0.2, 0.20019248, 0.20007794]\n",
      "[0.6008324, 0.2, 0.20031679, 0.20012556]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7710 iterations: 2.065879734357198 mins\n",
      "Train Loss: [0.6008324, 0.2, 0.20031679, 0.20012556]\n",
      "[0.60133386, 0.2, 0.20011683, 0.20082696]\n",
      "[0.6008407, 0.2, 0.2001089, 0.20034166]\n",
      "[0.6007008, 0.2, 0.20019716, 0.20011343]\n",
      "[0.60075456, 0.2, 0.20024197, 0.20012216]\n",
      "[0.6011762, 0.2, 0.2002637, 0.20052193]\n",
      "[0.6007453, 0.2, 0.20023425, 0.20012037]\n",
      "[0.60102916, 0.2, 0.20032784, 0.20031047]\n",
      "[0.60101825, 0.2, 0.20020476, 0.20042264]\n",
      "[0.60067356, 0.2, 0.20010401, 0.20017876]\n",
      "[0.60086775, 0.2, 0.20034368, 0.20013332]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7720 iterations: 2.067769181728363 mins\n",
      "Train Loss: [0.60086775, 0.2, 0.20034368, 0.20013332]\n",
      "[0.60075575, 0.2, 0.2001835, 0.20018148]\n",
      "[0.60060555, 0.2, 0.2, 0.20021468]\n",
      "[0.6006876, 0.2, 0.2001296, 0.2001671]\n",
      "[0.6007285, 0.2, 0.20018831, 0.2001493]\n",
      "[0.60069174, 0.2, 0.20014982, 0.20015109]\n",
      "[0.6010528, 0.2, 0.20048721, 0.20017485]\n",
      "[0.6009493, 0.2, 0.20020892, 0.20034976]\n",
      "[0.6004764, 0.2, 0.20001434, 0.20007157]\n",
      "[0.6008454, 0.2, 0.20028679, 0.20016815]\n",
      "[0.6006788, 0.2, 0.20010951, 0.20017894]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7730 iterations: 2.0698012510935464 mins\n",
      "Train Loss: [0.6006788, 0.2, 0.20010951, 0.20017894]\n",
      "[0.60072917, 0.2, 0.20020413, 0.20013484]\n",
      "[0.60077816, 0.2, 0.20011988, 0.20026828]\n",
      "[0.60079974, 0.2, 0.20036063, 0.20004937]\n",
      "[0.60088325, 0.2, 0.200203, 0.20029092]\n",
      "[0.6007691, 0.2, 0.2001366, 0.20024356]\n",
      "[0.6005938, 0.2, 0.20010759, 0.2000977]\n",
      "[0.60070175, 0.2, 0.20018145, 0.20013213]\n",
      "[0.6008405, 0.2, 0.20026858, 0.20018394]\n",
      "[0.6008106, 0.2, 0.20019798, 0.20022467]\n",
      "[0.6008005, 0.2, 0.20009524, 0.20031725]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7740 iterations: 2.0716805338859556 mins\n",
      "Train Loss: [0.6008005, 0.2, 0.20009524, 0.20031725]\n",
      "[0.60070646, 0.2, 0.20021228, 0.20010601]\n",
      "[0.6007633, 0.2, 0.20005378, 0.20032142]\n",
      "[0.6007876, 0.2, 0.20015228, 0.20024727]\n",
      "[0.60055524, 0.2, 0.20010218, 0.20006508]\n",
      "[0.60070395, 0.2, 0.20010193, 0.2002141]\n",
      "[0.600851, 0.2, 0.2000779, 0.2003853]\n",
      "[0.60088897, 0.2, 0.20018566, 0.20031577]\n",
      "[0.60070705, 0.2, 0.20022199, 0.20009787]\n",
      "[0.6019551, 0.2, 0.20140171, 0.20016657]\n",
      "[0.600748, 0.2, 0.20020236, 0.20015873]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7750 iterations: 2.0737218499183654 mins\n",
      "Train Loss: [0.600748, 0.2, 0.20020236, 0.20015873]\n",
      "[0.60086155, 0.2, 0.20016675, 0.2003079]\n",
      "[0.60086143, 0.2, 0.20032379, 0.20015076]\n",
      "[0.6008239, 0.2, 0.20019127, 0.20024587]\n",
      "[0.6005962, 0.2, 0.20015502, 0.2000546]\n",
      "[0.60087466, 0.2, 0.20032004, 0.20016813]\n",
      "[0.60068697, 0.2, 0.20014372, 0.20015697]\n",
      "[0.600938, 0.2, 0.20044829, 0.20010366]\n",
      "[0.6011852, 0.2, 0.20052616, 0.20027344]\n",
      "[0.6009428, 0.2, 0.20015071, 0.20040724]\n",
      "[0.6008873, 0.2, 0.20037891, 0.20012419]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7760 iterations: 2.0756081978480023 mins\n",
      "Train Loss: [0.6008873, 0.2, 0.20037891, 0.20012419]\n",
      "[0.6008346, 0.2, 0.20019847, 0.20025274]\n",
      "[0.60091865, 0.2, 0.20024738, 0.20028847]\n",
      "[0.60064775, 0.2, 0.20013666, 0.20012881]\n",
      "[0.6007101, 0.2, 0.2001788, 0.20014912]\n",
      "[0.6006719, 0.2, 0.20015094, 0.20013866]\n",
      "[0.601196, 0.2, 0.20030658, 0.20050687]\n",
      "[0.6008405, 0.2, 0.20007992, 0.20037782]\n",
      "[0.6013815, 0.2, 0.20031951, 0.20067912]\n",
      "[0.60069233, 0.2, 0.20010006, 0.20020951]\n",
      "[0.6008304, 0.2, 0.2002386, 0.20020895]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7770 iterations: 2.07760724623998 mins\n",
      "Train Loss: [0.6008304, 0.2, 0.2002386, 0.20020895]\n",
      "[0.60110587, 0.2, 0.20021524, 0.20050761]\n",
      "[0.6009302, 0.2, 0.2002066, 0.20034035]\n",
      "[0.6011327, 0.2, 0.2001945, 0.20055442]\n",
      "[0.60147125, 0.2, 0.20022881, 0.2008581]\n",
      "[0.6006185, 0.2, 0.20014912, 0.20008433]\n",
      "[0.60121644, 0.2, 0.20027252, 0.20055807]\n",
      "[0.60087484, 0.2, 0.20018393, 0.20030415]\n",
      "[0.6007996, 0.2, 0.20024438, 0.20016758]\n",
      "[0.6006636, 0.2, 0.20013662, 0.20013846]\n",
      "[0.6008987, 0.2, 0.20030165, 0.20020774]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7780 iterations: 2.0795202175776164 mins\n",
      "Train Loss: [0.6008987, 0.2, 0.20030165, 0.20020774]\n",
      "[0.6007121, 0.2, 0.20010835, 0.20021398]\n",
      "[0.60067517, 0.2, 0.20012698, 0.20015782]\n",
      "[0.60061836, 0.2, 0.2000347, 0.20019285]\n",
      "[0.60082084, 0.2, 0.20028676, 0.20014282]\n",
      "[0.60092443, 0.2, 0.2001634, 0.20036948]\n",
      "[0.6006984, 0.2, 0.20008059, 0.20022602]\n",
      "[0.6010639, 0.2, 0.2002036, 0.2004682]\n",
      "[0.6008098, 0.2, 0.20026548, 0.2001519]\n",
      "[0.6021558, 0.2, 0.20113705, 0.20062606]\n",
      "[0.6011856, 0.2, 0.20018394, 0.20060894]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7790 iterations: 2.081837550799052 mins\n",
      "Train Loss: [0.6011856, 0.2, 0.20018394, 0.20060894]\n",
      "[0.6007799, 0.2, 0.2001039, 0.20028333]\n",
      "[0.6009742, 0.2, 0.20013365, 0.20044777]\n",
      "[0.6006484, 0.2, 0.20012088, 0.20013459]\n",
      "[0.6014209, 0.2, 0.20051745, 0.20051041]\n",
      "[0.60064507, 0.2, 0.20003395, 0.20021816]\n",
      "[0.6017088, 0.2, 0.2009545, 0.20036139]\n",
      "[0.6011738, 0.2, 0.20019484, 0.20058595]\n",
      "[0.6008077, 0.2, 0.20020948, 0.20020494]\n",
      "[0.6008922, 0.2, 0.20006171, 0.20043685]\n",
      "[0.6008206, 0.2, 0.20027837, 0.2001482]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7800 iterations: 2.0838942845662434 mins\n",
      "Train Loss: [0.6008206, 0.2, 0.20027837, 0.2001482]\n",
      "[0.60057557, 0.2, 0.20000003, 0.20018111]\n",
      "[0.6008918, 0.2, 0.20034496, 0.20015201]\n",
      "[0.60073304, 0.2, 0.20024692, 0.20009112]\n",
      "[0.6008712, 0.2, 0.20013265, 0.20034344]\n",
      "[0.60062706, 0.2, 0.20015636, 0.2000755]\n",
      "[0.60058343, 0.2, 0.20005144, 0.20013696]\n",
      "[0.60072744, 0.2, 0.20009306, 0.20023943]\n",
      "[0.6008405, 0.2, 0.20027015, 0.20017572]\n",
      "[0.60092604, 0.2, 0.20036799, 0.20016377]\n",
      "[0.600689, 0.2, 0.20009492, 0.20020029]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7810 iterations: 2.08574564854304 mins\n",
      "Train Loss: [0.600689, 0.2, 0.20009492, 0.20020029]\n",
      "[0.60075325, 0.2, 0.20017754, 0.20018251]\n",
      "[0.6015601, 0.2, 0.20089246, 0.20027515]\n",
      "[0.60088134, 0.2, 0.20035169, 0.20013805]\n",
      "[0.6008011, 0.2, 0.20022018, 0.20019023]\n",
      "[0.6005573, 0.2, 0.20007373, 0.20009376]\n",
      "[0.6006564, 0.2, 0.20015705, 0.20011032]\n",
      "[0.60072947, 0.2, 0.20021522, 0.20012608]\n",
      "[0.6008212, 0.2, 0.20028552, 0.20014846]\n",
      "[0.6006975, 0.2, 0.2001516, 0.20015973]\n",
      "[0.60087866, 0.2, 0.20030624, 0.2001873]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7820 iterations: 2.0878493189811707 mins\n",
      "Train Loss: [0.60087866, 0.2, 0.20030624, 0.2001873]\n",
      "[0.600668, 0.2, 0.20016374, 0.20012042]\n",
      "[0.6006591, 0.2, 0.20014946, 0.200127]\n",
      "[0.6006652, 0.2, 0.20005848, 0.20022553]\n",
      "[0.6008632, 0.2, 0.20016527, 0.2003181]\n",
      "[0.6005898, 0.2, 0.20010144, 0.20011003]\n",
      "[0.60110533, 0.2, 0.20057052, 0.20015791]\n",
      "[0.6006659, 0.2, 0.20012055, 0.2001698]\n",
      "[0.6011901, 0.2, 0.200261, 0.20055477]\n",
      "[0.60056317, 0.2, 0.2000585, 0.20013137]\n",
      "[0.60093117, 0.2, 0.20030773, 0.20025098]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7830 iterations: 2.0898351192474367 mins\n",
      "Train Loss: [0.60093117, 0.2, 0.20030773, 0.20025098]\n",
      "[0.60066015, 0.2, 0.20021701, 0.20007141]\n",
      "[0.6009488, 0.2, 0.2003831, 0.20019463]\n",
      "[0.6005931, 0.2, 0.20009951, 0.20012306]\n",
      "[0.6007803, 0.2, 0.20020606, 0.2002044]\n",
      "[0.6005703, 0.2, 0.20014709, 0.20005386]\n",
      "[0.60098624, 0.2, 0.20035362, 0.20026375]\n",
      "[0.6010266, 0.2, 0.20020038, 0.20045766]\n",
      "[0.6009083, 0.2, 0.20030832, 0.20023182]\n",
      "[0.6029315, 0.2, 0.20241675, 0.20014706]\n",
      "[0.60072654, 0.2, 0.20010127, 0.20025805]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7840 iterations: 2.091794164975484 mins\n",
      "Train Loss: [0.60072654, 0.2, 0.20010127, 0.20025805]\n",
      "[0.6006906, 0.2, 0.20020615, 0.20011757]\n",
      "[0.60059124, 0.2, 0.20013331, 0.20009148]\n",
      "[0.6007352, 0.2, 0.20025893, 0.20011026]\n",
      "[0.6006957, 0.2, 0.20015614, 0.20017403]\n",
      "[0.6009299, 0.2, 0.2003521, 0.20021275]\n",
      "[0.6008046, 0.2, 0.2000498, 0.20039023]\n",
      "[0.600918, 0.2, 0.20016995, 0.20038392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6005473, 0.2, 0.2001011, 0.20008257]\n",
      "[0.6009448, 0.2, 0.20036997, 0.20021182]\n",
      "[0.6008808, 0.2, 0.200175, 0.20034337]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7850 iterations: 2.093796380360921 mins\n",
      "Train Loss: [0.6008808, 0.2, 0.200175, 0.20034337]\n",
      "[0.6010015, 0.2, 0.20008513, 0.20055455]\n",
      "[0.6005514, 0.2, 0.20005879, 0.20013124]\n",
      "[0.6008373, 0.2, 0.20018576, 0.20029056]\n",
      "[0.60089993, 0.2, 0.20043737, 0.200102]\n",
      "[0.6008078, 0.2, 0.2002437, 0.20020394]\n",
      "[0.60087764, 0.2, 0.20023403, 0.20028369]\n",
      "[0.60130906, 0.2, 0.20054178, 0.2004073]\n",
      "[0.60079074, 0.2, 0.2001595, 0.20027113]\n",
      "[0.60077095, 0.2, 0.20016766, 0.20024294]\n",
      "[0.60099834, 0.2, 0.20031966, 0.20031792]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7860 iterations: 2.0956711332003275 mins\n",
      "Train Loss: [0.60099834, 0.2, 0.20031966, 0.20031792]\n",
      "[0.60059315, 0.2, 0.20010002, 0.20013191]\n",
      "[0.60068643, 0.2, 0.2002361, 0.20008864]\n",
      "[0.600591, 0.2, 0.20002516, 0.20020376]\n",
      "[0.6005173, 0.2, 0.20014147, 0.20001346]\n",
      "[0.6007329, 0.2, 0.20027284, 0.2000975]\n",
      "[0.60119253, 0.2, 0.20046481, 0.20036496]\n",
      "[0.6007305, 0.2, 0.2002659, 0.20010158]\n",
      "[0.6006878, 0.2, 0.20021918, 0.20010537]\n",
      "[0.6008583, 0.2, 0.20007946, 0.20041528]\n",
      "[0.60074896, 0.2, 0.20008525, 0.20029987]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7870 iterations: 2.0982975323994952 mins\n",
      "Train Loss: [0.60074896, 0.2, 0.20008525, 0.20029987]\n",
      "[0.60081995, 0.2, 0.20008716, 0.20036858]\n",
      "[0.6008444, 0.2, 0.20036758, 0.20011216]\n",
      "[0.6009335, 0.2, 0.20010394, 0.20046441]\n",
      "[0.60064346, 0.2, 0.20018986, 0.20008792]\n",
      "[0.6011635, 0.2, 0.20031877, 0.2004786]\n",
      "[0.60095096, 0.2, 0.20014794, 0.20043626]\n",
      "[0.6009366, 0.2, 0.20011415, 0.20045525]\n",
      "[0.6012317, 0.2, 0.2006565, 0.20020767]\n",
      "[0.6006422, 0.2, 0.200116, 0.20015867]\n",
      "[0.6007129, 0.2, 0.20014226, 0.20020303]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7880 iterations: 2.10023166735967 mins\n",
      "Train Loss: [0.6007129, 0.2, 0.20014226, 0.20020303]\n",
      "[0.6005275, 0.2, 0.20008267, 0.20007722]\n",
      "[0.60067797, 0.2, 0.200231, 0.20007937]\n",
      "[0.6005812, 0.2, 0.2001163, 0.20009741]\n",
      "[0.6007935, 0.2, 0.20015338, 0.20027284]\n",
      "[0.6018519, 0.2, 0.20122875, 0.2002562]\n",
      "[0.6006495, 0.2, 0.2002071, 0.20007569]\n",
      "[0.6005198, 0.2, 0.2, 0.20015325]\n",
      "[0.6006603, 0.2, 0.20018606, 0.20010771]\n",
      "[0.6006868, 0.2, 0.20014295, 0.20017725]\n",
      "[0.6006098, 0.2, 0.20012508, 0.2001179]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7890 iterations: 2.1021706819534303 mins\n",
      "Train Loss: [0.6006098, 0.2, 0.20012508, 0.2001179]\n",
      "[0.60075915, 0.2, 0.20016792, 0.200224]\n",
      "[0.6008843, 0.2, 0.2002272, 0.20028953]\n",
      "[0.60063684, 0.2, 0.2001524, 0.20011622]\n",
      "[0.6010629, 0.2, 0.20041333, 0.20028049]\n",
      "[0.6006605, 0.2, 0.20012632, 0.20016451]\n",
      "[0.60063493, 0.2, 0.20003347, 0.20023108]\n",
      "[0.60070616, 0.2, 0.20017388, 0.20016108]\n",
      "[0.6005995, 0.2, 0.20015247, 0.20007516]\n",
      "[0.60078055, 0.2, 0.2002191, 0.2001889]\n",
      "[0.60062057, 0.2, 0.20014267, 0.20010473]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7900 iterations: 2.1040591478347777 mins\n",
      "Train Loss: [0.60062057, 0.2, 0.20014267, 0.20010473]\n",
      "[0.60063744, 0.2, 0.20021248, 0.20005131]\n",
      "[0.6008402, 0.2, 0.20021266, 0.20025343]\n",
      "[0.60137373, 0.2, 0.20025432, 0.20074494]\n",
      "[0.60093087, 0.2, 0.20026657, 0.20028959]\n",
      "[0.60241795, 0.2, 0.20176883, 0.20027426]\n",
      "[0.600652, 0.2, 0.20011967, 0.20015727]\n",
      "[0.600797, 0.2, 0.20018934, 0.2002324]\n",
      "[0.60071576, 0.2, 0.20014603, 0.2001942]\n",
      "[0.60062283, 0.2, 0.20011488, 0.20013198]\n",
      "[0.60069597, 0.2, 0.20026985, 0.20004979]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7910 iterations: 2.106327966849009 mins\n",
      "Train Loss: [0.60069597, 0.2, 0.20026985, 0.20004979]\n",
      "[0.60074, 0.2, 0.20023166, 0.20013162]\n",
      "[0.6007634, 0.2, 0.20030126, 0.20008504]\n",
      "[0.6005683, 0.2, 0.20011632, 0.2000747]\n",
      "[0.60129, 0.2, 0.20059745, 0.20031506]\n",
      "[0.6018513, 0.2, 0.201289, 0.20018478]\n",
      "[0.60079587, 0.2, 0.20029694, 0.20012143]\n",
      "[0.60078377, 0.2, 0.2001347, 0.20027134]\n",
      "[0.6007055, 0.2, 0.20023237, 0.20009497]\n",
      "[0.6006556, 0.2, 0.20019644, 0.20008056]\n",
      "[0.60064596, 0.2, 0.20020701, 0.20005986]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7920 iterations: 2.1083141326904298 mins\n",
      "Train Loss: [0.60064596, 0.2, 0.20020701, 0.20005986]\n",
      "[0.60088694, 0.2, 0.2002812, 0.20022626]\n",
      "[0.6006046, 0.2, 0.20012914, 0.20009553]\n",
      "[0.6008709, 0.2, 0.20030555, 0.20018509]\n",
      "[0.60082155, 0.2, 0.20024572, 0.20019542]\n",
      "[0.60061085, 0.2, 0.20018245, 0.20004778]\n",
      "[0.60053694, 0.2, 0.20004952, 0.2001065]\n",
      "[0.6007764, 0.2, 0.20026374, 0.20013148]\n",
      "[0.6010505, 0.2, 0.2002878, 0.20038126]\n",
      "[0.6008989, 0.2, 0.2003018, 0.20021544]\n",
      "[0.6007535, 0.2, 0.20023705, 0.20013484]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7930 iterations: 2.110210351149241 mins\n",
      "Train Loss: [0.6007535, 0.2, 0.20023705, 0.20013484]\n",
      "[0.60078573, 0.2, 0.20026416, 0.2001402]\n",
      "[0.600732, 0.2, 0.20014963, 0.2002012]\n",
      "[0.60071886, 0.2, 0.20014009, 0.20019802]\n",
      "[0.60067314, 0.2, 0.20018247, 0.20011035]\n",
      "[0.6006605, 0.2, 0.20010187, 0.20017877]\n",
      "[0.60063434, 0.2, 0.2001039, 0.20015094]\n",
      "[0.60058504, 0.2, 0.20006205, 0.20014398]\n",
      "[0.6006835, 0.2, 0.20016892, 0.200136]\n",
      "[0.6007742, 0.2, 0.2002197, 0.20017645]\n",
      "[0.6037233, 0.2, 0.20026328, 0.20308252]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7940 iterations: 2.1122019489606223 mins\n",
      "Train Loss: [0.6037233, 0.2, 0.20026328, 0.20308252]\n",
      "[0.60077876, 0.2, 0.20007734, 0.2003248]\n",
      "[0.60067207, 0.2, 0.20017444, 0.20012152]\n",
      "[0.60128415, 0.2, 0.2007107, 0.20019773]\n",
      "[0.60058904, 0.2, 0.20011032, 0.20010303]\n",
      "[0.60061425, 0.2, 0.20020062, 0.20003794]\n",
      "[0.6008267, 0.2, 0.20020328, 0.20024763]\n",
      "[0.600636, 0.2, 0.20013303, 0.20012721]\n",
      "[0.60092986, 0.2, 0.20019417, 0.20035996]\n",
      "[0.6010317, 0.2, 0.20036978, 0.2002863]\n",
      "[0.60077745, 0.2, 0.20013613, 0.20026581]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7950 iterations: 2.114530797799428 mins\n",
      "Train Loss: [0.60077745, 0.2, 0.20013613, 0.20026581]\n",
      "[0.6008895, 0.2, 0.20025754, 0.20025653]\n",
      "[0.6006584, 0.2, 0.2001481, 0.20013495]\n",
      "[0.60062873, 0.2, 0.20012021, 0.20013328]\n",
      "[0.6008024, 0.2, 0.20022197, 0.20020533]\n",
      "[0.6008125, 0.2, 0.20020455, 0.20023313]\n",
      "[0.6006265, 0.2, 0.20015395, 0.20009807]\n",
      "[0.60076904, 0.2, 0.20025015, 0.20014487]\n",
      "[0.600605, 0.2, 0.20014806, 0.20008354]\n",
      "[0.60064906, 0.2, 0.20007497, 0.20020138]\n",
      "[0.6007017, 0.2, 0.20020255, 0.20012707]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7960 iterations: 2.11652694940567 mins\n",
      "Train Loss: [0.6007017, 0.2, 0.20020255, 0.20012707]\n",
      "[0.6006406, 0.2, 0.20020525, 0.20006394]\n",
      "[0.6007606, 0.2, 0.2001932, 0.20019676]\n",
      "[0.6008836, 0.2, 0.20021626, 0.20029747]\n",
      "[0.60176903, 0.2, 0.20010766, 0.20129228]\n",
      "[0.6005747, 0.2, 0.20011052, 0.20009577]\n",
      "[0.6006441, 0.2, 0.20013681, 0.2001396]\n",
      "[0.6005996, 0.2, 0.20013155, 0.20010103]\n",
      "[0.6007287, 0.2, 0.20016886, 0.20019355]\n",
      "[0.60055405, 0.2, 0.20012785, 0.20006056]\n",
      "[0.6007822, 0.2, 0.2001104, 0.2003069]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7970 iterations: 2.1183389822642007 mins\n",
      "Train Loss: [0.6007822, 0.2, 0.2001104, 0.2003069]\n",
      "[0.60064274, 0.2, 0.20011188, 0.20016676]\n",
      "[0.60062885, 0.2, 0.20007446, 0.20019114]\n",
      "[0.6005972, 0.2, 0.20014405, 0.20009075]\n",
      "[0.60078275, 0.2, 0.20022039, 0.2002009]\n",
      "[0.6009264, 0.2, 0.20038074, 0.20018524]\n",
      "[0.60073704, 0.2, 0.20012589, 0.20025171]\n",
      "[0.6005267, 0.2, 0.20009603, 0.20007227]\n",
      "[0.6006119, 0.2, 0.20020364, 0.20005077]\n",
      "[0.60063714, 0.2, 0.2001714, 0.20010923]\n",
      "[0.6006264, 0.2, 0.20006728, 0.20020366]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7980 iterations: 2.12039920091629 mins\n",
      "Train Loss: [0.6006264, 0.2, 0.20006728, 0.20020366]\n",
      "[0.6006716, 0.2, 0.20017238, 0.2001448]\n",
      "[0.60067827, 0.2, 0.2001551, 0.20016983]\n",
      "[0.6008613, 0.2, 0.20020899, 0.20030004]\n",
      "[0.60078037, 0.2, 0.20012356, 0.20030566]\n",
      "[0.60080934, 0.2, 0.2002102, 0.20024906]\n",
      "[0.60064644, 0.2, 0.20007636, 0.2002212]\n",
      "[0.6011164, 0.2, 0.20026648, 0.20050222]\n",
      "[0.6006804, 0.2, 0.20025131, 0.20008262]\n",
      "[0.60067654, 0.2, 0.20012882, 0.20020214]\n",
      "[0.6005401, 0.2, 0.20011286, 0.20008248]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7990 iterations: 2.1224715153376263 mins\n",
      "Train Loss: [0.6005401, 0.2, 0.20011286, 0.20008248]\n",
      "[0.60065573, 0.2, 0.20016299, 0.20014872]\n",
      "[0.6006936, 0.2, 0.2000807, 0.2002696]\n",
      "[0.6006611, 0.2, 0.20017649, 0.20014183]\n",
      "[0.6008213, 0.2, 0.20012724, 0.2003517]\n",
      "[0.60053015, 0.2, 0.20009185, 0.2000962]\n",
      "[0.60105544, 0.2, 0.20017566, 0.20053808]\n",
      "[0.60045743, 0.2, 0.2000441, 0.20007223]\n",
      "[0.60068136, 0.2, 0.20013022, 0.2002106]\n",
      "[0.6005712, 0.2, 0.20018725, 0.200044]\n",
      "[0.60062504, 0.2, 0.20004687, 0.20023885]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8000 iterations: 2.1243987679481506 mins\n",
      "Train Loss: [0.60062504, 0.2, 0.20004687, 0.20023885]\n",
      "[0.6008751, 0.2, 0.20026404, 0.20027247]\n",
      "[0.6006496, 0.2, 0.2001617, 0.2001499]\n",
      "[0.60063404, 0.2, 0.20015971, 0.20013703]\n",
      "[0.60071975, 0.2, 0.20015374, 0.20022947]\n",
      "[0.6008252, 0.2, 0.2004129, 0.20007652]\n",
      "[0.60084057, 0.2, 0.20018363, 0.20032205]\n",
      "[0.60079515, 0.2, 0.20031236, 0.20014879]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60070676, 0.2, 0.20016903, 0.20020448]\n",
      "[0.60060304, 0.2, 0.2000887, 0.200182]\n",
      "[0.6005259, 0.2, 0.20010634, 0.20008793]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8010 iterations: 2.1268545031547545 mins\n",
      "Train Loss: [0.6005259, 0.2, 0.20010634, 0.20008793]\n",
      "[0.60047936, 0.2, 0.20009004, 0.20005825]\n",
      "[0.6005574, 0.2, 0.20011312, 0.20011379]\n",
      "[0.60058266, 0.2, 0.20015307, 0.20009965]\n",
      "[0.60069716, 0.2, 0.20019053, 0.20017736]\n",
      "[0.6007373, 0.2, 0.200264, 0.20014481]\n",
      "[0.6009113, 0.2, 0.20025489, 0.20032878]\n",
      "[0.6006686, 0.2, 0.20027272, 0.20006894]\n",
      "[0.60071963, 0.2, 0.20026316, 0.20012999]\n",
      "[0.60075325, 0.2, 0.20013857, 0.20028861]\n",
      "[0.60050505, 0.2, 0.20007822, 0.20010099]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8020 iterations: 2.128632966677348 mins\n",
      "Train Loss: [0.60050505, 0.2, 0.20007822, 0.20010099]\n",
      "[0.6007752, 0.2, 0.20011239, 0.20033698]\n",
      "[0.60059315, 0.2, 0.20009522, 0.20017181]\n",
      "[0.60074025, 0.2, 0.20024419, 0.20016977]\n",
      "[0.6006906, 0.2, 0.20015438, 0.20020953]\n",
      "[0.6009093, 0.2, 0.20039423, 0.20018806]\n",
      "[0.6006502, 0.2, 0.2000949, 0.20022821]\n",
      "[0.60058063, 0.2, 0.20012109, 0.20013225]\n",
      "[0.60057545, 0.2, 0.20011108, 0.20013705]\n",
      "[0.6007017, 0.2, 0.20019646, 0.20017783]\n",
      "[0.6007938, 0.2, 0.20029582, 0.2001704]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8030 iterations: 2.1311972975730895 mins\n",
      "Train Loss: [0.6007938, 0.2, 0.20029582, 0.2001704]\n",
      "[0.600586, 0.2, 0.2001435, 0.20011498]\n",
      "[0.6007354, 0.2, 0.20015045, 0.20025738]\n",
      "[0.6006704, 0.2, 0.20011446, 0.20022832]\n",
      "[0.6005224, 0.2, 0.20012808, 0.20006676]\n",
      "[0.6007124, 0.2, 0.20025277, 0.20013206]\n",
      "[0.60091996, 0.2, 0.2002934, 0.20029883]\n",
      "[0.6007118, 0.2, 0.20008706, 0.20029697]\n",
      "[0.60069346, 0.2, 0.20015363, 0.20021202]\n",
      "[0.6008815, 0.2, 0.20025313, 0.20030051]\n",
      "[0.6008078, 0.2, 0.20023347, 0.20024638]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8040 iterations: 2.1331037998199465 mins\n",
      "Train Loss: [0.6008078, 0.2, 0.20023347, 0.20024638]\n",
      "[0.60069066, 0.2, 0.20022844, 0.20013404]\n",
      "[0.6005884, 0.2, 0.2001108, 0.20014928]\n",
      "[0.6006937, 0.2, 0.20011024, 0.20025492]\n",
      "[0.60061216, 0.2, 0.20014152, 0.20014194]\n",
      "[0.60065705, 0.2, 0.2002046, 0.20012379]\n",
      "[0.60059536, 0.2, 0.2001464, 0.20012034]\n",
      "[0.6005063, 0.2, 0.2000761, 0.20010181]\n",
      "[0.60056436, 0.2, 0.20002979, 0.20020634]\n",
      "[0.60082436, 0.2, 0.20008624, 0.20041026]\n",
      "[0.6005311, 0.2, 0.20004892, 0.20015477]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8050 iterations: 2.1350568493207294 mins\n",
      "Train Loss: [0.6005311, 0.2, 0.20004892, 0.20015477]\n",
      "[0.6008347, 0.2, 0.2003144, 0.20019343]\n",
      "[0.60051507, 0.2, 0.2000437, 0.20014514]\n",
      "[0.6006163, 0.2, 0.20015194, 0.2001388]\n",
      "[0.6006596, 0.2, 0.20020579, 0.20012905]\n",
      "[0.60070777, 0.2, 0.20026495, 0.20011874]\n",
      "[0.600795, 0.2, 0.20024258, 0.20022906]\n",
      "[0.60096395, 0.2, 0.20026383, 0.20037743]\n",
      "[0.60059947, 0.2, 0.20010433, 0.2001731]\n",
      "[0.6006061, 0.2, 0.20011134, 0.20017329]\n",
      "[0.6006205, 0.2, 0.20016891, 0.20013073]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8060 iterations: 2.13699578444163 mins\n",
      "Train Loss: [0.6006205, 0.2, 0.20016891, 0.20013073]\n",
      "[0.600678, 0.2, 0.20016159, 0.20019591]\n",
      "[0.6006188, 0.2, 0.20007737, 0.20022146]\n",
      "[0.6009287, 0.2, 0.20028941, 0.20031977]\n",
      "[0.6007515, 0.2, 0.2002912, 0.20014107]\n",
      "[0.60075825, 0.2, 0.20029111, 0.20014782]\n",
      "[0.60070676, 0.2, 0.20018876, 0.20019852]\n",
      "[0.60067374, 0.2, 0.20011, 0.20024396]\n",
      "[0.6005859, 0.2, 0.20011812, 0.20014755]\n",
      "[0.6008542, 0.2, 0.2002992, 0.20023434]\n",
      "[0.60143423, 0.2, 0.20017293, 0.20094025]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8070 iterations: 2.1390200654665628 mins\n",
      "Train Loss: [0.60143423, 0.2, 0.20017293, 0.20094025]\n",
      "[0.6007217, 0.2, 0.20028284, 0.20011728]\n",
      "[0.6005614, 0.2, 0.20011923, 0.20012009]\n",
      "[0.60084695, 0.2, 0.20013903, 0.20038542]\n",
      "[0.6006933, 0.2, 0.20009576, 0.20027463]\n",
      "[0.60090566, 0.2, 0.20028992, 0.20029241]\n",
      "[0.6004868, 0.2, 0.20014758, 0.20001557]\n",
      "[0.601061, 0.2, 0.20038982, 0.20034689]\n",
      "[0.6007421, 0.2, 0.20022519, 0.20019214]\n",
      "[0.60064214, 0.2, 0.20009264, 0.20022397]\n",
      "[0.60093814, 0.2, 0.20040254, 0.2002094]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8080 iterations: 2.1408813993136087 mins\n",
      "Train Loss: [0.60093814, 0.2, 0.20040254, 0.2002094]\n",
      "[0.60064673, 0.2, 0.20010799, 0.20021176]\n",
      "[0.60041517, 0.2, 0.20005758, 0.20002975]\n",
      "[0.6009373, 0.2, 0.20040266, 0.20020595]\n",
      "[0.6008159, 0.2, 0.2002375, 0.20024885]\n",
      "[0.6006883, 0.2, 0.20015338, 0.20020452]\n",
      "[0.6007111, 0.2, 0.20019867, 0.20018117]\n",
      "[0.60091275, 0.2, 0.20039335, 0.20018733]\n",
      "[0.60062116, 0.2, 0.20013654, 0.20015186]\n",
      "[0.600518, 0.2, 0.20010059, 0.20008393]\n",
      "[0.60053676, 0.2, 0.20016447, 0.20003805]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8090 iterations: 2.142872714996338 mins\n",
      "Train Loss: [0.60053676, 0.2, 0.20016447, 0.20003805]\n",
      "[0.60046285, 0.2, 0.20000038, 0.2001276]\n",
      "[0.60105616, 0.2, 0.2001132, 0.20060752]\n",
      "[0.60075676, 0.2, 0.20026322, 0.20015799]\n",
      "[0.6008258, 0.2, 0.20012873, 0.20036128]\n",
      "[0.6008219, 0.2, 0.20017791, 0.200308]\n",
      "[0.6009432, 0.2, 0.20021698, 0.2003898]\n",
      "[0.6010058, 0.2, 0.20032042, 0.20034842]\n",
      "[0.6006424, 0.2, 0.20014168, 0.2001629]\n",
      "[0.6016014, 0.2, 0.20051841, 0.20074424]\n",
      "[0.60094506, 0.2, 0.20026772, 0.20033754]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8100 iterations: 2.1450045466423036 mins\n",
      "Train Loss: [0.60094506, 0.2, 0.20026772, 0.20033754]\n",
      "[0.6007278, 0.2, 0.20024274, 0.20014422]\n",
      "[0.60072976, 0.2, 0.20026936, 0.20011848]\n",
      "[0.6008675, 0.2, 0.20018291, 0.20034155]\n",
      "[0.601159, 0.2, 0.20065622, 0.20015858]\n",
      "[0.6012413, 0.2, 0.20056154, 0.20033462]\n",
      "[0.60093725, 0.2, 0.20022132, 0.20036954]\n",
      "[0.6010052, 0.2, 0.20026956, 0.20038788]\n",
      "[0.60063636, 0.2, 0.20015447, 0.20013267]\n",
      "[0.6007677, 0.2, 0.20020428, 0.20021261]\n",
      "[0.6010586, 0.2, 0.20039138, 0.2003149]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8110 iterations: 2.14746994972229 mins\n",
      "Train Loss: [0.6010586, 0.2, 0.20039138, 0.2003149]\n",
      "[0.6012612, 0.2, 0.2004589, 0.20044853]\n",
      "[0.6011041, 0.2, 0.20052354, 0.20022514]\n",
      "[0.60105604, 0.2, 0.20018277, 0.20051621]\n",
      "[0.6008488, 0.2, 0.20016381, 0.20032622]\n",
      "[0.6010822, 0.2, 0.2000019, 0.2007197]\n",
      "[0.6014588, 0.2, 0.20056261, 0.20053385]\n",
      "[0.6012216, 0.2, 0.20054504, 0.20031239]\n",
      "[0.6008556, 0.2, 0.20025356, 0.20023622]\n",
      "[0.60096395, 0.2, 0.20007873, 0.20051786]\n",
      "[0.60071814, 0.2, 0.20016663, 0.20018247]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8120 iterations: 2.1494845191637677 mins\n",
      "Train Loss: [0.60071814, 0.2, 0.20016663, 0.20018247]\n",
      "[0.6007982, 0.2, 0.20009364, 0.20033368]\n",
      "[0.60090476, 0.2, 0.20011605, 0.20041627]\n",
      "[0.6011193, 0.2, 0.20055652, 0.20018892]\n",
      "[0.6005035, 0.2, 0.20000003, 0.2001284]\n",
      "[0.60074115, 0.2, 0.20028569, 0.2000791]\n",
      "[0.6011619, 0.2, 0.20024562, 0.20053864]\n",
      "[0.6012091, 0.2, 0.20041035, 0.20041996]\n",
      "[0.601352, 0.2, 0.20037471, 0.20059763]\n",
      "[0.6011752, 0.2, 0.20033479, 0.20046002]\n",
      "[0.60125995, 0.2, 0.20030047, 0.20057824]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8130 iterations: 2.1513094464937845 mins\n",
      "Train Loss: [0.60125995, 0.2, 0.20030047, 0.20057824]\n",
      "[0.601031, 0.2, 0.20026793, 0.20038098]\n",
      "[0.6007843, 0.2, 0.20027474, 0.20012645]\n",
      "[0.60087, 0.2, 0.2000638, 0.20042211]\n",
      "[0.6012662, 0.2, 0.20004685, 0.20083411]\n",
      "[0.6007734, 0.2, 0.20017213, 0.20021494]\n",
      "[0.60064644, 0.2, 0.20016576, 0.2000928]\n",
      "[0.60101676, 0.2, 0.20017406, 0.20045291]\n",
      "[0.6007947, 0.2, 0.20019712, 0.20020595]\n",
      "[0.6027621, 0.2, 0.2019695, 0.20039909]\n",
      "[0.6007628, 0.2, 0.20008315, 0.20028423]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8140 iterations: 2.1533108830451964 mins\n",
      "Train Loss: [0.6007628, 0.2, 0.20008315, 0.20028423]\n",
      "[0.60056627, 0.2, 0.20009723, 0.20007165]\n",
      "[0.6011405, 0.2, 0.20022786, 0.20051357]\n",
      "[0.60088843, 0.2, 0.2002306, 0.200257]\n",
      "[0.6008273, 0.2, 0.20025085, 0.20017397]\n",
      "[0.6011733, 0.2, 0.20033987, 0.20042956]\n",
      "[0.60075015, 0.2, 0.20015506, 0.20019023]\n",
      "[0.6012065, 0.2, 0.20020202, 0.20059879]\n",
      "[0.6009738, 0.2, 0.20028774, 0.20027976]\n",
      "[0.6011197, 0.2, 0.20014325, 0.20056975]\n",
      "[0.60110736, 0.2, 0.20027076, 0.20042965]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8150 iterations: 2.155108380317688 mins\n",
      "Train Loss: [0.60110736, 0.2, 0.20027076, 0.20042965]\n",
      "[0.6013942, 0.2, 0.20070621, 0.20028046]\n",
      "[0.60087204, 0.2, 0.2000591, 0.2004049]\n",
      "[0.6007852, 0.2, 0.20005557, 0.20032091]\n",
      "[0.6011901, 0.2, 0.20041043, 0.20037019]\n",
      "[0.601492, 0.2, 0.20061995, 0.20046277]\n",
      "[0.60103405, 0.2, 0.20027001, 0.20035504]\n",
      "[0.6011478, 0.2, 0.20032603, 0.20041257]\n",
      "[0.60121876, 0.2, 0.20050721, 0.20030253]\n",
      "[0.60102725, 0.2, 0.2004628, 0.20015551]\n",
      "[0.6009741, 0.2, 0.2002925, 0.20027241]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8160 iterations: 2.1571726322174074 mins\n",
      "Train Loss: [0.6009741, 0.2, 0.2002925, 0.20027241]\n",
      "[0.60064656, 0.2, 0.20017706, 0.20006032]\n",
      "[0.60086083, 0.2, 0.20012097, 0.20033045]\n",
      "[0.6008762, 0.2, 0.20036064, 0.20010588]\n",
      "[0.6005528, 0.2, 0.2001007, 0.2000421]\n",
      "[0.60071695, 0.2, 0.20009145, 0.2002153]\n",
      "[0.6012419, 0.2, 0.2005159, 0.20031558]\n",
      "[0.6011674, 0.2, 0.20024744, 0.20050944]\n",
      "[0.60139984, 0.2, 0.20041552, 0.20057379]\n",
      "[0.60087943, 0.2, 0.20029871, 0.20017053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6010869, 0.2, 0.20040523, 0.20027165]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8170 iterations: 2.1591836333274843 mins\n",
      "Train Loss: [0.6010869, 0.2, 0.20040523, 0.20027165]\n",
      "[0.60112906, 0.2, 0.20044066, 0.20027858]\n",
      "[0.60070986, 0.2, 0.20000012, 0.2003002]\n",
      "[0.6007572, 0.2, 0.20012146, 0.20022662]\n",
      "[0.6009189, 0.2, 0.20023075, 0.20027927]\n",
      "[0.60075355, 0.2, 0.20015289, 0.20019184]\n",
      "[0.6006714, 0.2, 0.2001782, 0.20008434]\n",
      "[0.60105747, 0.2, 0.20027888, 0.20036969]\n",
      "[0.60133505, 0.2, 0.20057274, 0.20035365]\n",
      "[0.6008527, 0.2, 0.20022434, 0.20022075]\n",
      "[0.60112125, 0.2, 0.20037875, 0.20033586]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8180 iterations: 2.161224635442098 mins\n",
      "Train Loss: [0.60112125, 0.2, 0.20037875, 0.20033586]\n",
      "[0.60085875, 0.2, 0.20023581, 0.20021743]\n",
      "[0.6006888, 0.2, 0.2001749, 0.2001093]\n",
      "[0.6009927, 0.2, 0.20024146, 0.20034738]\n",
      "[0.60076916, 0.2, 0.20012784, 0.20023821]\n",
      "[0.6006691, 0.2, 0.20016924, 0.20009768]\n",
      "[0.6008876, 0.2, 0.20021656, 0.20026974]\n",
      "[0.60086024, 0.2, 0.20013458, 0.20032535]\n",
      "[0.6010716, 0.2, 0.20031565, 0.20035641]\n",
      "[0.6013179, 0.2, 0.2004255, 0.2004937]\n",
      "[0.6011292, 0.2, 0.2003466, 0.20038442]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8190 iterations: 2.1631470680236817 mins\n",
      "Train Loss: [0.6011292, 0.2, 0.2003466, 0.20038442]\n",
      "[0.60059136, 0.2, 0.20006941, 0.20012432]\n",
      "[0.6009568, 0.2, 0.2002293, 0.20033002]\n",
      "[0.6011659, 0.2, 0.20023413, 0.20053415]\n",
      "[0.6006573, 0.2, 0.20014173, 0.20011751]\n",
      "[0.60105705, 0.2, 0.20010225, 0.20055634]\n",
      "[0.6007058, 0.2, 0.200212, 0.20009495]\n",
      "[0.6011866, 0.2, 0.20058313, 0.2002038]\n",
      "[0.600956, 0.2, 0.20015886, 0.20039688]\n",
      "[0.60106593, 0.2, 0.20036684, 0.2002982]\n",
      "[0.60075516, 0.2, 0.20022967, 0.20012388]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8200 iterations: 2.1655366818110147 mins\n",
      "Train Loss: [0.60075516, 0.2, 0.20022967, 0.20012388]\n",
      "[0.6006915, 0.2, 0.20014751, 0.20014188]\n",
      "[0.6009441, 0.2, 0.2002815, 0.2002601]\n",
      "[0.60062474, 0.2, 0.20011893, 0.20010312]\n",
      "[0.6009717, 0.2, 0.20018096, 0.20038797]\n",
      "[0.60070163, 0.2, 0.20000003, 0.20029919]\n",
      "[0.60098636, 0.2, 0.20030618, 0.20027812]\n",
      "[0.60074824, 0.2, 0.20014037, 0.20020612]\n",
      "[0.60074633, 0.2, 0.20016955, 0.20017557]\n",
      "[0.6007414, 0.2, 0.20009804, 0.20024262]\n",
      "[0.6008843, 0.2, 0.20017318, 0.20031078]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8210 iterations: 2.1675177852312726 mins\n",
      "Train Loss: [0.6008843, 0.2, 0.20017318, 0.20031078]\n",
      "[0.6013231, 0.2, 0.20035352, 0.20056967]\n",
      "[0.6006905, 0.2, 0.20009355, 0.20019776]\n",
      "[0.6007361, 0.2, 0.20027433, 0.20006339]\n",
      "[0.60100204, 0.2, 0.20017976, 0.20042476]\n",
      "[0.6008287, 0.2, 0.2001868, 0.20024535]\n",
      "[0.6018771, 0.2, 0.2009318, 0.20054975]\n",
      "[0.6009273, 0.2, 0.20023097, 0.20030172]\n",
      "[0.60062474, 0.2, 0.20013867, 0.20009227]\n",
      "[0.6007828, 0.2, 0.2002391, 0.2001505]\n",
      "[0.6006607, 0.2, 0.20009625, 0.20017172]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8220 iterations: 2.1694806655248007 mins\n",
      "Train Loss: [0.6006607, 0.2, 0.20009625, 0.20017172]\n",
      "[0.6005978, 0.2, 0.20005657, 0.20014924]\n",
      "[0.60070276, 0.2, 0.20008022, 0.20023115]\n",
      "[0.60089636, 0.2, 0.20038457, 0.20012085]\n",
      "[0.6009675, 0.2, 0.20019077, 0.20038597]\n",
      "[0.6006474, 0.2, 0.20010225, 0.2001544]\n",
      "[0.6007708, 0.2, 0.20006111, 0.20031877]\n",
      "[0.60103065, 0.2, 0.20017438, 0.20046523]\n",
      "[0.601207, 0.2, 0.20021956, 0.20059603]\n",
      "[0.6011317, 0.2, 0.20041862, 0.2003214]\n",
      "[0.60089666, 0.2, 0.20030698, 0.20019792]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8230 iterations: 2.171555829048157 mins\n",
      "Train Loss: [0.60089666, 0.2, 0.20030698, 0.20019792]\n",
      "[0.60060805, 0.2, 0.20007676, 0.20013933]\n",
      "[0.60124767, 0.2, 0.2002659, 0.2005896]\n",
      "[0.6009728, 0.2, 0.2001346, 0.2004459]\n",
      "[0.6011019, 0.2, 0.20045945, 0.20024984]\n",
      "[0.60080624, 0.2, 0.20016012, 0.2002534]\n",
      "[0.6010117, 0.2, 0.20024125, 0.20037764]\n",
      "[0.6008682, 0.2, 0.20021752, 0.20025778]\n",
      "[0.6007532, 0.2, 0.2002165, 0.20014377]\n",
      "[0.60114676, 0.2, 0.20007786, 0.20067608]\n",
      "[0.60078, 0.2, 0.20016927, 0.20021774]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8240 iterations: 2.17358683347702 mins\n",
      "Train Loss: [0.60078, 0.2, 0.20016927, 0.20021774]\n",
      "[0.6009336, 0.2, 0.20019889, 0.20034167]\n",
      "[0.60102373, 0.2, 0.2002453, 0.20038484]\n",
      "[0.6008472, 0.2, 0.20013802, 0.20031495]\n",
      "[0.6009118, 0.2, 0.20024353, 0.20027368]\n",
      "[0.6017367, 0.2, 0.200626, 0.2007158]\n",
      "[0.60083944, 0.2, 0.20018417, 0.20025986]\n",
      "[0.60117203, 0.2, 0.20031615, 0.20046003]\n",
      "[0.6006826, 0.2, 0.20018376, 0.20010258]\n",
      "[0.6008614, 0.2, 0.20019688, 0.20026784]\n",
      "[0.6011399, 0.2, 0.2003467, 0.2003962]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8250 iterations: 2.175578598181407 mins\n",
      "Train Loss: [0.6011399, 0.2, 0.2003467, 0.2003962]\n",
      "[0.6008649, 0.2, 0.2001914, 0.20027645]\n",
      "[0.6006824, 0.2, 0.20007376, 0.20021142]\n",
      "[0.6009323, 0.2, 0.20029919, 0.20023565]\n",
      "[0.60069376, 0.2, 0.2, 0.20029633]\n",
      "[0.6008158, 0.2, 0.20008318, 0.20033503]\n",
      "[0.600916, 0.2, 0.20016718, 0.20035087]\n",
      "[0.60155463, 0.2, 0.20092578, 0.20023039]\n",
      "[0.60109025, 0.2, 0.20048858, 0.20020318]\n",
      "[0.6009284, 0.2, 0.2000371, 0.2004926]\n",
      "[0.60128856, 0.2, 0.20010401, 0.20078537]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8260 iterations: 2.177640450000763 mins\n",
      "Train Loss: [0.60128856, 0.2, 0.20010401, 0.20078537]\n",
      "[0.60081804, 0.2, 0.20014349, 0.2002747]\n",
      "[0.60095066, 0.2, 0.20026825, 0.20028163]\n",
      "[0.60065913, 0.2, 0.20012839, 0.20012902]\n",
      "[0.6016433, 0.2, 0.20027485, 0.20096579]\n",
      "[0.60079175, 0.2, 0.20024134, 0.20014682]\n",
      "[0.6011762, 0.2, 0.200209, 0.20056255]\n",
      "[0.6008908, 0.2, 0.2001407, 0.2003444]\n",
      "[0.60079205, 0.2, 0.20011401, 0.2002716]\n",
      "[0.60084254, 0.2, 0.20026006, 0.20017536]\n",
      "[0.6009258, 0.2, 0.20027357, 0.20024467]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8270 iterations: 2.179522466659546 mins\n",
      "Train Loss: [0.6009258, 0.2, 0.20027357, 0.20024467]\n",
      "[0.60097593, 0.2, 0.20019482, 0.20037304]\n",
      "[0.60097444, 0.2, 0.2003407, 0.20022564]\n",
      "[0.60139585, 0.2, 0.20018871, 0.20079906]\n",
      "[0.6011915, 0.2, 0.20048779, 0.20029585]\n",
      "[0.60169977, 0.2, 0.20050786, 0.20078452]\n",
      "[0.600978, 0.2, 0.2002761, 0.20029515]\n",
      "[0.60087305, 0.2, 0.2002871, 0.20017958]\n",
      "[0.6009094, 0.2, 0.2002151, 0.20028834]\n",
      "[0.60068715, 0.2, 0.20001596, 0.20026535]\n",
      "[0.60125196, 0.2, 0.20026228, 0.2005838]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8280 iterations: 2.1823521137237547 mins\n",
      "Train Loss: [0.60125196, 0.2, 0.20026228, 0.2005838]\n",
      "[0.6006105, 0.2, 0.20000003, 0.2002049]\n",
      "[0.60079896, 0.2, 0.20030099, 0.20009275]\n",
      "[0.6009091, 0.2, 0.20014256, 0.20036161]\n",
      "[0.6011077, 0.2, 0.20023614, 0.2004668]\n",
      "[0.6007751, 0.2, 0.20021372, 0.20015705]\n",
      "[0.60121757, 0.2, 0.20039055, 0.20042303]\n",
      "[0.6007196, 0.2, 0.20014338, 0.20017283]\n",
      "[0.600644, 0.2, 0.20009391, 0.2001469]\n",
      "[0.60081124, 0.2, 0.20008352, 0.20032446]\n",
      "[0.60103774, 0.2, 0.20043583, 0.20019846]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8290 iterations: 2.184323048591614 mins\n",
      "Train Loss: [0.60103774, 0.2, 0.20043583, 0.20019846]\n",
      "[0.6010489, 0.2, 0.2001229, 0.20052218]\n",
      "[0.60081565, 0.2, 0.20010513, 0.20030606]\n",
      "[0.6007062, 0.2, 0.2001606, 0.20014033]\n",
      "[0.60112673, 0.2, 0.20025034, 0.20046987]\n",
      "[0.6007974, 0.2, 0.20021696, 0.2001723]\n",
      "[0.6009616, 0.2, 0.20027085, 0.20028105]\n",
      "[0.60095733, 0.2, 0.20037964, 0.20016631]\n",
      "[0.6009384, 0.2, 0.20036292, 0.20016298]\n",
      "[0.6011079, 0.2, 0.20059897, 0.20009544]\n",
      "[0.6009533, 0.2, 0.2004938, 0.20004521]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8300 iterations: 2.186405583222707 mins\n",
      "Train Loss: [0.6009533, 0.2, 0.2004938, 0.20004521]\n",
      "[0.6007994, 0.2, 0.20007253, 0.20031157]\n",
      "[0.60120016, 0.2, 0.20041125, 0.20037232]\n",
      "[0.6009189, 0.2, 0.20025517, 0.20024566]\n",
      "[0.6009075, 0.2, 0.20042457, 0.20006317]\n",
      "[0.6011848, 0.2, 0.20015495, 0.20060822]\n",
      "[0.60152173, 0.2, 0.20042963, 0.20066905]\n",
      "[0.6010867, 0.2, 0.2003688, 0.20029351]\n",
      "[0.60169977, 0.2, 0.20020817, 0.20106594]\n",
      "[0.6016753, 0.2, 0.20049287, 0.20075594]\n",
      "[0.60110164, 0.2, 0.20016201, 0.20051247]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8310 iterations: 2.1884304682413735 mins\n",
      "Train Loss: [0.60110164, 0.2, 0.20016201, 0.20051247]\n",
      "[0.601455, 0.2, 0.20032065, 0.20070674]\n",
      "[0.60105246, 0.2, 0.20020436, 0.20042013]\n",
      "[0.60069484, 0.2, 0.20013808, 0.2001279]\n",
      "[0.6009589, 0.2, 0.20011845, 0.20041047]\n",
      "[0.60100406, 0.2, 0.20006563, 0.20050743]\n",
      "[0.6012921, 0.2, 0.20039639, 0.20046358]\n",
      "[0.601261, 0.2, 0.20025188, 0.20057605]\n",
      "[0.60093015, 0.2, 0.20039138, 0.20010458]\n",
      "[0.60098004, 0.2, 0.2000499, 0.20049503]\n",
      "[0.6010053, 0.2, 0.20013343, 0.20043577]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8320 iterations: 2.190311682224274 mins\n",
      "Train Loss: [0.6010053, 0.2, 0.20013343, 0.20043577]\n",
      "[0.60086274, 0.2, 0.20025131, 0.20017423]\n",
      "[0.6013734, 0.2, 0.20055789, 0.20037723]\n",
      "[0.6008393, 0.2, 0.20003691, 0.2003631]\n",
      "[0.60080945, 0.2, 0.20004335, 0.2003258]\n",
      "[0.60115564, 0.2, 0.20023674, 0.20047753]\n",
      "[0.601737, 0.2, 0.20051214, 0.20078237]\n",
      "[0.6011828, 0.2, 0.20032568, 0.20041376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60064024, 0.2, 0.20000009, 0.20019594]\n",
      "[0.60086244, 0.2, 0.20022851, 0.20018902]\n",
      "[0.6010169, 0.2, 0.20039953, 0.20017166]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8330 iterations: 2.1923292835553485 mins\n",
      "Train Loss: [0.6010169, 0.2, 0.20039953, 0.20017166]\n",
      "[0.6010725, 0.2, 0.20040615, 0.20021991]\n",
      "[0.601092, 0.2, 0.20024268, 0.20040192]\n",
      "[0.60108227, 0.2, 0.20026454, 0.2003693]\n",
      "[0.601079, 0.2, 0.20029621, 0.2003331]\n",
      "[0.60104203, 0.2, 0.20029636, 0.200295]\n",
      "[0.6008966, 0.2, 0.20010304, 0.2003423]\n",
      "[0.60156107, 0.2, 0.2005207, 0.20058845]\n",
      "[0.6010394, 0.2, 0.20016491, 0.20042218]\n",
      "[0.6010224, 0.2, 0.20019192, 0.20037784]\n",
      "[0.6008952, 0.2, 0.20032993, 0.20011228]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8340 iterations: 2.194341584046682 mins\n",
      "Train Loss: [0.6008952, 0.2, 0.20032993, 0.20011228]\n",
      "[0.6009075, 0.2, 0.20018265, 0.2002716]\n",
      "[0.6010052, 0.2, 0.20016846, 0.20038314]\n",
      "[0.60123086, 0.2, 0.20019947, 0.20057745]\n",
      "[0.6007294, 0.2, 0.20008937, 0.20018579]\n",
      "[0.6012367, 0.2, 0.20027122, 0.2005109]\n",
      "[0.6006972, 0.2, 0.20011118, 0.20013168]\n",
      "[0.6009035, 0.2, 0.20017603, 0.20027322]\n",
      "[0.6015236, 0.2, 0.20029986, 0.2007699]\n",
      "[0.6005977, 0.2, 0.20005867, 0.20008633]\n",
      "[0.600846, 0.2, 0.20031382, 0.20008068]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8350 iterations: 2.196398615837097 mins\n",
      "Train Loss: [0.600846, 0.2, 0.20031382, 0.20008068]\n",
      "[0.6011219, 0.2, 0.20024769, 0.20042369]\n",
      "[0.6008298, 0.2, 0.20033343, 0.20004696]\n",
      "[0.6007569, 0.2, 0.20011874, 0.20019013]\n",
      "[0.6008783, 0.2, 0.20021011, 0.2002214]\n",
      "[0.6013521, 0.2, 0.20063391, 0.20027255]\n",
      "[0.6006754, 0.2, 0.20015873, 0.20007229]\n",
      "[0.60088825, 0.2, 0.20037012, 0.20007496]\n",
      "[0.60107815, 0.2, 0.20023505, 0.20040138]\n",
      "[0.6011343, 0.2, 0.2002125, 0.20048165]\n",
      "[0.6006647, 0.2, 0.20010583, 0.20012034]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8360 iterations: 2.198718198140462 mins\n",
      "Train Loss: [0.6006647, 0.2, 0.20010583, 0.20012034]\n",
      "[0.6012426, 0.2, 0.20037271, 0.200433]\n",
      "[0.60093534, 0.2, 0.20029238, 0.20020764]\n",
      "[0.600991, 0.2, 0.20017067, 0.20038672]\n",
      "[0.6009297, 0.2, 0.20008813, 0.20040964]\n",
      "[0.6008, 0.2, 0.20016341, 0.20020647]\n",
      "[0.60075444, 0.2, 0.20012505, 0.20020089]\n",
      "[0.600587, 0.2, 0.2000229, 0.20013727]\n",
      "[0.60089856, 0.2, 0.20015316, 0.20032011]\n",
      "[0.60144955, 0.2, 0.20090663, 0.20011903]\n",
      "[0.60122514, 0.2, 0.20039973, 0.20040295]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8370 iterations: 2.200770616531372 mins\n",
      "Train Loss: [0.60122514, 0.2, 0.20039973, 0.20040295]\n",
      "[0.6012286, 0.2, 0.20050246, 0.20030497]\n",
      "[0.60112524, 0.2, 0.20038469, 0.20032054]\n",
      "[0.60105234, 0.2, 0.20023403, 0.2003994]\n",
      "[0.60087293, 0.2, 0.20020889, 0.20024627]\n",
      "[0.6011298, 0.2, 0.20026018, 0.20045286]\n",
      "[0.60060906, 0.2, 0.20006117, 0.2001319]\n",
      "[0.6007739, 0.2, 0.2000956, 0.20026311]\n",
      "[0.6008488, 0.2, 0.20023839, 0.20019604]\n",
      "[0.6010967, 0.2, 0.20033786, 0.20034537]\n",
      "[0.6008675, 0.2, 0.20036173, 0.20009325]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8380 iterations: 2.2026517828305563 mins\n",
      "Train Loss: [0.6008675, 0.2, 0.20036173, 0.20009325]\n",
      "[0.6008973, 0.2, 0.20020165, 0.20028414]\n",
      "[0.60113066, 0.2, 0.20020126, 0.20051885]\n",
      "[0.60100037, 0.2, 0.20020618, 0.20038463]\n",
      "[0.6006687, 0.2, 0.20011015, 0.20015007]\n",
      "[0.6010394, 0.2, 0.20029289, 0.20033891]\n",
      "[0.60060555, 0.2, 0.20008767, 0.20011118]\n",
      "[0.6008471, 0.2, 0.20021714, 0.20022412]\n",
      "[0.6010171, 0.2, 0.20031762, 0.20029467]\n",
      "[0.6011837, 0.2, 0.2001835, 0.20059638]\n",
      "[0.60079026, 0.2, 0.20019867, 0.20018867]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8390 iterations: 2.204578681786855 mins\n",
      "Train Loss: [0.60079026, 0.2, 0.20019867, 0.20018867]\n",
      "[0.6008454, 0.2, 0.20027666, 0.20016643]\n",
      "[0.60074925, 0.2, 0.20014283, 0.20020455]\n",
      "[0.6009882, 0.2, 0.20023708, 0.2003496]\n",
      "[0.60065603, 0.2, 0.2, 0.20025475]\n",
      "[0.6005086, 0.2, 0.20000008, 0.2001073]\n",
      "[0.60098493, 0.2, 0.20036244, 0.20022139]\n",
      "[0.60085166, 0.2, 0.20008647, 0.20036411]\n",
      "[0.6017883, 0.2, 0.20018332, 0.20120405]\n",
      "[0.6008886, 0.2, 0.20011088, 0.20037743]\n",
      "[0.60097575, 0.2, 0.20036471, 0.20021103]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8400 iterations: 2.206589066982269 mins\n",
      "Train Loss: [0.60097575, 0.2, 0.20036471, 0.20021103]\n",
      "[0.60091466, 0.2, 0.20025387, 0.20026074]\n",
      "[0.601135, 0.2, 0.20044507, 0.20028995]\n",
      "[0.6008186, 0.2, 0.20026071, 0.20015794]\n",
      "[0.6008393, 0.2, 0.20026281, 0.2001765]\n",
      "[0.6010333, 0.2, 0.20023124, 0.20040178]\n",
      "[0.6009564, 0.2, 0.20019154, 0.20036429]\n",
      "[0.600977, 0.2, 0.2001516, 0.20042442]\n",
      "[0.6007664, 0.2, 0.20019671, 0.20016822]\n",
      "[0.60094583, 0.2, 0.20019402, 0.20034966]\n",
      "[0.6008757, 0.2, 0.20022143, 0.20025177]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8410 iterations: 2.2084983507792155 mins\n",
      "Train Loss: [0.6008757, 0.2, 0.20022143, 0.20025177]\n",
      "[0.60089374, 0.2, 0.20031478, 0.20017612]\n",
      "[0.6010757, 0.2, 0.20042743, 0.20024522]\n",
      "[0.6005666, 0.2, 0.20004337, 0.20012015]\n",
      "[0.60076594, 0.2, 0.20022665, 0.20013611]\n",
      "[0.6008433, 0.2, 0.20015907, 0.20028098]\n",
      "[0.6009315, 0.2, 0.20007256, 0.20045555]\n",
      "[0.60076416, 0.2, 0.20018701, 0.20017377]\n",
      "[0.60073215, 0.2, 0.20007643, 0.20025231]\n",
      "[0.60085094, 0.2, 0.2001759, 0.20027144]\n",
      "[0.60107064, 0.2, 0.20029287, 0.200374]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8420 iterations: 2.2105315128962197 mins\n",
      "Train Loss: [0.60107064, 0.2, 0.20029287, 0.200374]\n",
      "[0.60053307, 0.2, 0.20000012, 0.20012915]\n",
      "[0.6008788, 0.2, 0.20018941, 0.20028545]\n",
      "[0.60063195, 0.2, 0.20001544, 0.20021257]\n",
      "[0.6007955, 0.2, 0.20003232, 0.20035924]\n",
      "[0.6006812, 0.2, 0.20018317, 0.20009424]\n",
      "[0.60066235, 0.2, 0.20015524, 0.20010355]\n",
      "[0.6011563, 0.2, 0.20068046, 0.20007265]\n",
      "[0.60089576, 0.2, 0.2001428, 0.20035045]\n",
      "[0.60099155, 0.2, 0.20035225, 0.20023754]\n",
      "[0.6007528, 0.2, 0.20013352, 0.20021823]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8430 iterations: 2.2123284657796223 mins\n",
      "Train Loss: [0.6007528, 0.2, 0.20013352, 0.20021823]\n",
      "[0.60074115, 0.2, 0.20022239, 0.20011856]\n",
      "[0.60103685, 0.2, 0.20050882, 0.20012885]\n",
      "[0.6006022, 0.2, 0.20010318, 0.2001011]\n",
      "[0.60153353, 0.2, 0.20073487, 0.20040204]\n",
      "[0.6005577, 0.2, 0.2001037, 0.20005888]\n",
      "[0.6008921, 0.2, 0.20009951, 0.20039883]\n",
      "[0.6006867, 0.2, 0.20015655, 0.20013751]\n",
      "[0.6006735, 0.2, 0.20011571, 0.20016623]\n",
      "[0.60074145, 0.2, 0.20030335, 0.20004775]\n",
      "[0.60061425, 0.2, 0.20006092, 0.20016438]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8440 iterations: 2.214866264661153 mins\n",
      "Train Loss: [0.60061425, 0.2, 0.20006092, 0.20016438]\n",
      "[0.60067385, 0.2, 0.20017223, 0.20011428]\n",
      "[0.6006642, 0.2, 0.20012878, 0.20014964]\n",
      "[0.60138005, 0.2, 0.20026918, 0.20072673]\n",
      "[0.6006531, 0.2, 0.20015003, 0.20012046]\n",
      "[0.60062414, 0.2, 0.20010956, 0.2001334]\n",
      "[0.60095274, 0.2, 0.20031674, 0.20025624]\n",
      "[0.6005898, 0.2, 0.20008984, 0.20012166]\n",
      "[0.6010841, 0.2, 0.20031871, 0.20038827]\n",
      "[0.6008564, 0.2, 0.20026912, 0.2002114]\n",
      "[0.60067225, 0.2, 0.20019783, 0.2000997]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8450 iterations: 2.216922465960185 mins\n",
      "Train Loss: [0.60067225, 0.2, 0.20019783, 0.2000997]\n",
      "[0.6006437, 0.2, 0.20018953, 0.20008056]\n",
      "[0.60072315, 0.2, 0.20024431, 0.20010635]\n",
      "[0.60063076, 0.2, 0.20003839, 0.20022084]\n",
      "[0.6007637, 0.2, 0.20015885, 0.20023426]\n",
      "[0.60119563, 0.2, 0.20052706, 0.20029904]\n",
      "[0.6011689, 0.2, 0.20063642, 0.20016398]\n",
      "[0.6010601, 0.2, 0.20034528, 0.20034751]\n",
      "[0.6007997, 0.2, 0.20018044, 0.20025273]\n",
      "[0.6009766, 0.2, 0.200464, 0.20014666]\n",
      "[0.6007387, 0.2, 0.20013395, 0.20023942]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8460 iterations: 2.2187984863917034 mins\n",
      "Train Loss: [0.6007387, 0.2, 0.20013395, 0.20023942]\n",
      "[0.60091615, 0.2, 0.20030737, 0.20024408]\n",
      "[0.60075724, 0.2, 0.20013857, 0.2002545]\n",
      "[0.6007876, 0.2, 0.20020634, 0.2002176]\n",
      "[0.6004893, 0.2, 0.20005405, 0.20007211]\n",
      "[0.6006615, 0.2, 0.20006953, 0.20022917]\n",
      "[0.60062164, 0.2, 0.20011531, 0.20014383]\n",
      "[0.6006116, 0.2, 0.2001082, 0.200141]\n",
      "[0.6008144, 0.2, 0.20013185, 0.20032011]\n",
      "[0.6011614, 0.2, 0.2001747, 0.20062418]\n",
      "[0.60065013, 0.2, 0.2001341, 0.20015359]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8470 iterations: 2.22086003224055 mins\n",
      "Train Loss: [0.60065013, 0.2, 0.2001341, 0.20015359]\n",
      "[0.6008373, 0.2, 0.20024075, 0.2002342]\n",
      "[0.6007541, 0.2, 0.20026994, 0.20012179]\n",
      "[0.6009603, 0.2, 0.20021553, 0.20038229]\n",
      "[0.6007784, 0.2, 0.20000021, 0.20041557]\n",
      "[0.6013703, 0.2, 0.20033167, 0.20067582]\n",
      "[0.6007885, 0.2, 0.20021082, 0.20021465]\n",
      "[0.6009276, 0.2, 0.20017906, 0.20038515]\n",
      "[0.600977, 0.2, 0.20045018, 0.20016296]\n",
      "[0.6009407, 0.2, 0.20029062, 0.20028573]\n",
      "[0.6010296, 0.2, 0.20026784, 0.20039675]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8480 iterations: 2.2227930823961892 mins\n",
      "Train Loss: [0.6010296, 0.2, 0.20026784, 0.20039675]\n",
      "[0.6008397, 0.2, 0.20041834, 0.20005584]\n",
      "[0.6009608, 0.2, 0.20025422, 0.20034029]\n",
      "[0.6007087, 0.2, 0.20006669, 0.20027477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6009376, 0.2, 0.20027044, 0.20029858]\n",
      "[0.60093236, 0.2, 0.2003645, 0.20019777]\n",
      "[0.60080826, 0.2, 0.20026717, 0.20016943]\n",
      "[0.6007133, 0.2, 0.20017566, 0.20016445]\n",
      "[0.6010406, 0.2, 0.20029604, 0.20036985]\n",
      "[0.6012131, 0.2, 0.2003033, 0.20053366]\n",
      "[0.6008288, 0.2, 0.20023529, 0.20021613]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8490 iterations: 2.224939235051473 mins\n",
      "Train Loss: [0.6008288, 0.2, 0.20023529, 0.20021613]\n",
      "[0.6008599, 0.2, 0.2001407, 0.20034048]\n",
      "[0.6008933, 0.2, 0.20041198, 0.20010139]\n",
      "[0.6009229, 0.2, 0.20033462, 0.20020686]\n",
      "[0.6009148, 0.2, 0.2003842, 0.20014776]\n",
      "[0.6008116, 0.2, 0.20027223, 0.2001551]\n",
      "[0.6006335, 0.2, 0.20017642, 0.2000714]\n",
      "[0.6007121, 0.2, 0.20018215, 0.20014288]\n",
      "[0.60126495, 0.2, 0.20038486, 0.20049186]\n",
      "[0.60083777, 0.2, 0.20023619, 0.20021228]\n",
      "[0.6006291, 0.2, 0.20007588, 0.20016314]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8500 iterations: 2.2268038630485534 mins\n",
      "Train Loss: [0.6006291, 0.2, 0.20007588, 0.20016314]\n",
      "[0.60078824, 0.2, 0.20013382, 0.20026378]\n",
      "[0.6006703, 0.2, 0.20010224, 0.20017703]\n",
      "[0.6006565, 0.2, 0.20012364, 0.20014162]\n",
      "[0.6006532, 0.2, 0.2001239, 0.20013806]\n",
      "[0.6006206, 0.2, 0.20009805, 0.2001315]\n",
      "[0.60090405, 0.2, 0.20015506, 0.2003582]\n",
      "[0.6006402, 0.2, 0.20007648, 0.20017353]\n",
      "[0.6011073, 0.2, 0.2000809, 0.20063682]\n",
      "[0.6007065, 0.2, 0.20024052, 0.20007738]\n",
      "[0.6009096, 0.2, 0.20027293, 0.20024917]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8510 iterations: 2.2288910309473673 mins\n",
      "Train Loss: [0.6009096, 0.2, 0.20027293, 0.20024917]\n",
      "[0.60057235, 0.2, 0.20005915, 0.2001267]\n",
      "[0.60082006, 0.2, 0.20013402, 0.20030044]\n",
      "[0.6006468, 0.2, 0.2000786, 0.2001833]\n",
      "[0.6005922, 0.2, 0.20011489, 0.20009314]\n",
      "[0.60217375, 0.2, 0.20023058, 0.20155948]\n",
      "[0.6019752, 0.2, 0.20124796, 0.200344]\n",
      "[0.6009338, 0.2, 0.2002565, 0.20029396]\n",
      "[0.6006753, 0.2, 0.20012042, 0.2001713]\n",
      "[0.60090077, 0.2, 0.20029359, 0.20022336]\n",
      "[0.6008386, 0.2, 0.20031013, 0.20014407]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8520 iterations: 2.2313968181610107 mins\n",
      "Train Loss: [0.6008386, 0.2, 0.20031013, 0.20014407]\n",
      "[0.60096824, 0.2, 0.2003135, 0.20026983]\n",
      "[0.6009731, 0.2, 0.20029879, 0.20028895]\n",
      "[0.60083467, 0.2, 0.20019008, 0.2002589]\n",
      "[0.6007456, 0.2, 0.2001406, 0.20021914]\n",
      "[0.6007033, 0.2, 0.20017077, 0.20014648]\n",
      "[0.6009276, 0.2, 0.2001461, 0.20039538]\n",
      "[0.6009099, 0.2, 0.20038687, 0.20013693]\n",
      "[0.6006554, 0.2, 0.20006783, 0.20020187]\n",
      "[0.6005307, 0.2, 0.20004463, 0.20010075]\n",
      "[0.6015931, 0.2, 0.20018229, 0.20102592]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8530 iterations: 2.2332561135292055 mins\n",
      "Train Loss: [0.6015931, 0.2, 0.20018229, 0.20102592]\n",
      "[0.60075647, 0.2, 0.20015031, 0.20022205]\n",
      "[0.6009152, 0.2, 0.20023364, 0.20029804]\n",
      "[0.60091907, 0.2, 0.20038137, 0.20015489]\n",
      "[0.60068285, 0.2, 0.20008297, 0.2002178]\n",
      "[0.6008937, 0.2, 0.20028411, 0.20022802]\n",
      "[0.6007099, 0.2, 0.20012288, 0.20020632]\n",
      "[0.60094047, 0.2, 0.20020898, 0.2003516]\n",
      "[0.60068345, 0.2, 0.2001913, 0.20011294]\n",
      "[0.60089654, 0.2, 0.20030726, 0.20021051]\n",
      "[0.6008179, 0.2, 0.20018204, 0.20025754]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8540 iterations: 2.2352946678797405 mins\n",
      "Train Loss: [0.6008179, 0.2, 0.20018204, 0.20025754]\n",
      "[0.6023809, 0.2, 0.20180391, 0.200199]\n",
      "[0.6011069, 0.2, 0.20023222, 0.20049675]\n",
      "[0.60099953, 0.2, 0.20021078, 0.20041081]\n",
      "[0.6008266, 0.2, 0.20028822, 0.2001603]\n",
      "[0.6015018, 0.2, 0.20031191, 0.20081143]\n",
      "[0.6008066, 0.2, 0.2002548, 0.20017326]\n",
      "[0.6006944, 0.2, 0.20016025, 0.20015533]\n",
      "[0.6010221, 0.2, 0.20018457, 0.20045823]\n",
      "[0.6008927, 0.2, 0.20020886, 0.20030402]\n",
      "[0.60091287, 0.2, 0.20012581, 0.20040686]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8550 iterations: 2.2371995647748313 mins\n",
      "Train Loss: [0.60091287, 0.2, 0.20012581, 0.20040686]\n",
      "[0.60070586, 0.2, 0.20021698, 0.20010841]\n",
      "[0.60082895, 0.2, 0.20011193, 0.20033635]\n",
      "[0.6005782, 0.2, 0.20010372, 0.20009355]\n",
      "[0.60110486, 0.2, 0.20038912, 0.2003344]\n",
      "[0.6008968, 0.2, 0.20034671, 0.20016855]\n",
      "[0.60101175, 0.2, 0.20036465, 0.20026544]\n",
      "[0.6009048, 0.2, 0.20026833, 0.20025474]\n",
      "[0.6008902, 0.2, 0.20039076, 0.20011778]\n",
      "[0.6009548, 0.2, 0.20016935, 0.20040388]\n",
      "[0.6008652, 0.2, 0.20018852, 0.20029539]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8560 iterations: 2.239376664161682 mins\n",
      "Train Loss: [0.6008652, 0.2, 0.20018852, 0.20029539]\n",
      "[0.6009659, 0.2, 0.2005109, 0.20007415]\n",
      "[0.6007073, 0.2, 0.20024501, 0.20008183]\n",
      "[0.60090923, 0.2, 0.2001119, 0.20041732]\n",
      "[0.60072184, 0.2, 0.20018649, 0.20015606]\n",
      "[0.6005633, 0.2, 0.20006317, 0.20012148]\n",
      "[0.60064244, 0.2, 0.2000915, 0.20017304]\n",
      "[0.6005266, 0.2, 0.20010519, 0.2000445]\n",
      "[0.6005783, 0.2, 0.20007794, 0.20012458]\n",
      "[0.60066867, 0.2, 0.20011078, 0.20018332]\n",
      "[0.6005832, 0.2, 0.20009531, 0.20011479]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8570 iterations: 2.24119903643926 mins\n",
      "Train Loss: [0.6005832, 0.2, 0.20009531, 0.20011479]\n",
      "[0.6005282, 0.2, 0.20006764, 0.20008896]\n",
      "[0.6006321, 0.2, 0.20011733, 0.20014472]\n",
      "[0.6006085, 0.2, 0.20011091, 0.2001292]\n",
      "[0.6005436, 0.2, 0.20005718, 0.20011963]\n",
      "[0.6008514, 0.2, 0.20034674, 0.20013948]\n",
      "[0.6006522, 0.2, 0.2001636, 0.20012505]\n",
      "[0.6005984, 0.2, 0.20002529, 0.20021114]\n",
      "[0.6005975, 0.2, 0.20018741, 0.20004962]\n",
      "[0.60085684, 0.2, 0.20031089, 0.20018707]\n",
      "[0.6006289, 0.2, 0.20009953, 0.20017214]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8580 iterations: 2.2440457979838055 mins\n",
      "Train Loss: [0.6006289, 0.2, 0.20009953, 0.20017214]\n",
      "[0.60099614, 0.2, 0.20021495, 0.20042548]\n",
      "[0.6014762, 0.2, 0.20094167, 0.20018059]\n",
      "[0.600742, 0.2, 0.20009188, 0.20029809]\n",
      "[0.6009629, 0.2, 0.20033014, 0.20028254]\n",
      "[0.6008245, 0.2, 0.20015237, 0.20032349]\n",
      "[0.60046875, 0.2, 0.2000673, 0.2000546]\n",
      "[0.60084075, 0.2, 0.20040351, 0.20009206]\n",
      "[0.60102546, 0.2, 0.20027603, 0.20040579]\n",
      "[0.60085696, 0.2, 0.20035982, 0.20015486]\n",
      "[0.6005934, 0.2, 0.20000005, 0.20025206]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8590 iterations: 2.245953714847565 mins\n",
      "Train Loss: [0.6005934, 0.2, 0.20000005, 0.20025206]\n",
      "[0.6005361, 0.2, 0.20006202, 0.20013365]\n",
      "[0.60063195, 0.2, 0.2001857, 0.2001065]\n",
      "[0.60086316, 0.2, 0.20031585, 0.20020826]\n",
      "[0.60051197, 0.2, 0.20008083, 0.2000928]\n",
      "[0.60057455, 0.2, 0.20012555, 0.20011117]\n",
      "[0.60065794, 0.2, 0.2000945, 0.20022592]\n",
      "[0.6006996, 0.2, 0.20006564, 0.20029682]\n",
      "[0.6005932, 0.2, 0.20011188, 0.20014459]\n",
      "[0.6007457, 0.2, 0.20026353, 0.20014566]\n",
      "[0.6008398, 0.2, 0.20019293, 0.2003108]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8600 iterations: 2.248542932669322 mins\n",
      "Train Loss: [0.6008398, 0.2, 0.20019293, 0.2003108]\n",
      "[0.60092014, 0.2, 0.2004996, 0.20008466]\n",
      "[0.60103995, 0.2, 0.20018245, 0.20052171]\n",
      "[0.6006178, 0.2, 0.20019433, 0.20008777]\n",
      "[0.6007937, 0.2, 0.20003587, 0.20042218]\n",
      "[0.60054684, 0.2, 0.20007427, 0.20013696]\n",
      "[0.60081965, 0.2, 0.20030287, 0.20018128]\n",
      "[0.60111266, 0.2, 0.2006532, 0.20012419]\n",
      "[0.6008731, 0.2, 0.20014071, 0.20039748]\n",
      "[0.6008, 0.2, 0.20026661, 0.20019867]\n",
      "[0.60080045, 0.2, 0.2001569, 0.200309]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8610 iterations: 2.250524381796519 mins\n",
      "Train Loss: [0.60080045, 0.2, 0.2001569, 0.200309]\n",
      "[0.60070044, 0.2, 0.20004757, 0.20031838]\n",
      "[0.600721, 0.2, 0.20017739, 0.20020916]\n",
      "[0.60071325, 0.2, 0.200107, 0.20027205]\n",
      "[0.60052675, 0.2, 0.20013721, 0.20005572]\n",
      "[0.60060716, 0.2, 0.20016535, 0.20010838]\n",
      "[0.6007646, 0.2, 0.20023291, 0.20019878]\n",
      "[0.6009159, 0.2, 0.20039663, 0.20018698]\n",
      "[0.60048443, 0.2, 0.20008431, 0.20006864]\n",
      "[0.6005952, 0.2, 0.20015317, 0.20011136]\n",
      "[0.6006828, 0.2, 0.20017308, 0.20017987]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8620 iterations: 2.2523619651794435 mins\n",
      "Train Loss: [0.6006828, 0.2, 0.20017308, 0.20017987]\n",
      "[0.6006745, 0.2, 0.20013183, 0.20021367]\n",
      "[0.60077274, 0.2, 0.20024842, 0.20019612]\n",
      "[0.60089594, 0.2, 0.20013909, 0.20042971]\n",
      "[0.60089195, 0.2, 0.20020398, 0.20036191]\n",
      "[0.6006825, 0.2, 0.20013846, 0.20021893]\n",
      "[0.60050756, 0.2, 0.20008147, 0.20010172]\n",
      "[0.600655, 0.2, 0.20013876, 0.20019232]\n",
      "[0.60063297, 0.2, 0.20022912, 0.20008011]\n",
      "[0.6008266, 0.2, 0.20032041, 0.2001827]\n",
      "[0.6007976, 0.2, 0.20020056, 0.20027359]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8630 iterations: 2.2543742338816326 mins\n",
      "Train Loss: [0.6007976, 0.2, 0.20020056, 0.20027359]\n",
      "[0.6008927, 0.2, 0.20036831, 0.20020097]\n",
      "[0.6009021, 0.2, 0.20032696, 0.20025167]\n",
      "[0.60068554, 0.2, 0.20008956, 0.20027253]\n",
      "[0.60065925, 0.2, 0.2000983, 0.20023714]\n",
      "[0.60071814, 0.2, 0.20016034, 0.20023355]\n",
      "[0.600941, 0.2, 0.20043275, 0.20018353]\n",
      "[0.6005896, 0.2, 0.2001648, 0.20009974]\n",
      "[0.60080355, 0.2, 0.2002931, 0.2001851]\n",
      "[0.6013569, 0.2, 0.20047498, 0.2005563]\n",
      "[0.60071677, 0.2, 0.20021115, 0.20017958]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8640 iterations: 2.256239930788676 mins\n",
      "Train Loss: [0.60071677, 0.2, 0.20021115, 0.20017958]\n",
      "[0.60062987, 0.2, 0.20008308, 0.20022044]\n",
      "[0.60085696, 0.2, 0.20019715, 0.20033325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60077256, 0.2, 0.20015375, 0.20029213]\n",
      "[0.6006626, 0.2, 0.20021346, 0.20012234]\n",
      "[0.6007306, 0.2, 0.20017202, 0.20023194]\n",
      "[0.60072863, 0.2, 0.20012447, 0.20027784]\n",
      "[0.60057193, 0.2, 0.20019123, 0.20005502]\n",
      "[0.60121924, 0.2, 0.20070638, 0.20018773]\n",
      "[0.6008297, 0.2, 0.20023465, 0.20027058]\n",
      "[0.60048926, 0.2, 0.20006299, 0.20010236]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8650 iterations: 2.258314232031504 mins\n",
      "Train Loss: [0.60048926, 0.2, 0.20006299, 0.20010236]\n",
      "[0.60080713, 0.2, 0.20029087, 0.2001926]\n",
      "[0.60058266, 0.2, 0.20010598, 0.20015292]\n",
      "[0.60065335, 0.2, 0.2002279, 0.20010146]\n",
      "[0.6006095, 0.2, 0.2001608, 0.20012426]\n",
      "[0.60089654, 0.2, 0.20027687, 0.20029463]\n",
      "[0.60063535, 0.2, 0.20017381, 0.20013598]\n",
      "[0.6006399, 0.2, 0.20012538, 0.20018855]\n",
      "[0.6007384, 0.2, 0.20025752, 0.20015429]\n",
      "[0.60070735, 0.2, 0.2001207, 0.20025942]\n",
      "[0.60069907, 0.2, 0.20025069, 0.20012057]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8660 iterations: 2.260127902030945 mins\n",
      "Train Loss: [0.60069907, 0.2, 0.20025069, 0.20012057]\n",
      "[0.6011473, 0.2, 0.20021664, 0.20060234]\n",
      "[0.60072404, 0.2, 0.20029996, 0.20009531]\n",
      "[0.60064614, 0.2, 0.20014603, 0.20017068]\n",
      "[0.60082203, 0.2, 0.20025922, 0.20023257]\n",
      "[0.60079926, 0.2, 0.20005819, 0.20041022]\n",
      "[0.60068685, 0.2, 0.20023811, 0.20011733]\n",
      "[0.60085666, 0.2, 0.20037515, 0.2001496]\n",
      "[0.60063285, 0.2, 0.20015116, 0.20014946]\n",
      "[0.6005879, 0.2, 0.20006423, 0.20019121]\n",
      "[0.6007894, 0.2, 0.20022124, 0.20023546]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8670 iterations: 2.2622674187024434 mins\n",
      "Train Loss: [0.6007894, 0.2, 0.20022124, 0.20023546]\n",
      "[0.60063124, 0.2, 0.2002305, 0.20006754]\n",
      "[0.6004979, 0.2, 0.20006785, 0.20009628]\n",
      "[0.6011023, 0.2, 0.2005888, 0.20017922]\n",
      "[0.6010426, 0.2, 0.20041682, 0.20029122]\n",
      "[0.60087204, 0.2, 0.20022245, 0.20031473]\n",
      "[0.60091084, 0.2, 0.20031953, 0.20025618]\n",
      "[0.6008885, 0.2, 0.20014162, 0.2004114]\n",
      "[0.6010665, 0.2, 0.20007697, 0.20065375]\n",
      "[0.60069513, 0.2, 0.20018984, 0.20016924]\n",
      "[0.60054386, 0.2, 0.20011164, 0.200096]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8680 iterations: 2.2646987001101175 mins\n",
      "Train Loss: [0.60054386, 0.2, 0.20011164, 0.200096]\n",
      "[0.6006966, 0.2, 0.20008239, 0.20027788]\n",
      "[0.60062766, 0.2, 0.20017856, 0.20011261]\n",
      "[0.6007528, 0.2, 0.20009565, 0.20032051]\n",
      "[0.60063934, 0.2, 0.20012347, 0.20017911]\n",
      "[0.6008841, 0.2, 0.20025866, 0.20028815]\n",
      "[0.60099846, 0.2, 0.20030211, 0.20035855]\n",
      "[0.6006401, 0.2, 0.20022099, 0.20008075]\n",
      "[0.6010679, 0.2, 0.20031524, 0.2004139]\n",
      "[0.60130256, 0.2, 0.20035318, 0.20061046]\n",
      "[0.60057527, 0.2, 0.20013493, 0.20010155]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8690 iterations: 2.266788117090861 mins\n",
      "Train Loss: [0.60057527, 0.2, 0.20013493, 0.20010155]\n",
      "[0.60115534, 0.2, 0.2006131, 0.20020324]\n",
      "[0.60091436, 0.2, 0.20041256, 0.20016263]\n",
      "[0.60078406, 0.2, 0.20038083, 0.2000639]\n",
      "[0.6006088, 0.2, 0.20007138, 0.20019743]\n",
      "[0.6007735, 0.2, 0.2002623, 0.20017034]\n",
      "[0.600579, 0.2, 0.20011498, 0.20012207]\n",
      "[0.60080653, 0.2, 0.20026074, 0.20020255]\n",
      "[0.6010044, 0.2, 0.20038411, 0.20027563]\n",
      "[0.6006701, 0.2, 0.20003289, 0.20029147]\n",
      "[0.60112077, 0.2, 0.20031731, 0.20045659]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8700 iterations: 2.268845999240875 mins\n",
      "Train Loss: [0.60112077, 0.2, 0.20031731, 0.20045659]\n",
      "[0.60076284, 0.2, 0.20018701, 0.20022807]\n",
      "[0.6010208, 0.2, 0.20019197, 0.20048021]\n",
      "[0.6007392, 0.2, 0.20020692, 0.20018269]\n",
      "[0.6007794, 0.2, 0.20030311, 0.20012541]\n",
      "[0.6007271, 0.2, 0.2001921, 0.20018275]\n",
      "[0.6007236, 0.2, 0.2002018, 0.2001684]\n",
      "[0.6007762, 0.2, 0.20007332, 0.20034823]\n",
      "[0.60094136, 0.2, 0.20034169, 0.2002439]\n",
      "[0.6009368, 0.2, 0.20034763, 0.2002325]\n",
      "[0.6007974, 0.2, 0.20012344, 0.20031695]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8710 iterations: 2.270708382129669 mins\n",
      "Train Loss: [0.6007974, 0.2, 0.20012344, 0.20031695]\n",
      "[0.6007875, 0.2, 0.20014761, 0.2002823]\n",
      "[0.60087466, 0.2, 0.20018354, 0.2003328]\n",
      "[0.60107917, 0.2, 0.20042282, 0.2002975]\n",
      "[0.60079885, 0.2, 0.20026931, 0.20017016]\n",
      "[0.6007825, 0.2, 0.2000855, 0.20033741]\n",
      "[0.600974, 0.2, 0.20039909, 0.20021506]\n",
      "[0.6008905, 0.2, 0.20026071, 0.2002698]\n",
      "[0.6006116, 0.2, 0.20000002, 0.20025116]\n",
      "[0.6006952, 0.2, 0.20018698, 0.2001472]\n",
      "[0.60106254, 0.2, 0.20029512, 0.20040552]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8720 iterations: 2.272807582219442 mins\n",
      "Train Loss: [0.60106254, 0.2, 0.20029512, 0.20040552]\n",
      "[0.6009444, 0.2, 0.20025162, 0.20033081]\n",
      "[0.6005934, 0.2, 0.20011516, 0.2001159]\n",
      "[0.60106975, 0.2, 0.20052086, 0.20018622]\n",
      "[0.60105157, 0.2, 0.20030785, 0.20038074]\n",
      "[0.6009796, 0.2, 0.20011455, 0.2005017]\n",
      "[0.60063344, 0.2, 0.20019943, 0.20007049]\n",
      "[0.60107964, 0.2, 0.20028834, 0.20042735]\n",
      "[0.60113084, 0.2, 0.2003089, 0.20045751]\n",
      "[0.6010916, 0.2, 0.2002921, 0.20043452]\n",
      "[0.60105306, 0.2, 0.20034696, 0.20034033]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8730 iterations: 2.2746867656707765 mins\n",
      "Train Loss: [0.60105306, 0.2, 0.20034696, 0.20034033]\n",
      "[0.601067, 0.2, 0.2002419, 0.20045839]\n",
      "[0.6009156, 0.2, 0.20018485, 0.20036286]\n",
      "[0.6005466, 0.2, 0.20000012, 0.20017746]\n",
      "[0.6011708, 0.2, 0.20037037, 0.20043002]\n",
      "[0.6008996, 0.2, 0.2001195, 0.20040847]\n",
      "[0.60135484, 0.2, 0.20059277, 0.20038949]\n",
      "[0.6008449, 0.2, 0.20016447, 0.20030704]\n",
      "[0.60073346, 0.2, 0.20014682, 0.20021255]\n",
      "[0.6008971, 0.2, 0.20027296, 0.20024942]\n",
      "[0.6006047, 0.2, 0.20003666, 0.20019297]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8740 iterations: 2.276693348089854 mins\n",
      "Train Loss: [0.6006047, 0.2, 0.20003666, 0.20019297]\n",
      "[0.60071975, 0.2, 0.2001979, 0.20014639]\n",
      "[0.6009373, 0.2, 0.20031166, 0.20025003]\n",
      "[0.6007081, 0.2, 0.20020206, 0.20013055]\n",
      "[0.60089827, 0.2, 0.20006481, 0.20045835]\n",
      "[0.6009874, 0.2, 0.20016582, 0.200447]\n",
      "[0.60067105, 0.2, 0.20004158, 0.20025572]\n",
      "[0.60076123, 0.2, 0.20008491, 0.20030339]\n",
      "[0.60078025, 0.2, 0.20019847, 0.20020954]\n",
      "[0.6006319, 0.2, 0.20012522, 0.20013516]\n",
      "[0.60074675, 0.2, 0.20013304, 0.20024268]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8750 iterations: 2.278607066472371 mins\n",
      "Train Loss: [0.60074675, 0.2, 0.20013304, 0.20024268]\n",
      "[0.60103613, 0.2, 0.20032153, 0.20034418]\n",
      "[0.60110456, 0.2, 0.20022501, 0.20050965]\n",
      "[0.60079765, 0.2, 0.2001406, 0.20028761]\n",
      "[0.6009653, 0.2, 0.20026611, 0.2003301]\n",
      "[0.6007505, 0.2, 0.20014647, 0.2002353]\n",
      "[0.6007497, 0.2, 0.20022722, 0.20015393]\n",
      "[0.6006819, 0.2, 0.20021644, 0.20009667]\n",
      "[0.6007318, 0.2, 0.20007828, 0.2002843]\n",
      "[0.60079336, 0.2, 0.20025627, 0.20016715]\n",
      "[0.60115, 0.2, 0.20054302, 0.20023626]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8760 iterations: 2.2811891158421833 mins\n",
      "Train Loss: [0.60115, 0.2, 0.20054302, 0.20023626]\n",
      "[0.60094243, 0.2, 0.20040703, 0.20016417]\n",
      "[0.60063505, 0.2, 0.20011693, 0.20014639]\n",
      "[0.60099834, 0.2, 0.20034856, 0.20027746]\n",
      "[0.6008053, 0.2, 0.20031717, 0.20011514]\n",
      "[0.6007995, 0.2, 0.20015554, 0.20027019]\n",
      "[0.601069, 0.2, 0.20035076, 0.2003435]\n",
      "[0.6009724, 0.2, 0.20032181, 0.20027517]\n",
      "[0.6013303, 0.2, 0.20053822, 0.20041607]\n",
      "[0.6012951, 0.2, 0.20027149, 0.2006475]\n",
      "[0.6012747, 0.2, 0.20054692, 0.2003518]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8770 iterations: 2.2831510345141095 mins\n",
      "Train Loss: [0.6012747, 0.2, 0.20054692, 0.2003518]\n",
      "[0.60078216, 0.2, 0.20018518, 0.20022126]\n",
      "[0.6006456, 0.2, 0.20016865, 0.20010102]\n",
      "[0.6008043, 0.2, 0.20017521, 0.20025286]\n",
      "[0.60072637, 0.2, 0.20019183, 0.20015803]\n",
      "[0.6007453, 0.2, 0.2002734, 0.20009539]\n",
      "[0.60065114, 0.2, 0.20015465, 0.20012018]\n",
      "[0.6006618, 0.2, 0.20013553, 0.2001505]\n",
      "[0.60072756, 0.2, 0.2001483, 0.20020425]\n",
      "[0.60071784, 0.2, 0.20011985, 0.20022371]\n",
      "[0.60060614, 0.2, 0.2001288, 0.20010395]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8780 iterations: 2.2850272337595623 mins\n",
      "Train Loss: [0.60060614, 0.2, 0.2001288, 0.20010395]\n",
      "[0.6007387, 0.2, 0.20030832, 0.20005767]\n",
      "[0.600861, 0.2, 0.20014614, 0.20034316]\n",
      "[0.6009, 0.2, 0.20037276, 0.20015664]\n",
      "[0.6007411, 0.2, 0.20011657, 0.20025519]\n",
      "[0.6004938, 0.2, 0.20003064, 0.20009495]\n",
      "[0.6010665, 0.2, 0.20049724, 0.2002021]\n",
      "[0.60041976, 0.2, 0.20003796, 0.20001568]\n",
      "[0.6010229, 0.2, 0.2004106, 0.20024705]\n",
      "[0.60070556, 0.2, 0.20018548, 0.20015585]\n",
      "[0.6007422, 0.2, 0.2001497, 0.20022906]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8790 iterations: 2.287078030904134 mins\n",
      "Train Loss: [0.6007422, 0.2, 0.2001497, 0.20022906]\n",
      "[0.6008452, 0.2, 0.2001329, 0.20034938]\n",
      "[0.6009057, 0.2, 0.20036332, 0.20017979]\n",
      "[0.6006869, 0.2, 0.20020849, 0.20011608]\n",
      "[0.6011128, 0.2, 0.20043407, 0.20031634]\n",
      "[0.6009815, 0.2, 0.20021372, 0.20040506]\n",
      "[0.601217, 0.2, 0.20036042, 0.20049356]\n",
      "[0.6013446, 0.2, 0.20072898, 0.20025247]\n",
      "[0.600933, 0.2, 0.20026375, 0.20030591]\n",
      "[0.60091496, 0.2, 0.20026937, 0.20028135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6008182, 0.2, 0.20011018, 0.2003423]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8800 iterations: 2.2889517823855083 mins\n",
      "Train Loss: [0.6008182, 0.2, 0.20011018, 0.2003423]\n",
      "[0.60081476, 0.2, 0.20017411, 0.2002728]\n",
      "[0.6008038, 0.2, 0.20026764, 0.20016567]\n",
      "[0.60112464, 0.2, 0.20023654, 0.20051451]\n",
      "[0.6015839, 0.2, 0.2010129, 0.200194]\n",
      "[0.6008141, 0.2, 0.20018886, 0.2002447]\n",
      "[0.60336304, 0.2, 0.20219521, 0.20078346]\n",
      "[0.6016005, 0.2, 0.20018344, 0.20102972]\n",
      "[0.6006874, 0.2, 0.20015772, 0.20013875]\n",
      "[0.6008626, 0.2, 0.20032473, 0.20014286]\n",
      "[0.600938, 0.2, 0.20025347, 0.20028499]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8810 iterations: 2.2910114963849386 mins\n",
      "Train Loss: [0.600938, 0.2, 0.20025347, 0.20028499]\n",
      "[0.6008902, 0.2, 0.2002365, 0.20024966]\n",
      "[0.60114914, 0.2, 0.20025635, 0.20048425]\n",
      "[0.600723, 0.2, 0.20011763, 0.20019251]\n",
      "[0.6022324, 0.2, 0.20098425, 0.20083119]\n",
      "[0.6008976, 0.2, 0.20014681, 0.20033051]\n",
      "[0.6009781, 0.2, 0.2001853, 0.20036933]\n",
      "[0.6010378, 0.2, 0.20035174, 0.20025964]\n",
      "[0.601121, 0.2, 0.20003927, 0.2006525]\n",
      "[0.6008124, 0.2, 0.20011413, 0.20026651]\n",
      "[0.6007547, 0.2, 0.20011069, 0.20020992]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8820 iterations: 2.2930585503578187 mins\n",
      "Train Loss: [0.6007547, 0.2, 0.20011069, 0.20020992]\n",
      "[0.6008892, 0.2, 0.20008375, 0.20036916]\n",
      "[0.60153717, 0.2, 0.20035937, 0.20073934]\n",
      "[0.6019474, 0.2, 0.20020224, 0.20130506]\n",
      "[0.60125065, 0.2, 0.20037551, 0.2004337]\n",
      "[0.6013161, 0.2, 0.20013165, 0.20074177]\n",
      "[0.6011818, 0.2, 0.20026852, 0.20046961]\n",
      "[0.6009824, 0.2, 0.20019186, 0.20034617]\n",
      "[0.6012686, 0.2, 0.20028278, 0.20054069]\n",
      "[0.60260504, 0.2, 0.20177056, 0.20038894]\n",
      "[0.6012001, 0.2, 0.200422, 0.20033216]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8830 iterations: 2.2949509660402936 mins\n",
      "Train Loss: [0.6012001, 0.2, 0.200422, 0.20033216]\n",
      "[0.6007429, 0.2, 0.20021565, 0.20008107]\n",
      "[0.6017673, 0.2, 0.20001636, 0.20130473]\n",
      "[0.60082495, 0.2, 0.20022996, 0.20014891]\n",
      "[0.6006745, 0.2, 0.20005801, 0.20017068]\n",
      "[0.6011368, 0.2, 0.20036241, 0.20032892]\n",
      "[0.60179293, 0.2, 0.20072404, 0.20062387]\n",
      "[0.60172045, 0.2, 0.2007229, 0.20055293]\n",
      "[0.601664, 0.2, 0.20108339, 0.20013581]\n",
      "[0.60125023, 0.2, 0.2002316, 0.2005733]\n",
      "[0.60106814, 0.2, 0.20033793, 0.2002842]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8840 iterations: 2.297483479976654 mins\n",
      "Train Loss: [0.60106814, 0.2, 0.20033793, 0.2002842]\n",
      "[0.6009255, 0.2, 0.20026457, 0.20021416]\n",
      "[0.60104203, 0.2, 0.20022978, 0.20036456]\n",
      "[0.60113364, 0.2, 0.20011775, 0.20056728]\n",
      "[0.6010118, 0.2, 0.20042463, 0.20013778]\n",
      "[0.60074353, 0.2, 0.20016922, 0.20012447]\n",
      "[0.6006174, 0.2, 0.20007229, 0.20009498]\n",
      "[0.60072947, 0.2, 0.20007707, 0.20020226]\n",
      "[0.60057646, 0.2, 0.20005523, 0.2000713]\n",
      "[0.60096973, 0.2, 0.2002654, 0.20025487]\n",
      "[0.60133094, 0.2, 0.2007025, 0.20017976]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8850 iterations: 2.2993674675623574 mins\n",
      "Train Loss: [0.60133094, 0.2, 0.2007025, 0.20017976]\n",
      "[0.60078526, 0.2, 0.200148, 0.20018986]\n",
      "[0.600616, 0.2, 0.20010063, 0.20006923]\n",
      "[0.601036, 0.2, 0.2001297, 0.20046166]\n",
      "[0.60126734, 0.2, 0.20047568, 0.20034868]\n",
      "[0.6008071, 0.2, 0.20029224, 0.20007364]\n",
      "[0.601201, 0.2, 0.20045301, 0.20030859]\n",
      "[0.600743, 0.2, 0.20016591, 0.20014006]\n",
      "[0.60080343, 0.2, 0.2002676, 0.20010108]\n",
      "[0.60119444, 0.2, 0.200268, 0.20049398]\n",
      "[0.60115516, 0.2, 0.20013535, 0.20058978]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8860 iterations: 2.3014098167419434 mins\n",
      "Train Loss: [0.60115516, 0.2, 0.20013535, 0.20058978]\n",
      "[0.6004956, 0.2, 0.20004763, 0.20002048]\n",
      "[0.60091174, 0.2, 0.20023747, 0.2002493]\n",
      "[0.60102415, 0.2, 0.20036161, 0.20024031]\n",
      "[0.60067976, 0.2, 0.20004874, 0.20021155]\n",
      "[0.6010801, 0.2, 0.20026128, 0.20040202]\n",
      "[0.6008121, 0.2, 0.20025858, 0.2001394]\n",
      "[0.6009574, 0.2, 0.20035613, 0.20019004]\n",
      "[0.6006921, 0.2, 0.20001885, 0.20026489]\n",
      "[0.6005961, 0.2, 0.2000642, 0.20012644]\n",
      "[0.6010808, 0.2, 0.20022817, 0.20045012]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8870 iterations: 2.3033921639124553 mins\n",
      "Train Loss: [0.6010808, 0.2, 0.20022817, 0.20045012]\n",
      "[0.6006444, 0.2, 0.200173, 0.20007206]\n",
      "[0.6006283, 0.2, 0.20013134, 0.20010047]\n",
      "[0.60064095, 0.2, 0.20015296, 0.200094]\n",
      "[0.6011878, 0.2, 0.20042019, 0.20037578]\n",
      "[0.600542, 0.2, 0.20014943, 0.20000297]\n",
      "[0.6009524, 0.2, 0.20008512, 0.20047973]\n",
      "[0.60073763, 0.2, 0.20025076, 0.20010135]\n",
      "[0.6007211, 0.2, 0.20017935, 0.2001582]\n",
      "[0.6007271, 0.2, 0.20013772, 0.20020773]\n",
      "[0.60057575, 0.2, 0.20007905, 0.20011696]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8880 iterations: 2.3053170522054036 mins\n",
      "Train Loss: [0.60057575, 0.2, 0.20007905, 0.20011696]\n",
      "[0.60071903, 0.2, 0.2000933, 0.20024797]\n",
      "[0.6007513, 0.2, 0.20017448, 0.20020081]\n",
      "[0.6007027, 0.2, 0.20022868, 0.20009972]\n",
      "[0.600729, 0.2, 0.20000018, 0.20035605]\n",
      "[0.6008665, 0.2, 0.20035645, 0.2001388]\n",
      "[0.6010921, 0.2, 0.20035283, 0.20036972]\n",
      "[0.6007441, 0.2, 0.20006748, 0.20030893]\n",
      "[0.6010123, 0.2, 0.2003426, 0.20030385]\n",
      "[0.60096717, 0.2, 0.20031323, 0.20029049]\n",
      "[0.60085756, 0.2, 0.20022766, 0.200269]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8890 iterations: 2.3072431008021037 mins\n",
      "Train Loss: [0.60085756, 0.2, 0.20022766, 0.200269]\n",
      "[0.6009851, 0.2, 0.20037171, 0.2002548]\n",
      "[0.6007374, 0.2, 0.2001932, 0.20018773]\n",
      "[0.6006999, 0.2, 0.20026289, 0.20008299]\n",
      "[0.6006239, 0.2, 0.20016839, 0.20010361]\n",
      "[0.60058767, 0.2, 0.2000902, 0.20014761]\n",
      "[0.6006872, 0.2, 0.20011386, 0.20022523]\n",
      "[0.60054183, 0.2, 0.20015402, 0.20004144]\n",
      "[0.6005618, 0.2, 0.20010804, 0.20010893]\n",
      "[0.6008726, 0.2, 0.20038196, 0.20014754]\n",
      "[0.6004691, 0.2, 0.2000326, 0.20009524]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8900 iterations: 2.309201780954997 mins\n",
      "Train Loss: [0.6004691, 0.2, 0.2000326, 0.20009524]\n",
      "[0.6006707, 0.2, 0.2002152, 0.20011595]\n",
      "[0.600458, 0.2, 0.20003399, 0.20008622]\n",
      "[0.60056555, 0.2, 0.20014171, 0.20008786]\n",
      "[0.6005525, 0.2, 0.20013554, 0.20008267]\n",
      "[0.60051244, 0.2, 0.20011878, 0.20006132]\n",
      "[0.600621, 0.2, 0.2001088, 0.20018178]\n",
      "[0.60055435, 0.2, 0.20017675, 0.20004907]\n",
      "[0.6004724, 0.2, 0.20008333, 0.20006242]\n",
      "[0.60054225, 0.2, 0.20006399, 0.20015354]\n",
      "[0.60081476, 0.2, 0.20005238, 0.2004397]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8910 iterations: 2.31123530069987 mins\n",
      "Train Loss: [0.60081476, 0.2, 0.20005238, 0.2004397]\n",
      "[0.60052484, 0.2, 0.20007595, 0.20012794]\n",
      "[0.6004421, 0.2, 0.20003043, 0.20009248]\n",
      "[0.600541, 0.2, 0.20006438, 0.20015888]\n",
      "[0.6006289, 0.2, 0.2001486, 0.20016369]\n",
      "[0.6004795, 0.2, 0.20011126, 0.20005275]\n",
      "[0.60055417, 0.2, 0.2001038, 0.20013589]\n",
      "[0.6005039, 0.2, 0.2001044, 0.20008628]\n",
      "[0.6008301, 0.2, 0.20033744, 0.20018041]\n",
      "[0.6004535, 0.2, 0.20000002, 0.2001422]\n",
      "[0.601795, 0.2, 0.201441, 0.20004359]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8920 iterations: 2.3131019790967304 mins\n",
      "Train Loss: [0.601795, 0.2, 0.201441, 0.20004359]\n",
      "[0.6004797, 0.2, 0.20005633, 0.20011349]\n",
      "[0.6004626, 0.2, 0.20004864, 0.20010443]\n",
      "[0.60054845, 0.2, 0.20007107, 0.2001679]\n",
      "[0.6005285, 0.2, 0.20005672, 0.20016226]\n",
      "[0.60043675, 0.2, 0.20004693, 0.20008041]\n",
      "[0.60042685, 0.2, 0.200055, 0.20006262]\n",
      "[0.600509, 0.2, 0.200127, 0.20007312]\n",
      "[0.6006169, 0.2, 0.2000665, 0.20024207]\n",
      "[0.60052055, 0.2, 0.2001033, 0.20010981]\n",
      "[0.60056746, 0.2, 0.20009702, 0.20016398]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8930 iterations: 2.315792417526245 mins\n",
      "Train Loss: [0.60056746, 0.2, 0.20009702, 0.20016398]\n",
      "[0.6005501, 0.2, 0.20009552, 0.20014961]\n",
      "[0.60100335, 0.2, 0.20005207, 0.20064776]\n",
      "[0.6007197, 0.2, 0.20028356, 0.20013393]\n",
      "[0.6005386, 0.2, 0.20017914, 0.20005843]\n",
      "[0.6004453, 0.2, 0.20004353, 0.20010215]\n",
      "[0.60046846, 0.2, 0.20009634, 0.2000738]\n",
      "[0.6005374, 0.2, 0.20011145, 0.20012903]\n",
      "[0.600466, 0.2, 0.20007955, 0.20009087]\n",
      "[0.600442, 0.2, 0.20007427, 0.20007358]\n",
      "[0.60043293, 0.2, 0.20005476, 0.20008552]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8940 iterations: 2.3178455511728924 mins\n",
      "Train Loss: [0.60043293, 0.2, 0.20005476, 0.20008552]\n",
      "[0.60068613, 0.2, 0.20004372, 0.20035148]\n",
      "[0.60046077, 0.2, 0.20006578, 0.20010585]\n",
      "[0.6007298, 0.2, 0.20007259, 0.20036998]\n",
      "[0.60060775, 0.2, 0.20011334, 0.20020902]\n",
      "[0.6005615, 0.2, 0.20010883, 0.20016927]\n",
      "[0.6007588, 0.2, 0.20031092, 0.20016637]\n",
      "[0.600622, 0.2, 0.20011446, 0.20022814]\n",
      "[0.60108274, 0.2, 0.20052807, 0.2002773]\n",
      "[0.60047305, 0.2, 0.20007686, 0.20012079]\n",
      "[0.6003642, 0.2, 0.20005572, 0.20003499]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8950 iterations: 2.31979459921519 mins\n",
      "Train Loss: [0.6003642, 0.2, 0.20005572, 0.20003499]\n",
      "[0.6004031, 0.2, 0.20007983, 0.20005159]\n",
      "[0.6005276, 0.2, 0.20010765, 0.2001502]\n",
      "[0.60057527, 0.2, 0.20012362, 0.20018385]\n",
      "[0.6006917, 0.2, 0.20027223, 0.20015374]\n",
      "[0.6004643, 0.2, 0.20014627, 0.20005424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60041386, 0.2, 0.20006935, 0.20008267]\n",
      "[0.6004307, 0.2, 0.20009474, 0.20007585]\n",
      "[0.6008536, 0.2, 0.20049585, 0.20009936]\n",
      "[0.600596, 0.2, 0.20002513, 0.200314]\n",
      "[0.60042524, 0.2, 0.2000836, 0.2000861]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8960 iterations: 2.321834218502045 mins\n",
      "Train Loss: [0.60042524, 0.2, 0.2000836, 0.2000861]\n",
      "[0.60050565, 0.2, 0.20006098, 0.20019042]\n",
      "[0.6005934, 0.2, 0.20028694, 0.20005345]\n",
      "[0.6003914, 0.2, 0.2000781, 0.20006138]\n",
      "[0.60040545, 0.2, 0.20011127, 0.20004326]\n",
      "[0.600655, 0.2, 0.20019294, 0.20021203]\n",
      "[0.6004031, 0.2, 0.20000723, 0.20014663]\n",
      "[0.6007329, 0.2, 0.20019582, 0.20028868]\n",
      "[0.600433, 0.2, 0.20013776, 0.20004752]\n",
      "[0.60041857, 0.2, 0.2001066, 0.20006502]\n",
      "[0.6003868, 0.2, 0.20006627, 0.20007439]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8970 iterations: 2.3237016479174297 mins\n",
      "Train Loss: [0.6003868, 0.2, 0.20006627, 0.20007439]\n",
      "[0.6004114, 0.2, 0.200089, 0.20007709]\n",
      "[0.6003879, 0.2, 0.2001022, 0.20004112]\n",
      "[0.60055715, 0.2, 0.2001027, 0.20021074]\n",
      "[0.6019328, 0.2, 0.20160688, 0.20008302]\n",
      "[0.60069066, 0.2, 0.20037596, 0.20007265]\n",
      "[0.6007225, 0.2, 0.20040026, 0.20008005]\n",
      "[0.6004689, 0.2, 0.20007586, 0.20015052]\n",
      "[0.6004077, 0.2, 0.20006308, 0.20010139]\n",
      "[0.6004387, 0.2, 0.20007086, 0.20012364]\n",
      "[0.60044485, 0.2, 0.20014368, 0.20005567]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8980 iterations: 2.3257110357284545 mins\n",
      "Train Loss: [0.60044485, 0.2, 0.20014368, 0.20005567]\n",
      "[0.6005861, 0.2, 0.20009814, 0.2002411]\n",
      "[0.60048085, 0.2, 0.20015877, 0.20007406]\n",
      "[0.6004315, 0.2, 0.20010994, 0.20007236]\n",
      "[0.6003844, 0.2, 0.20010218, 0.20003201]\n",
      "[0.60045594, 0.2, 0.20005791, 0.20014687]\n",
      "[0.6006286, 0.2, 0.20030424, 0.2000722]\n",
      "[0.6005881, 0.2, 0.20017424, 0.20016071]\n",
      "[0.60043025, 0.2, 0.20007002, 0.20010622]\n",
      "[0.600361, 0.2, 0.20000029, 0.20010583]\n",
      "[0.6005311, 0.2, 0.20013788, 0.20013754]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8990 iterations: 2.327638566493988 mins\n",
      "Train Loss: [0.6005311, 0.2, 0.20013788, 0.20013754]\n",
      "[0.6005601, 0.2, 0.20009169, 0.200212]\n",
      "[0.60045135, 0.2, 0.20006216, 0.20013207]\n",
      "[0.60061437, 0.2, 0.20024922, 0.20010725]\n",
      "[0.60057914, 0.2, 0.20012088, 0.2001995]\n",
      "[0.60141784, 0.2, 0.20032376, 0.20083444]\n",
      "[0.60057914, 0.2, 0.20016162, 0.20015745]\n",
      "[0.6007208, 0.2, 0.20014487, 0.20031513]\n",
      "[0.60056776, 0.2, 0.20018782, 0.2001179]\n",
      "[0.6006756, 0.2, 0.20018964, 0.20022254]\n",
      "[0.6009231, 0.2, 0.20029826, 0.20035994]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9000 iterations: 2.329632802804311 mins\n",
      "Train Loss: [0.6009231, 0.2, 0.20029826, 0.20035994]\n",
      "[0.6006502, 0.2, 0.20022903, 0.20015448]\n",
      "[0.600419, 0.2, 0.20012511, 0.20002532]\n",
      "[0.6006072, 0.2, 0.20017764, 0.20015919]\n",
      "[0.6005938, 0.2, 0.20021823, 0.20010333]\n",
      "[0.6005815, 0.2, 0.20011982, 0.20018776]\n",
      "[0.6005738, 0.2, 0.20015706, 0.20014125]\n",
      "[0.6009318, 0.2, 0.20046368, 0.20019117]\n",
      "[0.60119677, 0.2, 0.20035632, 0.20056225]\n",
      "[0.6006024, 0.2, 0.20027675, 0.20004688]\n",
      "[0.60060227, 0.2, 0.20010959, 0.20021339]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9010 iterations: 2.331999150911967 mins\n",
      "Train Loss: [0.60060227, 0.2, 0.20010959, 0.20021339]\n",
      "[0.60110277, 0.2, 0.20064554, 0.20017718]\n",
      "[0.6006522, 0.2, 0.20012519, 0.20024621]\n",
      "[0.6012482, 0.2, 0.2003946, 0.20057178]\n",
      "[0.6007332, 0.2, 0.20029886, 0.20015164]\n",
      "[0.6008582, 0.2, 0.20047553, 0.20009898]\n",
      "[0.6010863, 0.2, 0.2006369, 0.20016456]\n",
      "[0.60139406, 0.2, 0.20047581, 0.20063217]\n",
      "[0.6007092, 0.2, 0.2001886, 0.20023343]\n",
      "[0.600512, 0.2, 0.20008458, 0.20013882]\n",
      "[0.60113925, 0.2, 0.20077994, 0.20006897]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9020 iterations: 2.333871666590373 mins\n",
      "Train Loss: [0.60113925, 0.2, 0.20077994, 0.20006897]\n",
      "[0.601151, 0.2, 0.2004096, 0.20044956]\n",
      "[0.60066897, 0.2, 0.20014885, 0.20022687]\n",
      "[0.60059226, 0.2, 0.20020033, 0.20009741]\n",
      "[0.6007307, 0.2, 0.20015398, 0.20028074]\n",
      "[0.6004978, 0.2, 0.20014471, 0.20005523]\n",
      "[0.6005318, 0.2, 0.20011182, 0.20012012]\n",
      "[0.6004212, 0.2, 0.20000002, 0.20011914]\n",
      "[0.60131097, 0.2, 0.20046467, 0.20054176]\n",
      "[0.60127574, 0.2, 0.20081338, 0.2001551]\n",
      "[0.6011733, 0.2, 0.20048703, 0.20037617]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9030 iterations: 2.335856266816457 mins\n",
      "Train Loss: [0.6011733, 0.2, 0.20048703, 0.20037617]\n",
      "[0.60113424, 0.2, 0.20032617, 0.20049506]\n",
      "[0.6008659, 0.2, 0.20024277, 0.2003074]\n",
      "[0.6008134, 0.2, 0.20032932, 0.20016554]\n",
      "[0.60086846, 0.2, 0.20027816, 0.20026962]\n",
      "[0.6008027, 0.2, 0.20026405, 0.20021565]\n",
      "[0.60067374, 0.2, 0.20023765, 0.20011084]\n",
      "[0.6007468, 0.2, 0.20011929, 0.20030002]\n",
      "[0.6006706, 0.2, 0.20008327, 0.20025766]\n",
      "[0.60057205, 0.2, 0.20008603, 0.20015433]\n",
      "[0.60179156, 0.2, 0.20131102, 0.20014687]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9040 iterations: 2.33778338432312 mins\n",
      "Train Loss: [0.60179156, 0.2, 0.20131102, 0.20014687]\n",
      "[0.6006807, 0.2, 0.20017248, 0.20017344]\n",
      "[0.601281, 0.2, 0.20008284, 0.20086202]\n",
      "[0.6010446, 0.2, 0.20048514, 0.20022234]\n",
      "[0.6010264, 0.2, 0.20018038, 0.20050807]\n",
      "[0.6005617, 0.2, 0.20010701, 0.20011598]\n",
      "[0.6010658, 0.2, 0.20039988, 0.20032646]\n",
      "[0.6008849, 0.2, 0.20013633, 0.2004085]\n",
      "[0.6009394, 0.2, 0.20027992, 0.20031926]\n",
      "[0.6007018, 0.2, 0.20018147, 0.20017993]\n",
      "[0.6007105, 0.2, 0.20000005, 0.2003699]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9050 iterations: 2.339805463949839 mins\n",
      "Train Loss: [0.6007105, 0.2, 0.20000005, 0.2003699]\n",
      "[0.6006685, 0.2, 0.20011291, 0.20021483]\n",
      "[0.60083467, 0.2, 0.20019592, 0.20029792]\n",
      "[0.6005754, 0.2, 0.20010659, 0.20012821]\n",
      "[0.6006015, 0.2, 0.20011418, 0.20014697]\n",
      "[0.60066634, 0.2, 0.20013297, 0.20019317]\n",
      "[0.6007096, 0.2, 0.20009623, 0.20027329]\n",
      "[0.6008294, 0.2, 0.20034966, 0.20013998]\n",
      "[0.6005131, 0.2, 0.2001301, 0.20004378]\n",
      "[0.6006981, 0.2, 0.20025483, 0.2001044]\n",
      "[0.60079175, 0.2, 0.20028561, 0.20016792]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9060 iterations: 2.3416997671127318 mins\n",
      "Train Loss: [0.60079175, 0.2, 0.20028561, 0.20016792]\n",
      "[0.6009407, 0.2, 0.20027499, 0.20032808]\n",
      "[0.6006717, 0.2, 0.20013992, 0.20019467]\n",
      "[0.60076815, 0.2, 0.20032738, 0.20010409]\n",
      "[0.6008787, 0.2, 0.20045337, 0.20008925]\n",
      "[0.60087436, 0.2, 0.20014833, 0.2003906]\n",
      "[0.60078025, 0.2, 0.200359, 0.2000864]\n",
      "[0.6006709, 0.2, 0.20021912, 0.20011726]\n",
      "[0.60068893, 0.2, 0.2002071, 0.20014802]\n",
      "[0.60062385, 0.2, 0.20010142, 0.20018929]\n",
      "[0.60068077, 0.2, 0.20011678, 0.2002314]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9070 iterations: 2.3437397321065268 mins\n",
      "Train Loss: [0.60068077, 0.2, 0.20011678, 0.2002314]\n",
      "[0.6004717, 0.2, 0.200008, 0.20013186]\n",
      "[0.60071313, 0.2, 0.20029889, 0.2000833]\n",
      "[0.6009075, 0.2, 0.20031099, 0.20026682]\n",
      "[0.6009112, 0.2, 0.200294, 0.20028897]\n",
      "[0.60101837, 0.2, 0.20024748, 0.20044388]\n",
      "[0.6006237, 0.2, 0.20009321, 0.20020472]\n",
      "[0.6005922, 0.2, 0.20007583, 0.20019144]\n",
      "[0.6009415, 0.2, 0.20017909, 0.2004382]\n",
      "[0.6005739, 0.2, 0.2001055, 0.20014486]\n",
      "[0.60104364, 0.2, 0.2003119, 0.20040864]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9080 iterations: 2.3457423289616903 mins\n",
      "Train Loss: [0.60104364, 0.2, 0.2003119, 0.20040864]\n",
      "[0.6006943, 0.2, 0.20017405, 0.20019773]\n",
      "[0.60075504, 0.2, 0.20009752, 0.20033562]\n",
      "[0.6010203, 0.2, 0.20032592, 0.20037279]\n",
      "[0.60092837, 0.2, 0.20030323, 0.20030382]\n",
      "[0.601108, 0.2, 0.20067298, 0.2001137]\n",
      "[0.60110015, 0.2, 0.20035598, 0.2004231]\n",
      "[0.6007033, 0.2, 0.20021085, 0.20017152]\n",
      "[0.60061795, 0.2, 0.20009118, 0.20020573]\n",
      "[0.6006272, 0.2, 0.20009296, 0.20021282]\n",
      "[0.6006767, 0.2, 0.20014015, 0.20021465]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9090 iterations: 2.348191765944163 mins\n",
      "Train Loss: [0.6006767, 0.2, 0.20014015, 0.20021465]\n",
      "[0.60058427, 0.2, 0.20017517, 0.20008671]\n",
      "[0.600873, 0.2, 0.2002084, 0.20034182]\n",
      "[0.6006367, 0.2, 0.20019995, 0.200114]\n",
      "[0.6007188, 0.2, 0.2002265, 0.20016938]\n",
      "[0.6008799, 0.2, 0.20036308, 0.20019385]\n",
      "[0.6012629, 0.2, 0.20027761, 0.20066231]\n",
      "[0.6014168, 0.2, 0.20083588, 0.2002579]\n",
      "[0.60079825, 0.2, 0.2002551, 0.20021974]\n",
      "[0.60115564, 0.2, 0.2002069, 0.20062481]\n",
      "[0.6011087, 0.2, 0.2004642, 0.20032032]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9100 iterations: 2.3502504030863443 mins\n",
      "Train Loss: [0.6011087, 0.2, 0.2004642, 0.20032032]\n",
      "[0.6005452, 0.2, 0.20014395, 0.200077]\n",
      "[0.6009111, 0.2, 0.20019507, 0.20039134]\n",
      "[0.60091156, 0.2, 0.20037428, 0.20021231]\n",
      "[0.6008407, 0.2, 0.20022723, 0.20028824]\n",
      "[0.601068, 0.2, 0.20054536, 0.20019697]\n",
      "[0.6007485, 0.2, 0.20025167, 0.20017076]\n",
      "[0.6006115, 0.2, 0.20009929, 0.20018561]\n",
      "[0.600881, 0.2, 0.20030904, 0.20024438]\n",
      "[0.60074073, 0.2, 0.20017235, 0.2002399]\n",
      "[0.6013248, 0.2, 0.20034574, 0.20064951]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9110 iterations: 2.352173316478729 mins\n",
      "Train Loss: [0.6013248, 0.2, 0.20034574, 0.20064951]\n",
      "[0.60070574, 0.2, 0.20025165, 0.20012398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60098076, 0.2, 0.20036714, 0.20028283]\n",
      "[0.6008788, 0.2, 0.20024373, 0.20030347]\n",
      "[0.60056967, 0.2, 0.20015827, 0.20007902]\n",
      "[0.60064286, 0.2, 0.20009571, 0.200214]\n",
      "[0.6005345, 0.2, 0.20008223, 0.20011853]\n",
      "[0.60059357, 0.2, 0.20008367, 0.20017584]\n",
      "[0.60114163, 0.2, 0.20059298, 0.20021452]\n",
      "[0.6014547, 0.2, 0.20036063, 0.20076023]\n",
      "[0.60067594, 0.2, 0.20009059, 0.20025188]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9120 iterations: 2.3541911840438843 mins\n",
      "Train Loss: [0.60067594, 0.2, 0.20009059, 0.20025188]\n",
      "[0.6006669, 0.2, 0.20013547, 0.20019825]\n",
      "[0.6006982, 0.2, 0.20019321, 0.20017175]\n",
      "[0.60075694, 0.2, 0.2002871, 0.20013657]\n",
      "[0.60084224, 0.2, 0.20026322, 0.2002458]\n",
      "[0.6006971, 0.2, 0.20015025, 0.20021386]\n",
      "[0.60051, 0.2, 0.20000002, 0.20017698]\n",
      "[0.60081637, 0.2, 0.20027839, 0.2002051]\n",
      "[0.6016085, 0.2, 0.20064093, 0.20063472]\n",
      "[0.6012004, 0.2, 0.20017138, 0.2006963]\n",
      "[0.6010253, 0.2, 0.20053187, 0.20016076]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9130 iterations: 2.3561489661534627 mins\n",
      "Train Loss: [0.6010253, 0.2, 0.20053187, 0.20016076]\n",
      "[0.6006355, 0.2, 0.20020624, 0.20009704]\n",
      "[0.6013676, 0.2, 0.20048821, 0.20054764]\n",
      "[0.60080487, 0.2, 0.20039177, 0.20008203]\n",
      "[0.6007874, 0.2, 0.20036995, 0.20008706]\n",
      "[0.6007127, 0.2, 0.20027113, 0.20011197]\n",
      "[0.6006932, 0.2, 0.20021802, 0.20014633]\n",
      "[0.6006763, 0.2, 0.20012258, 0.20022568]\n",
      "[0.60058004, 0.2, 0.20016514, 0.20008779]\n",
      "[0.600774, 0.2, 0.2002567, 0.20019116]\n",
      "[0.60062104, 0.2, 0.20009755, 0.20019855]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9140 iterations: 2.358202064037323 mins\n",
      "Train Loss: [0.60062104, 0.2, 0.20009755, 0.20019855]\n",
      "[0.6007651, 0.2, 0.20021427, 0.2002271]\n",
      "[0.6007032, 0.2, 0.20015308, 0.2002275]\n",
      "[0.6008214, 0.2, 0.20025459, 0.20024534]\n",
      "[0.60063714, 0.2, 0.20016678, 0.20014991]\n",
      "[0.600733, 0.2, 0.20015664, 0.20025663]\n",
      "[0.6005489, 0.2, 0.2001658, 0.20006418]\n",
      "[0.6004496, 0.2, 0.2000756, 0.20005569]\n",
      "[0.60052985, 0.2, 0.20014518, 0.2000669]\n",
      "[0.6005746, 0.2, 0.2001657, 0.20009173]\n",
      "[0.60082686, 0.2, 0.20013276, 0.20037754]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9150 iterations: 2.360171679655711 mins\n",
      "Train Loss: [0.60082686, 0.2, 0.20013276, 0.20037754]\n",
      "[0.6007776, 0.2, 0.20022793, 0.20023364]\n",
      "[0.60065836, 0.2, 0.20020825, 0.20013471]\n",
      "[0.600669, 0.2, 0.2001804, 0.20017394]\n",
      "[0.6007122, 0.2, 0.20014715, 0.20025091]\n",
      "[0.60057926, 0.2, 0.2001046, 0.20016126]\n",
      "[0.60049665, 0.2, 0.20010324, 0.20008081]\n",
      "[0.60060304, 0.2, 0.20009805, 0.20019321]\n",
      "[0.6006646, 0.2, 0.20024592, 0.20010777]\n",
      "[0.6005635, 0.2, 0.2001956, 0.20005783]\n",
      "[0.60073596, 0.2, 0.20022665, 0.20020016]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9160 iterations: 2.3619855801264444 mins\n",
      "Train Loss: [0.60073596, 0.2, 0.20022665, 0.20020016]\n",
      "[0.6005828, 0.2, 0.20014146, 0.20013294]\n",
      "[0.60074306, 0.2, 0.20027542, 0.20016037]\n",
      "[0.6005126, 0.2, 0.20005912, 0.20014745]\n",
      "[0.60063624, 0.2, 0.20012954, 0.20020178]\n",
      "[0.6005897, 0.2, 0.20011204, 0.20017405]\n",
      "[0.6007372, 0.2, 0.20027077, 0.20016429]\n",
      "[0.60068375, 0.2, 0.20019127, 0.20019168]\n",
      "[0.6005322, 0.2, 0.20010825, 0.20012456]\n",
      "[0.60067505, 0.2, 0.20029327, 0.20008388]\n",
      "[0.6005668, 0.2, 0.20012394, 0.20014657]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9170 iterations: 2.3644280314445494 mins\n",
      "Train Loss: [0.6005668, 0.2, 0.20012394, 0.20014657]\n",
      "[0.60053617, 0.2, 0.20009817, 0.20014323]\n",
      "[0.6008858, 0.2, 0.20021257, 0.2003799]\n",
      "[0.60069215, 0.2, 0.20011072, 0.20028953]\n",
      "[0.60051066, 0.2, 0.20002264, 0.20019743]\n",
      "[0.600595, 0.2, 0.2001235, 0.20018221]\n",
      "[0.60062796, 0.2, 0.20010923, 0.2002307]\n",
      "[0.600573, 0.2, 0.20000009, 0.20028591]\n",
      "[0.60111606, 0.2, 0.20034426, 0.20048563]\n",
      "[0.6006609, 0.2, 0.20030679, 0.20006877]\n",
      "[0.6005723, 0.2, 0.20011067, 0.2001769]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9180 iterations: 2.366255748271942 mins\n",
      "Train Loss: [0.6005723, 0.2, 0.20011067, 0.2001769]\n",
      "[0.6006567, 0.2, 0.20020351, 0.2001691]\n",
      "[0.6007466, 0.2, 0.20023786, 0.20022532]\n",
      "[0.6006375, 0.2, 0.20021276, 0.20014206]\n",
      "[0.600518, 0.2, 0.20011123, 0.2001248]\n",
      "[0.6004712, 0.2, 0.20008232, 0.20010774]\n",
      "[0.60055655, 0.2, 0.20014197, 0.20013423]\n",
      "[0.6004236, 0.2, 0.20007415, 0.20006995]\n",
      "[0.600585, 0.2, 0.20017703, 0.20012933]\n",
      "[0.6005342, 0.2, 0.20016216, 0.20009448]\n",
      "[0.6004881, 0.2, 0.20010822, 0.20010349]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9190 iterations: 2.3682782848676047 mins\n",
      "Train Loss: [0.6004881, 0.2, 0.20010822, 0.20010349]\n",
      "[0.60043097, 0.2, 0.2000644, 0.20009135]\n",
      "[0.60057884, 0.2, 0.20016354, 0.2001414]\n",
      "[0.60065377, 0.2, 0.20019476, 0.20018634]\n",
      "[0.60055625, 0.2, 0.20014378, 0.20014128]\n",
      "[0.6006392, 0.2, 0.20017001, 0.20019935]\n",
      "[0.60054517, 0.2, 0.20010364, 0.20017314]\n",
      "[0.60071707, 0.2, 0.20040673, 0.20004326]\n",
      "[0.600562, 0.2, 0.20015046, 0.2001457]\n",
      "[0.60070246, 0.2, 0.20026352, 0.2001744]\n",
      "[0.6006767, 0.2, 0.20028412, 0.20012926]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9200 iterations: 2.3702874143918353 mins\n",
      "Train Loss: [0.6006767, 0.2, 0.20028412, 0.20012926]\n",
      "[0.60045326, 0.2, 0.20006886, 0.20012209]\n",
      "[0.60057354, 0.2, 0.20006308, 0.20024908]\n",
      "[0.6003899, 0.2, 0.200072, 0.20005739]\n",
      "[0.6006076, 0.2, 0.2001936, 0.20015427]\n",
      "[0.60058343, 0.2, 0.20021442, 0.20011018]\n",
      "[0.6005307, 0.2, 0.20016868, 0.20010406]\n",
      "[0.60057074, 0.2, 0.20009662, 0.20021705]\n",
      "[0.6005021, 0.2, 0.20019259, 0.20005332]\n",
      "[0.6004929, 0.2, 0.20009677, 0.2001408]\n",
      "[0.60055095, 0.2, 0.20012404, 0.20017232]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9210 iterations: 2.372276465098063 mins\n",
      "Train Loss: [0.60055095, 0.2, 0.20012404, 0.20017232]\n",
      "[0.60046375, 0.2, 0.20009808, 0.20011178]\n",
      "[0.60062194, 0.2, 0.20024058, 0.200128]\n",
      "[0.60034704, 0.2, 0.20001248, 0.20008187]\n",
      "[0.60044354, 0.2, 0.20009808, 0.20009339]\n",
      "[0.60058445, 0.2, 0.20012753, 0.20020556]\n",
      "[0.6005502, 0.2, 0.2001095, 0.20019014]\n",
      "[0.6003937, 0.2, 0.20003772, 0.20010628]\n",
      "[0.60046744, 0.2, 0.2001265, 0.20009196]\n",
      "[0.6004533, 0.2, 0.20004699, 0.20015818]\n",
      "[0.60041976, 0.2, 0.2000533, 0.20011918]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9220 iterations: 2.3743187308311464 mins\n",
      "Train Loss: [0.60041976, 0.2, 0.2000533, 0.20011918]\n",
      "[0.6005503, 0.2, 0.2001636, 0.20014042]\n",
      "[0.60055614, 0.2, 0.20010613, 0.20020473]\n",
      "[0.6006834, 0.2, 0.20032623, 0.20011282]\n",
      "[0.60055625, 0.2, 0.20017126, 0.20014153]\n",
      "[0.600569, 0.2, 0.20004494, 0.20028134]\n",
      "[0.60059816, 0.2, 0.20010953, 0.2002466]\n",
      "[0.6005726, 0.2, 0.20023176, 0.20009941]\n",
      "[0.6003959, 0.2, 0.20007429, 0.20008077]\n",
      "[0.6006231, 0.2, 0.20016699, 0.20021579]\n",
      "[0.6005133, 0.2, 0.20020758, 0.2000661]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9230 iterations: 2.3763073841730753 mins\n",
      "Train Loss: [0.6005133, 0.2, 0.20020758, 0.2000661]\n",
      "[0.60061985, 0.2, 0.20017117, 0.20020965]\n",
      "[0.6004993, 0.2, 0.20017724, 0.20008351]\n",
      "[0.6004243, 0.2, 0.2000594, 0.20012693]\n",
      "[0.6004103, 0.2, 0.20004684, 0.20012605]\n",
      "[0.6005232, 0.2, 0.20015158, 0.20013472]\n",
      "[0.60043544, 0.2, 0.2000823, 0.200117]\n",
      "[0.60038924, 0.2, 0.20008384, 0.20007]\n",
      "[0.6004252, 0.2, 0.2001387, 0.20005162]\n",
      "[0.60050225, 0.2, 0.20012027, 0.20014782]\n",
      "[0.60031414, 0.2, 0.20000002, 0.20008065]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9240 iterations: 2.378307549158732 mins\n",
      "Train Loss: [0.60031414, 0.2, 0.20000002, 0.20008065]\n",
      "[0.6003856, 0.2, 0.20009206, 0.20006081]\n",
      "[0.600487, 0.2, 0.20011392, 0.20014107]\n",
      "[0.60042983, 0.2, 0.20011632, 0.20008238]\n",
      "[0.6004564, 0.2, 0.20008181, 0.2001444]\n",
      "[0.60050476, 0.2, 0.20012885, 0.20014675]\n",
      "[0.6003341, 0.2, 0.2000476, 0.20005848]\n",
      "[0.60038644, 0.2, 0.20009242, 0.20006706]\n",
      "[0.6003917, 0.2, 0.20007135, 0.20009454]\n",
      "[0.6005217, 0.2, 0.20025454, 0.20004249]\n",
      "[0.60049677, 0.2, 0.2001653, 0.20010804]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9250 iterations: 2.3806662638982137 mins\n",
      "Train Loss: [0.60049677, 0.2, 0.2001653, 0.20010804]\n",
      "[0.6003595, 0.2, 0.20004915, 0.20008826]\n",
      "[0.60046166, 0.2, 0.20018563, 0.20005523]\n",
      "[0.6005226, 0.2, 0.20015119, 0.20015185]\n",
      "[0.60037017, 0.2, 0.20005062, 0.2001013]\n",
      "[0.60040385, 0.2, 0.20009917, 0.20008764]\n",
      "[0.6004265, 0.2, 0.20010145, 0.20010921]\n",
      "[0.60044414, 0.2, 0.20016858, 0.20006093]\n",
      "[0.60033053, 0.2, 0.20007807, 0.20003897]\n",
      "[0.60032386, 0.2, 0.20004968, 0.20006165]\n",
      "[0.6003735, 0.2, 0.20008852, 0.20007353]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9260 iterations: 2.3835920174916585 mins\n",
      "Train Loss: [0.6003735, 0.2, 0.20008852, 0.20007353]\n",
      "[0.60038745, 0.2, 0.20010096, 0.20007595]\n",
      "[0.6003104, 0.2, 0.2000428, 0.20005795]\n",
      "[0.6005334, 0.2, 0.20022313, 0.20010151]\n",
      "[0.60047096, 0.2, 0.20009506, 0.2001681]\n",
      "[0.6004705, 0.2, 0.20015232, 0.20011118]\n",
      "[0.6007269, 0.2, 0.20024805, 0.20027275]\n",
      "[0.60065955, 0.2, 0.20012102, 0.20033331]\n",
      "[0.6004327, 0.2, 0.20010166, 0.20012686]\n",
      "[0.6004666, 0.2, 0.2001559, 0.2001075]\n",
      "[0.6004437, 0.2, 0.20016357, 0.2000777]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9270 iterations: 2.385491633415222 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: [0.6004437, 0.2, 0.20016357, 0.2000777]\n",
      "[0.60043085, 0.2, 0.20013607, 0.20009309]\n",
      "[0.600375, 0.2, 0.20007901, 0.20009492]\n",
      "[0.6003931, 0.2, 0.200067, 0.20012563]\n",
      "[0.6003153, 0.2, 0.20004992, 0.20006527]\n",
      "[0.60038316, 0.2, 0.20004472, 0.20013855]\n",
      "[0.60047925, 0.2, 0.2001597, 0.20011987]\n",
      "[0.600347, 0.2, 0.2000635, 0.20008391]\n",
      "[0.60041785, 0.2, 0.20008872, 0.20012952]\n",
      "[0.6004388, 0.2, 0.20017771, 0.20006129]\n",
      "[0.60054827, 0.2, 0.20016675, 0.20018154]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9280 iterations: 2.387544349829356 mins\n",
      "Train Loss: [0.60054827, 0.2, 0.20016675, 0.20018154]\n",
      "[0.6003969, 0.2, 0.20008947, 0.20010714]\n",
      "[0.60055345, 0.2, 0.20014451, 0.20020829]\n",
      "[0.6005096, 0.2, 0.20007767, 0.20023097]\n",
      "[0.60048836, 0.2, 0.20015946, 0.20012772]\n",
      "[0.6006096, 0.2, 0.20022716, 0.20018117]\n",
      "[0.6004195, 0.2, 0.20007934, 0.20013879]\n",
      "[0.60051644, 0.2, 0.20008187, 0.20023295]\n",
      "[0.60044104, 0.2, 0.20016414, 0.2000751]\n",
      "[0.6003437, 0.2, 0.20004556, 0.20009595]\n",
      "[0.6003815, 0.2, 0.20004499, 0.20013396]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9290 iterations: 2.389570001761119 mins\n",
      "Train Loss: [0.6003815, 0.2, 0.20004499, 0.20013396]\n",
      "[0.6004999, 0.2, 0.20010614, 0.2001908]\n",
      "[0.60040545, 0.2, 0.20007184, 0.20013022]\n",
      "[0.6005153, 0.2, 0.20024411, 0.20006748]\n",
      "[0.6004336, 0.2, 0.20010853, 0.20012087]\n",
      "[0.60036904, 0.2, 0.20011367, 0.2000507]\n",
      "[0.60058385, 0.2, 0.2001506, 0.20022787]\n",
      "[0.6008154, 0.2, 0.20037958, 0.20022944]\n",
      "[0.60111475, 0.2, 0.20032679, 0.20058061]\n",
      "[0.6005147, 0.2, 0.20016508, 0.20014112]\n",
      "[0.6005216, 0.2, 0.20019019, 0.20012173]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9300 iterations: 2.3914607644081114 mins\n",
      "Train Loss: [0.6005216, 0.2, 0.20019019, 0.20012173]\n",
      "[0.60051256, 0.2, 0.20010899, 0.2001929]\n",
      "[0.60040945, 0.2, 0.20011084, 0.20008686]\n",
      "[0.6005691, 0.2, 0.20024134, 0.2001149]\n",
      "[0.60050553, 0.2, 0.20016454, 0.2001272]\n",
      "[0.60048646, 0.2, 0.20021933, 0.20005244]\n",
      "[0.6003872, 0.2, 0.20010343, 0.20006824]\n",
      "[0.60053754, 0.2, 0.20024388, 0.20007692]\n",
      "[0.60041493, 0.2, 0.20009066, 0.20010616]\n",
      "[0.60077953, 0.2, 0.20046993, 0.20009]\n",
      "[0.60041875, 0.2, 0.20006989, 0.20012763]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9310 iterations: 2.3936723669370017 mins\n",
      "Train Loss: [0.60041875, 0.2, 0.20006989, 0.20012763]\n",
      "[0.6004679, 0.2, 0.20011425, 0.200131]\n",
      "[0.6007951, 0.2, 0.20008716, 0.20048356]\n",
      "[0.6005046, 0.2, 0.2001916, 0.20008686]\n",
      "[0.6005618, 0.2, 0.20017837, 0.20015575]\n",
      "[0.60046995, 0.2, 0.20017757, 0.20006308]\n",
      "[0.6006258, 0.2, 0.20003591, 0.20035924]\n",
      "[0.6006078, 0.2, 0.20011021, 0.20026587]\n",
      "[0.60056114, 0.2, 0.20006597, 0.20026234]\n",
      "[0.6004966, 0.2, 0.20016804, 0.20009467]\n",
      "[0.6008867, 0.2, 0.20034887, 0.20030288]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9320 iterations: 2.395699119567871 mins\n",
      "Train Loss: [0.6008867, 0.2, 0.20034887, 0.20030288]\n",
      "[0.60076773, 0.2, 0.20021668, 0.20031492]\n",
      "[0.6004993, 0.2, 0.2001277, 0.20013443]\n",
      "[0.60087645, 0.2, 0.20022877, 0.20040955]\n",
      "[0.6004627, 0.2, 0.20005278, 0.20017101]\n",
      "[0.60054487, 0.2, 0.20014468, 0.20016046]\n",
      "[0.6005881, 0.2, 0.20009263, 0.20025495]\n",
      "[0.60041785, 0.2, 0.20004515, 0.20013155]\n",
      "[0.6005919, 0.2, 0.20030047, 0.20004967]\n",
      "[0.600579, 0.2, 0.20005189, 0.20028485]\n",
      "[0.60052866, 0.2, 0.20012951, 0.20015654]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9330 iterations: 2.399212535222371 mins\n",
      "Train Loss: [0.60052866, 0.2, 0.20012951, 0.20015654]\n",
      "[0.6006068, 0.2, 0.20022933, 0.20013465]\n",
      "[0.60049754, 0.2, 0.20008327, 0.20017141]\n",
      "[0.6005926, 0.2, 0.20025958, 0.20009002]\n",
      "[0.6004173, 0.2, 0.20000006, 0.20017415]\n",
      "[0.6009482, 0.2, 0.20031993, 0.2003851]\n",
      "[0.6008151, 0.2, 0.20029669, 0.20027521]\n",
      "[0.6004697, 0.2, 0.20012869, 0.20009807]\n",
      "[0.60080606, 0.2, 0.20019028, 0.20037311]\n",
      "[0.6005835, 0.2, 0.20011792, 0.20022327]\n",
      "[0.6005178, 0.2, 0.20014954, 0.20012632]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9340 iterations: 2.4011759320894877 mins\n",
      "Train Loss: [0.6005178, 0.2, 0.20014954, 0.20012632]\n",
      "[0.60043997, 0.2, 0.2001185, 0.2000797]\n",
      "[0.60080504, 0.2, 0.20019504, 0.20036836]\n",
      "[0.60081744, 0.2, 0.20040816, 0.2001678]\n",
      "[0.60040814, 0.2, 0.20007263, 0.20009382]\n",
      "[0.6004784, 0.2, 0.20009518, 0.20014107]\n",
      "[0.6005413, 0.2, 0.20020096, 0.20009737]\n",
      "[0.60039717, 0.2, 0.20008321, 0.20006981]\n",
      "[0.6006769, 0.2, 0.20026176, 0.2001696]\n",
      "[0.6008692, 0.2, 0.20029728, 0.20032485]\n",
      "[0.6006847, 0.2, 0.2002311, 0.20020528]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9350 iterations: 2.4030054489771526 mins\n",
      "Train Loss: [0.6006847, 0.2, 0.2002311, 0.20020528]\n",
      "[0.6006759, 0.2, 0.2001907, 0.2002357]\n",
      "[0.6004604, 0.2, 0.2001296, 0.2000802]\n",
      "[0.6005493, 0.2, 0.20007941, 0.200218]\n",
      "[0.6008898, 0.2, 0.20009978, 0.20053664]\n",
      "[0.60064095, 0.2, 0.20008974, 0.2002963]\n",
      "[0.60074586, 0.2, 0.20032617, 0.20016325]\n",
      "[0.6010451, 0.2, 0.20063348, 0.20015362]\n",
      "[0.60076153, 0.2, 0.20030159, 0.20020041]\n",
      "[0.6006584, 0.2, 0.20028932, 0.20010789]\n",
      "[0.60079145, 0.2, 0.2000996, 0.20042893]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9360 iterations: 2.405023515224457 mins\n",
      "Train Loss: [0.60079145, 0.2, 0.2000996, 0.20042893]\n",
      "[0.60052836, 0.2, 0.20007917, 0.20018454]\n",
      "[0.6007759, 0.2, 0.2002631, 0.20024654]\n",
      "[0.6012762, 0.2, 0.2001157, 0.20089287]\n",
      "[0.60068643, 0.2, 0.20028459, 0.20013224]\n",
      "[0.6007649, 0.2, 0.20029771, 0.20019574]\n",
      "[0.60057825, 0.2, 0.20009805, 0.20020647]\n",
      "[0.60048515, 0.2, 0.2001534, 0.20005564]\n",
      "[0.6005604, 0.2, 0.2001541, 0.20012775]\n",
      "[0.60049087, 0.2, 0.20008196, 0.20012805]\n",
      "[0.60041535, 0.2, 0.20008986, 0.20004249]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9370 iterations: 2.4069291989008588 mins\n",
      "Train Loss: [0.60041535, 0.2, 0.20008986, 0.20004249]\n",
      "[0.60063326, 0.2, 0.2002005, 0.2001479]\n",
      "[0.6007027, 0.2, 0.20018055, 0.2002355]\n",
      "[0.60044926, 0.2, 0.20010968, 0.20005132]\n",
      "[0.60056776, 0.2, 0.20012835, 0.20014985]\n",
      "[0.60077214, 0.2, 0.20013957, 0.20034185]\n",
      "[0.6008205, 0.2, 0.20031065, 0.2002181]\n",
      "[0.6007598, 0.2, 0.20009224, 0.2003749]\n",
      "[0.60053897, 0.2, 0.20016229, 0.20008306]\n",
      "[0.60067505, 0.2, 0.20031732, 0.20006338]\n",
      "[0.60071963, 0.2, 0.20019819, 0.20022635]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9380 iterations: 2.4089531977971395 mins\n",
      "Train Loss: [0.60071963, 0.2, 0.20019819, 0.20022635]\n",
      "[0.600738, 0.2, 0.20029874, 0.2001435]\n",
      "[0.6007069, 0.2, 0.2001644, 0.20024611]\n",
      "[0.6006359, 0.2, 0.20016785, 0.20017104]\n",
      "[0.6015388, 0.2, 0.20034295, 0.20089842]\n",
      "[0.60067683, 0.2, 0.20025906, 0.20012066]\n",
      "[0.600903, 0.2, 0.20011948, 0.20048675]\n",
      "[0.60065097, 0.2, 0.20022632, 0.20012876]\n",
      "[0.600728, 0.2, 0.20019197, 0.20024087]\n",
      "[0.6007839, 0.2, 0.20022374, 0.20026536]\n",
      "[0.60072, 0.2, 0.20008828, 0.20033711]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9390 iterations: 2.410905317465464 mins\n",
      "Train Loss: [0.60072, 0.2, 0.20008828, 0.20033711]\n",
      "[0.600807, 0.2, 0.20022011, 0.2002921]\n",
      "[0.60105574, 0.2, 0.20040421, 0.20035641]\n",
      "[0.60122144, 0.2, 0.20022103, 0.20070511]\n",
      "[0.6005388, 0.2, 0.20014654, 0.2000967]\n",
      "[0.6015322, 0.2, 0.20063822, 0.20059778]\n",
      "[0.60094017, 0.2, 0.20019512, 0.20044798]\n",
      "[0.60084313, 0.2, 0.20010045, 0.20044456]\n",
      "[0.6004888, 0.2, 0.20007966, 0.20011029]\n",
      "[0.60044485, 0.2, 0.20009083, 0.20005402]\n",
      "[0.6007376, 0.2, 0.20024796, 0.20018837]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9400 iterations: 2.4128090500831605 mins\n",
      "Train Loss: [0.6007376, 0.2, 0.20024796, 0.20018837]\n",
      "[0.60108125, 0.2, 0.20037399, 0.20040461]\n",
      "[0.60057145, 0.2, 0.20021027, 0.20005696]\n",
      "[0.60063726, 0.2, 0.20016967, 0.20016178]\n",
      "[0.600982, 0.2, 0.20033312, 0.20034158]\n",
      "[0.6007826, 0.2, 0.20019843, 0.20027585]\n",
      "[0.60095996, 0.2, 0.20048039, 0.20017055]\n",
      "[0.60065603, 0.2, 0.20032221, 0.20002417]\n",
      "[0.6006883, 0.2, 0.20029964, 0.20007837]\n",
      "[0.6006708, 0.2, 0.20011806, 0.20024209]\n",
      "[0.60075593, 0.2, 0.20016414, 0.20028071]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9410 iterations: 2.415284283955892 mins\n",
      "Train Loss: [0.60075593, 0.2, 0.20016414, 0.20028071]\n",
      "[0.60068786, 0.2, 0.20006464, 0.2003119]\n",
      "[0.6005139, 0.2, 0.20012939, 0.20007268]\n",
      "[0.6009827, 0.2, 0.20036489, 0.20030542]\n",
      "[0.6008297, 0.2, 0.20044628, 0.20007055]\n",
      "[0.6005361, 0.2, 0.2000567, 0.2001661]\n",
      "[0.6008443, 0.2, 0.20038828, 0.20014204]\n",
      "[0.6006293, 0.2, 0.20024857, 0.20006613]\n",
      "[0.6006049, 0.2, 0.20010039, 0.2001893]\n",
      "[0.6005204, 0.2, 0.20007427, 0.20013027]\n",
      "[0.6005397, 0.2, 0.2, 0.20022328]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9420 iterations: 2.41708798011144 mins\n",
      "Train Loss: [0.6005397, 0.2, 0.2, 0.20022328]\n",
      "[0.6006328, 0.2, 0.20014825, 0.20016764]\n",
      "[0.60055983, 0.2, 0.20014715, 0.20009537]\n",
      "[0.6008021, 0.2, 0.20023014, 0.20025435]\n",
      "[0.60076874, 0.2, 0.20016065, 0.20029052]\n",
      "[0.60062724, 0.2, 0.20009181, 0.20021805]\n",
      "[0.6007441, 0.2, 0.20015799, 0.20026904]\n",
      "[0.6008977, 0.2, 0.2002614, 0.20031947]\n",
      "[0.60059446, 0.2, 0.20013964, 0.2001383]\n",
      "[0.60062444, 0.2, 0.2001106, 0.20019755]\n",
      "[0.6005191, 0.2, 0.20016243, 0.20004065]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9430 iterations: 2.4191927671432496 mins\n",
      "Train Loss: [0.6005191, 0.2, 0.20016243, 0.20004065]\n",
      "[0.6009633, 0.2, 0.20011725, 0.20053035]\n",
      "[0.6005309, 0.2, 0.20014931, 0.20006649]\n",
      "[0.60046726, 0.2, 0.20005316, 0.20009984]\n",
      "[0.6005201, 0.2, 0.20008928, 0.20011751]\n",
      "[0.6006332, 0.2, 0.20005535, 0.20026563]\n",
      "[0.6006331, 0.2, 0.2001424, 0.20017958]\n",
      "[0.60067534, 0.2, 0.20013086, 0.20023464]\n",
      "[0.6006894, 0.2, 0.20022078, 0.20015989]\n",
      "[0.6005646, 0.2, 0.20015131, 0.20010562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6005774, 0.2, 0.20012905, 0.20014185]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9440 iterations: 2.421127963066101 mins\n",
      "Train Loss: [0.6005774, 0.2, 0.20012905, 0.20014185]\n",
      "[0.60062945, 0.2, 0.20014569, 0.20017849]\n",
      "[0.60076606, 0.2, 0.20019534, 0.20026687]\n",
      "[0.6005205, 0.2, 0.20006819, 0.2001501]\n",
      "[0.6005537, 0.2, 0.20009528, 0.20015772]\n",
      "[0.6008666, 0.2, 0.2003887, 0.20017852]\n",
      "[0.60086036, 0.2, 0.20034243, 0.20021953]\n",
      "[0.6010606, 0.2, 0.20017612, 0.2005869]\n",
      "[0.6005447, 0.2, 0.20007731, 0.20017025]\n",
      "[0.60072196, 0.2, 0.20021445, 0.20021066]\n",
      "[0.6005227, 0.2, 0.20011258, 0.2001133]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9450 iterations: 2.423042901357015 mins\n",
      "Train Loss: [0.6005227, 0.2, 0.20011258, 0.2001133]\n",
      "[0.6005644, 0.2, 0.20008983, 0.20017748]\n",
      "[0.6007267, 0.2, 0.20020853, 0.20022054]\n",
      "[0.6006908, 0.2, 0.20022416, 0.20016856]\n",
      "[0.6009634, 0.2, 0.20031823, 0.20034662]\n",
      "[0.6006633, 0.2, 0.20013231, 0.20023184]\n",
      "[0.6008922, 0.2, 0.2004173, 0.2001752]\n",
      "[0.6006697, 0.2, 0.20019107, 0.20017841]\n",
      "[0.600352, 0.2, 0.20000003, 0.20005138]\n",
      "[0.6005475, 0.2, 0.20018966, 0.20005701]\n",
      "[0.60070777, 0.2, 0.20015296, 0.200254]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9460 iterations: 2.4251949469248455 mins\n",
      "Train Loss: [0.60070777, 0.2, 0.20015296, 0.200254]\n",
      "[0.6003993, 0.2, 0.2000546, 0.2000444]\n",
      "[0.60064876, 0.2, 0.2002149, 0.20013402]\n",
      "[0.6005118, 0.2, 0.20006424, 0.20014863]\n",
      "[0.6008036, 0.2, 0.2002532, 0.20025237]\n",
      "[0.60046417, 0.2, 0.20007789, 0.20008942]\n",
      "[0.60062563, 0.2, 0.2001038, 0.20022593]\n",
      "[0.60064185, 0.2, 0.20007284, 0.20027411]\n",
      "[0.6005124, 0.2, 0.20016316, 0.20005523]\n",
      "[0.60044265, 0.2, 0.20009373, 0.20005603]\n",
      "[0.60057193, 0.2, 0.2000001, 0.20027992]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9470 iterations: 2.427169382572174 mins\n",
      "Train Loss: [0.60057193, 0.2, 0.2000001, 0.20027992]\n",
      "[0.6010401, 0.2, 0.20046322, 0.20028576]\n",
      "[0.6008251, 0.2, 0.2003583, 0.20017667]\n",
      "[0.60047734, 0.2, 0.20016317, 0.20002514]\n",
      "[0.6005654, 0.2, 0.20015107, 0.20012638]\n",
      "[0.60053456, 0.2, 0.20016916, 0.20007858]\n",
      "[0.6005338, 0.2, 0.20012458, 0.20012352]\n",
      "[0.60052526, 0.2, 0.20010331, 0.20013745]\n",
      "[0.6004152, 0.2, 0.2000555, 0.20007655]\n",
      "[0.60047096, 0.2, 0.20006444, 0.20012477]\n",
      "[0.60042185, 0.2, 0.20006762, 0.20007402]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9480 iterations: 2.429152250289917 mins\n",
      "Train Loss: [0.60042185, 0.2, 0.20006762, 0.20007402]\n",
      "[0.6004262, 0.2, 0.20009913, 0.20004836]\n",
      "[0.6004753, 0.2, 0.20006531, 0.20013277]\n",
      "[0.600464, 0.2, 0.20006949, 0.2001187]\n",
      "[0.6005365, 0.2, 0.20013635, 0.20012613]\n",
      "[0.60050046, 0.2, 0.20014855, 0.20007943]\n",
      "[0.600497, 0.2, 0.2001132, 0.20011286]\n",
      "[0.6005026, 0.2, 0.20014693, 0.20008624]\n",
      "[0.600573, 0.2, 0.20003462, 0.20027028]\n",
      "[0.6004484, 0.2, 0.20005049, 0.2001313]\n",
      "[0.6004123, 0.2, 0.20006736, 0.2000798]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9490 iterations: 2.431615630785624 mins\n",
      "Train Loss: [0.6004123, 0.2, 0.20006736, 0.2000798]\n",
      "[0.60058725, 0.2, 0.20022596, 0.2000973]\n",
      "[0.60035086, 0.2, 0.20007564, 0.20001264]\n",
      "[0.6004378, 0.2, 0.20005119, 0.20012547]\n",
      "[0.60050637, 0.2, 0.20019598, 0.20005046]\n",
      "[0.6004168, 0.2, 0.20008811, 0.2000701]\n",
      "[0.60041916, 0.2, 0.2000464, 0.20011559]\n",
      "[0.600475, 0.2, 0.20007716, 0.20014225]\n",
      "[0.6005034, 0.2, 0.2001474, 0.20010194]\n",
      "[0.6004371, 0.2, 0.200148, 0.20003681]\n",
      "[0.6005877, 0.2, 0.2001281, 0.200209]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9500 iterations: 2.433544647693634 mins\n",
      "Train Loss: [0.6005877, 0.2, 0.2001281, 0.200209]\n",
      "[0.60047203, 0.2, 0.2000934, 0.20012999]\n",
      "[0.600445, 0.2, 0.20008722, 0.20011105]\n",
      "[0.600455, 0.2, 0.20011108, 0.20009907]\n",
      "[0.60050744, 0.2, 0.20014206, 0.20012216]\n",
      "[0.60040283, 0.2, 0.20011814, 0.20004305]\n",
      "[0.60044444, 0.2, 0.20007126, 0.2001331]\n",
      "[0.6002982, 0.2, 0.20000003, 0.20005973]\n",
      "[0.6004157, 0.2, 0.20009084, 0.20008789]\n",
      "[0.6003956, 0.2, 0.20007853, 0.20008156]\n",
      "[0.60034144, 0.2, 0.20007604, 0.20003141]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9510 iterations: 2.4355156660079955 mins\n",
      "Train Loss: [0.60034144, 0.2, 0.20007604, 0.20003141]\n",
      "[0.6005805, 0.2, 0.20028311, 0.20006475]\n",
      "[0.60049707, 0.2, 0.20012726, 0.20013891]\n",
      "[0.60068333, 0.2, 0.20013548, 0.20031841]\n",
      "[0.60039705, 0.2, 0.20002826, 0.20014085]\n",
      "[0.60062814, 0.2, 0.20027405, 0.20012735]\n",
      "[0.6005052, 0.2, 0.20019135, 0.2000879]\n",
      "[0.6006486, 0.2, 0.20019928, 0.20022418]\n",
      "[0.6005408, 0.2, 0.20009305, 0.20022336]\n",
      "[0.6006433, 0.2, 0.20030081, 0.20011836]\n",
      "[0.6005256, 0.2, 0.20005274, 0.20024896]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9520 iterations: 2.437379066149394 mins\n",
      "Train Loss: [0.6005256, 0.2, 0.20005274, 0.20024896]\n",
      "[0.6005802, 0.2, 0.20013806, 0.20021819]\n",
      "[0.6004261, 0.2, 0.20006038, 0.20014158]\n",
      "[0.6004409, 0.2, 0.20005311, 0.2001632]\n",
      "[0.6005919, 0.2, 0.2001007, 0.20026582]\n",
      "[0.6004, 0.2, 0.20007941, 0.20009442]\n",
      "[0.600505, 0.2, 0.2001724, 0.20010537]\n",
      "[0.6005718, 0.2, 0.2000868, 0.20025651]\n",
      "[0.6005008, 0.2, 0.2000988, 0.20017259]\n",
      "[0.60046226, 0.2, 0.20013481, 0.20009664]\n",
      "[0.60056186, 0.2, 0.20016856, 0.20016097]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9530 iterations: 2.439461568991343 mins\n",
      "Train Loss: [0.60056186, 0.2, 0.20016856, 0.20016097]\n",
      "[0.60054696, 0.2, 0.2, 0.20031326]\n",
      "[0.6005408, 0.2, 0.20013243, 0.2001735]\n",
      "[0.60041326, 0.2, 0.2000667, 0.2001103]\n",
      "[0.60040575, 0.2, 0.20010054, 0.20006755]\n",
      "[0.6005739, 0.2, 0.20013359, 0.20020132]\n",
      "[0.600785, 0.2, 0.20029472, 0.20025103]\n",
      "[0.6004402, 0.2, 0.20006883, 0.20013195]\n",
      "[0.60043144, 0.2, 0.2001383, 0.20005362]\n",
      "[0.6006131, 0.2, 0.20022385, 0.20014994]\n",
      "[0.6004862, 0.2, 0.20009609, 0.2001513]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9540 iterations: 2.44131730000178 mins\n",
      "Train Loss: [0.6004862, 0.2, 0.20009609, 0.2001513]\n",
      "[0.60034937, 0.2, 0.20007415, 0.20003678]\n",
      "[0.60032475, 0.2, 0.20002688, 0.20005998]\n",
      "[0.60046417, 0.2, 0.20005819, 0.20016874]\n",
      "[0.6003766, 0.2, 0.20003264, 0.20010757]\n",
      "[0.6006887, 0.2, 0.20017324, 0.20027994]\n",
      "[0.60069966, 0.2, 0.20019111, 0.20027386]\n",
      "[0.6004793, 0.2, 0.20016022, 0.20008545]\n",
      "[0.6005793, 0.2, 0.20011173, 0.20023474]\n",
      "[0.60050756, 0.2, 0.20009299, 0.20018232]\n",
      "[0.6004185, 0.2, 0.20007516, 0.20011152]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9550 iterations: 2.4434244632720947 mins\n",
      "Train Loss: [0.6004185, 0.2, 0.20007516, 0.20011152]\n",
      "[0.60060555, 0.2, 0.20021826, 0.2001557]\n",
      "[0.600591, 0.2, 0.20016299, 0.20019682]\n",
      "[0.6003629, 0.2, 0.2000679, 0.2000641]\n",
      "[0.60046405, 0.2, 0.20014788, 0.20008558]\n",
      "[0.6004684, 0.2, 0.2001683, 0.20006984]\n",
      "[0.6003362, 0.2, 0.20004833, 0.20005804]\n",
      "[0.60048217, 0.2, 0.20018996, 0.20006262]\n",
      "[0.6004388, 0.2, 0.20010138, 0.20010804]\n",
      "[0.600663, 0.2, 0.20011899, 0.20031473]\n",
      "[0.6007743, 0.2, 0.20010816, 0.20043716]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9560 iterations: 2.4453083793322246 mins\n",
      "Train Loss: [0.6007743, 0.2, 0.20010816, 0.20043716]\n",
      "[0.60063523, 0.2, 0.20022121, 0.20018536]\n",
      "[0.6005501, 0.2, 0.2000723, 0.20024961]\n",
      "[0.60041094, 0.2, 0.20012924, 0.20005389]\n",
      "[0.60086673, 0.2, 0.20025627, 0.20038328]\n",
      "[0.60037035, 0.2, 0.2000659, 0.20007844]\n",
      "[0.6005044, 0.2, 0.20017818, 0.20010118]\n",
      "[0.600407, 0.2, 0.20011404, 0.20006894]\n",
      "[0.60025954, 0.2, 0.2, 0.20003666]\n",
      "[0.60038066, 0.2, 0.20011209, 0.2000468]\n",
      "[0.60040915, 0.2, 0.20016108, 0.20002748]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9570 iterations: 2.447825781504313 mins\n",
      "Train Loss: [0.60040915, 0.2, 0.20016108, 0.20002748]\n",
      "[0.60038364, 0.2, 0.20006458, 0.20009974]\n",
      "[0.60030943, 0.2, 0.20004417, 0.20004712]\n",
      "[0.6004574, 0.2, 0.20012909, 0.20011124]\n",
      "[0.60048777, 0.2, 0.2001459, 0.20012616]\n",
      "[0.600465, 0.2, 0.2001305, 0.20011966]\n",
      "[0.6006033, 0.2, 0.20017473, 0.20021437]\n",
      "[0.600764, 0.2, 0.20028429, 0.20026602]\n",
      "[0.60044277, 0.2, 0.20017876, 0.20005096]\n",
      "[0.6005258, 0.2, 0.20008661, 0.2002264]\n",
      "[0.60053235, 0.2, 0.20017627, 0.2001434]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9580 iterations: 2.4498411337534587 mins\n",
      "Train Loss: [0.60053235, 0.2, 0.20017627, 0.2001434]\n",
      "[0.60051554, 0.2, 0.20024732, 0.20005563]\n",
      "[0.600915, 0.2, 0.20013689, 0.20056531]\n",
      "[0.600417, 0.2, 0.20007329, 0.2001302]\n",
      "[0.60051584, 0.2, 0.20011413, 0.20018655]\n",
      "[0.60051554, 0.2, 0.20013459, 0.20016366]\n",
      "[0.6006194, 0.2, 0.20018329, 0.2002163]\n",
      "[0.60064214, 0.2, 0.2001715, 0.20024785]\n",
      "[0.600372, 0.2, 0.2001133, 0.20003262]\n",
      "[0.6005892, 0.2, 0.20016536, 0.20019402]\n",
      "[0.600585, 0.2, 0.20025316, 0.20009804]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9590 iterations: 2.451673467954 mins\n",
      "Train Loss: [0.600585, 0.2, 0.20025316, 0.20009804]\n",
      "[0.6004409, 0.2, 0.2001143, 0.20008904]\n",
      "[0.6006233, 0.2, 0.20017886, 0.20020308]\n",
      "[0.60073715, 0.2, 0.20018394, 0.20030797]\n",
      "[0.6005133, 0.2, 0.20011394, 0.20015013]\n",
      "[0.60070753, 0.2, 0.20027491, 0.20017913]\n",
      "[0.6006754, 0.2, 0.20006244, 0.20035568]\n",
      "[0.6005178, 0.2, 0.20021184, 0.20004517]\n",
      "[0.6005274, 0.2, 0.20018327, 0.20008004]\n",
      "[0.60063535, 0.2, 0.20016491, 0.20020308]\n",
      "[0.6005495, 0.2, 0.20015375, 0.20012566]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9600 iterations: 2.453706514835358 mins\n",
      "Train Loss: [0.6005495, 0.2, 0.20015375, 0.20012566]\n",
      "[0.60065347, 0.2, 0.20013052, 0.20025031]\n",
      "[0.6004384, 0.2, 0.20010506, 0.20005883]\n",
      "[0.60086113, 0.2, 0.20028907, 0.20029575]\n",
      "[0.6005161, 0.2, 0.20012273, 0.20011587]\n",
      "[0.6009746, 0.2, 0.2004175, 0.20027877]\n",
      "[0.6007362, 0.2, 0.20036197, 0.20009562]\n",
      "[0.600632, 0.2, 0.20023972, 0.20011328]\n",
      "[0.60062736, 0.2, 0.2000998, 0.2002482]\n",
      "[0.60064435, 0.2, 0.20012061, 0.20024398]\n",
      "[0.60065264, 0.2, 0.20018597, 0.20018674]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9610 iterations: 2.4555885990460715 mins\n",
      "Train Loss: [0.60065264, 0.2, 0.20018597, 0.20018674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6005186, 0.2, 0.20011666, 0.20012175]\n",
      "[0.6005933, 0.2, 0.20021781, 0.20009513]\n",
      "[0.6007904, 0.2, 0.2004448, 0.20006499]\n",
      "[0.60093784, 0.2, 0.20018752, 0.20047037]\n",
      "[0.60049605, 0.2, 0.20013328, 0.2000836]\n",
      "[0.6007725, 0.2, 0.20016353, 0.20032986]\n",
      "[0.60081625, 0.2, 0.20020664, 0.20033005]\n",
      "[0.6004314, 0.2, 0.20007756, 0.20007402]\n",
      "[0.6003706, 0.2, 0.20006925, 0.2000211]\n",
      "[0.60076123, 0.2, 0.20031449, 0.20016599]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9620 iterations: 2.4577529350916545 mins\n",
      "Train Loss: [0.60076123, 0.2, 0.20031449, 0.20016599]\n",
      "[0.60078204, 0.2, 0.20019002, 0.20031136]\n",
      "[0.60066074, 0.2, 0.20028163, 0.2000989]\n",
      "[0.60077536, 0.2, 0.20033011, 0.2001657]\n",
      "[0.6006381, 0.2, 0.2001666, 0.20019281]\n",
      "[0.6010373, 0.2, 0.20037404, 0.20038547]\n",
      "[0.6008983, 0.2, 0.2004497, 0.20017189]\n",
      "[0.60114145, 0.2, 0.20027022, 0.2005955]\n",
      "[0.6011685, 0.2, 0.20032819, 0.20056514]\n",
      "[0.6008993, 0.2, 0.20018683, 0.20043752]\n",
      "[0.60066915, 0.2, 0.20015655, 0.20023711]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9630 iterations: 2.459856832027435 mins\n",
      "Train Loss: [0.60066915, 0.2, 0.20015655, 0.20023711]\n",
      "[0.6006899, 0.2, 0.20012842, 0.20028496]\n",
      "[0.60059035, 0.2, 0.20026149, 0.20005113]\n",
      "[0.6009869, 0.2, 0.20033231, 0.20037518]\n",
      "[0.6007071, 0.2, 0.20027837, 0.20014822]\n",
      "[0.60089713, 0.2, 0.20021066, 0.20040466]\n",
      "[0.60069823, 0.2, 0.20027193, 0.20014296]\n",
      "[0.6005099, 0.2, 0.20013072, 0.20009424]\n",
      "[0.6005005, 0.2, 0.20017742, 0.20003602]\n",
      "[0.6007699, 0.2, 0.20023191, 0.2002481]\n",
      "[0.6006924, 0.2, 0.20030983, 0.20008963]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9640 iterations: 2.4617316802342732 mins\n",
      "Train Loss: [0.6006924, 0.2, 0.20030983, 0.20008963]\n",
      "[0.60063493, 0.2, 0.2002183, 0.20012034]\n",
      "[0.6005635, 0.2, 0.2000819, 0.20018183]\n",
      "[0.60074025, 0.2, 0.20014614, 0.20029065]\n",
      "[0.6007957, 0.2, 0.20026568, 0.20022315]\n",
      "[0.6007865, 0.2, 0.20024386, 0.20023268]\n",
      "[0.60064155, 0.2, 0.2001661, 0.20016257]\n",
      "[0.60067236, 0.2, 0.20020205, 0.20015481]\n",
      "[0.6011384, 0.2, 0.20019872, 0.20062153]\n",
      "[0.6009093, 0.2, 0.20035733, 0.20023195]\n",
      "[0.6011143, 0.2, 0.20015235, 0.20064029]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9650 iterations: 2.464395566781362 mins\n",
      "Train Loss: [0.6011143, 0.2, 0.20015235, 0.20064029]\n",
      "[0.60078645, 0.2, 0.2001356, 0.20032787]\n",
      "[0.6005608, 0.2, 0.20016602, 0.20007074]\n",
      "[0.60090905, 0.2, 0.20033994, 0.2002442]\n",
      "[0.60067654, 0.2, 0.20021895, 0.20013207]\n",
      "[0.60098636, 0.2, 0.20020777, 0.2004528]\n",
      "[0.6008461, 0.2, 0.20012859, 0.20039193]\n",
      "[0.60071796, 0.2, 0.20024288, 0.20014976]\n",
      "[0.60086936, 0.2, 0.20038888, 0.20015535]\n",
      "[0.6011887, 0.2, 0.20066628, 0.20019764]\n",
      "[0.6006141, 0.2, 0.20013303, 0.20015633]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9660 iterations: 2.467463000615438 mins\n",
      "Train Loss: [0.6006141, 0.2, 0.20013303, 0.20015633]\n",
      "[0.60070974, 0.2, 0.20020302, 0.20018178]\n",
      "[0.60065866, 0.2, 0.2001197, 0.20021369]\n",
      "[0.60073555, 0.2, 0.20025961, 0.20014971]\n",
      "[0.6006868, 0.2, 0.20010696, 0.20025226]\n",
      "[0.60088205, 0.2, 0.20018333, 0.20036948]\n",
      "[0.60052484, 0.2, 0.20000014, 0.20019382]\n",
      "[0.6012579, 0.2, 0.20056723, 0.20035803]\n",
      "[0.60072726, 0.2, 0.20022708, 0.20016581]\n",
      "[0.60134363, 0.2, 0.2005218, 0.20048554]\n",
      "[0.6007582, 0.2, 0.20017359, 0.20024633]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9670 iterations: 2.469387499491374 mins\n",
      "Train Loss: [0.6007582, 0.2, 0.20017359, 0.20024633]\n",
      "[0.6008321, 0.2, 0.20044859, 0.20004305]\n",
      "[0.60048896, 0.2, 0.20009626, 0.20005022]\n",
      "[0.6009908, 0.2, 0.20045145, 0.2001949]\n",
      "[0.60065997, 0.2, 0.20019981, 0.20011438]\n",
      "[0.6009198, 0.2, 0.20011683, 0.20045596]\n",
      "[0.6006165, 0.2, 0.20015667, 0.20011218]\n",
      "[0.60072625, 0.2, 0.20017022, 0.20020787]\n",
      "[0.6011197, 0.2, 0.20018575, 0.20058553]\n",
      "[0.6007113, 0.2, 0.20018852, 0.20017461]\n",
      "[0.6009251, 0.2, 0.20029436, 0.20028323]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9680 iterations: 2.4713939666748046 mins\n",
      "Train Loss: [0.6009251, 0.2, 0.20029436, 0.20028323]\n",
      "[0.60053337, 0.2, 0.20007595, 0.20011087]\n",
      "[0.6006383, 0.2, 0.2002009, 0.20009197]\n",
      "[0.60075223, 0.2, 0.20013767, 0.20027049]\n",
      "[0.60069025, 0.2, 0.20029305, 0.20005481]\n",
      "[0.6010228, 0.2, 0.2004197, 0.2002627]\n",
      "[0.6008726, 0.2, 0.20010054, 0.20043385]\n",
      "[0.6008022, 0.2, 0.2001648, 0.20030133]\n",
      "[0.6006736, 0.2, 0.20012456, 0.2002151]\n",
      "[0.60108095, 0.2, 0.20046829, 0.2002806]\n",
      "[0.60109866, 0.2, 0.20048016, 0.20028812]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9690 iterations: 2.473225482304891 mins\n",
      "Train Loss: [0.60109866, 0.2, 0.20048016, 0.20028812]\n",
      "[0.6008776, 0.2, 0.20015025, 0.20039839]\n",
      "[0.60036564, 0.2, 0.20000726, 0.20003052]\n",
      "[0.60065144, 0.2, 0.20023853, 0.20008591]\n",
      "[0.6005468, 0.2, 0.20010139, 0.20011914]\n",
      "[0.600998, 0.2, 0.20013781, 0.2005347]\n",
      "[0.60065734, 0.2, 0.20018548, 0.2001471]\n",
      "[0.6007748, 0.2, 0.20010422, 0.20034619]\n",
      "[0.6008955, 0.2, 0.20042394, 0.20014761]\n",
      "[0.6007238, 0.2, 0.20004064, 0.20035934]\n",
      "[0.6007952, 0.2, 0.20036234, 0.20010881]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9700 iterations: 2.475270398457845 mins\n",
      "Train Loss: [0.6007952, 0.2, 0.20036234, 0.20010881]\n",
      "[0.600688, 0.2, 0.20020182, 0.20016123]\n",
      "[0.60079324, 0.2, 0.2002214, 0.20024566]\n",
      "[0.60105306, 0.2, 0.20043528, 0.20029016]\n",
      "[0.6005951, 0.2, 0.20006134, 0.20020497]\n",
      "[0.60078746, 0.2, 0.20023039, 0.20022708]\n",
      "[0.60113597, 0.2, 0.2005557, 0.20024894]\n",
      "[0.6004914, 0.2, 0.20005901, 0.20009983]\n",
      "[0.6005192, 0.2, 0.20011757, 0.20006813]\n",
      "[0.60064715, 0.2, 0.20018652, 0.20012635]\n",
      "[0.6006898, 0.2, 0.20016302, 0.2001921]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9710 iterations: 2.4771382490793865 mins\n",
      "Train Loss: [0.6006898, 0.2, 0.20016302, 0.2001921]\n",
      "[0.6005714, 0.2, 0.20010877, 0.2001277]\n",
      "[0.60054046, 0.2, 0.20009892, 0.20010664]\n",
      "[0.6006492, 0.2, 0.20019558, 0.20011896]\n",
      "[0.60045797, 0.2, 0.20008405, 0.20003991]\n",
      "[0.60069114, 0.2, 0.2002794, 0.20007859]\n",
      "[0.6006969, 0.2, 0.20021665, 0.20014817]\n",
      "[0.6006951, 0.2, 0.20012994, 0.20023412]\n",
      "[0.60074484, 0.2, 0.20017655, 0.20023867]\n",
      "[0.6006763, 0.2, 0.20014362, 0.20020467]\n",
      "[0.6006938, 0.2, 0.20008874, 0.20027882]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9720 iterations: 2.479056433836619 mins\n",
      "Train Loss: [0.6006938, 0.2, 0.20008874, 0.20027882]\n",
      "[0.6008276, 0.2, 0.20014799, 0.20035525]\n",
      "[0.6005698, 0.2, 0.2000727, 0.20017485]\n",
      "[0.60059434, 0.2, 0.20016474, 0.20010944]\n",
      "[0.6004246, 0.2, 0.2000408, 0.20006552]\n",
      "[0.6007925, 0.2, 0.20037673, 0.20009942]\n",
      "[0.6007512, 0.2, 0.20014091, 0.2002958]\n",
      "[0.60054654, 0.2, 0.20015812, 0.20007564]\n",
      "[0.60063636, 0.2, 0.20020297, 0.20012233]\n",
      "[0.6005316, 0.2, 0.20010385, 0.20011844]\n",
      "[0.6005102, 0.2, 0.20008916, 0.2001137]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9730 iterations: 2.481593382358551 mins\n",
      "Train Loss: [0.6005102, 0.2, 0.20008916, 0.2001137]\n",
      "[0.6004813, 0.2, 0.20008561, 0.20009033]\n",
      "[0.6006515, 0.2, 0.20010693, 0.20024127]\n",
      "[0.60057825, 0.2, 0.20014696, 0.20013018]\n",
      "[0.6006941, 0.2, 0.20011482, 0.20028041]\n",
      "[0.6005152, 0.2, 0.20012555, 0.20009294]\n",
      "[0.60056704, 0.2, 0.20009957, 0.20017283]\n",
      "[0.6006415, 0.2, 0.20029886, 0.20004983]\n",
      "[0.6007689, 0.2, 0.20010269, 0.20037502]\n",
      "[0.60065645, 0.2, 0.20002848, 0.20033853]\n",
      "[0.60045695, 0.2, 0.20008779, 0.20008147]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9740 iterations: 2.483392131328583 mins\n",
      "Train Loss: [0.60045695, 0.2, 0.20008779, 0.20008147]\n",
      "[0.60077137, 0.2, 0.2004015, 0.20008378]\n",
      "[0.60070205, 0.2, 0.20027256, 0.20014547]\n",
      "[0.6006268, 0.2, 0.20008397, 0.20026074]\n",
      "[0.6005261, 0.2, 0.20009744, 0.20014834]\n",
      "[0.60057056, 0.2, 0.20010084, 0.20019108]\n",
      "[0.6005034, 0.2, 0.20007192, 0.20015441]\n",
      "[0.6005722, 0.2, 0.20024598, 0.20005094]\n",
      "[0.600502, 0.2, 0.20007508, 0.20015316]\n",
      "[0.6004741, 0.2, 0.200067, 0.20013489]\n",
      "[0.6007657, 0.2, 0.20039308, 0.20010169]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9750 iterations: 2.485469981034597 mins\n",
      "Train Loss: [0.6007657, 0.2, 0.20039308, 0.20010169]\n",
      "[0.60088813, 0.2, 0.20039786, 0.2002204]\n",
      "[0.60061616, 0.2, 0.20020908, 0.20013829]\n",
      "[0.6006551, 0.2, 0.20022233, 0.20016502]\n",
      "[0.6005901, 0.2, 0.20025708, 0.20006648]\n",
      "[0.60068727, 0.2, 0.20032021, 0.20010154]\n",
      "[0.600491, 0.2, 0.20016585, 0.20006056]\n",
      "[0.60046494, 0.2, 0.20011392, 0.20008722]\n",
      "[0.60056186, 0.2, 0.2001873, 0.20011158]\n",
      "[0.60063666, 0.2, 0.20014903, 0.20022567]\n",
      "[0.60069, 0.2, 0.20015445, 0.20027433]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9760 iterations: 2.4873770475387573 mins\n",
      "Train Loss: [0.60069, 0.2, 0.20015445, 0.20027433]\n",
      "[0.6006491, 0.2, 0.20019008, 0.20019832]\n",
      "[0.6006966, 0.2, 0.20008552, 0.20035085]\n",
      "[0.60048664, 0.2, 0.20007984, 0.20014673]\n",
      "[0.6005286, 0.2, 0.20006555, 0.20020272]\n",
      "[0.6005666, 0.2, 0.2000642, 0.20024154]\n",
      "[0.6007516, 0.2, 0.20023514, 0.20025484]\n",
      "[0.60079074, 0.2, 0.20023778, 0.2002905]\n",
      "[0.60043734, 0.2, 0.20000002, 0.2001739]\n",
      "[0.6005613, 0.2, 0.20012394, 0.20017295]\n",
      "[0.6006627, 0.2, 0.20012343, 0.20027392]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9770 iterations: 2.4894230484962465 mins\n",
      "Train Loss: [0.6006627, 0.2, 0.20012343, 0.20027392]\n",
      "[0.60053617, 0.2, 0.20017865, 0.20009129]\n",
      "[0.6004596, 0.2, 0.20008235, 0.20011018]\n",
      "[0.60061526, 0.2, 0.20023705, 0.20011029]\n",
      "[0.6004525, 0.2, 0.20011167, 0.20007217]\n",
      "[0.600465, 0.2, 0.20000005, 0.20019594]\n",
      "[0.60063297, 0.2, 0.20021577, 0.20014787]\n",
      "[0.60046184, 0.2, 0.20006806, 0.20012441]\n",
      "[0.60060966, 0.2, 0.20009542, 0.200245]\n",
      "[0.6005099, 0.2, 0.20017163, 0.20006923]\n",
      "[0.60072273, 0.2, 0.20028406, 0.2001703]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9780 iterations: 2.491269115606944 mins\n",
      "Train Loss: [0.60072273, 0.2, 0.20028406, 0.2001703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6005216, 0.2, 0.20002924, 0.20022486]\n",
      "[0.60034996, 0.2, 0.20005368, 0.20002986]\n",
      "[0.6003726, 0.2, 0.20005426, 0.20005304]\n",
      "[0.6004389, 0.2, 0.20004264, 0.20013216]\n",
      "[0.6006241, 0.2, 0.20012265, 0.20023885]\n",
      "[0.6005111, 0.2, 0.20004474, 0.20020542]\n",
      "[0.60051477, 0.2, 0.20021476, 0.20004079]\n",
      "[0.60047334, 0.2, 0.20012999, 0.20008573]\n",
      "[0.6006519, 0.2, 0.20018409, 0.20021163]\n",
      "[0.60050434, 0.2, 0.20008992, 0.20015979]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9790 iterations: 2.4934011181195577 mins\n",
      "Train Loss: [0.60050434, 0.2, 0.20008992, 0.20015979]\n",
      "[0.6005099, 0.2, 0.2001769, 0.20007975]\n",
      "[0.60055625, 0.2, 0.20012529, 0.20017892]\n",
      "[0.60037637, 0.2, 0.2000434, 0.2000822]\n",
      "[0.60085267, 0.2, 0.200347, 0.20025614]\n",
      "[0.60069424, 0.2, 0.20013657, 0.20030947]\n",
      "[0.6005321, 0.2, 0.20024101, 0.20004424]\n",
      "[0.60067207, 0.2, 0.20013101, 0.20029537]\n",
      "[0.6004135, 0.2, 0.2001159, 0.20005307]\n",
      "[0.60049313, 0.2, 0.20012517, 0.20012444]\n",
      "[0.6005075, 0.2, 0.20007694, 0.20018809]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9800 iterations: 2.495442569255829 mins\n",
      "Train Loss: [0.6005075, 0.2, 0.20007694, 0.20018809]\n",
      "[0.60053444, 0.2, 0.20016694, 0.2001259]\n",
      "[0.60071874, 0.2, 0.20021632, 0.2002615]\n",
      "[0.6005134, 0.2, 0.20016445, 0.20010872]\n",
      "[0.60072064, 0.2, 0.20010506, 0.20037581]\n",
      "[0.6008061, 0.2, 0.20036176, 0.20020509]\n",
      "[0.6006367, 0.2, 0.20018947, 0.20020857]\n",
      "[0.6007736, 0.2, 0.20026618, 0.20026936]\n",
      "[0.60048866, 0.2, 0.20012124, 0.20013009]\n",
      "[0.6004055, 0.2, 0.20009492, 0.20007376]\n",
      "[0.600346, 0.2, 0.20008233, 0.20002724]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9810 iterations: 2.497952568531036 mins\n",
      "Train Loss: [0.600346, 0.2, 0.20008233, 0.20002724]\n",
      "[0.6002884, 0.2, 0.20002402, 0.20002808]\n",
      "[0.6004271, 0.2, 0.20016551, 0.20002548]\n",
      "[0.6002994, 0.2, 0.20003483, 0.20002873]\n",
      "[0.60053736, 0.2, 0.20011556, 0.20018625]\n",
      "[0.6005418, 0.2, 0.2001545, 0.20015226]\n",
      "[0.60044533, 0.2, 0.20002642, 0.20018464]\n",
      "[0.6004658, 0.2, 0.20010602, 0.20012638]\n",
      "[0.60034066, 0.2, 0.2000737, 0.20003445]\n",
      "[0.6006714, 0.2, 0.20013615, 0.20030364]\n",
      "[0.6003047, 0.2, 0.20004535, 0.20002891]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9820 iterations: 2.499965262413025 mins\n",
      "Train Loss: [0.6003047, 0.2, 0.20004535, 0.20002891]\n",
      "[0.6004205, 0.2, 0.2000559, 0.20013511]\n",
      "[0.6005676, 0.2, 0.20013388, 0.20020533]\n",
      "[0.6004212, 0.2, 0.20002504, 0.20016886]\n",
      "[0.60029525, 0.2, 0.20005037, 0.20001863]\n",
      "[0.6004958, 0.2, 0.20014533, 0.20012508]\n",
      "[0.6006107, 0.2, 0.20013592, 0.20025018]\n",
      "[0.60039836, 0.2, 0.20007345, 0.20010123]\n",
      "[0.600583, 0.2, 0.20024462, 0.2001156]\n",
      "[0.6004357, 0.2, 0.20006958, 0.2001442]\n",
      "[0.6003672, 0.2, 0.20008688, 0.20005915]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9830 iterations: 2.501851733525594 mins\n",
      "Train Loss: [0.6003672, 0.2, 0.20008688, 0.20005915]\n",
      "[0.6005398, 0.2, 0.2002796, 0.20003968]\n",
      "[0.60090196, 0.2, 0.20035395, 0.20032781]\n",
      "[0.60071087, 0.2, 0.2002652, 0.20022587]\n",
      "[0.6004872, 0.2, 0.20018846, 0.20007947]\n",
      "[0.600489, 0.2, 0.20009425, 0.20017566]\n",
      "[0.60061747, 0.2, 0.20031954, 0.20007885]\n",
      "[0.60073286, 0.2, 0.20030963, 0.20020407]\n",
      "[0.60035825, 0.2, 0.20008847, 0.2000506]\n",
      "[0.60040176, 0.2, 0.2001577, 0.20002486]\n",
      "[0.6005854, 0.2, 0.20025702, 0.20010905]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9840 iterations: 2.5038564999898276 mins\n",
      "Train Loss: [0.6005854, 0.2, 0.20025702, 0.20010905]\n",
      "[0.6004144, 0.2, 0.20011446, 0.2000806]\n",
      "[0.60028726, 0.2, 0.20004587, 0.20002201]\n",
      "[0.60041493, 0.2, 0.2001476, 0.20004787]\n",
      "[0.60060877, 0.2, 0.20032415, 0.20006493]\n",
      "[0.60072505, 0.2, 0.2000965, 0.20040889]\n",
      "[0.6007369, 0.2, 0.20010544, 0.2004118]\n",
      "[0.6003818, 0.2, 0.20004258, 0.2001197]\n",
      "[0.6004766, 0.2, 0.20000017, 0.20025688]\n",
      "[0.6005699, 0.2, 0.20014687, 0.20020331]\n",
      "[0.60057366, 0.2, 0.20030108, 0.20005275]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9850 iterations: 2.5057535489400227 mins\n",
      "Train Loss: [0.60057366, 0.2, 0.20030108, 0.20005275]\n",
      "[0.60040146, 0.2, 0.20010354, 0.20007792]\n",
      "[0.60054785, 0.2, 0.20018695, 0.20014073]\n",
      "[0.60062754, 0.2, 0.20023891, 0.20016824]\n",
      "[0.6004607, 0.2, 0.2001149, 0.20012549]\n",
      "[0.6003787, 0.2, 0.20005654, 0.20010172]\n",
      "[0.6002931, 0.2, 0.20003645, 0.20003615]\n",
      "[0.60038775, 0.2, 0.20005691, 0.20011036]\n",
      "[0.60060406, 0.2, 0.20031749, 0.20006618]\n",
      "[0.60050625, 0.2, 0.20005174, 0.2002344]\n",
      "[0.6005723, 0.2, 0.2002651, 0.20008744]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9860 iterations: 2.5077228506406146 mins\n",
      "Train Loss: [0.6005723, 0.2, 0.2002651, 0.20008744]\n",
      "[0.60035354, 0.2, 0.2000403, 0.20009409]\n",
      "[0.60043114, 0.2, 0.20015359, 0.20005898]\n",
      "[0.6005108, 0.2, 0.2001854, 0.20010747]\n",
      "[0.6004929, 0.2, 0.2001389, 0.20013686]\n",
      "[0.6008615, 0.2, 0.20028317, 0.2003621]\n",
      "[0.6005093, 0.2, 0.20005696, 0.20023692]\n",
      "[0.6004141, 0.2, 0.20014416, 0.20005533]\n",
      "[0.6005358, 0.2, 0.20010641, 0.20021515]\n",
      "[0.6004858, 0.2, 0.2001341, 0.20013766]\n",
      "[0.60070264, 0.2, 0.20014621, 0.2003423]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9870 iterations: 2.509760399659475 mins\n",
      "Train Loss: [0.60070264, 0.2, 0.20014621, 0.2003423]\n",
      "[0.6009863, 0.2, 0.20043774, 0.20033419]\n",
      "[0.60053855, 0.2, 0.20007879, 0.20024498]\n",
      "[0.6006264, 0.2, 0.20032778, 0.20008321]\n",
      "[0.60049313, 0.2, 0.20007773, 0.20019916]\n",
      "[0.60044754, 0.2, 0.20011894, 0.20011108]\n",
      "[0.60039085, 0.2, 0.2000367, 0.20013507]\n",
      "[0.600719, 0.2, 0.20032093, 0.20017704]\n",
      "[0.600375, 0.2, 0.20004694, 0.2001051]\n",
      "[0.60046655, 0.2, 0.20009491, 0.20014678]\n",
      "[0.60036623, 0.2, 0.20006408, 0.20007555]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9880 iterations: 2.511656200885773 mins\n",
      "Train Loss: [0.60036623, 0.2, 0.20006408, 0.20007555]\n",
      "[0.60051686, 0.2, 0.20013544, 0.20015314]\n",
      "[0.60041726, 0.2, 0.20015305, 0.20003462]\n",
      "[0.6004146, 0.2, 0.20007372, 0.20011005]\n",
      "[0.6003344, 0.2, 0.20004955, 0.20005292]\n",
      "[0.600523, 0.2, 0.20010014, 0.2001901]\n",
      "[0.6004376, 0.2, 0.20013145, 0.20007282]\n",
      "[0.60049224, 0.2, 0.20001401, 0.20024458]\n",
      "[0.6003801, 0.2, 0.20005861, 0.20008764]\n",
      "[0.6005993, 0.2, 0.20014323, 0.20022213]\n",
      "[0.60049284, 0.2, 0.20023084, 0.20002817]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9890 iterations: 2.514188464482625 mins\n",
      "Train Loss: [0.60049284, 0.2, 0.20023084, 0.20002817]\n",
      "[0.6006152, 0.2, 0.20015089, 0.20023063]\n",
      "[0.60065997, 0.2, 0.20018649, 0.20023999]\n",
      "[0.6008526, 0.2, 0.2001052, 0.20051423]\n",
      "[0.6005624, 0.2, 0.20014177, 0.20018816]\n",
      "[0.600523, 0.2, 0.20017923, 0.20011193]\n",
      "[0.60063183, 0.2, 0.20012505, 0.20027533]\n",
      "[0.60056627, 0.2, 0.20009375, 0.20024134]\n",
      "[0.600646, 0.2, 0.20023139, 0.20018356]\n",
      "[0.60064834, 0.2, 0.20014119, 0.20027603]\n",
      "[0.60183805, 0.2, 0.20021784, 0.2013889]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9900 iterations: 2.516053732236226 mins\n",
      "Train Loss: [0.60183805, 0.2, 0.20021784, 0.2013889]\n",
      "[0.60062784, 0.2, 0.20023945, 0.20015655]\n",
      "[0.6013254, 0.2, 0.20062643, 0.20046642]\n",
      "[0.60068953, 0.2, 0.2003724, 0.20008323]\n",
      "[0.6007539, 0.2, 0.20025468, 0.20026372]\n",
      "[0.60062665, 0.2, 0.20011467, 0.20027454]\n",
      "[0.60051304, 0.2, 0.20007838, 0.2001951]\n",
      "[0.6017518, 0.2, 0.20077841, 0.20073164]\n",
      "[0.60098183, 0.2, 0.20052095, 0.20021687]\n",
      "[0.6009312, 0.2, 0.20048633, 0.2001983]\n",
      "[0.6005832, 0.2, 0.20013659, 0.20019741]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9910 iterations: 2.518092699845632 mins\n",
      "Train Loss: [0.6005832, 0.2, 0.20013659, 0.20019741]\n",
      "[0.60057235, 0.2, 0.20011051, 0.2002099]\n",
      "[0.60049397, 0.2, 0.20011301, 0.2001265]\n",
      "[0.6005874, 0.2, 0.20029768, 0.20003268]\n",
      "[0.6006476, 0.2, 0.2001009, 0.2002872]\n",
      "[0.60058486, 0.2, 0.20017971, 0.20014314]\n",
      "[0.60093725, 0.2, 0.2001669, 0.20050608]\n",
      "[0.6007926, 0.2, 0.20022395, 0.20030239]\n",
      "[0.6005962, 0.2, 0.2001553, 0.20017286]\n",
      "[0.60057193, 0.2, 0.2000911, 0.20021117]\n",
      "[0.60059196, 0.2, 0.20016384, 0.20015708]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9920 iterations: 2.5200936992963157 mins\n",
      "Train Loss: [0.60059196, 0.2, 0.20016384, 0.20015708]\n",
      "[0.60049015, 0.2, 0.20016533, 0.20005263]\n",
      "[0.60079485, 0.2, 0.20022523, 0.20029643]\n",
      "[0.60071856, 0.2, 0.20015188, 0.20029294]\n",
      "[0.6004541, 0.2, 0.2000564, 0.20012364]\n",
      "[0.60048664, 0.2, 0.20009784, 0.20011467]\n",
      "[0.6006167, 0.2, 0.20008415, 0.20025863]\n",
      "[0.60060775, 0.2, 0.2001696, 0.20016469]\n",
      "[0.6008259, 0.2, 0.2001775, 0.2003755]\n",
      "[0.60078806, 0.2, 0.20010132, 0.20041466]\n",
      "[0.60045385, 0.2, 0.20009379, 0.20008874]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9930 iterations: 2.522013052304586 mins\n",
      "Train Loss: [0.60045385, 0.2, 0.20009379, 0.20008874]\n",
      "[0.6005271, 0.2, 0.20008314, 0.20017362]\n",
      "[0.6006796, 0.2, 0.20016307, 0.20024726]\n",
      "[0.6004448, 0.2, 0.20006648, 0.20011052]\n",
      "[0.6006596, 0.2, 0.20014167, 0.20025176]\n",
      "[0.6004771, 0.2, 0.2001641, 0.20004836]\n",
      "[0.6004217, 0.2, 0.20009466, 0.20006396]\n",
      "[0.6005347, 0.2, 0.20017917, 0.20009398]\n",
      "[0.6005628, 0.2, 0.20013583, 0.20016709]\n",
      "[0.6005736, 0.2, 0.20014392, 0.20017153]\n",
      "[0.6004704, 0.2, 0.20012233, 0.20009165]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9940 iterations: 2.524834096431732 mins\n",
      "Train Loss: [0.6004704, 0.2, 0.20012233, 0.20009165]\n",
      "[0.6005041, 0.2, 0.20016304, 0.20008639]\n",
      "[0.60051936, 0.2, 0.20004354, 0.20022285]\n",
      "[0.6003809, 0.2, 0.2000724, 0.20005713]\n",
      "[0.6006346, 0.2, 0.20017296, 0.20021182]\n",
      "[0.60060114, 0.2, 0.20016396, 0.200189]\n",
      "[0.6005555, 0.2, 0.20026089, 0.20004806]\n",
      "[0.60081625, 0.2, 0.20008755, 0.20048371]\n",
      "[0.60047543, 0.2, 0.20017391, 0.20005795]\n",
      "[0.60060674, 0.2, 0.2001065, 0.20025794]\n",
      "[0.60045636, 0.2, 0.20004892, 0.2001662]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9950 iterations: 2.526768986384074 mins\n",
      "Train Loss: [0.60045636, 0.2, 0.20004892, 0.2001662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60052127, 0.2, 0.20021638, 0.20006454]\n",
      "[0.6004789, 0.2, 0.20013663, 0.20010276]\n",
      "[0.6005859, 0.2, 0.20018202, 0.20016517]\n",
      "[0.6004506, 0.2, 0.20005414, 0.20015843]\n",
      "[0.6005494, 0.2, 0.20016858, 0.20014349]\n",
      "[0.6005948, 0.2, 0.2001804, 0.20017783]\n",
      "[0.6007606, 0.2, 0.20030825, 0.20021644]\n",
      "[0.6005764, 0.2, 0.20010896, 0.20023212]\n",
      "[0.60035723, 0.2, 0.2000423, 0.20008026]\n",
      "[0.6005206, 0.2, 0.20004259, 0.2002439]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9960 iterations: 2.5287935654322307 mins\n",
      "Train Loss: [0.6005206, 0.2, 0.20004259, 0.2002439]\n",
      "[0.6005109, 0.2, 0.20012254, 0.2001548]\n",
      "[0.60053265, 0.2, 0.20013604, 0.20016354]\n",
      "[0.6004849, 0.2, 0.20010465, 0.20014773]\n",
      "[0.60046643, 0.2, 0.20013152, 0.20010294]\n",
      "[0.60052913, 0.2, 0.20003425, 0.2002635]\n",
      "[0.60047376, 0.2, 0.20010825, 0.20013483]\n",
      "[0.6004754, 0.2, 0.20010003, 0.2001455]\n",
      "[0.6005511, 0.2, 0.20012788, 0.20019436]\n",
      "[0.6005135, 0.2, 0.20017827, 0.20010751]\n",
      "[0.60041755, 0.2, 0.200103, 0.20008793]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9970 iterations: 2.531285234292348 mins\n",
      "Train Loss: [0.60041755, 0.2, 0.200103, 0.20008793]\n",
      "[0.60058063, 0.2, 0.20023784, 0.20011717]\n",
      "[0.6004989, 0.2, 0.20022267, 0.2000517]\n",
      "[0.6004231, 0.2, 0.20009878, 0.20010065]\n",
      "[0.60036296, 0.2, 0.20007062, 0.20006971]\n",
      "[0.6004446, 0.2, 0.20012948, 0.20009339]\n",
      "[0.6004833, 0.2, 0.20007387, 0.20018855]\n",
      "[0.6005917, 0.2, 0.20016429, 0.20020734]\n",
      "[0.60047233, 0.2, 0.2002006, 0.20005247]\n",
      "[0.6004829, 0.2, 0.2001727, 0.20009187]\n",
      "[0.60054696, 0.2, 0.20014538, 0.20018429]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9980 iterations: 2.533119332790375 mins\n",
      "Train Loss: [0.60054696, 0.2, 0.20014538, 0.20018429]\n",
      "[0.600408, 0.2, 0.20012303, 0.20006873]\n",
      "[0.6008108, 0.2, 0.20044221, 0.20015344]\n",
      "[0.6006938, 0.2, 0.20011851, 0.20036131]\n",
      "[0.6004555, 0.2, 0.20012026, 0.20012233]\n",
      "[0.6003711, 0.2, 0.20005392, 0.20010515]\n",
      "[0.60047716, 0.2, 0.20012373, 0.200142]\n",
      "[0.6005039, 0.2, 0.20007682, 0.2002162]\n",
      "[0.600529, 0.2, 0.20026998, 0.20004871]\n",
      "[0.6003518, 0.2, 0.20004451, 0.20009741]\n",
      "[0.6005151, 0.2, 0.20022523, 0.20008022]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9990 iterations: 2.5351452668507894 mins\n",
      "Train Loss: [0.6005151, 0.2, 0.20022523, 0.20008022]\n",
      "[0.60048634, 0.2, 0.2000297, 0.20024721]\n",
      "[0.6005545, 0.2, 0.200169, 0.20017612]\n",
      "[0.6010208, 0.2, 0.20024997, 0.20056117]\n",
      "[0.60069555, 0.2, 0.20029323, 0.20019217]\n",
      "[0.60081214, 0.2, 0.20018117, 0.20041998]\n",
      "[0.6006429, 0.2, 0.2002747, 0.20015611]\n",
      "[0.6006126, 0.2, 0.20034859, 0.20005068]\n",
      "[0.600508, 0.2, 0.20012456, 0.20016873]\n",
      "[0.6002962, 0.2, 0.20000003, 0.2000801]\n",
      "[0.60048395, 0.2, 0.20015872, 0.20010777]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10000 iterations: 2.5369587818781536 mins\n",
      "Train Loss: [0.60048395, 0.2, 0.20015872, 0.20010777]\n",
      "[0.60050166, 0.2, 0.20007367, 0.20020908]\n",
      "[0.60068935, 0.2, 0.20027672, 0.20019235]\n",
      "[0.6007019, 0.2, 0.20015815, 0.20032196]\n",
      "[0.6005696, 0.2, 0.20023446, 0.2001116]\n",
      "[0.6008995, 0.2, 0.20044261, 0.20023149]\n",
      "[0.6006649, 0.2, 0.20027281, 0.20016453]\n",
      "[0.6005505, 0.2, 0.2001848, 0.20013584]\n",
      "[0.60049695, 0.2, 0.20011842, 0.20014624]\n",
      "[0.6006317, 0.2, 0.20020191, 0.20019518]\n",
      "[0.6005053, 0.2, 0.20007963, 0.20018896]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10010 iterations: 2.53897446791331 mins\n",
      "Train Loss: [0.6005053, 0.2, 0.20007963, 0.20018896]\n",
      "[0.6007736, 0.2, 0.20034306, 0.200192]\n",
      "[0.6003227, 0.2, 0.20000003, 0.20008257]\n",
      "[0.6004526, 0.2, 0.20011742, 0.20009384]\n",
      "[0.6003932, 0.2, 0.20004322, 0.2001076]\n",
      "[0.60046816, 0.2, 0.2001424, 0.20008267]\n",
      "[0.60047656, 0.2, 0.20007156, 0.20016155]\n",
      "[0.6004443, 0.2, 0.20012854, 0.20007215]\n",
      "[0.6004256, 0.2, 0.20006947, 0.20011272]\n",
      "[0.6003347, 0.2, 0.20001939, 0.20007229]\n",
      "[0.60032296, 0.2, 0.20003341, 0.20004717]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10020 iterations: 2.540796116987864 mins\n",
      "Train Loss: [0.60032296, 0.2, 0.20003341, 0.20004717]\n",
      "[0.6003627, 0.2, 0.20007236, 0.20004882]\n",
      "[0.6003371, 0.2, 0.20004532, 0.20005138]\n",
      "[0.60036767, 0.2, 0.20006359, 0.20006503]\n",
      "[0.60039955, 0.2, 0.20010947, 0.20005251]\n",
      "[0.60043514, 0.2, 0.20006503, 0.20013416]\n",
      "[0.6004096, 0.2, 0.200046, 0.2001295]\n",
      "[0.60045403, 0.2, 0.20013109, 0.20009065]\n",
      "[0.600304, 0.2, 0.20002614, 0.20004751]\n",
      "[0.6005595, 0.2, 0.2001611, 0.2001699]\n",
      "[0.60036236, 0.2, 0.20010382, 0.20003209]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10030 iterations: 2.5429359992345173 mins\n",
      "Train Loss: [0.60036236, 0.2, 0.20010382, 0.20003209]\n",
      "[0.6004463, 0.2, 0.20013505, 0.20008697]\n",
      "[0.6006956, 0.2, 0.20000459, 0.20046878]\n",
      "[0.60047007, 0.2, 0.20005798, 0.20019194]\n",
      "[0.6003551, 0.2, 0.20008484, 0.20005208]\n",
      "[0.60041916, 0.2, 0.2000733, 0.20012967]\n",
      "[0.6004363, 0.2, 0.20000002, 0.20022209]\n",
      "[0.6004769, 0.2, 0.20015597, 0.20010869]\n",
      "[0.6004698, 0.2, 0.20010103, 0.20015857]\n",
      "[0.6005044, 0.2, 0.20009151, 0.20020437]\n",
      "[0.6004932, 0.2, 0.2001732, 0.20011304]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10040 iterations: 2.5448364853858947 mins\n",
      "Train Loss: [0.6004932, 0.2, 0.2001732, 0.20011304]\n",
      "[0.6004388, 0.2, 0.20018499, 0.20004825]\n",
      "[0.6004026, 0.2, 0.2000934, 0.20010494]\n",
      "[0.6003396, 0.2, 0.20007373, 0.20006277]\n",
      "[0.6004325, 0.2, 0.20001954, 0.20021099]\n",
      "[0.6004396, 0.2, 0.20007604, 0.20016266]\n",
      "[0.60045534, 0.2, 0.20014963, 0.20010583]\n",
      "[0.60035115, 0.2, 0.20006168, 0.20009068]\n",
      "[0.600383, 0.2, 0.20013697, 0.20004818]\n",
      "[0.60042655, 0.2, 0.20008844, 0.20014115]\n",
      "[0.60045016, 0.2, 0.20010829, 0.2001457]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10050 iterations: 2.5472232500712075 mins\n",
      "Train Loss: [0.60045016, 0.2, 0.20010829, 0.2001457]\n",
      "[0.60036755, 0.2, 0.20009631, 0.20007586]\n",
      "[0.6004114, 0.2, 0.2001466, 0.2000701]\n",
      "[0.6004779, 0.2, 0.20011735, 0.20016648]\n",
      "[0.6005114, 0.2, 0.20012149, 0.20019622]\n",
      "[0.6003593, 0.2, 0.20007077, 0.20009533]\n",
      "[0.6004629, 0.2, 0.20001402, 0.20025581]\n",
      "[0.60057336, 0.2, 0.20025222, 0.20012826]\n",
      "[0.6002852, 0.2, 0.20003459, 0.20005782]\n",
      "[0.60049653, 0.2, 0.20013629, 0.2001676]\n",
      "[0.6004218, 0.2, 0.20018259, 0.20004646]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10060 iterations: 2.54916836420695 mins\n",
      "Train Loss: [0.6004218, 0.2, 0.20018259, 0.20004646]\n",
      "[0.6003389, 0.2, 0.20009166, 0.20005445]\n",
      "[0.6006668, 0.2, 0.20023005, 0.20024398]\n",
      "[0.60047305, 0.2, 0.20016333, 0.20011699]\n",
      "[0.60036886, 0.2, 0.20014226, 0.20003399]\n",
      "[0.60054564, 0.2, 0.20020957, 0.20014349]\n",
      "[0.60045654, 0.2, 0.20007877, 0.20018525]\n",
      "[0.60052603, 0.2, 0.2001605, 0.20017305]\n",
      "[0.6003356, 0.2, 0.2000456, 0.20009746]\n",
      "[0.60043794, 0.2, 0.200114, 0.20013128]\n",
      "[0.6003798, 0.2, 0.2001115, 0.20007549]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10070 iterations: 2.5510613997777303 mins\n",
      "Train Loss: [0.6003798, 0.2, 0.2001115, 0.20007549]\n",
      "[0.6003269, 0.2, 0.20007998, 0.20005383]\n",
      "[0.6003625, 0.2, 0.20008603, 0.20008288]\n",
      "[0.60072696, 0.2, 0.20032488, 0.20020817]\n",
      "[0.60045594, 0.2, 0.20020734, 0.20005439]\n",
      "[0.6003424, 0.2, 0.20006518, 0.20008276]\n",
      "[0.600443, 0.2, 0.20006162, 0.20018667]\n",
      "[0.6004019, 0.2, 0.20008747, 0.20011945]\n",
      "[0.60042214, 0.2, 0.20008555, 0.20014136]\n",
      "[0.60042363, 0.2, 0.20005351, 0.2001747]\n",
      "[0.6003647, 0.2, 0.20003271, 0.2001364]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10080 iterations: 2.553096663951874 mins\n",
      "Train Loss: [0.6003647, 0.2, 0.20003271, 0.2001364]\n",
      "[0.6004806, 0.2, 0.20012991, 0.20015506]\n",
      "[0.6005267, 0.2, 0.20018467, 0.20014645]\n",
      "[0.6002985, 0.2, 0.20007126, 0.20003185]\n",
      "[0.60041827, 0.2, 0.20006421, 0.20015877]\n",
      "[0.6006169, 0.2, 0.20009519, 0.2003266]\n",
      "[0.60046947, 0.2, 0.20020281, 0.20007163]\n",
      "[0.60051334, 0.2, 0.2002464, 0.20007187]\n",
      "[0.60059965, 0.2, 0.2001256, 0.20027886]\n",
      "[0.60042804, 0.2, 0.20010345, 0.20012932]\n",
      "[0.60026854, 0.2, 0.20002827, 0.2000448]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10090 iterations: 2.5550888140996295 mins\n",
      "Train Loss: [0.60026854, 0.2, 0.20002827, 0.2000448]\n",
      "[0.600396, 0.2, 0.20007965, 0.20012073]\n",
      "[0.6004065, 0.2, 0.20004489, 0.20016605]\n",
      "[0.60038936, 0.2, 0.20005639, 0.20013745]\n",
      "[0.6004911, 0.2, 0.20019601, 0.20009984]\n",
      "[0.6006035, 0.2, 0.2002031, 0.2002055]\n",
      "[0.6004261, 0.2, 0.20006056, 0.20017095]\n",
      "[0.6004356, 0.2, 0.20008251, 0.20015904]\n",
      "[0.6003357, 0.2, 0.20004994, 0.20009218]\n",
      "[0.6005072, 0.2, 0.2002193, 0.20009468]\n",
      "[0.6004397, 0.2, 0.20018375, 0.20006332]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10100 iterations: 2.5571693658828734 mins\n",
      "Train Loss: [0.6004397, 0.2, 0.20018375, 0.20006332]\n",
      "[0.60050565, 0.2, 0.20019533, 0.20011806]\n",
      "[0.60034937, 0.2, 0.20003767, 0.20011987]\n",
      "[0.6004153, 0.2, 0.2001143, 0.2001096]\n",
      "[0.6004123, 0.2, 0.2001309, 0.20009062]\n",
      "[0.6006118, 0.2, 0.20020966, 0.20021191]\n",
      "[0.6003919, 0.2, 0.20015877, 0.20004362]\n",
      "[0.6004123, 0.2, 0.20011754, 0.20010597]\n",
      "[0.6005956, 0.2, 0.2002699, 0.20013769]\n",
      "[0.6003185, 0.2, 0.20009239, 0.20003885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6003334, 0.2, 0.20007297, 0.20007394]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10110 iterations: 2.559070364634196 mins\n",
      "Train Loss: [0.6003334, 0.2, 0.20007297, 0.20007394]\n",
      "[0.60043323, 0.2, 0.20010485, 0.20014273]\n",
      "[0.6002672, 0.2, 0.20002583, 0.20005643]\n",
      "[0.6002405, 0.2, 0.20004468, 0.20001183]\n",
      "[0.60039264, 0.2, 0.20017043, 0.20003912]\n",
      "[0.6004973, 0.2, 0.2001492, 0.20016608]\n",
      "[0.60034806, 0.2, 0.2001036, 0.20006348]\n",
      "[0.6005081, 0.2, 0.20015532, 0.20017304]\n",
      "[0.60034084, 0.2, 0.200077, 0.20008516]\n",
      "[0.6004458, 0.2, 0.20013277, 0.20013542]\n",
      "[0.6004919, 0.2, 0.20022975, 0.20008552]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10120 iterations: 2.5610209663709003 mins\n",
      "Train Loss: [0.6004919, 0.2, 0.20022975, 0.20008552]\n",
      "[0.6003174, 0.2, 0.20008504, 0.20005675]\n",
      "[0.60055345, 0.2, 0.20017214, 0.20020628]\n",
      "[0.6003343, 0.2, 0.20003183, 0.20012775]\n",
      "[0.60042965, 0.2, 0.20011185, 0.20014325]\n",
      "[0.6003686, 0.2, 0.20007265, 0.20012164]\n",
      "[0.600439, 0.2, 0.20011702, 0.20014778]\n",
      "[0.6006559, 0.2, 0.20025691, 0.2002248]\n",
      "[0.60047203, 0.2, 0.20012638, 0.20017155]\n",
      "[0.60031855, 0.2, 0.20009954, 0.20004484]\n",
      "[0.60043705, 0.2, 0.20013992, 0.20012288]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10130 iterations: 2.5630619168281554 mins\n",
      "Train Loss: [0.60043705, 0.2, 0.20013992, 0.20012288]\n",
      "[0.60035807, 0.2, 0.20015001, 0.20003371]\n",
      "[0.60046947, 0.2, 0.20017296, 0.20012195]\n",
      "[0.6003515, 0.2, 0.20014031, 0.20003635]\n",
      "[0.6005051, 0.2, 0.20014927, 0.20018072]\n",
      "[0.6003872, 0.2, 0.20008488, 0.20012689]\n",
      "[0.600558, 0.2, 0.20022373, 0.20015818]\n",
      "[0.6005352, 0.2, 0.2001876, 0.20017084]\n",
      "[0.6004736, 0.2, 0.2001242, 0.20017198]\n",
      "[0.6004743, 0.2, 0.20012078, 0.20017539]\n",
      "[0.6003938, 0.2, 0.20005421, 0.20016061]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10140 iterations: 2.5653260310490924 mins\n",
      "Train Loss: [0.6003938, 0.2, 0.20005421, 0.20016061]\n",
      "[0.60055274, 0.2, 0.20014219, 0.20023076]\n",
      "[0.6004251, 0.2, 0.20008257, 0.20016187]\n",
      "[0.60060567, 0.2, 0.20019028, 0.20023376]\n",
      "[0.6003093, 0.2, 0.2000805, 0.20004643]\n",
      "[0.6004197, 0.2, 0.20016375, 0.2000726]\n",
      "[0.60041493, 0.2, 0.20009778, 0.20013279]\n",
      "[0.6003299, 0.2, 0.20008758, 0.20005704]\n",
      "[0.6003603, 0.2, 0.2000379, 0.20013636]\n",
      "[0.6003392, 0.2, 0.20005293, 0.20009954]\n",
      "[0.60029817, 0.2, 0.20004922, 0.2000618]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10150 iterations: 2.5674046516418456 mins\n",
      "Train Loss: [0.60029817, 0.2, 0.20004922, 0.2000618]\n",
      "[0.6004036, 0.2, 0.20004982, 0.20016634]\n",
      "[0.6004639, 0.2, 0.20016336, 0.20011301]\n",
      "[0.60054564, 0.2, 0.2001276, 0.2002305]\n",
      "[0.6003372, 0.2, 0.20000003, 0.20014957]\n",
      "[0.6005981, 0.2, 0.20015737, 0.20025317]\n",
      "[0.6003677, 0.2, 0.20011719, 0.2000631]\n",
      "[0.60032, 0.2, 0.20006247, 0.20007011]\n",
      "[0.60045046, 0.2, 0.20004588, 0.20021732]\n",
      "[0.6003766, 0.2, 0.20008302, 0.2001066]\n",
      "[0.60029423, 0.2, 0.20003934, 0.20006816]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10160 iterations: 2.5692176659901937 mins\n",
      "Train Loss: [0.60029423, 0.2, 0.20003934, 0.20006816]\n",
      "[0.60052866, 0.2, 0.20023324, 0.20010892]\n",
      "[0.60047096, 0.2, 0.20008518, 0.20019957]\n",
      "[0.60035396, 0.2, 0.20006342, 0.20010462]\n",
      "[0.60043186, 0.2, 0.2001351, 0.20011123]\n",
      "[0.60030454, 0.2, 0.20002449, 0.20009476]\n",
      "[0.6003241, 0.2, 0.20006728, 0.20007174]\n",
      "[0.60045296, 0.2, 0.20008501, 0.20018308]\n",
      "[0.6004036, 0.2, 0.2000439, 0.20017515]\n",
      "[0.6005525, 0.2, 0.2001159, 0.20025241]\n",
      "[0.6003336, 0.2, 0.20007655, 0.20007324]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10170 iterations: 2.571224315961202 mins\n",
      "Train Loss: [0.6003336, 0.2, 0.20007655, 0.20007324]\n",
      "[0.6005013, 0.2, 0.20015836, 0.20015958]\n",
      "[0.6003176, 0.2, 0.20006067, 0.200074]\n",
      "[0.6006298, 0.2, 0.20032504, 0.20012222]\n",
      "[0.6003754, 0.2, 0.20012163, 0.20007169]\n",
      "[0.60046256, 0.2, 0.200185, 0.20009579]\n",
      "[0.60036457, 0.2, 0.20008244, 0.20010056]\n",
      "[0.6004694, 0.2, 0.20017248, 0.20011564]\n",
      "[0.600356, 0.2, 0.20012248, 0.20005251]\n",
      "[0.6004075, 0.2, 0.20012338, 0.20010334]\n",
      "[0.6004522, 0.2, 0.20016463, 0.20010722]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10180 iterations: 2.573215901851654 mins\n",
      "Train Loss: [0.6004522, 0.2, 0.20016463, 0.20010722]\n",
      "[0.6004298, 0.2, 0.20006157, 0.20018831]\n",
      "[0.60040987, 0.2, 0.20008141, 0.20014918]\n",
      "[0.6003744, 0.2, 0.2000662, 0.2001296]\n",
      "[0.60031295, 0.2, 0.20005798, 0.200077]\n",
      "[0.6002894, 0.2, 0.20005545, 0.20005666]\n",
      "[0.60048914, 0.2, 0.20021926, 0.20009333]\n",
      "[0.6003873, 0.2, 0.2001303, 0.20008118]\n",
      "[0.6003881, 0.2, 0.20002353, 0.20018955]\n",
      "[0.6003479, 0.2, 0.20012948, 0.20004407]\n",
      "[0.6004547, 0.2, 0.20025104, 0.2000301]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10190 iterations: 2.5752567330996197 mins\n",
      "Train Loss: [0.6004547, 0.2, 0.20025104, 0.2000301]\n",
      "[0.60033363, 0.2, 0.20000005, 0.20016077]\n",
      "[0.6003463, 0.2, 0.20007393, 0.20010033]\n",
      "[0.6004101, 0.2, 0.20013183, 0.2001071]\n",
      "[0.60034597, 0.2, 0.20013005, 0.20004565]\n",
      "[0.60039645, 0.2, 0.20013903, 0.20008804]\n",
      "[0.60024065, 0.2, 0.20000443, 0.20006774]\n",
      "[0.6002773, 0.2, 0.20005907, 0.20005079]\n",
      "[0.6005135, 0.2, 0.20021395, 0.20013306]\n",
      "[0.60042924, 0.2, 0.20009, 0.20017385]\n",
      "[0.60036415, 0.2, 0.2001068, 0.20009296]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10200 iterations: 2.5773330012957256 mins\n",
      "Train Loss: [0.60036415, 0.2, 0.2001068, 0.20009296]\n",
      "[0.60039264, 0.2, 0.20017229, 0.200057]\n",
      "[0.60047734, 0.2, 0.20012854, 0.20018639]\n",
      "[0.60026205, 0.2, 0.20002511, 0.20007536]\n",
      "[0.60033876, 0.2, 0.20005096, 0.20012704]\n",
      "[0.60035676, 0.2, 0.2000411, 0.20015562]\n",
      "[0.6003797, 0.2, 0.20008089, 0.20013939]\n",
      "[0.60035586, 0.2, 0.2000657, 0.20013116]\n",
      "[0.60032874, 0.2, 0.20013022, 0.20004003]\n",
      "[0.6003353, 0.2, 0.20006528, 0.20011187]\n",
      "[0.6004687, 0.2, 0.20020713, 0.2001037]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10210 iterations: 2.5814072330792746 mins\n",
      "Train Loss: [0.6004687, 0.2, 0.20020713, 0.2001037]\n",
      "[0.6003972, 0.2, 0.2001066, 0.2001328]\n",
      "[0.6004375, 0.2, 0.20020318, 0.20007646]\n",
      "[0.60039926, 0.2, 0.20012797, 0.20011324]\n",
      "[0.6004672, 0.2, 0.20015673, 0.20015211]\n",
      "[0.60026515, 0.2, 0.20005743, 0.200049]\n",
      "[0.60026616, 0.2, 0.20006453, 0.2000424]\n",
      "[0.6002427, 0.2, 0.20002076, 0.20006232]\n",
      "[0.6004633, 0.2, 0.20021366, 0.20008965]\n",
      "[0.6003286, 0.2, 0.20007764, 0.20009063]\n",
      "[0.6003252, 0.2, 0.2000717, 0.20009296]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10220 iterations: 2.5841216166814167 mins\n",
      "Train Loss: [0.6003252, 0.2, 0.2000717, 0.20009296]\n",
      "[0.60034966, 0.2, 0.2, 0.20018879]\n",
      "[0.6002906, 0.2, 0.20003505, 0.2000944]\n",
      "[0.60056984, 0.2, 0.20024817, 0.20016024]\n",
      "[0.6004094, 0.2, 0.20006652, 0.20018114]\n",
      "[0.60061455, 0.2, 0.20027655, 0.20017584]\n",
      "[0.6007664, 0.2, 0.2004404, 0.2001633]\n",
      "[0.6011418, 0.2, 0.20008726, 0.20089127]\n",
      "[0.6002737, 0.2, 0.20005919, 0.20005034]\n",
      "[0.6002844, 0.2, 0.20003915, 0.2000797]\n",
      "[0.6003473, 0.2, 0.20007898, 0.20010132]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10230 iterations: 2.5861549655596416 mins\n",
      "Train Loss: [0.6003473, 0.2, 0.20007898, 0.20010132]\n",
      "[0.6003826, 0.2, 0.20010225, 0.20011179]\n",
      "[0.6004445, 0.2, 0.20010355, 0.20017089]\n",
      "[0.6003079, 0.2, 0.20005284, 0.20008361]\n",
      "[0.6002357, 0.2, 0.20000002, 0.20006287]\n",
      "[0.6004783, 0.2, 0.20009674, 0.20020738]\n",
      "[0.60037184, 0.2, 0.20006852, 0.20012781]\n",
      "[0.6003502, 0.2, 0.2000982, 0.2000754]\n",
      "[0.600483, 0.2, 0.20011985, 0.20018542]\n",
      "[0.60029286, 0.2, 0.2000353, 0.20007896]\n",
      "[0.60037917, 0.2, 0.20009199, 0.20010778]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10240 iterations: 2.588025915622711 mins\n",
      "Train Loss: [0.60037917, 0.2, 0.20009199, 0.20010778]\n",
      "[0.6004958, 0.2, 0.20007934, 0.20023648]\n",
      "[0.6005158, 0.2, 0.20006074, 0.20027445]\n",
      "[0.6003917, 0.2, 0.20004615, 0.20016463]\n",
      "[0.6003939, 0.2, 0.20003055, 0.2001822]\n",
      "[0.600417, 0.2, 0.20011853, 0.20011722]\n",
      "[0.6003038, 0.2, 0.20004764, 0.20007491]\n",
      "[0.6003583, 0.2, 0.20012897, 0.20004815]\n",
      "[0.6003512, 0.2, 0.20003787, 0.20013225]\n",
      "[0.60043573, 0.2, 0.20017931, 0.20007554]\n",
      "[0.60044754, 0.2, 0.20019525, 0.2000718]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10250 iterations: 2.5900686502456667 mins\n",
      "Train Loss: [0.60044754, 0.2, 0.20019525, 0.2000718]\n",
      "[0.60032815, 0.2, 0.20004149, 0.20010674]\n",
      "[0.60027397, 0.2, 0.20004351, 0.20005111]\n",
      "[0.60029685, 0.2, 0.2000298, 0.20008844]\n",
      "[0.6004626, 0.2, 0.2002098, 0.20007515]\n",
      "[0.6003435, 0.2, 0.20004937, 0.20011741]\n",
      "[0.60040504, 0.2, 0.20010212, 0.20012729]\n",
      "[0.60046524, 0.2, 0.20012856, 0.20016222]\n",
      "[0.60032785, 0.2, 0.20001975, 0.20013481]\n",
      "[0.6003827, 0.2, 0.20012096, 0.20008962]\n",
      "[0.60038453, 0.2, 0.20005143, 0.20016225]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10260 iterations: 2.5919506669044496 mins\n",
      "Train Loss: [0.60038453, 0.2, 0.20005143, 0.20016225]\n",
      "[0.60032076, 0.2, 0.20007803, 0.20007303]\n",
      "[0.60050565, 0.2, 0.2000436, 0.20029347]\n",
      "[0.600642, 0.2, 0.20005141, 0.20042323]\n",
      "[0.6004647, 0.2, 0.20013745, 0.2001611]\n",
      "[0.60045314, 0.2, 0.20014022, 0.20014788]\n",
      "[0.60041034, 0.2, 0.20005701, 0.20018926]\n",
      "[0.6003714, 0.2, 0.2001125, 0.20009592]\n",
      "[0.6002804, 0.2, 0.20006548, 0.20005274]\n",
      "[0.60030985, 0.2, 0.20008679, 0.20006156]\n",
      "[0.60035115, 0.2, 0.20011127, 0.20007902]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10270 iterations: 2.5939533988634746 mins\n",
      "Train Loss: [0.60035115, 0.2, 0.20011127, 0.20007902]\n",
      "[0.6002626, 0.2, 0.2000109, 0.20009142]\n",
      "[0.6003004, 0.2, 0.20007296, 0.20006758]\n",
      "[0.6002942, 0.2, 0.20006, 0.20007487]\n",
      "[0.6003933, 0.2, 0.20014018, 0.20009431]\n",
      "[0.60026467, 0.2, 0.20006084, 0.20004547]\n",
      "[0.60028565, 0.2, 0.20004424, 0.20008342]\n",
      "[0.60040224, 0.2, 0.2001756, 0.20006895]\n",
      "[0.60042953, 0.2, 0.20006406, 0.20020795]\n",
      "[0.6002513, 0.2, 0.2, 0.20009388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.600357, 0.2, 0.20012838, 0.20007119]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10280 iterations: 2.595847682158152 mins\n",
      "Train Loss: [0.600357, 0.2, 0.20012838, 0.20007119]\n",
      "[0.60047907, 0.2, 0.20020297, 0.20011866]\n",
      "[0.6003926, 0.2, 0.200075, 0.20016007]\n",
      "[0.60053974, 0.2, 0.20022081, 0.20016134]\n",
      "[0.6004203, 0.2, 0.20010231, 0.20016024]\n",
      "[0.60037935, 0.2, 0.20009871, 0.20012265]\n",
      "[0.6002965, 0.2, 0.2001072, 0.20003118]\n",
      "[0.6003705, 0.2, 0.20011237, 0.20009972]\n",
      "[0.600384, 0.2, 0.20012073, 0.20010467]\n",
      "[0.60034025, 0.2, 0.20012057, 0.2000609]\n",
      "[0.60029215, 0.2, 0.20010187, 0.20003131]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10290 iterations: 2.5984033664067585 mins\n",
      "Train Loss: [0.60029215, 0.2, 0.20010187, 0.20003131]\n",
      "[0.6004529, 0.2, 0.20006503, 0.2002286]\n",
      "[0.60024476, 0.2, 0.20000002, 0.2000849]\n",
      "[0.6003787, 0.2, 0.20005503, 0.20016307]\n",
      "[0.60030687, 0.2, 0.2000712, 0.20007434]\n",
      "[0.600344, 0.2, 0.2000972, 0.20008467]\n",
      "[0.60027593, 0.2, 0.20007162, 0.20004156]\n",
      "[0.6003487, 0.2, 0.20007366, 0.20011143]\n",
      "[0.60034984, 0.2, 0.20009738, 0.20008804]\n",
      "[0.6003674, 0.2, 0.20010622, 0.20009612]\n",
      "[0.60035634, 0.2, 0.20011029, 0.20008008]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10300 iterations: 2.6004046837488812 mins\n",
      "Train Loss: [0.60035634, 0.2, 0.20011029, 0.20008008]\n",
      "[0.6003629, 0.2, 0.20009589, 0.20010023]\n",
      "[0.6003158, 0.2, 0.20007056, 0.20007771]\n",
      "[0.60044295, 0.2, 0.20013604, 0.20013861]\n",
      "[0.6002917, 0.2, 0.20006755, 0.20005564]\n",
      "[0.60034454, 0.2, 0.20012924, 0.20004633]\n",
      "[0.6004848, 0.2, 0.20019825, 0.20011741]\n",
      "[0.6002528, 0.2, 0.20002908, 0.2000544]\n",
      "[0.6004706, 0.2, 0.2001619, 0.20013878]\n",
      "[0.6003156, 0.2, 0.20003323, 0.20011157]\n",
      "[0.60038716, 0.2, 0.20012794, 0.20008722]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10310 iterations: 2.602167212963104 mins\n",
      "Train Loss: [0.60038716, 0.2, 0.20012794, 0.20008722]\n",
      "[0.60048777, 0.2, 0.2002157, 0.20009848]\n",
      "[0.60049576, 0.2, 0.20025261, 0.20006794]\n",
      "[0.60049003, 0.2, 0.20008922, 0.20022388]\n",
      "[0.60044974, 0.2, 0.20014942, 0.20012093]\n",
      "[0.60053605, 0.2, 0.2001657, 0.20018737]\n",
      "[0.60072345, 0.2, 0.20021419, 0.20032197]\n",
      "[0.6004347, 0.2, 0.20007494, 0.20016839]\n",
      "[0.6007233, 0.2, 0.20022747, 0.20029941]\n",
      "[0.6008712, 0.2, 0.20017616, 0.20049301]\n",
      "[0.60081124, 0.2, 0.2003191, 0.20028459]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10320 iterations: 2.604117830594381 mins\n",
      "Train Loss: [0.60081124, 0.2, 0.2003191, 0.20028459]\n",
      "[0.6005361, 0.2, 0.20021549, 0.20010777]\n",
      "[0.6007231, 0.2, 0.20023954, 0.20026515]\n",
      "[0.6005157, 0.2, 0.20020492, 0.2000872]\n",
      "[0.6006536, 0.2, 0.20027648, 0.2001482]\n",
      "[0.6005984, 0.2, 0.20029938, 0.20006509]\n",
      "[0.6004054, 0.2, 0.2000779, 0.20008853]\n",
      "[0.6006612, 0.2, 0.2001442, 0.20027222]\n",
      "[0.60097355, 0.2, 0.20027576, 0.20044611]\n",
      "[0.6007032, 0.2, 0.20020849, 0.20023593]\n",
      "[0.60086846, 0.2, 0.2003563, 0.20024616]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10330 iterations: 2.6059948682785032 mins\n",
      "Train Loss: [0.60086846, 0.2, 0.2003563, 0.20024616]\n",
      "[0.6006783, 0.2, 0.20018838, 0.2002167]\n",
      "[0.60057575, 0.2, 0.20013106, 0.20016402]\n",
      "[0.60061514, 0.2, 0.20020935, 0.20011769]\n",
      "[0.6006331, 0.2, 0.20025465, 0.20008343]\n",
      "[0.60110563, 0.2, 0.2007489, 0.20005508]\n",
      "[0.6006249, 0.2, 0.20011184, 0.20020504]\n",
      "[0.6010123, 0.2, 0.2002078, 0.20049025]\n",
      "[0.6006269, 0.2, 0.20008317, 0.20022401]\n",
      "[0.60127515, 0.2, 0.20036614, 0.2005838]\n",
      "[0.6008665, 0.2, 0.20020749, 0.20032866]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10340 iterations: 2.6080329497655232 mins\n",
      "Train Loss: [0.6008665, 0.2, 0.20020749, 0.20032866]\n",
      "[0.60127765, 0.2, 0.20030954, 0.20063293]\n",
      "[0.6009968, 0.2, 0.2004912, 0.20016684]\n",
      "[0.60103095, 0.2, 0.20040032, 0.20028879]\n",
      "[0.6005698, 0.2, 0.2000003, 0.20022498]\n",
      "[0.6009438, 0.2, 0.20010523, 0.20049144]\n",
      "[0.6010611, 0.2, 0.20025721, 0.20045435]\n",
      "[0.60096437, 0.2, 0.20040822, 0.20020476]\n",
      "[0.60070074, 0.2, 0.2002335, 0.20011443]\n",
      "[0.6005996, 0.2, 0.20016116, 0.20008458]\n",
      "[0.6004258, 0.2, 0.20000009, 0.20007128]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10350 iterations: 2.6099185983339948 mins\n",
      "Train Loss: [0.6004258, 0.2, 0.20000009, 0.20007128]\n",
      "[0.6006718, 0.2, 0.20020747, 0.20010939]\n",
      "[0.60097545, 0.2, 0.20052919, 0.20009115]\n",
      "[0.60093194, 0.2, 0.20011045, 0.20046644]\n",
      "[0.6009077, 0.2, 0.20013708, 0.20041537]\n",
      "[0.60054183, 0.2, 0.20006034, 0.2001256]\n",
      "[0.6006026, 0.2, 0.2000464, 0.20019937]\n",
      "[0.6010032, 0.2, 0.20010926, 0.20053606]\n",
      "[0.60101247, 0.2, 0.20037396, 0.20027982]\n",
      "[0.6005504, 0.2, 0.20013905, 0.2000515]\n",
      "[0.60085475, 0.2, 0.20032153, 0.20017211]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10360 iterations: 2.611950135231018 mins\n",
      "Train Loss: [0.60085475, 0.2, 0.20032153, 0.20017211]\n",
      "[0.60070133, 0.2, 0.20016155, 0.20017746]\n",
      "[0.60053664, 0.2, 0.20002197, 0.20015162]\n",
      "[0.60107446, 0.2, 0.20042779, 0.20028281]\n",
      "[0.60078585, 0.2, 0.20012996, 0.20029184]\n",
      "[0.6007515, 0.2, 0.20018944, 0.20019814]\n",
      "[0.60062337, 0.2, 0.20010266, 0.200157]\n",
      "[0.60067683, 0.2, 0.20013475, 0.2001788]\n",
      "[0.6008201, 0.2, 0.20033179, 0.2001257]\n",
      "[0.60090387, 0.2, 0.20043498, 0.20010775]\n",
      "[0.60102355, 0.2, 0.20042, 0.20024446]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10370 iterations: 2.6144755641619364 mins\n",
      "Train Loss: [0.60102355, 0.2, 0.20042, 0.20024446]\n",
      "[0.6009903, 0.2, 0.20030805, 0.20032495]\n",
      "[0.60059345, 0.2, 0.20010756, 0.20013036]\n",
      "[0.60053563, 0.2, 0.20003827, 0.20014314]\n",
      "[0.600767, 0.2, 0.20025338, 0.20016032]\n",
      "[0.6009721, 0.2, 0.20035012, 0.20026942]\n",
      "[0.60086775, 0.2, 0.20016295, 0.20035318]\n",
      "[0.6006126, 0.2, 0.2000995, 0.20016266]\n",
      "[0.600479, 0.2, 0.20005137, 0.2000787]\n",
      "[0.6007151, 0.2, 0.20020278, 0.2001652]\n",
      "[0.60059434, 0.2, 0.20013838, 0.20011093]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10380 iterations: 2.616342234611511 mins\n",
      "Train Loss: [0.60059434, 0.2, 0.20013838, 0.20011093]\n",
      "[0.6005756, 0.2, 0.20018762, 0.20004548]\n",
      "[0.60050863, 0.2, 0.20007274, 0.20009612]\n",
      "[0.6005591, 0.2, 0.20004515, 0.20017728]\n",
      "[0.60058564, 0.2, 0.20015253, 0.20010003]\n",
      "[0.6006034, 0.2, 0.20014842, 0.20012556]\n",
      "[0.6005166, 0.2, 0.20008981, 0.20010123]\n",
      "[0.600535, 0.2, 0.20013648, 0.20007709]\n",
      "[0.6005227, 0.2, 0.20013028, 0.20007512]\n",
      "[0.60043967, 0.2, 0.20003684, 0.20008978]\n",
      "[0.6005796, 0.2, 0.20012511, 0.20014575]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10390 iterations: 2.618386280536652 mins\n",
      "Train Loss: [0.6005796, 0.2, 0.20012511, 0.20014575]\n",
      "[0.6005459, 0.2, 0.20007221, 0.20016919]\n",
      "[0.6003437, 0.2, 0.20000769, 0.20003577]\n",
      "[0.600494, 0.2, 0.2001109, 0.200087]\n",
      "[0.6005037, 0.2, 0.20009534, 0.20011629]\n",
      "[0.6005892, 0.2, 0.2001671, 0.20013407]\n",
      "[0.6004385, 0.2, 0.20010523, 0.20004913]\n",
      "[0.6003953, 0.2, 0.20002805, 0.20008698]\n",
      "[0.60039455, 0.2, 0.20003629, 0.20008175]\n",
      "[0.6004936, 0.2, 0.20007874, 0.20014194]\n",
      "[0.6005255, 0.2, 0.20003831, 0.20021772]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10400 iterations: 2.6202154318491617 mins\n",
      "Train Loss: [0.6005255, 0.2, 0.20003831, 0.20021772]\n",
      "[0.60039896, 0.2, 0.20003548, 0.20009749]\n",
      "[0.6004096, 0.2, 0.20006905, 0.20007804]\n",
      "[0.6004517, 0.2, 0.20010316, 0.20008954]\n",
      "[0.6003934, 0.2, 0.20010296, 0.2000349]\n",
      "[0.600384, 0.2, 0.20004384, 0.20008795]\n",
      "[0.6004423, 0.2, 0.20010528, 0.20008793]\n",
      "[0.6004368, 0.2, 0.20010695, 0.20008405]\n",
      "[0.60040206, 0.2, 0.20007995, 0.20007958]\n",
      "[0.60046774, 0.2, 0.20006667, 0.2001617]\n",
      "[0.60046154, 0.2, 0.20011944, 0.20010565]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10410 iterations: 2.62216268380483 mins\n",
      "Train Loss: [0.60046154, 0.2, 0.20011944, 0.20010565]\n",
      "[0.60040444, 0.2, 0.20006071, 0.20011011]\n",
      "[0.60046875, 0.2, 0.20005003, 0.20018794]\n",
      "[0.60035723, 0.2, 0.20002182, 0.2001076]\n",
      "[0.6004252, 0.2, 0.20005749, 0.20014264]\n",
      "[0.60046977, 0.2, 0.20012145, 0.20012586]\n",
      "[0.60034496, 0.2, 0.20008706, 0.20003784]\n",
      "[0.60037345, 0.2, 0.20010485, 0.20005076]\n",
      "[0.60034233, 0.2, 0.20005922, 0.20006733]\n",
      "[0.6003506, 0.2, 0.2000597, 0.20007722]\n",
      "[0.6005043, 0.2, 0.20020069, 0.2000917]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10420 iterations: 2.6239179015159606 mins\n",
      "Train Loss: [0.6005043, 0.2, 0.20020069, 0.2000917]\n",
      "[0.60055405, 0.2, 0.20009156, 0.2002521]\n",
      "[0.6004412, 0.2, 0.20013666, 0.2000954]\n",
      "[0.6005314, 0.2, 0.20022167, 0.20010145]\n",
      "[0.6003825, 0.2, 0.20007534, 0.20009957]\n",
      "[0.6004639, 0.2, 0.20011155, 0.20014502]\n",
      "[0.6006353, 0.2, 0.200175, 0.20025307]\n",
      "[0.6004852, 0.2, 0.20007193, 0.20020625]\n",
      "[0.6003057, 0.2, 0.20006712, 0.20003128]\n",
      "[0.6004847, 0.2, 0.20014878, 0.20012796]\n",
      "[0.6003333, 0.2, 0.20009467, 0.20002973]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10430 iterations: 2.6259979009628296 mins\n",
      "Train Loss: [0.6003333, 0.2, 0.20009467, 0.20002973]\n",
      "[0.6004705, 0.2, 0.20012456, 0.20013617]\n",
      "[0.6005846, 0.2, 0.2001514, 0.20022275]\n",
      "[0.60060275, 0.2, 0.20017713, 0.20021473]\n",
      "[0.60041386, 0.2, 0.20010647, 0.20009659]\n",
      "[0.60036886, 0.2, 0.20008707, 0.20007136]\n",
      "[0.60060096, 0.2, 0.2002723, 0.2001185]\n",
      "[0.6003872, 0.2, 0.20012356, 0.20005365]\n",
      "[0.60069084, 0.2, 0.20040166, 0.20007925]\n",
      "[0.60036206, 0.2, 0.20007916, 0.2000733]\n",
      "[0.60032195, 0.2, 0.20004755, 0.20006458]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10440 iterations: 2.627848382790883 mins\n",
      "Train Loss: [0.60032195, 0.2, 0.20004755, 0.20006458]\n",
      "[0.60034466, 0.2, 0.20005965, 0.20007467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6004136, 0.2, 0.20006578, 0.20013677]\n",
      "[0.60054076, 0.2, 0.20005187, 0.20027697]\n",
      "[0.60045314, 0.2, 0.20016187, 0.20007865]\n",
      "[0.60033375, 0.2, 0.20006561, 0.20005472]\n",
      "[0.60042787, 0.2, 0.20005889, 0.20015432]\n",
      "[0.60031444, 0.2, 0.20004041, 0.20005786]\n",
      "[0.60029656, 0.2, 0.20003964, 0.20003891]\n",
      "[0.60033226, 0.2, 0.20006233, 0.20004986]\n",
      "[0.6011937, 0.2, 0.20034654, 0.20062453]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10450 iterations: 2.6298436005910237 mins\n",
      "Train Loss: [0.6011937, 0.2, 0.20034654, 0.20062453]\n",
      "[0.6005179, 0.2, 0.20016085, 0.20013227]\n",
      "[0.6007477, 0.2, 0.20026676, 0.20025356]\n",
      "[0.6005358, 0.2, 0.2000235, 0.20028219]\n",
      "[0.60054433, 0.2, 0.20002104, 0.20028989]\n",
      "[0.60067105, 0.2, 0.2003678, 0.20006646]\n",
      "[0.6004287, 0.2, 0.20009981, 0.20008884]\n",
      "[0.6005607, 0.2, 0.20024331, 0.2000741]\n",
      "[0.60085624, 0.2, 0.20030013, 0.20030975]\n",
      "[0.60072136, 0.2, 0.20008516, 0.20038687]\n",
      "[0.60084224, 0.2, 0.20032468, 0.20026524]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10460 iterations: 2.632419200738271 mins\n",
      "Train Loss: [0.60084224, 0.2, 0.20032468, 0.20026524]\n",
      "[0.60043365, 0.2, 0.20006092, 0.20011765]\n",
      "[0.60077006, 0.2, 0.20024817, 0.20026352]\n",
      "[0.60063326, 0.2, 0.20011805, 0.2002535]\n",
      "[0.6006571, 0.2, 0.2001084, 0.2002842]\n",
      "[0.6004917, 0.2, 0.20019351, 0.20003147]\n",
      "[0.6011151, 0.2, 0.200394, 0.20045263]\n",
      "[0.6005901, 0.2, 0.2001747, 0.20014615]\n",
      "[0.60064805, 0.2, 0.20011507, 0.2002629]\n",
      "[0.6004782, 0.2, 0.20005004, 0.20015691]\n",
      "[0.6006762, 0.2, 0.2001737, 0.20023005]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10470 iterations: 2.6343998312950134 mins\n",
      "Train Loss: [0.6006762, 0.2, 0.2001737, 0.20023005]\n",
      "[0.6004911, 0.2, 0.20002027, 0.20019743]\n",
      "[0.60055965, 0.2, 0.20011455, 0.20017068]\n",
      "[0.60055894, 0.2, 0.20019285, 0.20009115]\n",
      "[0.60068375, 0.2, 0.20020644, 0.20020194]\n",
      "[0.6007173, 0.2, 0.20015594, 0.20028567]\n",
      "[0.6006276, 0.2, 0.20015876, 0.20019312]\n",
      "[0.6007076, 0.2, 0.20034303, 0.2000888]\n",
      "[0.6005015, 0.2, 0.20011182, 0.2001138]\n",
      "[0.6008296, 0.2, 0.20040467, 0.20014875]\n",
      "[0.60043794, 0.2, 0.2001274, 0.20003456]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10480 iterations: 2.636382750670115 mins\n",
      "Train Loss: [0.60043794, 0.2, 0.2001274, 0.20003456]\n",
      "[0.6006491, 0.2, 0.20004056, 0.20033276]\n",
      "[0.600478, 0.2, 0.20011184, 0.20009059]\n",
      "[0.600685, 0.2, 0.20018397, 0.20022507]\n",
      "[0.6004429, 0.2, 0.20011452, 0.20005222]\n",
      "[0.60067165, 0.2, 0.20011474, 0.20028047]\n",
      "[0.6006095, 0.2, 0.20010905, 0.20022371]\n",
      "[0.60064435, 0.2, 0.20013765, 0.20022911]\n",
      "[0.6005301, 0.2, 0.20014533, 0.2001061]\n",
      "[0.60044456, 0.2, 0.20009752, 0.2000673]\n",
      "[0.60050094, 0.2, 0.2001482, 0.20007205]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10490 iterations: 2.638207117716471 mins\n",
      "Train Loss: [0.60050094, 0.2, 0.2001482, 0.20007205]\n",
      "[0.60058707, 0.2, 0.20019366, 0.20011178]\n",
      "[0.6008076, 0.2, 0.20014156, 0.20038334]\n",
      "[0.6004967, 0.2, 0.20010598, 0.200107]\n",
      "[0.60076207, 0.2, 0.20012447, 0.20035273]\n",
      "[0.60046893, 0.2, 0.20004627, 0.2001368]\n",
      "[0.60075265, 0.2, 0.2001927, 0.20027295]\n",
      "[0.6008394, 0.2, 0.20028886, 0.20026262]\n",
      "[0.60059726, 0.2, 0.20022427, 0.20008424]\n",
      "[0.60067326, 0.2, 0.20014073, 0.20024268]\n",
      "[0.60067016, 0.2, 0.20029195, 0.20008703]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10500 iterations: 2.640256714820862 mins\n",
      "Train Loss: [0.60067016, 0.2, 0.20029195, 0.20008703]\n",
      "[0.60082495, 0.2, 0.2000965, 0.20043604]\n",
      "[0.60054356, 0.2, 0.20012635, 0.20012344]\n",
      "[0.6008228, 0.2, 0.20025381, 0.2002733]\n",
      "[0.6007654, 0.2, 0.20012543, 0.20034206]\n",
      "[0.60058564, 0.2, 0.20007274, 0.20021231]\n",
      "[0.60056466, 0.2, 0.20014232, 0.20011881]\n",
      "[0.60095286, 0.2, 0.20047872, 0.2001675]\n",
      "[0.6006332, 0.2, 0.20010193, 0.20022239]\n",
      "[0.6009331, 0.2, 0.20031776, 0.20030409]\n",
      "[0.60122854, 0.2, 0.20062146, 0.20029347]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10510 iterations: 2.6421589851379395 mins\n",
      "Train Loss: [0.60122854, 0.2, 0.20062146, 0.20029347]\n",
      "[0.6005873, 0.2, 0.20007835, 0.20019296]\n",
      "[0.6007656, 0.2, 0.20028828, 0.20015813]\n",
      "[0.6008427, 0.2, 0.20032623, 0.20019306]\n",
      "[0.60074735, 0.2, 0.20034494, 0.20007367]\n",
      "[0.60065496, 0.2, 0.20026235, 0.20005774]\n",
      "[0.600457, 0.2, 0.20002764, 0.20008798]\n",
      "[0.6008385, 0.2, 0.20039603, 0.2000944]\n",
      "[0.60069066, 0.2, 0.20012198, 0.20021427]\n",
      "[0.6005308, 0.2, 0.20005049, 0.20011993]\n",
      "[0.6008513, 0.2, 0.20035464, 0.2001306]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10520 iterations: 2.6441208322842917 mins\n",
      "Train Loss: [0.6008513, 0.2, 0.20035464, 0.2001306]\n",
      "[0.60070634, 0.2, 0.20019573, 0.20013973]\n",
      "[0.6008346, 0.2, 0.20025477, 0.20020472]\n",
      "[0.6009269, 0.2, 0.20041236, 0.20013571]\n",
      "[0.6006088, 0.2, 0.20013507, 0.20009144]\n",
      "[0.6010394, 0.2, 0.20041934, 0.20023435]\n",
      "[0.60095835, 0.2, 0.20037372, 0.20019513]\n",
      "[0.6010649, 0.2, 0.20036834, 0.2003035]\n",
      "[0.60100687, 0.2, 0.20011628, 0.20049366]\n",
      "[0.6010631, 0.2, 0.20004933, 0.20061217]\n",
      "[0.60134023, 0.2, 0.20040053, 0.2005329]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10530 iterations: 2.646065413951874 mins\n",
      "Train Loss: [0.60134023, 0.2, 0.20040053, 0.2005329]\n",
      "[0.6044286, 0.2, 0.20241684, 0.2015995]\n",
      "[0.6018347, 0.2, 0.20033653, 0.20107928]\n",
      "[0.6014904, 0.2, 0.20041114, 0.20065236]\n",
      "[0.6015258, 0.2, 0.20042638, 0.20066333]\n",
      "[0.6017618, 0.2, 0.20051192, 0.20080316]\n",
      "[0.6012816, 0.2, 0.20069948, 0.20012446]\n",
      "[0.60197943, 0.2, 0.2006236, 0.20088647]\n",
      "[0.60306525, 0.2, 0.20196478, 0.20061854]\n",
      "[0.6013471, 0.2, 0.20027888, 0.20057422]\n",
      "[0.6022775, 0.2, 0.20163637, 0.20013484]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10540 iterations: 2.6484896659851076 mins\n",
      "Train Loss: [0.6022775, 0.2, 0.20163637, 0.20013484]\n",
      "[0.600947, 0.2, 0.20019457, 0.20023395]\n",
      "[0.6017498, 0.2, 0.20106988, 0.20014854]\n",
      "[0.6013201, 0.2, 0.20023817, 0.20053756]\n",
      "[0.6015349, 0.2, 0.20081308, 0.2001651]\n",
      "[0.6010415, 0.2, 0.20018145, 0.20029202]\n",
      "[0.601582, 0.2, 0.20014408, 0.20085977]\n",
      "[0.6012641, 0.2, 0.20028095, 0.20039593]\n",
      "[0.6009494, 0.2, 0.20029745, 0.2000566]\n",
      "[0.60099685, 0.2, 0.20029731, 0.2000974]\n",
      "[0.6007545, 0.2, 0.20006095, 0.20008582]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10550 iterations: 2.6505602677663167 mins\n",
      "Train Loss: [0.6007545, 0.2, 0.20006095, 0.20008582]\n",
      "[0.6009967, 0.2, 0.20007603, 0.20030856]\n",
      "[0.60095125, 0.2, 0.20011063, 0.20022547]\n",
      "[0.6012762, 0.2, 0.20048322, 0.20017588]\n",
      "[0.6008564, 0.2, 0.20003994, 0.20019871]\n",
      "[0.60109115, 0.2, 0.20024392, 0.20022966]\n",
      "[0.6010048, 0.2, 0.2002261, 0.2001622]\n",
      "[0.60119164, 0.2, 0.20018375, 0.20039411]\n",
      "[0.6009955, 0.2, 0.20026164, 0.20012373]\n",
      "[0.6010413, 0.2, 0.20015736, 0.20027831]\n",
      "[0.60112804, 0.2, 0.20017111, 0.20035589]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10560 iterations: 2.6523969809214276 mins\n",
      "Train Loss: [0.60112804, 0.2, 0.20017111, 0.20035589]\n",
      "[0.60080063, 0.2, 0.20012702, 0.20007746]\n",
      "[0.60089546, 0.2, 0.20015308, 0.20015128]\n",
      "[0.6009634, 0.2, 0.20021462, 0.2001633]\n",
      "[0.6008578, 0.2, 0.20008086, 0.20019794]\n",
      "[0.6007234, 0.2, 0.20007084, 0.20008048]\n",
      "[0.60074127, 0.2, 0.20009354, 0.20008303]\n",
      "[0.6008714, 0.2, 0.20011029, 0.20020406]\n",
      "[0.6011253, 0.2, 0.20031743, 0.20025867]\n",
      "[0.60076505, 0.2, 0.2000986, 0.20012523]\n",
      "[0.60076904, 0.2, 0.20014492, 0.20009111]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10570 iterations: 2.6544617493947347 mins\n",
      "Train Loss: [0.60076904, 0.2, 0.20014492, 0.20009111]\n",
      "[0.6008375, 0.2, 0.20015576, 0.20015709]\n",
      "[0.60073, 0.2, 0.20012917, 0.20008476]\n",
      "[0.6009123, 0.2, 0.20021701, 0.2001879]\n",
      "[0.6008234, 0.2, 0.2001505, 0.2001745]\n",
      "[0.6007273, 0.2, 0.20012298, 0.20011504]\n",
      "[0.6009957, 0.2, 0.2001483, 0.20036708]\n",
      "[0.6007034, 0.2, 0.20002747, 0.20020463]\n",
      "[0.60069543, 0.2, 0.20019841, 0.20003445]\n",
      "[0.60068506, 0.2, 0.20008251, 0.20014872]\n",
      "[0.6006322, 0.2, 0.20015728, 0.2000296]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10580 iterations: 2.656289784113566 mins\n",
      "Train Loss: [0.6006322, 0.2, 0.20015728, 0.2000296]\n",
      "[0.6009161, 0.2, 0.20020837, 0.200271]\n",
      "[0.6007726, 0.2, 0.20025747, 0.20008685]\n",
      "[0.6007187, 0.2, 0.20023291, 0.20006551]\n",
      "[0.6008993, 0.2, 0.20005138, 0.20043522]\n",
      "[0.6007421, 0.2, 0.20022854, 0.20010829]\n",
      "[0.6005628, 0.2, 0.20008703, 0.2000778]\n",
      "[0.600647, 0.2, 0.20015474, 0.2001011]\n",
      "[0.60059494, 0.2, 0.20011759, 0.2000927]\n",
      "[0.60062045, 0.2, 0.20018205, 0.20006002]\n",
      "[0.60066444, 0.2, 0.20008422, 0.20020775]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10590 iterations: 2.65845764875412 mins\n",
      "Train Loss: [0.60066444, 0.2, 0.20008422, 0.20020775]\n",
      "[0.6009429, 0.2, 0.20011747, 0.20045859]\n",
      "[0.6009554, 0.2, 0.20028292, 0.20031099]\n",
      "[0.60090023, 0.2, 0.20035186, 0.20019187]\n",
      "[0.6006948, 0.2, 0.20019326, 0.2001498]\n",
      "[0.6006384, 0.2, 0.20018776, 0.20010334]\n",
      "[0.60055804, 0.2, 0.20008083, 0.20013401]\n",
      "[0.6007968, 0.2, 0.20028956, 0.2001679]\n",
      "[0.60045373, 0.2, 0.20006496, 0.2000536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6004764, 0.2, 0.20007281, 0.2000725]\n",
      "[0.60053694, 0.2, 0.20012532, 0.20008485]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10600 iterations: 2.6604354977607727 mins\n",
      "Train Loss: [0.60053694, 0.2, 0.20012532, 0.20008485]\n",
      "[0.60041064, 0.2, 0.20003156, 0.20005675]\n",
      "[0.6004752, 0.2, 0.20004524, 0.20011216]\n",
      "[0.60068, 0.2, 0.20012124, 0.20024553]\n",
      "[0.6004166, 0.2, 0.20008993, 0.2000182]\n",
      "[0.60052943, 0.2, 0.20005602, 0.20016968]\n",
      "[0.6007162, 0.2, 0.20026374, 0.20015368]\n",
      "[0.60050374, 0.2, 0.20007885, 0.20013091]\n",
      "[0.60042053, 0.2, 0.20004824, 0.20008276]\n",
      "[0.60037196, 0.2, 0.20003521, 0.20005162]\n",
      "[0.6005191, 0.2, 0.20003542, 0.20020257]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10610 iterations: 2.6623639663060508 mins\n",
      "Train Loss: [0.6005191, 0.2, 0.20003542, 0.20020257]\n",
      "[0.6004493, 0.2, 0.2000509, 0.20012116]\n",
      "[0.6006033, 0.2, 0.20019424, 0.20013542]\n",
      "[0.60056996, 0.2, 0.20011151, 0.20018837]\n",
      "[0.60047144, 0.2, 0.20014955, 0.20005515]\n",
      "[0.6005554, 0.2, 0.20006877, 0.20022297]\n",
      "[0.60059255, 0.2, 0.2001793, 0.20015244]\n",
      "[0.6006462, 0.2, 0.20008434, 0.20030375]\n",
      "[0.6003403, 0.2, 0.20005438, 0.20003067]\n",
      "[0.60084593, 0.2, 0.20030594, 0.20028757]\n",
      "[0.6005187, 0.2, 0.2002299, 0.20003948]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10620 iterations: 2.6657154162724814 mins\n",
      "Train Loss: [0.6005187, 0.2, 0.2002299, 0.20003948]\n",
      "[0.6003354, 0.2, 0.20005192, 0.20003696]\n",
      "[0.60045195, 0.2, 0.20016116, 0.20004688]\n",
      "[0.6005296, 0.2, 0.2000562, 0.20023195]\n",
      "[0.6004532, 0.2, 0.20007062, 0.20014347]\n",
      "[0.6003992, 0.2, 0.20005496, 0.20010737]\n",
      "[0.6004916, 0.2, 0.20016357, 0.20009322]\n",
      "[0.60040015, 0.2, 0.20010094, 0.20006657]\n",
      "[0.6002784, 0.2, 0.20002894, 0.20001891]\n",
      "[0.60032827, 0.2, 0.20005567, 0.20004417]\n",
      "[0.6003905, 0.2, 0.20003827, 0.20012599]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10630 iterations: 2.6676210800806683 mins\n",
      "Train Loss: [0.6003905, 0.2, 0.20003827, 0.20012599]\n",
      "[0.6005003, 0.2, 0.20019935, 0.20007709]\n",
      "[0.6003742, 0.2, 0.20008594, 0.2000671]\n",
      "[0.6003068, 0.2, 0.20005316, 0.20003502]\n",
      "[0.60035187, 0.2, 0.20001808, 0.20011775]\n",
      "[0.6003863, 0.2, 0.20007512, 0.2000978]\n",
      "[0.6003414, 0.2, 0.20008478, 0.20004584]\n",
      "[0.6003296, 0.2, 0.2000807, 0.20004076]\n",
      "[0.6004129, 0.2, 0.20008421, 0.20012303]\n",
      "[0.60042316, 0.2, 0.20012982, 0.20009027]\n",
      "[0.600317, 0.2, 0.20002836, 0.20008808]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10640 iterations: 2.669625397523244 mins\n",
      "Train Loss: [0.600317, 0.2, 0.20002836, 0.20008808]\n",
      "[0.60047233, 0.2, 0.20012361, 0.20015064]\n",
      "[0.60031, 0.2, 0.20005046, 0.200064]\n",
      "[0.60043555, 0.2, 0.2001267, 0.20011562]\n",
      "[0.6003985, 0.2, 0.2000693, 0.2001382]\n",
      "[0.6003851, 0.2, 0.20012759, 0.20006889]\n",
      "[0.6003688, 0.2, 0.2001019, 0.20008045]\n",
      "[0.6003068, 0.2, 0.20006746, 0.20005503]\n",
      "[0.600327, 0.2, 0.20006463, 0.20007999]\n",
      "[0.6003858, 0.2, 0.20010398, 0.20010124]\n",
      "[0.60033035, 0.2, 0.20008226, 0.20006959]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10650 iterations: 2.6715261975924176 mins\n",
      "Train Loss: [0.60033035, 0.2, 0.20008226, 0.20006959]\n",
      "[0.6003337, 0.2, 0.20005874, 0.20009838]\n",
      "[0.6003964, 0.2, 0.20010312, 0.20011865]\n",
      "[0.6002777, 0.2, 0.20006023, 0.20004454]\n",
      "[0.60020643, 0.2, 0.20002161, 0.20001335]\n",
      "[0.60051227, 0.2, 0.20025867, 0.20008333]\n",
      "[0.600387, 0.2, 0.20011267, 0.20010504]\n",
      "[0.60059065, 0.2, 0.20017684, 0.20024505]\n",
      "[0.6003364, 0.2, 0.20016144, 0.20000625]\n",
      "[0.6004859, 0.2, 0.20008561, 0.20023116]\n",
      "[0.6004661, 0.2, 0.20008291, 0.2002133]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10660 iterations: 2.6734636664390563 mins\n",
      "Train Loss: [0.6004661, 0.2, 0.20008291, 0.2002133]\n",
      "[0.60055494, 0.2, 0.20023285, 0.20015131]\n",
      "[0.60035056, 0.2, 0.20005679, 0.20012203]\n",
      "[0.600487, 0.2, 0.20014091, 0.20017335]\n",
      "[0.60036206, 0.2, 0.2000924, 0.20009606]\n",
      "[0.6004621, 0.2, 0.20014204, 0.20014572]\n",
      "[0.60046107, 0.2, 0.20022534, 0.20006078]\n",
      "[0.6004546, 0.2, 0.20009495, 0.20018409]\n",
      "[0.60026145, 0.2, 0.20005092, 0.20003435]\n",
      "[0.60074997, 0.2, 0.20019197, 0.20038106]\n",
      "[0.60090303, 0.2, 0.20014837, 0.2005771]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10670 iterations: 2.675485348701477 mins\n",
      "Train Loss: [0.60090303, 0.2, 0.20014837, 0.2005771]\n",
      "[0.600688, 0.2, 0.20004968, 0.20046008]\n",
      "[0.60091823, 0.2, 0.20025823, 0.20048083]\n",
      "[0.60036206, 0.2, 0.20012264, 0.20005906]\n",
      "[0.60032916, 0.2, 0.20010944, 0.2000379]\n",
      "[0.600366, 0.2, 0.20003195, 0.2001506]\n",
      "[0.60037756, 0.2, 0.20009275, 0.20009954]\n",
      "[0.6004758, 0.2, 0.2002271, 0.20006174]\n",
      "[0.6003793, 0.2, 0.20004939, 0.2001414]\n",
      "[0.6006109, 0.2, 0.20024869, 0.20017228]\n",
      "[0.60032445, 0.2, 0.20005357, 0.20007974]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10680 iterations: 2.677332949638367 mins\n",
      "Train Loss: [0.60032445, 0.2, 0.20005357, 0.20007974]\n",
      "[0.6003388, 0.2, 0.20006905, 0.20007733]\n",
      "[0.6003908, 0.2, 0.20006946, 0.20012769]\n",
      "[0.6004965, 0.2, 0.2001501, 0.2001516]\n",
      "[0.6006238, 0.2, 0.20018153, 0.20024644]\n",
      "[0.60075444, 0.2, 0.2003453, 0.20021236]\n",
      "[0.60047734, 0.2, 0.20010796, 0.20017184]\n",
      "[0.60036314, 0.2, 0.20006727, 0.20009758]\n",
      "[0.60067284, 0.2, 0.20031184, 0.20016204]\n",
      "[0.6006002, 0.2, 0.20022129, 0.20017935]\n",
      "[0.6007657, 0.2, 0.20032543, 0.2002403]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10690 iterations: 2.679383667310079 mins\n",
      "Train Loss: [0.6007657, 0.2, 0.20032543, 0.2002403]\n",
      "[0.6004419, 0.2, 0.20019509, 0.20004664]\n",
      "[0.60061395, 0.2, 0.20008828, 0.20032547]\n",
      "[0.60045934, 0.2, 0.20014124, 0.2001182]\n",
      "[0.6003461, 0.2, 0.20008071, 0.20006585]\n",
      "[0.6003803, 0.2, 0.20008352, 0.20009758]\n",
      "[0.6005159, 0.2, 0.2002289, 0.20008822]\n",
      "[0.6008264, 0.2, 0.200391, 0.20023698]\n",
      "[0.6004126, 0.2, 0.20009644, 0.2001181]\n",
      "[0.60039866, 0.2, 0.20011953, 0.2000811]\n",
      "[0.60039467, 0.2, 0.20005609, 0.20014052]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10700 iterations: 2.681712234020233 mins\n",
      "Train Loss: [0.60039467, 0.2, 0.20005609, 0.20014052]\n",
      "[0.6005593, 0.2, 0.20013951, 0.20022146]\n",
      "[0.60031545, 0.2, 0.20008792, 0.20002918]\n",
      "[0.6003209, 0.2, 0.20008673, 0.2000357]\n",
      "[0.600656, 0.2, 0.200151, 0.20030661]\n",
      "[0.60052806, 0.2, 0.20030284, 0.20002706]\n",
      "[0.60033816, 0.2, 0.20005427, 0.20008582]\n",
      "[0.6004687, 0.2, 0.20024627, 0.20002444]\n",
      "[0.6006266, 0.2, 0.20021996, 0.20020875]\n",
      "[0.6002987, 0.2, 0.20002821, 0.20007285]\n",
      "[0.6004373, 0.2, 0.2000894, 0.20015055]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10710 iterations: 2.6837130149205524 mins\n",
      "Train Loss: [0.6004373, 0.2, 0.2000894, 0.20015055]\n",
      "[0.60034364, 0.2, 0.20004974, 0.20009692]\n",
      "[0.600526, 0.2, 0.20020361, 0.2001258]\n",
      "[0.6003308, 0.2, 0.20003209, 0.2001026]\n",
      "[0.6004172, 0.2, 0.20013621, 0.20008534]\n",
      "[0.60048425, 0.2, 0.20021385, 0.20007536]\n",
      "[0.60036963, 0.2, 0.20010997, 0.20006548]\n",
      "[0.60049903, 0.2, 0.2000763, 0.20022948]\n",
      "[0.60037655, 0.2, 0.20005406, 0.20013034]\n",
      "[0.6002985, 0.2, 0.20002605, 0.20008157]\n",
      "[0.60033476, 0.2, 0.20009178, 0.20005329]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10720 iterations: 2.6856196522712708 mins\n",
      "Train Loss: [0.60033476, 0.2, 0.20009178, 0.20005329]\n",
      "[0.6002703, 0.2, 0.2000664, 0.20001544]\n",
      "[0.6003648, 0.2, 0.20004447, 0.20013331]\n",
      "[0.60040927, 0.2, 0.20015985, 0.20006388]\n",
      "[0.600313, 0.2, 0.20011178, 0.20001732]\n",
      "[0.60035074, 0.2, 0.20007922, 0.20008923]\n",
      "[0.6003013, 0.2, 0.20007098, 0.20004982]\n",
      "[0.60040206, 0.2, 0.2001141, 0.20010912]\n",
      "[0.60034573, 0.2, 0.20002069, 0.20014803]\n",
      "[0.6003338, 0.2, 0.2000512, 0.20010741]\n",
      "[0.60027885, 0.2, 0.20003553, 0.20007007]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10730 iterations: 2.6876299818356832 mins\n",
      "Train Loss: [0.60027885, 0.2, 0.20003553, 0.20007007]\n",
      "[0.6003785, 0.2, 0.20010976, 0.20009732]\n",
      "[0.600288, 0.2, 0.20006916, 0.20004918]\n",
      "[0.6003782, 0.2, 0.2000932, 0.20011723]\n",
      "[0.6003026, 0.2, 0.20010279, 0.20003377]\n",
      "[0.6002938, 0.2, 0.20007421, 0.20005535]\n",
      "[0.60024637, 0.2, 0.20005034, 0.20003352]\n",
      "[0.60026574, 0.2, 0.20004123, 0.20006369]\n",
      "[0.60020417, 0.2, 0.20001304, 0.20003203]\n",
      "[0.6003094, 0.2, 0.20004116, 0.20011076]\n",
      "[0.60028505, 0.2, 0.20004936, 0.2000799]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10740 iterations: 2.689664602279663 mins\n",
      "Train Loss: [0.60028505, 0.2, 0.20004936, 0.2000799]\n",
      "[0.60037833, 0.2, 0.2000942, 0.20012993]\n",
      "[0.60018754, 0.2, 0.200013, 0.20002182]\n",
      "[0.6003807, 0.2, 0.20006928, 0.20016007]\n",
      "[0.6002294, 0.2, 0.20002691, 0.2000524]\n",
      "[0.6003048, 0.2, 0.20006326, 0.20009255]\n",
      "[0.6004136, 0.2, 0.20015667, 0.200109]\n",
      "[0.6002253, 0.2, 0.20005251, 0.20002593]\n",
      "[0.6002674, 0.2, 0.20006223, 0.20005935]\n",
      "[0.6002748, 0.2, 0.20003124, 0.20009877]\n",
      "[0.60021853, 0.2, 0.2, 0.20007479]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10750 iterations: 2.6915433327356975 mins\n",
      "Train Loss: [0.60021853, 0.2, 0.2, 0.20007479]\n",
      "[0.60023844, 0.2, 0.20006785, 0.2000278]\n",
      "[0.60022706, 0.2, 0.20004766, 0.2000375]\n",
      "[0.60032505, 0.2, 0.20006193, 0.20012207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60031605, 0.2, 0.20007478, 0.2001012]\n",
      "[0.6005622, 0.2, 0.20039524, 0.20002772]\n",
      "[0.60026425, 0.2, 0.20004962, 0.20007615]\n",
      "[0.60025316, 0.2, 0.20006783, 0.20004746]\n",
      "[0.60027224, 0.2, 0.20009671, 0.20003822]\n",
      "[0.60052407, 0.2, 0.2002093, 0.20017792]\n",
      "[0.6006492, 0.2, 0.20032924, 0.20018342]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10760 iterations: 2.6935226639111836 mins\n",
      "Train Loss: [0.6006492, 0.2, 0.20032924, 0.20018342]\n",
      "[0.60039616, 0.2, 0.2001689, 0.20009081]\n",
      "[0.60036194, 0.2, 0.2000816, 0.20014332]\n",
      "[0.6003477, 0.2, 0.20011787, 0.20009178]\n",
      "[0.60031337, 0.2, 0.20010053, 0.20007348]\n",
      "[0.60037905, 0.2, 0.20013611, 0.20010193]\n",
      "[0.60028255, 0.2, 0.20004624, 0.20009363]\n",
      "[0.6002365, 0.2, 0.20005026, 0.20004176]\n",
      "[0.60052586, 0.2, 0.20009765, 0.20028204]\n",
      "[0.6004611, 0.2, 0.20013784, 0.20017551]\n",
      "[0.60035455, 0.2, 0.20009644, 0.20010899]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10770 iterations: 2.6953911662101744 mins\n",
      "Train Loss: [0.60035455, 0.2, 0.20009644, 0.20010899]\n",
      "[0.6003222, 0.2, 0.2001274, 0.20004442]\n",
      "[0.6003608, 0.2, 0.20005132, 0.20015799]\n",
      "[0.6002648, 0.2, 0.20002607, 0.20008613]\n",
      "[0.60036486, 0.2, 0.20009889, 0.20011246]\n",
      "[0.60028476, 0.2, 0.20005126, 0.20007914]\n",
      "[0.6004179, 0.2, 0.20005085, 0.20021188]\n",
      "[0.60025007, 0.2, 0.2000479, 0.2000463]\n",
      "[0.6003861, 0.2, 0.20008522, 0.20014437]\n",
      "[0.6002819, 0.2, 0.20004757, 0.20007713]\n",
      "[0.60038316, 0.2, 0.20014632, 0.2000791]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10780 iterations: 2.698043163617452 mins\n",
      "Train Loss: [0.60038316, 0.2, 0.20014632, 0.2000791]\n",
      "[0.6005752, 0.2, 0.20030113, 0.20011596]\n",
      "[0.60041666, 0.2, 0.20007922, 0.20017907]\n",
      "[0.60050535, 0.2, 0.20004874, 0.2002978]\n",
      "[0.6005275, 0.2, 0.20018184, 0.2001865]\n",
      "[0.6003983, 0.2, 0.20013715, 0.20010117]\n",
      "[0.6010777, 0.2, 0.20007388, 0.20084274]\n",
      "[0.60040325, 0.2, 0.20015822, 0.20008215]\n",
      "[0.600682, 0.2, 0.20022132, 0.20029522]\n",
      "[0.60066426, 0.2, 0.20028509, 0.20021027]\n",
      "[0.60111195, 0.2, 0.20067582, 0.20026287]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10790 iterations: 2.7001264691352844 mins\n",
      "Train Loss: [0.60111195, 0.2, 0.20067582, 0.20026287]\n",
      "[0.6012132, 0.2, 0.2009489, 0.20008604]\n",
      "[0.6016159, 0.2, 0.20058842, 0.20084369]\n",
      "[0.6008795, 0.2, 0.2002906, 0.20039923]\n",
      "[0.6007335, 0.2, 0.20045722, 0.20008036]\n",
      "[0.6006869, 0.2, 0.20042345, 0.20006134]\n",
      "[0.6005977, 0.2, 0.20011465, 0.2002745]\n",
      "[0.60064155, 0.2, 0.20024748, 0.20017885]\n",
      "[0.60055566, 0.2, 0.20018788, 0.20014608]\n",
      "[0.60041314, 0.2, 0.20001164, 0.20017345]\n",
      "[0.60057247, 0.2, 0.20019022, 0.20014827]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10800 iterations: 2.70199978351593 mins\n",
      "Train Loss: [0.60057247, 0.2, 0.20019022, 0.20014827]\n",
      "[0.60053086, 0.2, 0.2001678, 0.20012377]\n",
      "[0.6006396, 0.2, 0.20033972, 0.20005585]\n",
      "[0.6006112, 0.2, 0.20025313, 0.20010978]\n",
      "[0.60061896, 0.2, 0.20019245, 0.20017447]\n",
      "[0.6006342, 0.2, 0.2000986, 0.20028007]\n",
      "[0.6007513, 0.2, 0.20036034, 0.20013227]\n",
      "[0.60073876, 0.2, 0.20032845, 0.20014873]\n",
      "[0.6006117, 0.2, 0.20017193, 0.20017558]\n",
      "[0.60071355, 0.2, 0.20010117, 0.20034574]\n",
      "[0.60141045, 0.2, 0.20031591, 0.20082581]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10810 iterations: 2.7040013988812763 mins\n",
      "Train Loss: [0.60141045, 0.2, 0.20031591, 0.20082581]\n",
      "[0.6006404, 0.2, 0.2002592, 0.20011047]\n",
      "[0.60039526, 0.2, 0.20011303, 0.20000967]\n",
      "[0.6006034, 0.2, 0.20017117, 0.20015807]\n",
      "[0.6003972, 0.2, 0.20002446, 0.20009732]\n",
      "[0.6005476, 0.2, 0.20018137, 0.20008975]\n",
      "[0.60043174, 0.2, 0.20003505, 0.20011948]\n",
      "[0.60038733, 0.2, 0.20002882, 0.20008093]\n",
      "[0.60071397, 0.2, 0.20039202, 0.20004438]\n",
      "[0.6007508, 0.2, 0.20040518, 0.20006828]\n",
      "[0.6005651, 0.2, 0.20018174, 0.20010638]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10820 iterations: 2.705863849322001 mins\n",
      "Train Loss: [0.6005651, 0.2, 0.20018174, 0.20010638]\n",
      "[0.6004858, 0.2, 0.2001103, 0.20009926]\n",
      "[0.60044605, 0.2, 0.2000651, 0.20010568]\n",
      "[0.60055417, 0.2, 0.20020843, 0.20007168]\n",
      "[0.6004218, 0.2, 0.20006876, 0.20008038]\n",
      "[0.6003931, 0.2, 0.20007728, 0.2000448]\n",
      "[0.6006326, 0.2, 0.20016724, 0.2001963]\n",
      "[0.60036886, 0.2, 0.20004031, 0.20006146]\n",
      "[0.6004353, 0.2, 0.20006092, 0.20010945]\n",
      "[0.6004925, 0.2, 0.20006813, 0.20016171]\n",
      "[0.60046434, 0.2, 0.20015787, 0.20004624]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10830 iterations: 2.7079471667607624 mins\n",
      "Train Loss: [0.60046434, 0.2, 0.20015787, 0.20004624]\n",
      "[0.60035354, 0.2, 0.20006596, 0.20002976]\n",
      "[0.6003913, 0.2, 0.20003882, 0.20009717]\n",
      "[0.6005577, 0.2, 0.20015264, 0.20015247]\n",
      "[0.6003615, 0.2, 0.20001149, 0.20010011]\n",
      "[0.60042965, 0.2, 0.20009731, 0.20008524]\n",
      "[0.600367, 0.2, 0.20007238, 0.20005034]\n",
      "[0.60043705, 0.2, 0.2000903, 0.20010535]\n",
      "[0.6005375, 0.2, 0.20014247, 0.20015647]\n",
      "[0.6004142, 0.2, 0.20016055, 0.20001791]\n",
      "[0.6003079, 0.2, 0.20000343, 0.20007154]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10840 iterations: 2.7099127491315205 mins\n",
      "Train Loss: [0.6003079, 0.2, 0.20000343, 0.20007154]\n",
      "[0.60040104, 0.2, 0.20003106, 0.20014004]\n",
      "[0.60052216, 0.2, 0.20021059, 0.20008452]\n",
      "[0.6003724, 0.2, 0.20003685, 0.20011131]\n",
      "[0.6005603, 0.2, 0.20008372, 0.20025533]\n",
      "[0.6004939, 0.2, 0.20005496, 0.20022048]\n",
      "[0.6004007, 0.2, 0.20008557, 0.20009941]\n",
      "[0.6003689, 0.2, 0.20005324, 0.20010261]\n",
      "[0.60035634, 0.2, 0.20003262, 0.20011336]\n",
      "[0.60036814, 0.2, 0.20011476, 0.20004573]\n",
      "[0.6003883, 0.2, 0.20011073, 0.20007272]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10850 iterations: 2.7119404474894204 mins\n",
      "Train Loss: [0.6003883, 0.2, 0.20011073, 0.20007272]\n",
      "[0.60035056, 0.2, 0.20007019, 0.20007817]\n",
      "[0.6003655, 0.2, 0.20007372, 0.20009233]\n",
      "[0.60040605, 0.2, 0.20012929, 0.20007995]\n",
      "[0.6003026, 0.2, 0.20005108, 0.20005742]\n",
      "[0.60026294, 0.2, 0.20004423, 0.20002727]\n",
      "[0.60032254, 0.2, 0.2000795, 0.20005415]\n",
      "[0.6002287, 0.2, 0.20001356, 0.20002882]\n",
      "[0.6003536, 0.2, 0.20010334, 0.20006639]\n",
      "[0.60034335, 0.2, 0.20006731, 0.20009443]\n",
      "[0.600444, 0.2, 0.2001562, 0.20010863]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10860 iterations: 2.7144147833188375 mins\n",
      "Train Loss: [0.600444, 0.2, 0.2001562, 0.20010863]\n",
      "[0.6002212, 0.2, 0.20002228, 0.2000219]\n",
      "[0.60047704, 0.2, 0.20019737, 0.20010458]\n",
      "[0.60029244, 0.2, 0.20007487, 0.20004438]\n",
      "[0.6003123, 0.2, 0.20004082, 0.20009983]\n",
      "[0.6003601, 0.2, 0.20008321, 0.2001065]\n",
      "[0.60029924, 0.2, 0.20005672, 0.20007321]\n",
      "[0.6004317, 0.2, 0.20016, 0.20010333]\n",
      "[0.6003391, 0.2, 0.2000284, 0.20014337]\n",
      "[0.6005788, 0.2, 0.20031375, 0.2000986]\n",
      "[0.60039073, 0.2, 0.2000532, 0.20017184]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10870 iterations: 2.7162805835405988 mins\n",
      "Train Loss: [0.60039073, 0.2, 0.2000532, 0.20017184]\n",
      "[0.60032374, 0.2, 0.20003359, 0.20012504]\n",
      "[0.60045034, 0.2, 0.20007685, 0.20020883]\n",
      "[0.60040694, 0.2, 0.20010129, 0.20014143]\n",
      "[0.6003414, 0.2, 0.20002493, 0.2001527]\n",
      "[0.60030466, 0.2, 0.20009555, 0.2000459]\n",
      "[0.6002424, 0.2, 0.20002867, 0.20005108]\n",
      "[0.60042953, 0.2, 0.20011467, 0.20015295]\n",
      "[0.6002987, 0.2, 0.20008698, 0.2000504]\n",
      "[0.60041696, 0.2, 0.2000743, 0.20018214]\n",
      "[0.60058206, 0.2, 0.20020688, 0.20021553]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10880 iterations: 2.718348519007365 mins\n",
      "Train Loss: [0.60058206, 0.2, 0.20020688, 0.20021553]\n",
      "[0.6003232, 0.2, 0.20010933, 0.20005511]\n",
      "[0.6008594, 0.2, 0.20034954, 0.20035195]\n",
      "[0.6004147, 0.2, 0.200145, 0.20011301]\n",
      "[0.60023534, 0.2, 0.20003034, 0.20004915]\n",
      "[0.60035485, 0.2, 0.20007455, 0.200125]\n",
      "[0.6003089, 0.2, 0.20006375, 0.20009021]\n",
      "[0.60026634, 0.2, 0.20007952, 0.20003219]\n",
      "[0.6002353, 0.2, 0.20002231, 0.20005864]\n",
      "[0.6003056, 0.2, 0.20006433, 0.20008717]\n",
      "[0.60026354, 0.2, 0.200072, 0.2000378]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10890 iterations: 2.72020259698232 mins\n",
      "Train Loss: [0.60026354, 0.2, 0.200072, 0.2000378]\n",
      "[0.6003808, 0.2, 0.20005205, 0.20017542]\n",
      "[0.6003643, 0.2, 0.20007786, 0.20013364]\n",
      "[0.6002633, 0.2, 0.20007676, 0.20003417]\n",
      "[0.6003452, 0.2, 0.20010637, 0.20008682]\n",
      "[0.6003013, 0.2, 0.20009132, 0.20005836]\n",
      "[0.6006959, 0.2, 0.20043154, 0.20011297]\n",
      "[0.6003225, 0.2, 0.20008929, 0.20008197]\n",
      "[0.60051394, 0.2, 0.20014144, 0.20022126]\n",
      "[0.60031426, 0.2, 0.2000884, 0.20007463]\n",
      "[0.6002682, 0.2, 0.20002636, 0.2000904]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10900 iterations: 2.7222054322560627 mins\n",
      "Train Loss: [0.6002682, 0.2, 0.20002636, 0.2000904]\n",
      "[0.6002415, 0.2, 0.20006011, 0.20002972]\n",
      "[0.6003346, 0.2, 0.20005256, 0.20013012]\n",
      "[0.60024685, 0.2, 0.2000636, 0.20003112]\n",
      "[0.60022026, 0.2, 0.20002769, 0.20004037]\n",
      "[0.60023415, 0.2, 0.20003435, 0.20004757]\n",
      "[0.60031635, 0.2, 0.20006195, 0.20010228]\n",
      "[0.60032624, 0.2, 0.20008712, 0.20008726]\n",
      "[0.60032696, 0.2, 0.2000927, 0.20008284]\n",
      "[0.60033643, 0.2, 0.20008181, 0.20010382]\n",
      "[0.6003151, 0.2, 0.20007972, 0.20008528]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10910 iterations: 2.724060869216919 mins\n",
      "Train Loss: [0.6003151, 0.2, 0.20007972, 0.20008528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6002541, 0.2, 0.2000402, 0.2000646]\n",
      "[0.6003074, 0.2, 0.20007199, 0.20008698]\n",
      "[0.60028386, 0.2, 0.20005752, 0.2000787]\n",
      "[0.60028976, 0.2, 0.20007615, 0.20006683]\n",
      "[0.60034007, 0.2, 0.20010059, 0.20009364]\n",
      "[0.6003104, 0.2, 0.20003472, 0.2001307]\n",
      "[0.6003587, 0.2, 0.20012827, 0.20008639]\n",
      "[0.60032076, 0.2, 0.20008136, 0.2000963]\n",
      "[0.60035264, 0.2, 0.20003426, 0.20017615]\n",
      "[0.60030913, 0.2, 0.20009138, 0.20007652]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10920 iterations: 2.726172379652659 mins\n",
      "Train Loss: [0.60030913, 0.2, 0.20009138, 0.20007652]\n",
      "[0.6002608, 0.2, 0.20004267, 0.20007774]\n",
      "[0.60024244, 0.2, 0.20006596, 0.20003709]\n",
      "[0.6002547, 0.2, 0.20006317, 0.200053]\n",
      "[0.600337, 0.2, 0.20008072, 0.20011841]\n",
      "[0.6002617, 0.2, 0.20007429, 0.20005016]\n",
      "[0.60029346, 0.2, 0.20005016, 0.20010655]\n",
      "[0.6002582, 0.2, 0.20008102, 0.20004067]\n",
      "[0.6003273, 0.2, 0.20011947, 0.2000717]\n",
      "[0.6002132, 0.2, 0.20003314, 0.20004424]\n",
      "[0.6002271, 0.2, 0.20003772, 0.20005387]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10930 iterations: 2.728182931741079 mins\n",
      "Train Loss: [0.6002271, 0.2, 0.20003772, 0.20005387]\n",
      "[0.6003886, 0.2, 0.20012407, 0.20012935]\n",
      "[0.6002824, 0.2, 0.20004557, 0.20010196]\n",
      "[0.60039735, 0.2, 0.2001147, 0.20014817]\n",
      "[0.60032654, 0.2, 0.20008145, 0.20011103]\n",
      "[0.6003818, 0.2, 0.20014009, 0.20010792]\n",
      "[0.6004424, 0.2, 0.20006257, 0.20024632]\n",
      "[0.60041153, 0.2, 0.20015049, 0.20012751]\n",
      "[0.6003627, 0.2, 0.20011114, 0.20011783]\n",
      "[0.60027456, 0.2, 0.20007296, 0.20006746]\n",
      "[0.60031223, 0.2, 0.2000312, 0.20014638]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10940 iterations: 2.7302859822909036 mins\n",
      "Train Loss: [0.60031223, 0.2, 0.2000312, 0.20014638]\n",
      "[0.60028356, 0.2, 0.20004092, 0.20010749]\n",
      "[0.6003102, 0.2, 0.20005526, 0.20011918]\n",
      "[0.6004897, 0.2, 0.20012933, 0.2002239]\n",
      "[0.6004697, 0.2, 0.20024799, 0.20008467]\n",
      "[0.60031796, 0.2, 0.2001578, 0.20002264]\n",
      "[0.60035604, 0.2, 0.20016672, 0.20005125]\n",
      "[0.60055363, 0.2, 0.20014562, 0.20026913]\n",
      "[0.60060537, 0.2, 0.20012857, 0.20033698]\n",
      "[0.6004812, 0.2, 0.20013992, 0.20020014]\n",
      "[0.6003769, 0.2, 0.20006865, 0.20016536]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10950 iterations: 2.732586133480072 mins\n",
      "Train Loss: [0.6003769, 0.2, 0.20006865, 0.20016536]\n",
      "[0.60046947, 0.2, 0.2001438, 0.20018087]\n",
      "[0.6003952, 0.2, 0.20013826, 0.20010997]\n",
      "[0.6002968, 0.2, 0.20004608, 0.20010154]\n",
      "[0.6003662, 0.2, 0.20014927, 0.20006546]\n",
      "[0.6003528, 0.2, 0.20007108, 0.20012802]\n",
      "[0.6003445, 0.2, 0.20013243, 0.20005608]\n",
      "[0.6003361, 0.2, 0.20012471, 0.20005307]\n",
      "[0.6002736, 0.2, 0.20007879, 0.20003441]\n",
      "[0.60071564, 0.2, 0.2004352, 0.20011792]\n",
      "[0.6002026, 0.2, 0.20000333, 0.20003499]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10960 iterations: 2.7343962669372557 mins\n",
      "Train Loss: [0.6002026, 0.2, 0.20000333, 0.20003499]\n",
      "[0.6005648, 0.2, 0.200207, 0.20019184]\n",
      "[0.600425, 0.2, 0.20005706, 0.20020068]\n",
      "[0.6006597, 0.2, 0.20020038, 0.20029089]\n",
      "[0.60058093, 0.2, 0.20023856, 0.20017283]\n",
      "[0.60047156, 0.2, 0.20011291, 0.20018823]\n",
      "[0.600272, 0.2, 0.20007622, 0.20002456]\n",
      "[0.60033655, 0.2, 0.20014213, 0.20002227]\n",
      "[0.60038245, 0.2, 0.20005114, 0.20015845]\n",
      "[0.60052955, 0.2, 0.20014863, 0.20020755]\n",
      "[0.6005257, 0.2, 0.20000005, 0.20035166]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10970 iterations: 2.7364365180333454 mins\n",
      "Train Loss: [0.6005257, 0.2, 0.20000005, 0.20035166]\n",
      "[0.60065866, 0.2, 0.20037328, 0.20011084]\n",
      "[0.6006004, 0.2, 0.20024596, 0.20017928]\n",
      "[0.60065216, 0.2, 0.20028515, 0.2001911]\n",
      "[0.6004163, 0.2, 0.20009656, 0.2001432]\n",
      "[0.6004608, 0.2, 0.20012572, 0.20015785]\n",
      "[0.60033435, 0.2, 0.20005459, 0.20010185]\n",
      "[0.6004279, 0.2, 0.20004119, 0.20020816]\n",
      "[0.6006126, 0.2, 0.20013359, 0.20029967]\n",
      "[0.6004041, 0.2, 0.20011999, 0.20010406]\n",
      "[0.6005182, 0.2, 0.20027848, 0.20005877]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10980 iterations: 2.738339634736379 mins\n",
      "Train Loss: [0.6005182, 0.2, 0.20027848, 0.20005877]\n",
      "[0.6006903, 0.2, 0.20034036, 0.20016788]\n",
      "[0.6004896, 0.2, 0.20012058, 0.20018585]\n",
      "[0.600471, 0.2, 0.20007153, 0.20021488]\n",
      "[0.6003593, 0.2, 0.20012431, 0.20004877]\n",
      "[0.6004552, 0.2, 0.20014657, 0.20012085]\n",
      "[0.60057336, 0.2, 0.20008531, 0.20029856]\n",
      "[0.6004389, 0.2, 0.2001302, 0.2001175]\n",
      "[0.6003759, 0.2, 0.20011339, 0.2000699]\n",
      "[0.60043895, 0.2, 0.20011349, 0.20013161]\n",
      "[0.60043323, 0.2, 0.20010045, 0.2001379]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10990 iterations: 2.7402979334195456 mins\n",
      "Train Loss: [0.60043323, 0.2, 0.20010045, 0.2001379]\n",
      "[0.6004754, 0.2, 0.20005146, 0.2002284]\n",
      "[0.60054785, 0.2, 0.20022497, 0.20012708]\n",
      "[0.60030496, 0.2, 0.20006338, 0.20004572]\n",
      "[0.6003379, 0.2, 0.2000735, 0.2000687]\n",
      "[0.60043806, 0.2, 0.20007151, 0.2001711]\n",
      "[0.60034984, 0.2, 0.20005953, 0.20009549]\n",
      "[0.6003811, 0.2, 0.20015763, 0.20002934]\n",
      "[0.6003188, 0.2, 0.20003016, 0.20009542]\n",
      "[0.6003584, 0.2, 0.20010753, 0.20005867]\n",
      "[0.60069567, 0.2, 0.20008044, 0.20042405]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11000 iterations: 2.7423094471295673 mins\n",
      "Train Loss: [0.60069567, 0.2, 0.20008044, 0.20042405]\n",
      "[0.6003158, 0.2, 0.20005251, 0.20007327]\n",
      "[0.6003259, 0.2, 0.20003262, 0.20010434]\n",
      "[0.6003191, 0.2, 0.20003796, 0.20009324]\n",
      "[0.60036373, 0.2, 0.20007052, 0.20010614]\n",
      "[0.6003105, 0.2, 0.2000671, 0.20005722]\n",
      "[0.6003529, 0.2, 0.20009652, 0.20007105]\n",
      "[0.6002765, 0.2, 0.20005073, 0.2000413]\n",
      "[0.6002231, 0.2, 0.2, 0.2000395]\n",
      "[0.6003727, 0.2, 0.20010777, 0.20008215]\n",
      "[0.60029006, 0.2, 0.20003532, 0.200073]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11010 iterations: 2.7441894014676413 mins\n",
      "Train Loss: [0.60029006, 0.2, 0.20003532, 0.200073]\n",
      "[0.60046935, 0.2, 0.20014894, 0.2001397]\n",
      "[0.60038567, 0.2, 0.20013352, 0.20007266]\n",
      "[0.6003456, 0.2, 0.20006186, 0.20010553]\n",
      "[0.6002616, 0.2, 0.2, 0.20008479]\n",
      "[0.6003236, 0.2, 0.2000818, 0.20006646]\n",
      "[0.6002283, 0.2, 0.20001642, 0.2000382]\n",
      "[0.60030675, 0.2, 0.20004883, 0.20008603]\n",
      "[0.6004052, 0.2, 0.20009483, 0.2001404]\n",
      "[0.60040504, 0.2, 0.20015797, 0.20007914]\n",
      "[0.60030544, 0.2, 0.2000945, 0.20004503]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11020 iterations: 2.7462043325106302 mins\n",
      "Train Loss: [0.60030544, 0.2, 0.2000945, 0.20004503]\n",
      "[0.60024875, 0.2, 0.20006804, 0.20001672]\n",
      "[0.6003699, 0.2, 0.20011142, 0.2000964]\n",
      "[0.6002493, 0.2, 0.20003846, 0.20005073]\n",
      "[0.60029435, 0.2, 0.20006253, 0.20007364]\n",
      "[0.60032433, 0.2, 0.20007226, 0.20009585]\n",
      "[0.6002837, 0.2, 0.20006788, 0.20006153]\n",
      "[0.600353, 0.2, 0.20013063, 0.20006998]\n",
      "[0.6004663, 0.2, 0.20007487, 0.20024076]\n",
      "[0.6002991, 0.2, 0.20009664, 0.20005332]\n",
      "[0.60030115, 0.2, 0.20006983, 0.20008354]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11030 iterations: 2.748651651541392 mins\n",
      "Train Loss: [0.60030115, 0.2, 0.20006983, 0.20008354]\n",
      "[0.60022897, 0.2, 0.20001107, 0.20007142]\n",
      "[0.60033435, 0.2, 0.20006481, 0.20012441]\n",
      "[0.6002493, 0.2, 0.20004335, 0.20006208]\n",
      "[0.6002943, 0.2, 0.20003884, 0.20011307]\n",
      "[0.60041606, 0.2, 0.20018227, 0.20009267]\n",
      "[0.6003877, 0.2, 0.20014453, 0.20010322]\n",
      "[0.6002484, 0.2, 0.20006424, 0.20004526]\n",
      "[0.6002303, 0.2, 0.20007212, 0.20002021]\n",
      "[0.6002775, 0.2, 0.20007323, 0.2000673]\n",
      "[0.60037464, 0.2, 0.20010434, 0.2001343]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11040 iterations: 2.7506426334381104 mins\n",
      "Train Loss: [0.60037464, 0.2, 0.20010434, 0.2001343]\n",
      "[0.60025334, 0.2, 0.20003903, 0.20007926]\n",
      "[0.60025394, 0.2, 0.20007062, 0.20004916]\n",
      "[0.6003495, 0.2, 0.20004527, 0.2001709]\n",
      "[0.60017955, 0.2, 0.200043, 0.20000394]\n",
      "[0.60022205, 0.2, 0.200039, 0.20005108]\n",
      "[0.60027474, 0.2, 0.20008767, 0.2000558]\n",
      "[0.6002271, 0.2, 0.20003194, 0.2000645]\n",
      "[0.6002312, 0.2, 0.2, 0.20010114]\n",
      "[0.60030204, 0.2, 0.20006748, 0.20010519]\n",
      "[0.6002095, 0.2, 0.20001797, 0.20006281]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11050 iterations: 2.7524526516596475 mins\n",
      "Train Loss: [0.6002095, 0.2, 0.20001797, 0.20006281]\n",
      "[0.60020155, 0.2, 0.20003247, 0.2000412]\n",
      "[0.6002262, 0.2, 0.20006886, 0.20003034]\n",
      "[0.60023105, 0.2, 0.20007247, 0.20003258]\n",
      "[0.6002548, 0.2, 0.20009677, 0.20003295]\n",
      "[0.60031736, 0.2, 0.20013309, 0.20006017]\n",
      "[0.60024375, 0.2, 0.2000048, 0.2001157]\n",
      "[0.6003864, 0.2, 0.20013627, 0.20012759]\n",
      "[0.60023046, 0.2, 0.20007914, 0.20002952]\n",
      "[0.60027325, 0.2, 0.20005466, 0.20009734]\n",
      "[0.60028654, 0.2, 0.20005143, 0.20011447]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11060 iterations: 2.7544333815574644 mins\n",
      "Train Loss: [0.60028654, 0.2, 0.20005143, 0.20011447]\n",
      "[0.6001974, 0.2, 0.20000002, 0.20007724]\n",
      "[0.60044545, 0.2, 0.2001747, 0.20015112]\n",
      "[0.6002446, 0.2, 0.20008996, 0.20003544]\n",
      "[0.6003267, 0.2, 0.20010485, 0.20010306]\n",
      "[0.60016644, 0.2, 0.2, 0.20004801]\n",
      "[0.6003257, 0.2, 0.20010123, 0.20010616]\n",
      "[0.60036355, 0.2, 0.20014493, 0.20010035]\n",
      "[0.60037243, 0.2, 0.20004597, 0.20020817]\n",
      "[0.6002644, 0.2, 0.20001093, 0.20013492]\n",
      "[0.6002026, 0.2, 0.20004173, 0.20004225]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11070 iterations: 2.7562842845916746 mins\n",
      "Train Loss: [0.6002026, 0.2, 0.20004173, 0.20004225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60022926, 0.2, 0.20003816, 0.2000722]\n",
      "[0.60020435, 0.2, 0.20004883, 0.20003648]\n",
      "[0.60021776, 0.2, 0.20007294, 0.20002572]\n",
      "[0.600203, 0.2, 0.20005137, 0.20003249]\n",
      "[0.60030884, 0.2, 0.20011766, 0.20007205]\n",
      "[0.6002487, 0.2, 0.2001014, 0.20002837]\n",
      "[0.60021216, 0.2, 0.20006527, 0.20002814]\n",
      "[0.6002777, 0.2, 0.20008299, 0.20007618]\n",
      "[0.60019076, 0.2, 0.2000364, 0.20003603]\n",
      "[0.60033756, 0.2, 0.20014465, 0.2000748]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11080 iterations: 2.7583887497584025 mins\n",
      "Train Loss: [0.60033756, 0.2, 0.20014465, 0.2000748]\n",
      "[0.60022783, 0.2, 0.20008846, 0.20002173]\n",
      "[0.60037094, 0.2, 0.20008259, 0.2001711]\n",
      "[0.6002922, 0.2, 0.20010161, 0.200074]\n",
      "[0.60034084, 0.2, 0.20009963, 0.20012538]\n",
      "[0.60029685, 0.2, 0.20010783, 0.2000738]\n",
      "[0.60016733, 0.2, 0.2, 0.20005259]\n",
      "[0.60041255, 0.2, 0.2000967, 0.20020145]\n",
      "[0.60043705, 0.2, 0.2000969, 0.20022635]\n",
      "[0.6002986, 0.2, 0.20009299, 0.2000922]\n",
      "[0.6002294, 0.2, 0.20004472, 0.20007147]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11090 iterations: 2.7605064312616983 mins\n",
      "Train Loss: [0.6002294, 0.2, 0.20004472, 0.20007147]\n",
      "[0.6003635, 0.2, 0.2000665, 0.20018399]\n",
      "[0.60037756, 0.2, 0.20021202, 0.20005277]\n",
      "[0.60032976, 0.2, 0.20003606, 0.20018086]\n",
      "[0.60037124, 0.2, 0.20008622, 0.20017165]\n",
      "[0.6002271, 0.2, 0.2000366, 0.20007631]\n",
      "[0.60028344, 0.2, 0.20009415, 0.20007394]\n",
      "[0.60022295, 0.2, 0.20006393, 0.20004237]\n",
      "[0.6002567, 0.2, 0.20002532, 0.20011319]\n",
      "[0.6003443, 0.2, 0.2001482, 0.20007633]\n",
      "[0.60020286, 0.2, 0.20004351, 0.20003839]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11100 iterations: 2.762537984053294 mins\n",
      "Train Loss: [0.60020286, 0.2, 0.20004351, 0.20003839]\n",
      "[0.60033435, 0.2, 0.20004824, 0.20016384]\n",
      "[0.60025316, 0.2, 0.20008662, 0.20004287]\n",
      "[0.6001853, 0.2, 0.20002645, 0.20003372]\n",
      "[0.6003656, 0.2, 0.20004845, 0.20019053]\n",
      "[0.6002212, 0.2, 0.20005581, 0.20003755]\n",
      "[0.6002141, 0.2, 0.20003258, 0.20005256]\n",
      "[0.6004335, 0.2, 0.20019707, 0.20010646]\n",
      "[0.6003101, 0.2, 0.20009421, 0.20008522]\n",
      "[0.6002895, 0.2, 0.20010664, 0.20005171]\n",
      "[0.60028714, 0.2, 0.20006548, 0.20008986]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11110 iterations: 2.765183115005493 mins\n",
      "Train Loss: [0.60028714, 0.2, 0.20006548, 0.20008986]\n",
      "[0.600359, 0.2, 0.2001303, 0.20009623]\n",
      "[0.60040206, 0.2, 0.20011902, 0.20015009]\n",
      "[0.6003547, 0.2, 0.20006654, 0.20015484]\n",
      "[0.60037726, 0.2, 0.20009659, 0.20014708]\n",
      "[0.6002994, 0.2, 0.20005126, 0.20011452]\n",
      "[0.6002837, 0.2, 0.2000161, 0.20013396]\n",
      "[0.60035545, 0.2, 0.20012662, 0.20009528]\n",
      "[0.6003468, 0.2, 0.20007585, 0.20013754]\n",
      "[0.60047954, 0.2, 0.200104, 0.20024227]\n",
      "[0.6003818, 0.2, 0.20012729, 0.20012133]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11120 iterations: 2.7670281847318012 mins\n",
      "Train Loss: [0.6003818, 0.2, 0.20012729, 0.20012133]\n",
      "[0.6003563, 0.2, 0.20009415, 0.20012903]\n",
      "[0.6004494, 0.2, 0.20022693, 0.2000892]\n",
      "[0.6003392, 0.2, 0.20005122, 0.20015465]\n",
      "[0.600414, 0.2, 0.20011254, 0.2001679]\n",
      "[0.6004244, 0.2, 0.2000959, 0.20019452]\n",
      "[0.60061616, 0.2, 0.20032467, 0.20015705]\n",
      "[0.60022795, 0.2, 0.20003484, 0.20005824]\n",
      "[0.60032684, 0.2, 0.20006768, 0.20012352]\n",
      "[0.60030204, 0.2, 0.20007837, 0.2000874]\n",
      "[0.6003408, 0.2, 0.20011677, 0.20008692]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11130 iterations: 2.7690330306688944 mins\n",
      "Train Loss: [0.6003408, 0.2, 0.20011677, 0.20008692]\n",
      "[0.600233, 0.2, 0.20006551, 0.2000295]\n",
      "[0.60019153, 0.2, 0.20001617, 0.20003629]\n",
      "[0.60021245, 0.2, 0.20002109, 0.20005116]\n",
      "[0.6002298, 0.2, 0.20007144, 0.20001708]\n",
      "[0.60041326, 0.2, 0.20014858, 0.20012258]\n",
      "[0.6003232, 0.2, 0.20005584, 0.20012474]\n",
      "[0.60056263, 0.2, 0.20015314, 0.20026639]\n",
      "[0.6003841, 0.2, 0.20008643, 0.20015429]\n",
      "[0.6004336, 0.2, 0.20014176, 0.2001481]\n",
      "[0.60042256, 0.2, 0.20013912, 0.20013942]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11140 iterations: 2.770985730489095 mins\n",
      "Train Loss: [0.60042256, 0.2, 0.20013912, 0.20013942]\n",
      "[0.60037935, 0.2, 0.2001488, 0.20008618]\n",
      "[0.60030556, 0.2, 0.2000692, 0.20009154]\n",
      "[0.60047007, 0.2, 0.20005937, 0.20026521]\n",
      "[0.60035133, 0.2, 0.20010087, 0.20010433]\n",
      "[0.60056174, 0.2, 0.20020077, 0.20021395]\n",
      "[0.60044885, 0.2, 0.20014857, 0.20015231]\n",
      "[0.6004253, 0.2, 0.20019856, 0.20007774]\n",
      "[0.60024405, 0.2, 0.20003161, 0.20006259]\n",
      "[0.6004381, 0.2, 0.20010924, 0.20017815]\n",
      "[0.60056466, 0.2, 0.20009287, 0.20032014]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11150 iterations: 2.7729520161946613 mins\n",
      "Train Loss: [0.60056466, 0.2, 0.20009287, 0.20032014]\n",
      "[0.60052884, 0.2, 0.20011045, 0.20026597]\n",
      "[0.6003615, 0.2, 0.20007938, 0.20012905]\n",
      "[0.6005128, 0.2, 0.20025717, 0.20010176]\n",
      "[0.6003605, 0.2, 0.20010743, 0.2000985]\n",
      "[0.60035115, 0.2, 0.20011233, 0.20008342]\n",
      "[0.60033315, 0.2, 0.20007488, 0.20010199]\n",
      "[0.6004717, 0.2, 0.20016101, 0.20015343]\n",
      "[0.6003596, 0.2, 0.20003375, 0.2001678]\n",
      "[0.600356, 0.2, 0.20012249, 0.2000747]\n",
      "[0.600392, 0.2, 0.20009051, 0.20014192]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11160 iterations: 2.775101884206136 mins\n",
      "Train Loss: [0.600392, 0.2, 0.20009051, 0.20014192]\n",
      "[0.60037386, 0.2, 0.20016521, 0.2000483]\n",
      "[0.60044366, 0.2, 0.20016344, 0.20011923]\n",
      "[0.60037965, 0.2, 0.20008579, 0.20013233]\n",
      "[0.6003334, 0.2, 0.2001339, 0.20003751]\n",
      "[0.6005655, 0.2, 0.20024389, 0.20015931]\n",
      "[0.60056615, 0.2, 0.20021927, 0.20018424]\n",
      "[0.60048187, 0.2, 0.20011279, 0.20020619]\n",
      "[0.60034907, 0.2, 0.20015703, 0.20002888]\n",
      "[0.6003902, 0.2, 0.20008117, 0.20014565]\n",
      "[0.6003294, 0.2, 0.20011786, 0.2000479]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11170 iterations: 2.777048031489054 mins\n",
      "Train Loss: [0.6003294, 0.2, 0.20011786, 0.2000479]\n",
      "[0.6004316, 0.2, 0.20015194, 0.20011584]\n",
      "[0.60032797, 0.2, 0.20008987, 0.20007408]\n",
      "[0.6002773, 0.2, 0.20005953, 0.20005359]\n",
      "[0.6003162, 0.2, 0.20004827, 0.20010349]\n",
      "[0.60024685, 0.2, 0.2000445, 0.20003776]\n",
      "[0.60035455, 0.2, 0.20006041, 0.20012952]\n",
      "[0.6003214, 0.2, 0.2000554, 0.2001014]\n",
      "[0.60029685, 0.2, 0.20006335, 0.200069]\n",
      "[0.60032946, 0.2, 0.20011303, 0.20005211]\n",
      "[0.6002887, 0.2, 0.20006971, 0.20005484]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11180 iterations: 2.779126981894175 mins\n",
      "Train Loss: [0.6002887, 0.2, 0.20006971, 0.20005484]\n",
      "[0.6004895, 0.2, 0.20016947, 0.2001561]\n",
      "[0.60055536, 0.2, 0.20024711, 0.20014483]\n",
      "[0.60046667, 0.2, 0.20009673, 0.20020705]\n",
      "[0.6003416, 0.2, 0.20004529, 0.20013395]\n",
      "[0.60032994, 0.2, 0.20007576, 0.2000922]\n",
      "[0.6003119, 0.2, 0.20011306, 0.20003733]\n",
      "[0.60045195, 0.2, 0.2000665, 0.20022435]\n",
      "[0.6003997, 0.2, 0.20013507, 0.200104]\n",
      "[0.6003518, 0.2, 0.2000359, 0.20015593]\n",
      "[0.6002708, 0.2, 0.20005319, 0.20005819]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11190 iterations: 2.7818665345509848 mins\n",
      "Train Loss: [0.6002708, 0.2, 0.20005319, 0.20005819]\n",
      "[0.6002883, 0.2, 0.20008156, 0.2000478]\n",
      "[0.60034364, 0.2, 0.2000214, 0.20016378]\n",
      "[0.6002587, 0.2, 0.20002589, 0.20007476]\n",
      "[0.6003167, 0.2, 0.20005587, 0.20010321]\n",
      "[0.60027903, 0.2, 0.20006977, 0.20005228]\n",
      "[0.60043335, 0.2, 0.20012315, 0.20015395]\n",
      "[0.6002345, 0.2, 0.20004256, 0.20003636]\n",
      "[0.60026926, 0.2, 0.2000655, 0.20004892]\n",
      "[0.6004008, 0.2, 0.20016694, 0.20007981]\n",
      "[0.60030645, 0.2, 0.20010392, 0.20004931]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11200 iterations: 2.783738648891449 mins\n",
      "Train Loss: [0.60030645, 0.2, 0.20010392, 0.20004931]\n",
      "[0.6002511, 0.2, 0.20001732, 0.20008153]\n",
      "[0.60028756, 0.2, 0.20006669, 0.20006958]\n",
      "[0.60034734, 0.2, 0.200095, 0.20010217]\n",
      "[0.6002749, 0.2, 0.20006455, 0.20006125]\n",
      "[0.6002737, 0.2, 0.20008513, 0.20004049]\n",
      "[0.6003049, 0.2, 0.20011894, 0.20003897]\n",
      "[0.6002925, 0.2, 0.20003447, 0.20011202]\n",
      "[0.6004973, 0.2, 0.20022976, 0.20012257]\n",
      "[0.60037655, 0.2, 0.20009995, 0.20013244]\n",
      "[0.6004352, 0.2, 0.20019498, 0.20009671]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11210 iterations: 2.7857152342796327 mins\n",
      "Train Loss: [0.6004352, 0.2, 0.20019498, 0.20009671]\n",
      "[0.6003418, 0.2, 0.20014259, 0.20005628]\n",
      "[0.60033363, 0.2, 0.20015438, 0.2000366]\n",
      "[0.6002666, 0.2, 0.20010091, 0.20002326]\n",
      "[0.60038704, 0.2, 0.20007344, 0.20017147]\n",
      "[0.6003196, 0.2, 0.2001027, 0.20007508]\n",
      "[0.60039127, 0.2, 0.20019537, 0.20005436]\n",
      "[0.60051674, 0.2, 0.20029536, 0.20008007]\n",
      "[0.600391, 0.2, 0.2001924, 0.2000575]\n",
      "[0.6004897, 0.2, 0.20028143, 0.20006722]\n",
      "[0.6005129, 0.2, 0.20018896, 0.20018302]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11220 iterations: 2.787608714898427 mins\n",
      "Train Loss: [0.6005129, 0.2, 0.20018896, 0.20018302]\n",
      "[0.6002995, 0.2, 0.2000483, 0.20011027]\n",
      "[0.60039467, 0.2, 0.20006855, 0.20018497]\n",
      "[0.60029525, 0.2, 0.2000633, 0.2000905]\n",
      "[0.6003673, 0.2, 0.20007615, 0.20014921]\n",
      "[0.6002425, 0.2, 0.20005406, 0.20004587]\n",
      "[0.60036397, 0.2, 0.2001102, 0.2001106]\n",
      "[0.6002413, 0.2, 0.20004316, 0.20005435]\n",
      "[0.6003198, 0.2, 0.20009209, 0.20008336]\n",
      "[0.60030574, 0.2, 0.20008524, 0.2000756]\n",
      "[0.6003191, 0.2, 0.20009269, 0.20008108]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11230 iterations: 2.7896565477053326 mins\n",
      "Train Loss: [0.6003191, 0.2, 0.20009269, 0.20008108]\n",
      "[0.6002486, 0.2, 0.20004407, 0.20005879]\n",
      "[0.6004871, 0.2, 0.20015915, 0.20018202]\n",
      "[0.60025024, 0.2, 0.20008107, 0.200023]\n",
      "[0.60028034, 0.2, 0.20010692, 0.20002711]\n",
      "[0.60040337, 0.2, 0.20016134, 0.20009558]\n",
      "[0.60031885, 0.2, 0.20010541, 0.20006706]\n",
      "[0.60035753, 0.2, 0.20008217, 0.20012921]\n",
      "[0.600279, 0.2, 0.20007664, 0.20005657]\n",
      "[0.6004101, 0.2, 0.20022357, 0.20004123]\n",
      "[0.6003149, 0.2, 0.20008264, 0.20008752]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11240 iterations: 2.7915327191352843 mins\n",
      "Train Loss: [0.6003149, 0.2, 0.20008264, 0.20008752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6002945, 0.2, 0.20007995, 0.20007028]\n",
      "[0.60025686, 0.2, 0.20006032, 0.20005295]\n",
      "[0.6002967, 0.2, 0.200107, 0.20004672]\n",
      "[0.60024905, 0.2, 0.20004296, 0.20006375]\n",
      "[0.6004667, 0.2, 0.20012484, 0.20020014]\n",
      "[0.60027295, 0.2, 0.20005453, 0.20007712]\n",
      "[0.6002225, 0.2, 0.20004915, 0.20003231]\n",
      "[0.6002192, 0.2, 0.20003076, 0.20004742]\n",
      "[0.6004783, 0.2, 0.20025782, 0.20007944]\n",
      "[0.60056084, 0.2, 0.20005651, 0.20036325]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11250 iterations: 2.7936509013175965 mins\n",
      "Train Loss: [0.60056084, 0.2, 0.20005651, 0.20036325]\n",
      "[0.60040003, 0.2, 0.20016892, 0.20008992]\n",
      "[0.6002108, 0.2, 0.20002605, 0.20004334]\n",
      "[0.6002845, 0.2, 0.20006467, 0.20007822]\n",
      "[0.6002515, 0.2, 0.20004463, 0.200065]\n",
      "[0.6003756, 0.2, 0.20004295, 0.20019057]\n",
      "[0.60024947, 0.2, 0.20007709, 0.20003024]\n",
      "[0.6003665, 0.2, 0.2000216, 0.2002025]\n",
      "[0.6004953, 0.2, 0.20022202, 0.20013082]\n",
      "[0.6002935, 0.2, 0.20009981, 0.20005105]\n",
      "[0.6002858, 0.2, 0.20007424, 0.20006858]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11260 iterations: 2.795593015352885 mins\n",
      "Train Loss: [0.6002858, 0.2, 0.20007424, 0.20006858]\n",
      "[0.60026693, 0.2, 0.20011045, 0.20001301]\n",
      "[0.60050744, 0.2, 0.20005465, 0.20030873]\n",
      "[0.60031164, 0.2, 0.20009334, 0.20007356]\n",
      "[0.6003046, 0.2, 0.20007306, 0.20008619]\n",
      "[0.60035676, 0.2, 0.20013474, 0.2000759]\n",
      "[0.60051876, 0.2, 0.20029867, 0.20007338]\n",
      "[0.60031253, 0.2, 0.20006989, 0.20009512]\n",
      "[0.6003304, 0.2, 0.2000595, 0.20012255]\n",
      "[0.600344, 0.2, 0.20012185, 0.20007294]\n",
      "[0.60036755, 0.2, 0.20012306, 0.2000945]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11270 iterations: 2.798072350025177 mins\n",
      "Train Loss: [0.60036755, 0.2, 0.20012306, 0.2000945]\n",
      "[0.6003451, 0.2, 0.20003027, 0.20016424]\n",
      "[0.6003937, 0.2, 0.20013373, 0.20010902]\n",
      "[0.6004498, 0.2, 0.20009835, 0.20020016]\n",
      "[0.60032344, 0.2, 0.20007652, 0.20009549]\n",
      "[0.60029763, 0.2, 0.20007479, 0.20007135]\n",
      "[0.6002326, 0.2, 0.20005566, 0.2000255]\n",
      "[0.6003189, 0.2, 0.2000935, 0.20007414]\n",
      "[0.6002098, 0.2, 0.20003566, 0.20002313]\n",
      "[0.60030913, 0.2, 0.20013936, 0.20001924]\n",
      "[0.60029346, 0.2, 0.20003481, 0.20010872]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11280 iterations: 2.800150382518768 mins\n",
      "Train Loss: [0.60029346, 0.2, 0.20003481, 0.20010872]\n",
      "[0.6002437, 0.2, 0.20007502, 0.20001946]\n",
      "[0.6002962, 0.2, 0.20006837, 0.20007953]\n",
      "[0.6002979, 0.2, 0.20007388, 0.20007668]\n",
      "[0.60030234, 0.2, 0.2001211, 0.20003492]\n",
      "[0.6002944, 0.2, 0.20008, 0.20006919]\n",
      "[0.60042214, 0.2, 0.20015967, 0.20011836]\n",
      "[0.60041916, 0.2, 0.20016503, 0.200111]\n",
      "[0.60025907, 0.2, 0.20003876, 0.20007804]\n",
      "[0.6002945, 0.2, 0.2001001, 0.200053]\n",
      "[0.60039026, 0.2, 0.2001312, 0.20011841]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11290 iterations: 2.801965514818827 mins\n",
      "Train Loss: [0.60039026, 0.2, 0.2001312, 0.20011841]\n",
      "[0.6003329, 0.2, 0.20006125, 0.20013161]\n",
      "[0.60027385, 0.2, 0.2000384, 0.20009598]\n",
      "[0.6002799, 0.2, 0.20008473, 0.20005631]\n",
      "[0.600258, 0.2, 0.20007023, 0.2000494]\n",
      "[0.60019475, 0.2, 0.20000465, 0.20005229]\n",
      "[0.60025436, 0.2, 0.20003732, 0.20007978]\n",
      "[0.60038733, 0.2, 0.20011081, 0.20013979]\n",
      "[0.60025626, 0.2, 0.20007208, 0.20004806]\n",
      "[0.6002961, 0.2, 0.20006894, 0.20009165]\n",
      "[0.6003873, 0.2, 0.20009363, 0.2001587]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11300 iterations: 2.8047194321950277 mins\n",
      "Train Loss: [0.6003873, 0.2, 0.20009363, 0.2001587]\n",
      "[0.6003254, 0.2, 0.20011404, 0.20007685]\n",
      "[0.6003508, 0.2, 0.200121, 0.20009573]\n",
      "[0.600351, 0.2, 0.20005198, 0.2001655]\n",
      "[0.6001993, 0.2, 0.2000031, 0.20006318]\n",
      "[0.6002488, 0.2, 0.20007208, 0.20004413]\n",
      "[0.6002345, 0.2, 0.20004039, 0.20006198]\n",
      "[0.60022587, 0.2, 0.20002528, 0.20006885]\n",
      "[0.60034806, 0.2, 0.20006084, 0.20015599]\n",
      "[0.6002043, 0.2, 0.20003924, 0.20003428]\n",
      "[0.60021603, 0.2, 0.20002589, 0.20005983]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11310 iterations: 2.806684116522471 mins\n",
      "Train Loss: [0.60021603, 0.2, 0.20002589, 0.20005983]\n",
      "[0.60020626, 0.2, 0.20004642, 0.20003003]\n",
      "[0.6003337, 0.2, 0.20015313, 0.20005135]\n",
      "[0.60028327, 0.2, 0.20008583, 0.20006895]\n",
      "[0.6002278, 0.2, 0.20003992, 0.20006005]\n",
      "[0.60037154, 0.2, 0.20017713, 0.20006727]\n",
      "[0.6002955, 0.2, 0.20008565, 0.20008335]\n",
      "[0.60025305, 0.2, 0.20004107, 0.20008618]\n",
      "[0.6002858, 0.2, 0.20007205, 0.20008858]\n",
      "[0.6003062, 0.2, 0.2000989, 0.20008266]\n",
      "[0.6002204, 0.2, 0.20003462, 0.20006172]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11320 iterations: 2.8087266167004903 mins\n",
      "Train Loss: [0.6002204, 0.2, 0.20003462, 0.20006172]\n",
      "[0.6002768, 0.2, 0.20011398, 0.20003927]\n",
      "[0.60037404, 0.2, 0.20013757, 0.20011345]\n",
      "[0.6002693, 0.2, 0.20003796, 0.20010906]\n",
      "[0.6002963, 0.2, 0.2000758, 0.20009886]\n",
      "[0.60027325, 0.2, 0.20011075, 0.20004122]\n",
      "[0.6003614, 0.2, 0.20009397, 0.20014636]\n",
      "[0.6003243, 0.2, 0.20010845, 0.2000949]\n",
      "[0.6003337, 0.2, 0.20006832, 0.20014441]\n",
      "[0.60026026, 0.2, 0.20005968, 0.20007972]\n",
      "[0.6002653, 0.2, 0.20007494, 0.20006956]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11330 iterations: 2.810750448703766 mins\n",
      "Train Loss: [0.6002653, 0.2, 0.20007494, 0.20006956]\n",
      "[0.6002271, 0.2, 0.2000731, 0.20003307]\n",
      "[0.60035884, 0.2, 0.20008345, 0.2001542]\n",
      "[0.60039467, 0.2, 0.20017676, 0.20009638]\n",
      "[0.6004684, 0.2, 0.2000896, 0.20025682]\n",
      "[0.60059947, 0.2, 0.20023294, 0.20024411]\n",
      "[0.6003109, 0.2, 0.20004109, 0.2001468]\n",
      "[0.60051006, 0.2, 0.20013879, 0.2002475]\n",
      "[0.60037553, 0.2, 0.20011121, 0.2001397]\n",
      "[0.6004178, 0.2, 0.20020057, 0.20009165]\n",
      "[0.6002767, 0.2, 0.20006134, 0.2000888]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11340 iterations: 2.812639033794403 mins\n",
      "Train Loss: [0.6002767, 0.2, 0.20006134, 0.2000888]\n",
      "[0.60028917, 0.2, 0.20006911, 0.20009239]\n",
      "[0.60027033, 0.2, 0.20006724, 0.20007433]\n",
      "[0.60028774, 0.2, 0.20006347, 0.20009445]\n",
      "[0.60026467, 0.2, 0.20000002, 0.20013388]\n",
      "[0.6004213, 0.2, 0.20003404, 0.20025559]\n",
      "[0.6003483, 0.2, 0.20017214, 0.20004357]\n",
      "[0.6003949, 0.2, 0.20019019, 0.20007114]\n",
      "[0.60046226, 0.2, 0.20007947, 0.20024784]\n",
      "[0.60033613, 0.2, 0.20008908, 0.20011032]\n",
      "[0.6005366, 0.2, 0.20018616, 0.20021158]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11350 iterations: 2.8151439984639484 mins\n",
      "Train Loss: [0.6005366, 0.2, 0.20018616, 0.20021158]\n",
      "[0.6003475, 0.2, 0.20015039, 0.2000562]\n",
      "[0.60051596, 0.2, 0.20004547, 0.20032744]\n",
      "[0.60056406, 0.2, 0.20012069, 0.20029813]\n",
      "[0.6007633, 0.2, 0.20037015, 0.20024547]\n",
      "[0.6057304, 0.2, 0.20524694, 0.20033295]\n",
      "[0.6950385, 0.2, 0.29310986, 0.20168102]\n",
      "[0.68624395, 0.2, 0.27689812, 0.20881724]\n",
      "[0.6287132, 0.2, 0.20922554, 0.21829148]\n",
      "[0.70432514, 0.2, 0.27786052, 0.22427015]\n",
      "[0.6535653, 0.2, 0.22535217, 0.22472203]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11360 iterations: 2.817091965675354 mins\n",
      "Train Loss: [0.6535653, 0.2, 0.22535217, 0.22472203]\n",
      "[0.62982816, 0.2, 0.2085115, 0.21628672]\n",
      "[0.6586634, 0.2, 0.21607183, 0.23593614]\n",
      "[0.68819046, 0.2, 0.24042676, 0.23939964]\n",
      "[0.62936354, 0.2, 0.20516263, 0.21407987]\n",
      "[0.67433083, 0.2, 0.25015864, 0.21230397]\n",
      "[0.6688293, 0.2, 0.23082726, 0.22444163]\n",
      "[0.64091295, 0.2, 0.21327327, 0.21242037]\n",
      "[0.6563213, 0.2, 0.22676401, 0.2127523]\n",
      "[0.6676948, 0.2, 0.24062817, 0.20874564]\n",
      "[0.63601327, 0.2, 0.2102491, 0.20603779]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11370 iterations: 2.8191033164660135 mins\n",
      "Train Loss: [0.63601327, 0.2, 0.2102491, 0.20603779]\n",
      "[0.6648784, 0.2, 0.23934492, 0.20451425]\n",
      "[0.6348543, 0.2, 0.20719405, 0.20544703]\n",
      "[0.6382839, 0.2, 0.20867775, 0.20631485]\n",
      "[0.6523684, 0.2, 0.21518452, 0.2129259]\n",
      "[0.6374721, 0.2, 0.2094283, 0.20292005]\n",
      "[0.64685166, 0.2, 0.21157427, 0.20939888]\n",
      "[0.6756851, 0.2, 0.2442376, 0.20489794]\n",
      "[0.63433397, 0.2, 0.20498258, 0.20220289]\n",
      "[0.6508342, 0.2, 0.2181032, 0.20506895]\n",
      "[0.6963604, 0.2, 0.25956795, 0.20868355]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11380 iterations: 2.820996117591858 mins\n",
      "Train Loss: [0.6963604, 0.2, 0.25956795, 0.20868355]\n",
      "[0.6935888, 0.2, 0.25795475, 0.20710933]\n",
      "[0.77484196, 0.2, 0.33992165, 0.20598452]\n",
      "[0.6766378, 0.2, 0.24519198, 0.20203136]\n",
      "[0.6669106, 0.2, 0.23181725, 0.20522054]\n",
      "[0.6799676, 0.2, 0.23880874, 0.21085033]\n",
      "[0.66804373, 0.2, 0.23050208, 0.20681824]\n",
      "[0.6753929, 0.2, 0.23940586, 0.20489316]\n",
      "[0.6786163, 0.2, 0.24132097, 0.20588908]\n",
      "[0.64666283, 0.2, 0.21052472, 0.2044393]\n",
      "[0.67372656, 0.2, 0.23616464, 0.2056223]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11390 iterations: 2.8230456670125323 mins\n",
      "Train Loss: [0.67372656, 0.2, 0.23616464, 0.2056223]\n",
      "[0.6882292, 0.2, 0.24344851, 0.2126397]\n",
      "[0.6588467, 0.2, 0.20893024, 0.21760315]\n",
      "[0.6615678, 0.2, 0.2149891, 0.2141268]\n",
      "[0.6631123, 0.2, 0.2028133, 0.22774512]\n",
      "[0.64711523, 0.2, 0.20646113, 0.20802964]\n",
      "[0.6622946, 0.2, 0.21368288, 0.21593921]\n",
      "[0.6735955, 0.2, 0.2280859, 0.21280041]\n",
      "[0.6710996, 0.2, 0.2249241, 0.21344198]\n",
      "[0.65337104, 0.2, 0.21339048, 0.20723103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65329367, 0.2, 0.21685994, 0.20371793]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11400 iterations: 2.825169634819031 mins\n",
      "Train Loss: [0.65329367, 0.2, 0.21685994, 0.20371793]\n",
      "[0.6457479, 0.2, 0.20227349, 0.21081875]\n",
      "[0.6716281, 0.2, 0.23277526, 0.20627603]\n",
      "[0.66216147, 0.2, 0.21683276, 0.21279866]\n",
      "[0.6598204, 0.2, 0.22215013, 0.20520315]\n",
      "[0.64912605, 0.2, 0.20548363, 0.21125905]\n",
      "[0.6676869, 0.2, 0.23237224, 0.20303144]\n",
      "[0.6643045, 0.2, 0.22138196, 0.21075313]\n",
      "[0.6856854, 0.2, 0.24967293, 0.20396464]\n",
      "[0.644394, 0.2, 0.20619752, 0.20626639]\n",
      "[0.6518089, 0.2, 0.2107694, 0.20924865]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11410 iterations: 2.8271548827489217 mins\n",
      "Train Loss: [0.6518089, 0.2, 0.2107694, 0.20924865]\n",
      "[0.66136426, 0.2, 0.20574535, 0.22397825]\n",
      "[0.6549159, 0.2, 0.21276018, 0.2106623]\n",
      "[0.65172833, 0.2, 0.21838848, 0.20200068]\n",
      "[0.6562025, 0.2, 0.2165603, 0.20845638]\n",
      "[0.65062034, 0.2, 0.21595941, 0.20363685]\n",
      "[0.65941995, 0.2, 0.219948, 0.20861784]\n",
      "[0.6588448, 0.2, 0.21639441, 0.21174335]\n",
      "[0.6667102, 0.2, 0.2318425, 0.20430827]\n",
      "[0.66836745, 0.2, 0.23357937, 0.20437567]\n",
      "[0.6391552, 0.2, 0.2035855, 0.20530836]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11420 iterations: 2.829243767261505 mins\n",
      "Train Loss: [0.6391552, 0.2, 0.2035855, 0.20530836]\n",
      "[0.6443223, 0.2, 0.21104158, 0.20318314]\n",
      "[0.6423035, 0.2, 0.20666036, 0.20571622]\n",
      "[0.6552161, 0.2, 0.21501136, 0.2104549]\n",
      "[0.64962256, 0.2, 0.20910738, 0.21094501]\n",
      "[0.6513571, 0.2, 0.21411596, 0.20784727]\n",
      "[0.6552202, 0.2, 0.22234115, 0.20366363]\n",
      "[0.64399403, 0.2, 0.2054608, 0.20949696]\n",
      "[0.64934915, 0.2, 0.21327178, 0.20720464]\n",
      "[0.6511285, 0.2, 0.2099628, 0.21245843]\n",
      "[0.6658098, 0.2, 0.22321221, 0.2140534]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11430 iterations: 2.831560750802358 mins\n",
      "Train Loss: [0.6658098, 0.2, 0.22321221, 0.2140534]\n",
      "[0.65766186, 0.2, 0.21943024, 0.20984945]\n",
      "[0.6482786, 0.2, 0.21013024, 0.20989309]\n",
      "[0.6402674, 0.2, 0.20364764, 0.2084882]\n",
      "[0.66953766, 0.2, 0.23636508, 0.20516779]\n",
      "[0.6671935, 0.2, 0.22373305, 0.21557492]\n",
      "[0.6672487, 0.2, 0.23254293, 0.20693679]\n",
      "[0.6349457, 0.2, 0.2048447, 0.20244798]\n",
      "[0.67939734, 0.2, 0.24490525, 0.20696437]\n",
      "[0.6456412, 0.2, 0.21518953, 0.20304725]\n",
      "[0.6668364, 0.2, 0.23584223, 0.20371485]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11440 iterations: 2.8336351990699766 mins\n",
      "Train Loss: [0.6668364, 0.2, 0.23584223, 0.20371485]\n",
      "[0.65515, 0.2, 0.22239506, 0.20560065]\n",
      "[0.6605682, 0.2, 0.21882889, 0.21471223]\n",
      "[0.6723511, 0.2, 0.23843393, 0.20701724]\n",
      "[0.64003325, 0.2, 0.20865977, 0.20459734]\n",
      "[0.6624609, 0.2, 0.2330073, 0.20280261]\n",
      "[0.6502198, 0.2, 0.21106012, 0.21262783]\n",
      "[0.6374773, 0.2, 0.20468575, 0.20637076]\n",
      "[0.64067644, 0.2, 0.20557967, 0.2087944]\n",
      "[0.6510909, 0.2, 0.22081827, 0.2040866]\n",
      "[0.69592184, 0.2, 0.26194334, 0.20791572]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11450 iterations: 2.8354870835940043 mins\n",
      "Train Loss: [0.69592184, 0.2, 0.26194334, 0.20791572]\n",
      "[0.6720376, 0.2, 0.24168852, 0.20441148]\n",
      "[0.6410013, 0.2, 0.21083815, 0.2043542]\n",
      "[0.6600088, 0.2, 0.22525302, 0.20904516]\n",
      "[0.65653765, 0.2, 0.22310552, 0.20781314]\n",
      "[0.65982145, 0.2, 0.2276594, 0.20665126]\n",
      "[0.66083264, 0.2, 0.22876099, 0.20665683]\n",
      "[0.6320741, 0.2, 0.2028186, 0.20394024]\n",
      "[0.6634135, 0.2, 0.22986229, 0.20834026]\n",
      "[0.6486272, 0.2, 0.21625122, 0.2072741]\n",
      "[0.65118575, 0.2, 0.22417468, 0.2020182]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11460 iterations: 2.8375094811121624 mins\n",
      "Train Loss: [0.65118575, 0.2, 0.22417468, 0.2020182]\n",
      "[0.6401544, 0.2, 0.2089768, 0.20629865]\n",
      "[0.64098334, 0.2, 0.20756729, 0.20865133]\n",
      "[0.6705103, 0.2, 0.22923361, 0.21662824]\n",
      "[0.64080167, 0.2, 0.21257141, 0.20368472]\n",
      "[0.64381534, 0.2, 0.20779279, 0.21158561]\n",
      "[0.64109, 0.2, 0.21489021, 0.20187218]\n",
      "[0.64076877, 0.2, 0.2115062, 0.2050457]\n",
      "[0.63132644, 0.2, 0.20234142, 0.2048787]\n",
      "[0.65930355, 0.2, 0.22654168, 0.20876989]\n",
      "[0.63406205, 0.2, 0.20709679, 0.20308797]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11470 iterations: 2.839361580212911 mins\n",
      "Train Loss: [0.63406205, 0.2, 0.20709679, 0.20308797]\n",
      "[0.65869105, 0.2, 0.23295546, 0.20197573]\n",
      "[0.6403494, 0.2, 0.21046095, 0.20624755]\n",
      "[0.6623688, 0.2, 0.23509294, 0.20374781]\n",
      "[0.65462595, 0.2, 0.21654546, 0.21462888]\n",
      "[0.631505, 0.2, 0.20319407, 0.20492457]\n",
      "[0.65628034, 0.2, 0.23171034, 0.20125149]\n",
      "[0.63056606, 0.2, 0.20404837, 0.20326202]\n",
      "[0.64751965, 0.2, 0.22034581, 0.20398363]\n",
      "[0.6506687, 0.2, 0.21796988, 0.20957361]\n",
      "[0.6307092, 0.2, 0.20605218, 0.201602]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11480 iterations: 2.8413028001785277 mins\n",
      "Train Loss: [0.6307092, 0.2, 0.20605218, 0.201602]\n",
      "[0.6390426, 0.2, 0.2098819, 0.20618233]\n",
      "[0.65130335, 0.2, 0.22375679, 0.20464784]\n",
      "[0.6583499, 0.2, 0.22538689, 0.21014012]\n",
      "[0.6399658, 0.2, 0.20959772, 0.20761177]\n",
      "[0.6616085, 0.2, 0.21878175, 0.22013521]\n",
      "[0.63414997, 0.2, 0.20796923, 0.20355348]\n",
      "[0.6489211, 0.2, 0.2208635, 0.2054899]\n",
      "[0.75685364, 0.2, 0.20768087, 0.32667142]\n",
      "[0.6485708, 0.2, 0.21516785, 0.21095379]\n",
      "[0.6330965, 0.2, 0.20646329, 0.2042389]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11490 iterations: 2.8433700164159137 mins\n",
      "Train Loss: [0.6330965, 0.2, 0.20646329, 0.2042389]\n",
      "[0.65380806, 0.2, 0.22393431, 0.20753463]\n",
      "[0.64413804, 0.2, 0.21838127, 0.20347525]\n",
      "[0.6594617, 0.2, 0.23119958, 0.206035]\n",
      "[0.6597261, 0.2, 0.23483267, 0.20271866]\n",
      "[0.65065336, 0.2, 0.21991399, 0.20863353]\n",
      "[0.64234245, 0.2, 0.21135305, 0.20894676]\n",
      "[0.64378417, 0.2, 0.21650928, 0.2052984]\n",
      "[0.6341689, 0.2, 0.20463589, 0.207625]\n",
      "[0.65248966, 0.2, 0.21560532, 0.21504956]\n",
      "[0.6359277, 0.2, 0.20509589, 0.20906839]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11500 iterations: 2.845267848173777 mins\n",
      "Train Loss: [0.6359277, 0.2, 0.20509589, 0.20906839]\n",
      "[0.64962626, 0.2, 0.21879843, 0.20913348]\n",
      "[0.6432526, 0.2, 0.21871306, 0.2029121]\n",
      "[0.6315054, 0.2, 0.20473, 0.20521641]\n",
      "[0.64167154, 0.2, 0.21501318, 0.20517154]\n",
      "[0.63951963, 0.2, 0.20621374, 0.21190035]\n",
      "[0.6392062, 0.2, 0.21026172, 0.20762335]\n",
      "[0.6522263, 0.2, 0.21803549, 0.21295586]\n",
      "[0.62888014, 0.2, 0.20469967, 0.2030274]\n",
      "[0.6424809, 0.2, 0.21310686, 0.20830503]\n",
      "[0.6358388, 0.2, 0.2086539, 0.20620005]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11510 iterations: 2.847827434539795 mins\n",
      "Train Loss: [0.6358388, 0.2, 0.2086539, 0.20620005]\n",
      "[0.6322358, 0.2, 0.20400839, 0.20732942]\n",
      "[0.63801354, 0.2, 0.2134909, 0.20371144]\n",
      "[0.6467826, 0.2, 0.22098577, 0.20507318]\n",
      "[0.66113824, 0.2, 0.22764592, 0.21284091]\n",
      "[0.6410451, 0.2, 0.21914102, 0.20127502]\n",
      "[0.6429877, 0.2, 0.213334, 0.20904803]\n",
      "[0.6413586, 0.2, 0.2161195, 0.20466168]\n",
      "[0.63329744, 0.2, 0.20897399, 0.20377593]\n",
      "[0.6526412, 0.2, 0.22054715, 0.21158452]\n",
      "[0.6332589, 0.2, 0.20708977, 0.2056944]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11520 iterations: 2.8496758977572125 mins\n",
      "Train Loss: [0.6332589, 0.2, 0.20708977, 0.2056944]\n",
      "[0.63517857, 0.2, 0.21057677, 0.20417018]\n",
      "[0.6469721, 0.2, 0.22228093, 0.20430301]\n",
      "[0.6327716, 0.2, 0.20871791, 0.2037088]\n",
      "[0.64031947, 0.2, 0.2146827, 0.20534159]\n",
      "[0.64416474, 0.2, 0.21794218, 0.20597388]\n",
      "[0.63631666, 0.2, 0.21027939, 0.20583932]\n",
      "[0.65044343, 0.2, 0.22028038, 0.21002069]\n",
      "[0.6693157, 0.2, 0.24229681, 0.2069353]\n",
      "[0.6476348, 0.2, 0.22580138, 0.20182024]\n",
      "[0.63793087, 0.2, 0.21238102, 0.20560719]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11530 iterations: 2.851695414384206 mins\n",
      "Train Loss: [0.63793087, 0.2, 0.21238102, 0.20560719]\n",
      "[0.6401472, 0.2, 0.21636745, 0.20390475]\n",
      "[0.62493986, 0.2, 0.20235783, 0.20277186]\n",
      "[0.63218606, 0.2, 0.20635764, 0.20608258]\n",
      "[0.63527787, 0.2, 0.21168561, 0.20391297]\n",
      "[0.6422166, 0.2, 0.2198667, 0.20273814]\n",
      "[0.63538975, 0.2, 0.2106509, 0.2051952]\n",
      "[0.6364133, 0.2, 0.21403682, 0.20290081]\n",
      "[0.64642364, 0.2, 0.22461388, 0.20240617]\n",
      "[0.63737047, 0.2, 0.2119589, 0.20607546]\n",
      "[0.6367092, 0.2, 0.21021438, 0.20722447]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11540 iterations: 2.8535829822222394 mins\n",
      "Train Loss: [0.6367092, 0.2, 0.21021438, 0.20722447]\n",
      "[0.63154286, 0.2, 0.20736298, 0.20497704]\n",
      "[0.65595895, 0.2, 0.21330099, 0.22351965]\n",
      "[0.63731027, 0.2, 0.21187776, 0.20635147]\n",
      "[0.633841, 0.2, 0.21119387, 0.20362034]\n",
      "[0.6271258, 0.2, 0.20579581, 0.20235705]\n",
      "[0.6283778, 0.2, 0.20395714, 0.20549862]\n",
      "[0.64490867, 0.2, 0.21896765, 0.20706867]\n",
      "[0.63594806, 0.2, 0.21343318, 0.20368981]\n",
      "[0.6379284, 0.2, 0.21427193, 0.20487948]\n",
      "[0.64144313, 0.2, 0.2144186, 0.20829986]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11550 iterations: 2.8556161006291707 mins\n",
      "Train Loss: [0.64144313, 0.2, 0.2144186, 0.20829986]\n",
      "[0.63588345, 0.2, 0.21376005, 0.20345098]\n",
      "[0.64111835, 0.2, 0.21611813, 0.2063814]\n",
      "[0.63537544, 0.2, 0.21060924, 0.20619571]\n",
      "[0.638942, 0.2, 0.2167935, 0.20362884]\n",
      "[0.6552014, 0.2, 0.23064132, 0.20609394]\n",
      "[0.6366132, 0.2, 0.21482113, 0.2033864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63410527, 0.2, 0.2118772, 0.20387979]\n",
      "[0.637659, 0.2, 0.21517795, 0.20418191]\n",
      "[0.6312363, 0.2, 0.20540507, 0.20758149]\n",
      "[0.6475323, 0.2, 0.22422774, 0.2051074]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11560 iterations: 2.857677733898163 mins\n",
      "Train Loss: [0.6475323, 0.2, 0.22422774, 0.2051074]\n",
      "[0.6268146, 0.2, 0.20507213, 0.20359889]\n",
      "[0.6312239, 0.2, 0.20594247, 0.20719543]\n",
      "[0.7157457, 0.2, 0.20597014, 0.29174635]\n",
      "[0.63700354, 0.2, 0.21720767, 0.20182802]\n",
      "[0.6344682, 0.2, 0.21257621, 0.20398135]\n",
      "[0.62983084, 0.2, 0.20504479, 0.20693292]\n",
      "[0.6380858, 0.2, 0.21370988, 0.20658018]\n",
      "[0.6351102, 0.2, 0.21107762, 0.2062917]\n",
      "[0.63399, 0.2, 0.21473156, 0.20157042]\n",
      "[0.62915725, 0.2, 0.20624858, 0.20527141]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11570 iterations: 2.8595881342887877 mins\n",
      "Train Loss: [0.62915725, 0.2, 0.20624858, 0.20527141]\n",
      "[0.6479929, 0.2, 0.227679, 0.20272906]\n",
      "[0.69811404, 0.2, 0.20805582, 0.27252477]\n",
      "[0.648716, 0.2, 0.22285081, 0.2083655]\n",
      "[0.63737726, 0.2, 0.21571092, 0.20419991]\n",
      "[0.6331027, 0.2, 0.20970768, 0.20596056]\n",
      "[0.6440539, 0.2, 0.22377801, 0.20287481]\n",
      "[0.64334893, 0.2, 0.21994728, 0.20604002]\n",
      "[0.6348834, 0.2, 0.20870544, 0.20885637]\n",
      "[0.62610495, 0.2, 0.20735516, 0.20146841]\n",
      "[0.6264893, 0.2, 0.20587401, 0.2033758]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11580 iterations: 2.861600665251414 mins\n",
      "Train Loss: [0.6264893, 0.2, 0.20587401, 0.2033758]\n",
      "[0.63358295, 0.2, 0.2111261, 0.20526065]\n",
      "[0.6324439, 0.2, 0.21147005, 0.20382155]\n",
      "[0.63587046, 0.2, 0.216125, 0.20263672]\n",
      "[0.63515985, 0.2, 0.21102911, 0.20706439]\n",
      "[0.6387017, 0.2, 0.21505147, 0.20662542]\n",
      "[0.63877255, 0.2, 0.21914773, 0.20263852]\n",
      "[0.6293731, 0.2, 0.20889316, 0.20353396]\n",
      "[0.63732433, 0.2, 0.21732582, 0.2030944]\n",
      "[0.63955814, 0.2, 0.21688204, 0.20581451]\n",
      "[0.6313476, 0.2, 0.21063703, 0.20389159]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11590 iterations: 2.8641244133313495 mins\n",
      "Train Loss: [0.6313476, 0.2, 0.21063703, 0.20389159]\n",
      "[0.6343812, 0.2, 0.20850456, 0.20910038]\n",
      "[0.6326202, 0.2, 0.21160746, 0.20427948]\n",
      "[0.6467989, 0.2, 0.22270738, 0.2074023]\n",
      "[0.62325805, 0.2, 0.20145029, 0.20516047]\n",
      "[0.62920064, 0.2, 0.21088846, 0.20171]\n",
      "[0.62343484, 0.2, 0.20453797, 0.20233764]\n",
      "[0.63659585, 0.2, 0.21152037, 0.20856135]\n",
      "[0.6345976, 0.2, 0.2130661, 0.2050612]\n",
      "[0.63253653, 0.2, 0.21569534, 0.20041181]\n",
      "[0.62725276, 0.2, 0.20795889, 0.20290607]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11600 iterations: 2.866034483909607 mins\n",
      "Train Loss: [0.62725276, 0.2, 0.20795889, 0.20290607]\n",
      "[0.63424855, 0.2, 0.21166001, 0.20624338]\n",
      "[0.63211703, 0.2, 0.21222486, 0.20358962]\n",
      "[0.63468874, 0.2, 0.21301879, 0.20540705]\n",
      "[0.63199687, 0.2, 0.21161258, 0.20415977]\n",
      "[0.6368738, 0.2, 0.2164648, 0.20422326]\n",
      "[0.6348858, 0.2, 0.21594052, 0.2027997]\n",
      "[0.6413732, 0.2, 0.21801737, 0.2072469]\n",
      "[0.6281919, 0.2, 0.20754988, 0.20456652]\n",
      "[0.63904166, 0.2, 0.21809015, 0.2049119]\n",
      "[0.6425809, 0.2, 0.22474894, 0.2018221]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11610 iterations: 2.8679677804311114 mins\n",
      "Train Loss: [0.6425809, 0.2, 0.22474894, 0.2018221]\n",
      "[0.62297744, 0.2, 0.20146467, 0.20552948]\n",
      "[0.6352444, 0.2, 0.21677527, 0.20251557]\n",
      "[0.6307715, 0.2, 0.21053834, 0.20431039]\n",
      "[0.62720364, 0.2, 0.20691957, 0.20438477]\n",
      "[0.63558084, 0.2, 0.21605143, 0.20365314]\n",
      "[0.62809175, 0.2, 0.20749928, 0.20473504]\n",
      "[0.6269475, 0.2, 0.20753348, 0.20357388]\n",
      "[0.6285823, 0.2, 0.20821449, 0.20454803]\n",
      "[0.6251071, 0.2, 0.20554826, 0.20376085]\n",
      "[0.63350445, 0.2, 0.21250913, 0.20522316]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11620 iterations: 2.8698803663253782 mins\n",
      "Train Loss: [0.63350445, 0.2, 0.21250913, 0.20522316]\n",
      "[0.6835611, 0.2, 0.26262254, 0.20519187]\n",
      "[0.63393927, 0.2, 0.21357678, 0.20463246]\n",
      "[0.6295146, 0.2, 0.21029404, 0.20350902]\n",
      "[0.6247486, 0.2, 0.20491694, 0.20414026]\n",
      "[0.62627834, 0.2, 0.20538367, 0.20522937]\n",
      "[0.63320386, 0.2, 0.21218798, 0.2053801]\n",
      "[0.6248508, 0.2, 0.20647085, 0.2027716]\n",
      "[0.653325, 0.2, 0.20632474, 0.23142383]\n",
      "[0.6293892, 0.2, 0.20881028, 0.2050258]\n",
      "[0.62956196, 0.2, 0.2097802, 0.2042486]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11630 iterations: 2.8719027320543926 mins\n",
      "Train Loss: [0.62956196, 0.2, 0.2097802, 0.2042486]\n",
      "[0.6315622, 0.2, 0.21215019, 0.20390326]\n",
      "[0.62487113, 0.2, 0.20753118, 0.20185561]\n",
      "[0.6306922, 0.2, 0.21048847, 0.20474444]\n",
      "[0.65067476, 0.2, 0.20617482, 0.2290712]\n",
      "[0.6281536, 0.2, 0.21110898, 0.20164047]\n",
      "[0.638343, 0.2, 0.22027224, 0.20267734]\n",
      "[0.62990206, 0.2, 0.21054952, 0.20396112]\n",
      "[0.6297283, 0.2, 0.20688173, 0.20745419]\n",
      "[0.6238337, 0.2, 0.2047206, 0.20372164]\n",
      "[0.6329945, 0.2, 0.21156487, 0.20604278]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11640 iterations: 2.873732133706411 mins\n",
      "Train Loss: [0.6329945, 0.2, 0.21156487, 0.20604278]\n",
      "[0.6255089, 0.2, 0.20395695, 0.20616972]\n",
      "[0.62505436, 0.2, 0.2065715, 0.20310915]\n",
      "[0.6374895, 0.2, 0.21999103, 0.20213756]\n",
      "[0.6276008, 0.2, 0.20947716, 0.202779]\n",
      "[0.64354527, 0.2, 0.22193651, 0.20628653]\n",
      "[0.64135647, 0.2, 0.22377995, 0.20227835]\n",
      "[0.6240897, 0.2, 0.20769347, 0.20111825]\n",
      "[0.6441878, 0.2, 0.22287796, 0.20605472]\n",
      "[0.64493126, 0.2, 0.2239359, 0.20577154]\n",
      "[0.6254611, 0.2, 0.20678693, 0.20347084]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11650 iterations: 2.875789717833201 mins\n",
      "Train Loss: [0.6254611, 0.2, 0.20678693, 0.20347084]\n",
      "[0.624887, 0.2, 0.20667714, 0.20303236]\n",
      "[0.63316715, 0.2, 0.21099289, 0.20702407]\n",
      "[0.6205941, 0.2, 0.20186377, 0.20360745]\n",
      "[0.63267976, 0.2, 0.21243346, 0.20515323]\n",
      "[0.6408081, 0.2, 0.22089809, 0.20484944]\n",
      "[0.6358296, 0.2, 0.21825472, 0.20254752]\n",
      "[0.62404245, 0.2, 0.20526241, 0.20378754]\n",
      "[0.62835836, 0.2, 0.20960967, 0.20379002]\n",
      "[0.62612146, 0.2, 0.20809694, 0.20310241]\n",
      "[0.6265648, 0.2, 0.2077879, 0.20389357]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11660 iterations: 2.8777377645174664 mins\n",
      "Train Loss: [0.6265648, 0.2, 0.2077879, 0.20389357]\n",
      "[0.6338058, 0.2, 0.21699412, 0.20196849]\n",
      "[0.63699317, 0.2, 0.21336715, 0.20882054]\n",
      "[0.62493867, 0.2, 0.2070442, 0.20312458]\n",
      "[0.64282006, 0.2, 0.22421142, 0.20387213]\n",
      "[0.6488201, 0.2, 0.22776572, 0.20634656]\n",
      "[0.6388308, 0.2, 0.22075038, 0.20339784]\n",
      "[0.63378495, 0.2, 0.21166028, 0.20746422]\n",
      "[0.6344743, 0.2, 0.21536988, 0.20446686]\n",
      "[0.6491679, 0.2, 0.22564942, 0.20890139]\n",
      "[0.6247913, 0.2, 0.20812567, 0.20206885]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11670 iterations: 2.8797497351964316 mins\n",
      "Train Loss: [0.6247913, 0.2, 0.20812567, 0.20206885]\n",
      "[0.6709248, 0.2, 0.2113775, 0.2449714]\n",
      "[0.633776, 0.2, 0.21616448, 0.20305501]\n",
      "[0.62721735, 0.2, 0.20737816, 0.2052991]\n",
      "[0.62708527, 0.2, 0.2066578, 0.20590352]\n",
      "[0.64825135, 0.2, 0.23131526, 0.20242809]\n",
      "[0.6250888, 0.2, 0.20277326, 0.20782046]\n",
      "[0.6459389, 0.2, 0.22848487, 0.20297092]\n",
      "[0.6253314, 0.2, 0.20746584, 0.20339546]\n",
      "[0.69093657, 0.2, 0.21878695, 0.2576921]\n",
      "[0.641114, 0.2, 0.2226534, 0.20400402]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11680 iterations: 2.8824011007944743 mins\n",
      "Train Loss: [0.641114, 0.2, 0.2226534, 0.20400402]\n",
      "[0.6332386, 0.2, 0.2138517, 0.20493206]\n",
      "[0.6374265, 0.2, 0.21107996, 0.21189326]\n",
      "[0.69111973, 0.2, 0.21509358, 0.26157883]\n",
      "[0.63289213, 0.2, 0.21359403, 0.20485596]\n",
      "[0.6298517, 0.2, 0.21026148, 0.20515214]\n",
      "[0.629502, 0.2, 0.21215752, 0.2029102]\n",
      "[0.6297439, 0.2, 0.21099184, 0.20432456]\n",
      "[0.62718, 0.2, 0.20928381, 0.20347674]\n",
      "[0.64818066, 0.2, 0.22975217, 0.20401928]\n",
      "[0.6255508, 0.2, 0.20605202, 0.2051022]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11690 iterations: 2.8843828797340394 mins\n",
      "Train Loss: [0.6255508, 0.2, 0.20605202, 0.2051022]\n",
      "[0.62713844, 0.2, 0.210253, 0.20250382]\n",
      "[0.630236, 0.2, 0.21117721, 0.20469488]\n",
      "[0.62644744, 0.2, 0.20766345, 0.20443806]\n",
      "[0.6957912, 0.2, 0.20749167, 0.27397496]\n",
      "[0.6238628, 0.2, 0.2062853, 0.2032572]\n",
      "[0.6952572, 0.2, 0.22003193, 0.2609099]\n",
      "[0.67088616, 0.2, 0.20727482, 0.24928048]\n",
      "[0.63956577, 0.2, 0.2190927, 0.20611803]\n",
      "[0.6255501, 0.2, 0.20585158, 0.20531742]\n",
      "[0.64040744, 0.2, 0.22244085, 0.20356284]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11700 iterations: 2.8864157160123187 mins\n",
      "Train Loss: [0.64040744, 0.2, 0.22244085, 0.20356284]\n",
      "[0.67557454, 0.2, 0.20632872, 0.254821]\n",
      "[0.63573086, 0.2, 0.21799584, 0.20328136]\n",
      "[0.6209113, 0.2, 0.20335872, 0.20306976]\n",
      "[0.6275962, 0.2, 0.20914331, 0.203944]\n",
      "[0.62626415, 0.2, 0.20580031, 0.20593041]\n",
      "[0.6381561, 0.2, 0.21517558, 0.20842712]\n",
      "[0.63442284, 0.2, 0.20829916, 0.21155319]\n",
      "[0.62117964, 0.2, 0.20508355, 0.20151496]\n",
      "[0.63484955, 0.2, 0.2150296, 0.20523247]\n",
      "[0.6300634, 0.2, 0.21178117, 0.20369847]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11710 iterations: 2.8882930517196654 mins\n",
      "Train Loss: [0.6300634, 0.2, 0.21178117, 0.20369847]\n",
      "[0.62883973, 0.2, 0.20998089, 0.20427863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6417929, 0.2, 0.22263391, 0.20458397]\n",
      "[0.6545878, 0.2, 0.23469575, 0.20532398]\n",
      "[0.6326369, 0.2, 0.21499962, 0.20308454]\n",
      "[0.62614185, 0.2, 0.20707263, 0.20453137]\n",
      "[0.64810395, 0.2, 0.22559546, 0.20798503]\n",
      "[0.63763523, 0.2, 0.21711582, 0.2060097]\n",
      "[0.65758455, 0.2, 0.24016552, 0.20292653]\n",
      "[0.6318429, 0.2, 0.21360414, 0.2037595]\n",
      "[0.7066844, 0.2, 0.22499035, 0.26722816]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11720 iterations: 2.8903013308842977 mins\n",
      "Train Loss: [0.7066844, 0.2, 0.22499035, 0.26722816]\n",
      "[0.63031256, 0.2, 0.2123252, 0.20352688]\n",
      "[0.62967515, 0.2, 0.2115611, 0.20365365]\n",
      "[0.63608086, 0.2, 0.21772371, 0.20389543]\n",
      "[0.63936937, 0.2, 0.22292764, 0.20198001]\n",
      "[0.6329135, 0.2, 0.21253856, 0.20591049]\n",
      "[0.62202513, 0.2, 0.2049825, 0.20257504]\n",
      "[0.6248206, 0.2, 0.20851086, 0.20184135]\n",
      "[0.6295695, 0.2, 0.20977174, 0.20532857]\n",
      "[0.63035595, 0.2, 0.21240428, 0.20348094]\n",
      "[0.66524637, 0.2, 0.22149356, 0.22928484]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11730 iterations: 2.892329434553782 mins\n",
      "Train Loss: [0.66524637, 0.2, 0.22149356, 0.22928484]\n",
      "[0.62068635, 0.2, 0.20378427, 0.20243752]\n",
      "[0.6548419, 0.2, 0.21150205, 0.22888325]\n",
      "[0.6296827, 0.2, 0.2120026, 0.20322523]\n",
      "[0.63879764, 0.2, 0.22098586, 0.20335491]\n",
      "[0.64959186, 0.2, 0.20700487, 0.22813186]\n",
      "[0.62634206, 0.2, 0.20885876, 0.20301859]\n",
      "[0.6306037, 0.2, 0.21345648, 0.20267478]\n",
      "[0.62744635, 0.2, 0.20983395, 0.20313136]\n",
      "[0.62580365, 0.2, 0.20678686, 0.20452681]\n",
      "[0.6227578, 0.2, 0.20301832, 0.20524138]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11740 iterations: 2.894297746817271 mins\n",
      "Train Loss: [0.6227578, 0.2, 0.20301832, 0.20524138]\n",
      "[0.6312095, 0.2, 0.21308932, 0.20361556]\n",
      "[0.63070256, 0.2, 0.21176061, 0.20443049]\n",
      "[0.628605, 0.2, 0.21406658, 0.20002213]\n",
      "[0.62069577, 0.2, 0.20273231, 0.2034407]\n",
      "[0.636788, 0.2, 0.21424332, 0.20801814]\n",
      "[0.63969016, 0.2, 0.21597424, 0.20919149]\n",
      "[0.63648343, 0.2, 0.21662311, 0.20534086]\n",
      "[0.6457595, 0.2, 0.20852561, 0.22271916]\n",
      "[0.6269878, 0.2, 0.20900506, 0.20346802]\n",
      "[0.62037975, 0.2, 0.20230696, 0.20355853]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11750 iterations: 2.8978604475657144 mins\n",
      "Train Loss: [0.62037975, 0.2, 0.20230696, 0.20355853]\n",
      "[0.6325557, 0.2, 0.21224202, 0.20580193]\n",
      "[0.6351518, 0.2, 0.21456255, 0.20608243]\n",
      "[0.6399739, 0.2, 0.2212199, 0.20425415]\n",
      "[0.6253103, 0.2, 0.20547348, 0.20534556]\n",
      "[0.62520283, 0.2, 0.20559071, 0.20513189]\n",
      "[0.634956, 0.2, 0.21369915, 0.20679215]\n",
      "[0.62856054, 0.2, 0.2105289, 0.2035841]\n",
      "[0.6521168, 0.2, 0.2250504, 0.21263759]\n",
      "[0.645945, 0.2, 0.22968857, 0.20184785]\n",
      "[0.7181888, 0.2, 0.21437074, 0.28942782]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11760 iterations: 2.899826002120972 mins\n",
      "Train Loss: [0.7181888, 0.2, 0.21437074, 0.28942782]\n",
      "[0.6392342, 0.2, 0.21875763, 0.20610799]\n",
      "[0.62439585, 0.2, 0.2064046, 0.20364492]\n",
      "[0.6436258, 0.2, 0.220649, 0.20865375]\n",
      "[0.63437617, 0.2, 0.21423098, 0.20584244]\n",
      "[0.64316064, 0.2, 0.22098503, 0.20789197]\n",
      "[0.6712236, 0.2, 0.2514123, 0.20555176]\n",
      "[0.64820653, 0.2, 0.22618061, 0.20777012]\n",
      "[0.64808, 0.2, 0.23029104, 0.20353778]\n",
      "[0.62756884, 0.2, 0.21051459, 0.20280968]\n",
      "[0.6396327, 0.2, 0.22177197, 0.2036211]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11770 iterations: 2.9017604192097983 mins\n",
      "Train Loss: [0.6396327, 0.2, 0.22177197, 0.2036211]\n",
      "[0.6446854, 0.2, 0.20174645, 0.2287068]\n",
      "[0.6451634, 0.2, 0.22509615, 0.2058315]\n",
      "[0.6318777, 0.2, 0.21435662, 0.20327064]\n",
      "[0.6271812, 0.2, 0.20896523, 0.20394863]\n",
      "[0.63064015, 0.2, 0.21128763, 0.20507331]\n",
      "[0.6402162, 0.2, 0.21817411, 0.20775503]\n",
      "[0.62792766, 0.2, 0.20518474, 0.20845063]\n",
      "[0.70024353, 0.2, 0.24119432, 0.24475244]\n",
      "[0.66548663, 0.2, 0.24714838, 0.20404711]\n",
      "[0.6397949, 0.2, 0.22073905, 0.2047599]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11780 iterations: 2.903718348344167 mins\n",
      "Train Loss: [0.6397949, 0.2, 0.22073905, 0.2047599]\n",
      "[0.6195003, 0.2, 0.2026205, 0.20258358]\n",
      "[0.62630117, 0.2, 0.20629165, 0.20571452]\n",
      "[0.6460935, 0.2, 0.20844457, 0.22335671]\n",
      "[0.62426573, 0.2, 0.20684132, 0.20314392]\n",
      "[0.62752914, 0.2, 0.21016121, 0.20309488]\n",
      "[0.62072444, 0.2, 0.20451547, 0.20194069]\n",
      "[0.6396709, 0.2, 0.22044131, 0.20496646]\n",
      "[0.6277295, 0.2, 0.20979226, 0.20368022]\n",
      "[0.64167076, 0.2, 0.2194943, 0.2079272]\n",
      "[0.6393573, 0.2, 0.2191228, 0.2059941]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11790 iterations: 2.9057238976160686 mins\n",
      "Train Loss: [0.6393573, 0.2, 0.2191228, 0.2059941]\n",
      "[0.6284828, 0.2, 0.2087929, 0.20545709]\n",
      "[0.6694265, 0.2, 0.21478513, 0.24041598]\n",
      "[0.6396003, 0.2, 0.21710435, 0.20827124]\n",
      "[0.68429327, 0.2, 0.20847225, 0.26160002]\n",
      "[0.6335257, 0.2, 0.21642408, 0.20288858]\n",
      "[0.62180656, 0.2, 0.2049799, 0.20261893]\n",
      "[0.6289548, 0.2, 0.20896794, 0.20578398]\n",
      "[0.6385708, 0.2, 0.2184554, 0.20591727]\n",
      "[0.6516028, 0.2, 0.23048528, 0.20692189]\n",
      "[0.6202738, 0.2, 0.20407586, 0.20200144]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11800 iterations: 2.9077346682548524 mins\n",
      "Train Loss: [0.6202738, 0.2, 0.20407586, 0.20200144]\n",
      "[0.6293804, 0.2, 0.21069556, 0.20448917]\n",
      "[0.62231326, 0.2, 0.20472905, 0.20338984]\n",
      "[0.6342875, 0.2, 0.21562341, 0.20447284]\n",
      "[0.6279703, 0.2, 0.20536491, 0.20841831]\n",
      "[0.6246139, 0.2, 0.20483325, 0.20560163]\n",
      "[0.634151, 0.2, 0.216159, 0.20382605]\n",
      "[0.6209242, 0.2, 0.20174299, 0.20503096]\n",
      "[0.63810617, 0.2, 0.21489966, 0.2090748]\n",
      "[0.63297737, 0.2, 0.21418338, 0.20468272]\n",
      "[0.654177, 0.2, 0.23508264, 0.20500617]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11810 iterations: 2.9096983830134073 mins\n",
      "Train Loss: [0.654177, 0.2, 0.23508264, 0.20500617]\n",
      "[0.62786305, 0.2, 0.20841324, 0.20536232]\n",
      "[0.6430752, 0.2, 0.22425786, 0.20473117]\n",
      "[0.6395382, 0.2, 0.22154579, 0.20391075]\n",
      "[0.63130593, 0.2, 0.21525663, 0.20197387]\n",
      "[0.63148195, 0.2, 0.21130595, 0.2061088]\n",
      "[0.62755686, 0.2, 0.21005943, 0.20343934]\n",
      "[0.6214987, 0.2, 0.20236948, 0.20508187]\n",
      "[0.65210706, 0.2, 0.2356004, 0.20247217]\n",
      "[0.65239465, 0.2, 0.23465675, 0.20372]\n",
      "[0.6694012, 0.2, 0.2525561, 0.20285062]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11820 iterations: 2.9117350816726684 mins\n",
      "Train Loss: [0.6694012, 0.2, 0.2525561, 0.20285062]\n",
      "[0.64177907, 0.2, 0.22361536, 0.20420748]\n",
      "[0.62707096, 0.2, 0.20689541, 0.20625643]\n",
      "[0.62864697, 0.2, 0.2109409, 0.20382223]\n",
      "[0.6316341, 0.2, 0.21485443, 0.20293325]\n",
      "[0.6525694, 0.2, 0.23308551, 0.20567226]\n",
      "[0.6351756, 0.2, 0.2153071, 0.2060902]\n",
      "[0.63565975, 0.2, 0.2189707, 0.20294128]\n",
      "[0.62974846, 0.2, 0.21113874, 0.20489028]\n",
      "[0.6412976, 0.2, 0.21950017, 0.20810474]\n",
      "[0.6370949, 0.2, 0.21632895, 0.20709974]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11830 iterations: 2.9142943302790325 mins\n",
      "Train Loss: [0.6370949, 0.2, 0.21632895, 0.20709974]\n",
      "[0.629641, 0.2, 0.211823, 0.20417568]\n",
      "[0.6286309, 0.2, 0.21031924, 0.204694]\n",
      "[0.63173884, 0.2, 0.21104662, 0.20709863]\n",
      "[0.6444112, 0.2, 0.22634406, 0.20449506]\n",
      "[0.6189729, 0.2, 0.2024781, 0.20294283]\n",
      "[0.6233369, 0.2, 0.20783783, 0.2019675]\n",
      "[0.62299806, 0.2, 0.20693162, 0.20255402]\n",
      "[0.63250065, 0.2, 0.2127063, 0.20630386]\n",
      "[0.6393658, 0.2, 0.2248158, 0.20108183]\n",
      "[0.63283557, 0.2, 0.21422446, 0.20516396]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11840 iterations: 2.916187846660614 mins\n",
      "Train Loss: [0.63283557, 0.2, 0.21422446, 0.20516396]\n",
      "[0.63110924, 0.2, 0.21288905, 0.20479424]\n",
      "[0.62977505, 0.2, 0.21323064, 0.2031373]\n",
      "[0.63552535, 0.2, 0.21807408, 0.20406505]\n",
      "[0.66712385, 0.2, 0.25017062, 0.20358706]\n",
      "[0.62943643, 0.2, 0.21257047, 0.20350447]\n",
      "[0.62879664, 0.2, 0.21094787, 0.20449056]\n",
      "[0.6340294, 0.2, 0.21602468, 0.2046498]\n",
      "[0.62910223, 0.2, 0.20711794, 0.2086293]\n",
      "[0.62209165, 0.2, 0.20531349, 0.20342208]\n",
      "[0.62582535, 0.2, 0.2107263, 0.20174347]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11850 iterations: 2.918210550149282 mins\n",
      "Train Loss: [0.62582535, 0.2, 0.2107263, 0.20174347]\n",
      "[0.6372342, 0.2, 0.21984051, 0.20404074]\n",
      "[0.61919725, 0.2, 0.20271559, 0.2031332]\n",
      "[0.6365501, 0.2, 0.21828866, 0.20491982]\n",
      "[0.6350805, 0.2, 0.21914648, 0.20260325]\n",
      "[0.6395793, 0.2, 0.22208662, 0.20417488]\n",
      "[0.628196, 0.2, 0.21038294, 0.20450972]\n",
      "[0.62348294, 0.2, 0.20660448, 0.2035888]\n",
      "[0.63365, 0.2, 0.21726304, 0.20311055]\n",
      "[0.6249163, 0.2, 0.20350309, 0.20814918]\n",
      "[0.6268897, 0.2, 0.21138373, 0.20225523]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11860 iterations: 2.9200891653696694 mins\n",
      "Train Loss: [0.6268897, 0.2, 0.21138373, 0.20225523]\n",
      "[0.6240913, 0.2, 0.20658347, 0.20427035]\n",
      "[0.66231954, 0.2, 0.20652539, 0.24257044]\n",
      "[0.6280083, 0.2, 0.21026136, 0.20452122]\n",
      "[0.62682575, 0.2, 0.2117624, 0.20183505]\n",
      "[0.6313083, 0.2, 0.21323355, 0.20484155]\n",
      "[0.6314152, 0.2, 0.21567331, 0.20250413]\n",
      "[0.6205493, 0.2, 0.20301817, 0.20429052]\n",
      "[0.64188343, 0.2, 0.22678116, 0.20186207]\n",
      "[0.6244373, 0.2, 0.207473, 0.20372514]\n",
      "[0.6217022, 0.2, 0.20586936, 0.20259884]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11870 iterations: 2.922101080417633 mins\n",
      "Train Loss: [0.6217022, 0.2, 0.20586936, 0.20259884]\n",
      "[0.62730783, 0.2, 0.21098185, 0.20309857]\n",
      "[0.62656516, 0.2, 0.20917338, 0.20417109]\n",
      "[0.6266713, 0.2, 0.21112666, 0.20233421]\n",
      "[0.6266283, 0.2, 0.20830138, 0.20512798]\n",
      "[0.6275148, 0.2, 0.21226494, 0.2020649]\n",
      "[0.6235406, 0.2, 0.20468353, 0.20568624]\n",
      "[0.64784104, 0.2, 0.22808586, 0.20660126]\n",
      "[0.6314599, 0.2, 0.21526165, 0.20307037]\n",
      "[0.64825046, 0.2, 0.20979606, 0.2253515]\n",
      "[0.7009368, 0.2, 0.26443845, 0.22341692]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11880 iterations: 2.923928916454315 mins\n",
      "Train Loss: [0.7009368, 0.2, 0.26443845, 0.22341692]\n",
      "[0.62169033, 0.2, 0.2048059, 0.20380645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6216169, 0.2, 0.20642743, 0.20211442]\n",
      "[0.63207936, 0.2, 0.21653253, 0.20247552]\n",
      "[0.63072985, 0.2, 0.21497166, 0.20269123]\n",
      "[0.62543213, 0.2, 0.20853946, 0.20383026]\n",
      "[0.6304078, 0.2, 0.2128891, 0.20446213]\n",
      "[0.6356601, 0.2, 0.21914062, 0.2034723]\n",
      "[0.63817, 0.2, 0.22038345, 0.20475082]\n",
      "[0.648213, 0.2, 0.23302297, 0.20216574]\n",
      "[0.62574774, 0.2, 0.21002056, 0.20272261]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11890 iterations: 2.9262198011080423 mins\n",
      "Train Loss: [0.62574774, 0.2, 0.21002056, 0.20272261]\n",
      "[0.642688, 0.2, 0.2254936, 0.20420846]\n",
      "[0.67430925, 0.2, 0.21606939, 0.24527173]\n",
      "[0.6265726, 0.2, 0.20813653, 0.20548314]\n",
      "[0.6249628, 0.2, 0.20797177, 0.20405069]\n",
      "[0.6285065, 0.2, 0.21280387, 0.20277366]\n",
      "[0.642396, 0.2, 0.22617184, 0.20330894]\n",
      "[0.6251021, 0.2, 0.20959423, 0.20260534]\n",
      "[0.62648183, 0.2, 0.20705405, 0.2065377]\n",
      "[0.6193257, 0.2, 0.20379673, 0.20265087]\n",
      "[0.6332823, 0.2, 0.21821569, 0.20220117]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11900 iterations: 2.9282486836115518 mins\n",
      "Train Loss: [0.6332823, 0.2, 0.21821569, 0.20220117]\n",
      "[0.62767386, 0.2, 0.2108129, 0.20400889]\n",
      "[0.62484795, 0.2, 0.21007454, 0.20193394]\n",
      "[0.63256574, 0.2, 0.21391219, 0.20582719]\n",
      "[0.6380479, 0.2, 0.21739452, 0.20783836]\n",
      "[0.62696195, 0.2, 0.21014816, 0.20401117]\n",
      "[0.6201746, 0.2, 0.20472455, 0.20266044]\n",
      "[0.6380076, 0.2, 0.2191279, 0.20610401]\n",
      "[0.62357235, 0.2, 0.20389746, 0.20691401]\n",
      "[0.62077457, 0.2, 0.20605473, 0.20197397]\n",
      "[0.63112926, 0.2, 0.21094003, 0.2074599]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11910 iterations: 2.930207582314809 mins\n",
      "Train Loss: [0.63112926, 0.2, 0.21094003, 0.2074599]\n",
      "[0.63597465, 0.2, 0.22046475, 0.20279552]\n",
      "[0.62190175, 0.2, 0.2069913, 0.20220868]\n",
      "[0.6374677, 0.2, 0.22078373, 0.20399587]\n",
      "[0.6226833, 0.2, 0.20586467, 0.20414637]\n",
      "[0.6476218, 0.2, 0.20766479, 0.2272995]\n",
      "[0.6328014, 0.2, 0.21597783, 0.20419103]\n",
      "[0.6318496, 0.2, 0.21280941, 0.2064261]\n",
      "[0.6296797, 0.2, 0.21380806, 0.20326945]\n",
      "[0.63606435, 0.2, 0.21670645, 0.20676361]\n",
      "[0.6305325, 0.2, 0.2143711, 0.20357378]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11920 iterations: 2.932738717397054 mins\n",
      "Train Loss: [0.6305325, 0.2, 0.2143711, 0.20357378]\n",
      "[0.62076896, 0.2, 0.20537584, 0.20281078]\n",
      "[0.6244014, 0.2, 0.2033123, 0.20851123]\n",
      "[0.62717485, 0.2, 0.21211791, 0.2024819]\n",
      "[0.64569795, 0.2, 0.2287689, 0.20435748]\n",
      "[0.63346875, 0.2, 0.2167014, 0.20419933]\n",
      "[0.6227285, 0.2, 0.20469716, 0.2054678]\n",
      "[0.6253571, 0.2, 0.20952466, 0.20327382]\n",
      "[0.6202134, 0.2, 0.20503414, 0.2026272]\n",
      "[0.6329452, 0.2, 0.21359113, 0.20680839]\n",
      "[0.6345115, 0.2, 0.2193132, 0.20266]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11930 iterations: 2.934566267331441 mins\n",
      "Train Loss: [0.6345115, 0.2, 0.2193132, 0.20266]\n",
      "[0.62754935, 0.2, 0.21018636, 0.20483132]\n",
      "[0.6260182, 0.2, 0.20903458, 0.20446092]\n",
      "[0.6309641, 0.2, 0.21582632, 0.20262419]\n",
      "[0.64891225, 0.2, 0.21420208, 0.22220819]\n",
      "[0.6275768, 0.2, 0.21287045, 0.20221524]\n",
      "[0.62321824, 0.2, 0.20396648, 0.20677035]\n",
      "[0.62536836, 0.2, 0.20959528, 0.20330219]\n",
      "[0.62634957, 0.2, 0.20940426, 0.2044853]\n",
      "[0.6395585, 0.2, 0.22262497, 0.20448406]\n",
      "[0.62833595, 0.2, 0.21213204, 0.20376445]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11940 iterations: 2.9365607857704163 mins\n",
      "Train Loss: [0.62833595, 0.2, 0.21213204, 0.20376445]\n",
      "[0.625163, 0.2, 0.20919615, 0.20353661]\n",
      "[0.6328134, 0.2, 0.21751326, 0.20287946]\n",
      "[0.6778959, 0.2, 0.2132254, 0.25225848]\n",
      "[0.6210619, 0.2, 0.20475714, 0.20390208]\n",
      "[0.62554324, 0.2, 0.21028012, 0.20287117]\n",
      "[0.6176098, 0.2, 0.20233865, 0.20289141]\n",
      "[0.6433486, 0.2, 0.20281225, 0.22817026]\n",
      "[0.6294078, 0.2, 0.21410939, 0.20294712]\n",
      "[0.62742865, 0.2, 0.21270105, 0.20239004]\n",
      "[0.6248167, 0.2, 0.2098191, 0.20267236]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11950 iterations: 2.938523014386495 mins\n",
      "Train Loss: [0.6248167, 0.2, 0.2098191, 0.20267236]\n",
      "[0.6242931, 0.2, 0.20834412, 0.20363592]\n",
      "[0.6191563, 0.2, 0.20509791, 0.20175752]\n",
      "[0.6314001, 0.2, 0.21612488, 0.20298615]\n",
      "[0.627742, 0.2, 0.21241751, 0.20304994]\n",
      "[0.6181239, 0.2, 0.20356049, 0.20230427]\n",
      "[0.6286168, 0.2, 0.21393308, 0.20244054]\n",
      "[0.6216647, 0.2, 0.20681076, 0.2026272]\n",
      "[0.6255791, 0.2, 0.21095619, 0.20241368]\n",
      "[0.62442434, 0.2, 0.20988022, 0.20235385]\n",
      "[0.6219521, 0.2, 0.20736709, 0.20241308]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11960 iterations: 2.940513817469279 mins\n",
      "Train Loss: [0.6219521, 0.2, 0.20736709, 0.20241308]\n",
      "[0.62271833, 0.2, 0.20788878, 0.20267798]\n",
      "[0.62498, 0.2, 0.20842178, 0.20442708]\n",
      "[0.6257507, 0.2, 0.20976822, 0.20387247]\n",
      "[0.622528, 0.2, 0.2071377, 0.203301]\n",
      "[0.6310621, 0.2, 0.21548295, 0.20350836]\n",
      "[0.6372142, 0.2, 0.22126344, 0.20389707]\n",
      "[0.64497644, 0.2, 0.20480591, 0.22813343]\n",
      "[0.6262915, 0.2, 0.21107347, 0.20320487]\n",
      "[0.6276611, 0.2, 0.21177727, 0.20388916]\n",
      "[0.62864256, 0.2, 0.21477337, 0.20189066]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11970 iterations: 2.9426101485888165 mins\n",
      "Train Loss: [0.62864256, 0.2, 0.21477337, 0.20189066]\n",
      "[0.620737, 0.2, 0.2040183, 0.20475264]\n",
      "[0.64525145, 0.2, 0.21257648, 0.22072084]\n",
      "[0.634778, 0.2, 0.21835756, 0.20447989]\n",
      "[0.6282682, 0.2, 0.20877051, 0.20756443]\n",
      "[0.6253523, 0.2, 0.20658338, 0.20684089]\n",
      "[0.6281097, 0.2, 0.21171607, 0.20446756]\n",
      "[0.6252588, 0.2, 0.20807014, 0.20526396]\n",
      "[0.6244298, 0.2, 0.20713048, 0.20537601]\n",
      "[0.61741835, 0.2, 0.20326155, 0.20223787]\n",
      "[0.7108985, 0.2, 0.20686638, 0.2921172]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11980 iterations: 2.9445605993270876 mins\n",
      "Train Loss: [0.7108985, 0.2, 0.20686638, 0.2921172]\n",
      "[0.62987006, 0.2, 0.21402651, 0.20393403]\n",
      "[0.62464345, 0.2, 0.20857963, 0.20415942]\n",
      "[0.62465745, 0.2, 0.21020058, 0.20255442]\n",
      "[0.6328494, 0.2, 0.21813737, 0.20281012]\n",
      "[0.6374342, 0.2, 0.22114822, 0.20438696]\n",
      "[0.62567586, 0.2, 0.21023576, 0.2035439]\n",
      "[0.6264758, 0.2, 0.213353, 0.2012311]\n",
      "[0.62686175, 0.2, 0.2126602, 0.20231582]\n",
      "[0.623021, 0.2, 0.20873125, 0.20241116]\n",
      "[0.6537499, 0.2, 0.23817255, 0.20370632]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11990 iterations: 2.9471917351086936 mins\n",
      "Train Loss: [0.6537499, 0.2, 0.23817255, 0.20370632]\n",
      "[0.63452697, 0.2, 0.21080486, 0.21185654]\n",
      "[0.6844536, 0.2, 0.24642146, 0.22617303]\n",
      "[0.6256414, 0.2, 0.20750335, 0.20629139]\n",
      "[0.63235056, 0.2, 0.21588585, 0.2046293]\n",
      "[0.62599975, 0.2, 0.2116592, 0.20251504]\n",
      "[0.6943393, 0.2, 0.20409656, 0.2784262]\n",
      "[0.6228314, 0.2, 0.20832694, 0.20269412]\n",
      "[0.6252843, 0.2, 0.20829055, 0.205187]\n",
      "[0.6239855, 0.2, 0.20999467, 0.20218672]\n",
      "[0.6418643, 0.2, 0.20769419, 0.2223685]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12000 iterations: 2.9492066820462544 mins\n",
      "Train Loss: [0.6418643, 0.2, 0.20769419, 0.2223685]\n",
      "[0.62584674, 0.2, 0.21258375, 0.20146485]\n",
      "[0.63323736, 0.2, 0.21856327, 0.20287718]\n",
      "[0.6305299, 0.2, 0.21453342, 0.20420308]\n",
      "[0.6218442, 0.2, 0.20334038, 0.20671159]\n",
      "[0.62176377, 0.2, 0.20853595, 0.20143755]\n",
      "[0.64009356, 0.2, 0.22417536, 0.20412847]\n",
      "[0.6223958, 0.2, 0.2071283, 0.2034754]\n",
      "[0.6215432, 0.2, 0.20758213, 0.20216666]\n",
      "[0.6657915, 0.2, 0.21448858, 0.23950696]\n",
      "[0.6217296, 0.2, 0.20383406, 0.2060923]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12010 iterations: 2.9511412978172302 mins\n",
      "Train Loss: [0.6217296, 0.2, 0.20383406, 0.2060923]\n",
      "[0.63003707, 0.2, 0.2111669, 0.20706132]\n",
      "[0.6222377, 0.2, 0.20670414, 0.2037205]\n",
      "[0.626251, 0.2, 0.20929347, 0.20514108]\n",
      "[0.6279501, 0.2, 0.21315654, 0.20297575]\n",
      "[0.62312764, 0.2, 0.20560299, 0.20570785]\n",
      "[0.62201375, 0.2, 0.20661867, 0.20358047]\n",
      "[0.6240747, 0.2, 0.20969582, 0.20256868]\n",
      "[0.62625766, 0.2, 0.21306923, 0.20138353]\n",
      "[0.62491, 0.2, 0.20956935, 0.20354229]\n",
      "[0.6240561, 0.2, 0.20990883, 0.20235695]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12020 iterations: 2.9531801184018454 mins\n",
      "Train Loss: [0.6240561, 0.2, 0.20990883, 0.20235695]\n",
      "[0.66464716, 0.2, 0.2120048, 0.24086006]\n",
      "[0.6218441, 0.2, 0.20737265, 0.2027008]\n",
      "[0.6311824, 0.2, 0.21574159, 0.20368089]\n",
      "[0.6192647, 0.2, 0.20365238, 0.20386666]\n",
      "[0.6170204, 0.2, 0.20237698, 0.20291308]\n",
      "[0.619122, 0.2, 0.20371816, 0.20368935]\n",
      "[0.6235141, 0.2, 0.2086035, 0.20321108]\n",
      "[0.61966693, 0.2, 0.20488936, 0.20309328]\n",
      "[0.62664616, 0.2, 0.21115842, 0.20381969]\n",
      "[0.6315634, 0.2, 0.21817306, 0.20173691]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12030 iterations: 2.955034816265106 mins\n",
      "Train Loss: [0.6315634, 0.2, 0.21817306, 0.20173691]\n",
      "[0.6355033, 0.2, 0.21949075, 0.20437263]\n",
      "[0.6272415, 0.2, 0.21347284, 0.20214361]\n",
      "[0.63694555, 0.2, 0.21951933, 0.20581654]\n",
      "[0.63237363, 0.2, 0.21469052, 0.20608528]\n",
      "[0.6188026, 0.2, 0.20412964, 0.20308939]\n",
      "[0.61803365, 0.2, 0.20403747, 0.20242646]\n",
      "[0.62240595, 0.2, 0.20802361, 0.20282628]\n",
      "[0.6322061, 0.2, 0.21660452, 0.20405924]\n",
      "[0.62192637, 0.2, 0.20621589, 0.2041807]\n",
      "[0.6256779, 0.2, 0.20877714, 0.20538232]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12040 iterations: 2.9570558667182922 mins\n",
      "Train Loss: [0.6256779, 0.2, 0.20877714, 0.20538232]\n",
      "[0.61968386, 0.2, 0.2051816, 0.20299591]\n",
      "[0.6638959, 0.2, 0.21079281, 0.24160843]\n",
      "[0.63448864, 0.2, 0.221674, 0.20133741]\n",
      "[0.6248336, 0.2, 0.20789613, 0.20547523]\n",
      "[0.6468123, 0.2, 0.23220788, 0.20315707]\n",
      "[0.61900127, 0.2, 0.20298, 0.20459105]\n",
      "[0.62630665, 0.2, 0.21121109, 0.20368227]\n",
      "[0.62396485, 0.2, 0.20927179, 0.20329718]\n",
      "[0.62637097, 0.2, 0.21349406, 0.20149681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6166681, 0.2, 0.20199381, 0.20330828]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12050 iterations: 2.958932081858317 mins\n",
      "Train Loss: [0.6166681, 0.2, 0.20199381, 0.20330828]\n",
      "[0.62155753, 0.2, 0.20632377, 0.20388073]\n",
      "[0.6622228, 0.2, 0.24780092, 0.20308082]\n",
      "[0.62221587, 0.2, 0.20787103, 0.20300654]\n",
      "[0.62713027, 0.2, 0.21236421, 0.20343167]\n",
      "[0.6189967, 0.2, 0.20484807, 0.20281836]\n",
      "[0.6330715, 0.2, 0.21657413, 0.20517248]\n",
      "[0.61829734, 0.2, 0.20363288, 0.20335016]\n",
      "[0.62268436, 0.2, 0.20870042, 0.20267998]\n",
      "[0.6256497, 0.2, 0.20923382, 0.20512095]\n",
      "[0.62700725, 0.2, 0.21193543, 0.20378536]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12060 iterations: 2.9608308831850687 mins\n",
      "Train Loss: [0.62700725, 0.2, 0.21193543, 0.20378536]\n",
      "[0.62310266, 0.2, 0.2092611, 0.20256135]\n",
      "[0.61997336, 0.2, 0.20548598, 0.20321363]\n",
      "[0.6240125, 0.2, 0.20839351, 0.20435166]\n",
      "[0.62329775, 0.2, 0.21018416, 0.20185296]\n",
      "[0.62654805, 0.2, 0.21106412, 0.20423071]\n",
      "[0.63113606, 0.2, 0.21243884, 0.20745638]\n",
      "[0.622737, 0.2, 0.20696302, 0.20454706]\n",
      "[0.6272133, 0.2, 0.2129823, 0.20301978]\n",
      "[0.6174804, 0.2, 0.20329183, 0.2029929]\n",
      "[0.6256565, 0.2, 0.21122183, 0.20325398]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12070 iterations: 2.962912599245707 mins\n",
      "Train Loss: [0.6256565, 0.2, 0.21122183, 0.20325398]\n",
      "[0.6236124, 0.2, 0.20954302, 0.2029048]\n",
      "[0.690198, 0.2, 0.27680856, 0.20224094]\n",
      "[0.62402374, 0.2, 0.20669211, 0.20618047]\n",
      "[0.62404287, 0.2, 0.2104437, 0.20244426]\n",
      "[0.6425049, 0.2, 0.21028703, 0.22106057]\n",
      "[0.6203043, 0.2, 0.20382579, 0.205322]\n",
      "[0.6257883, 0.2, 0.20985335, 0.20477958]\n",
      "[0.62367034, 0.2, 0.20985816, 0.20265949]\n",
      "[0.6223303, 0.2, 0.207816, 0.20336549]\n",
      "[0.6224318, 0.2, 0.20694932, 0.20433798]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12080 iterations: 2.9653049151102704 mins\n",
      "Train Loss: [0.6224318, 0.2, 0.20694932, 0.20433798]\n",
      "[0.628262, 0.2, 0.21205826, 0.2050637]\n",
      "[0.6170559, 0.2, 0.20387149, 0.2020491]\n",
      "[0.62069947, 0.2, 0.20789422, 0.2016753]\n",
      "[0.6190384, 0.2, 0.20407125, 0.20384292]\n",
      "[0.6232122, 0.2, 0.20848924, 0.20360556]\n",
      "[0.62256646, 0.2, 0.20813595, 0.20332117]\n",
      "[0.6176796, 0.2, 0.20279104, 0.20378813]\n",
      "[0.62741905, 0.2, 0.2124935, 0.2038347]\n",
      "[0.63123125, 0.2, 0.2171085, 0.20304213]\n",
      "[0.6201085, 0.2, 0.20454381, 0.20449369]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12090 iterations: 2.9673129161198935 mins\n",
      "Train Loss: [0.6201085, 0.2, 0.20454381, 0.20449369]\n",
      "[0.6325753, 0.2, 0.21873707, 0.20277674]\n",
      "[0.62241316, 0.2, 0.20658545, 0.20477578]\n",
      "[0.6215505, 0.2, 0.20713489, 0.20337325]\n",
      "[0.6253981, 0.2, 0.20897822, 0.20538679]\n",
      "[0.6326897, 0.2, 0.21596816, 0.2056974]\n",
      "[0.63392824, 0.2, 0.22097461, 0.20193928]\n",
      "[0.6255391, 0.2, 0.21103267, 0.20350128]\n",
      "[0.6382283, 0.2, 0.22094005, 0.20629214]\n",
      "[0.6567866, 0.2, 0.24329767, 0.20249957]\n",
      "[0.6225767, 0.2, 0.21019079, 0.20139457]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12100 iterations: 2.9692238489786784 mins\n",
      "Train Loss: [0.6225767, 0.2, 0.21019079, 0.20139457]\n",
      "[0.6375205, 0.2, 0.22048911, 0.20603925]\n",
      "[0.6288575, 0.2, 0.21308324, 0.2047801]\n",
      "[0.6257865, 0.2, 0.21197516, 0.20281556]\n",
      "[0.6225729, 0.2, 0.21004488, 0.20153058]\n",
      "[0.6209842, 0.2, 0.20799637, 0.20198956]\n",
      "[0.6247492, 0.2, 0.20831065, 0.2054405]\n",
      "[0.6279044, 0.2, 0.21405558, 0.20285147]\n",
      "[0.62771225, 0.2, 0.21015613, 0.20656064]\n",
      "[0.6323127, 0.2, 0.21360783, 0.20771255]\n",
      "[0.6451147, 0.2, 0.2073187, 0.2268086]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12110 iterations: 2.971242650349935 mins\n",
      "Train Loss: [0.6451147, 0.2, 0.2073187, 0.2268086]\n",
      "[0.6251174, 0.2, 0.20959295, 0.20454295]\n",
      "[0.6293239, 0.2, 0.21603319, 0.20231433]\n",
      "[0.6245844, 0.2, 0.20926617, 0.20434517]\n",
      "[0.61948895, 0.2, 0.20619813, 0.20231989]\n",
      "[0.6229641, 0.2, 0.20986883, 0.20212907]\n",
      "[0.6158973, 0.2, 0.20285429, 0.20208342]\n",
      "[0.61682457, 0.2, 0.20453312, 0.20133807]\n",
      "[0.6198856, 0.2, 0.20761995, 0.20131896]\n",
      "[0.6211662, 0.2, 0.20801185, 0.20221543]\n",
      "[0.6203661, 0.2, 0.20874813, 0.20068726]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12120 iterations: 2.9733311812082928 mins\n",
      "Train Loss: [0.6203661, 0.2, 0.20874813, 0.20068726]\n",
      "[0.67481685, 0.2, 0.2592439, 0.20465113]\n",
      "[0.6231494, 0.2, 0.2063602, 0.2058761]\n",
      "[0.6221366, 0.2, 0.20788935, 0.20334294]\n",
      "[0.6274418, 0.2, 0.21313503, 0.20341222]\n",
      "[0.62325424, 0.2, 0.20827365, 0.2040939]\n",
      "[0.6223192, 0.2, 0.20747048, 0.20397255]\n",
      "[0.6160918, 0.2, 0.20260954, 0.20261587]\n",
      "[0.62930405, 0.2, 0.21511815, 0.20333037]\n",
      "[0.6230611, 0.2, 0.20931482, 0.20290153]\n",
      "[0.62504333, 0.2, 0.21155447, 0.2026556]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12130 iterations: 2.9752660989761353 mins\n",
      "Train Loss: [0.62504333, 0.2, 0.21155447, 0.2026556]\n",
      "[0.62210715, 0.2, 0.20870751, 0.20257966]\n",
      "[0.62487745, 0.2, 0.21040814, 0.20366119]\n",
      "[0.62471455, 0.2, 0.21143958, 0.20247927]\n",
      "[0.61811316, 0.2, 0.20340979, 0.20391913]\n",
      "[0.64987534, 0.2, 0.23703758, 0.20206493]\n",
      "[0.6292296, 0.2, 0.21525455, 0.20321025]\n",
      "[0.61843055, 0.2, 0.20436665, 0.20330665]\n",
      "[0.62163776, 0.2, 0.20716995, 0.20371902]\n",
      "[0.6288615, 0.2, 0.21515884, 0.20296358]\n",
      "[0.6236985, 0.2, 0.20939726, 0.20357172]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12140 iterations: 2.9772858301798504 mins\n",
      "Train Loss: [0.6236985, 0.2, 0.20939726, 0.20357172]\n",
      "[0.62034076, 0.2, 0.20720077, 0.20241927]\n",
      "[0.6234959, 0.2, 0.20951958, 0.20326427]\n",
      "[0.6316899, 0.2, 0.2186325, 0.20235318]\n",
      "[0.66340536, 0.2, 0.20143937, 0.25126976]\n",
      "[0.6211788, 0.2, 0.20701164, 0.20347756]\n",
      "[0.6229958, 0.2, 0.20784514, 0.20446664]\n",
      "[0.62245107, 0.2, 0.2090671, 0.2027045]\n",
      "[0.6208574, 0.2, 0.20819375, 0.20198728]\n",
      "[0.6168284, 0.2, 0.20467085, 0.20148176]\n",
      "[0.6219435, 0.2, 0.2090537, 0.20221503]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12150 iterations: 2.9791357477506 mins\n",
      "Train Loss: [0.6219435, 0.2, 0.2090537, 0.20221503]\n",
      "[0.64932626, 0.2, 0.2139908, 0.22466189]\n",
      "[0.617864, 0.2, 0.20373067, 0.2034643]\n",
      "[0.61976373, 0.2, 0.20651102, 0.20258853]\n",
      "[0.61826104, 0.2, 0.20580749, 0.2017946]\n",
      "[0.6219316, 0.2, 0.20590454, 0.20537348]\n",
      "[0.64970845, 0.2, 0.21380484, 0.22525705]\n",
      "[0.6264595, 0.2, 0.21050802, 0.2053131]\n",
      "[0.6198278, 0.2, 0.2064433, 0.20275559]\n",
      "[0.6271852, 0.2, 0.20481181, 0.21175379]\n",
      "[0.62001735, 0.2, 0.20558494, 0.20382267]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12160 iterations: 2.981839386622111 mins\n",
      "Train Loss: [0.62001735, 0.2, 0.20558494, 0.20382267]\n",
      "[0.6210968, 0.2, 0.20849447, 0.20200267]\n",
      "[0.61934686, 0.2, 0.2050941, 0.20366254]\n",
      "[0.62050754, 0.2, 0.20739383, 0.20253235]\n",
      "[0.6291835, 0.2, 0.2147706, 0.20383938]\n",
      "[0.69196683, 0.2, 0.27628157, 0.20512131]\n",
      "[0.6228357, 0.2, 0.21046491, 0.20181952]\n",
      "[0.6155609, 0.2, 0.2033998, 0.20162039]\n",
      "[0.62347776, 0.2, 0.20824781, 0.20469947]\n",
      "[0.61863214, 0.2, 0.20398654, 0.20412417]\n",
      "[0.6207986, 0.2, 0.20677106, 0.20351562]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12170 iterations: 2.9837714791297913 mins\n",
      "Train Loss: [0.6207986, 0.2, 0.20677106, 0.20351562]\n",
      "[0.6338053, 0.2, 0.21970282, 0.20360067]\n",
      "[0.6265796, 0.2, 0.2114063, 0.20468189]\n",
      "[0.6286234, 0.2, 0.21367303, 0.2044683]\n",
      "[0.62180585, 0.2, 0.20960595, 0.20172691]\n",
      "[0.6231894, 0.2, 0.2087747, 0.2039506]\n",
      "[0.637499, 0.2, 0.20542096, 0.2216229]\n",
      "[0.6162496, 0.2, 0.20258215, 0.20321894]\n",
      "[0.6364588, 0.2, 0.22319686, 0.20281926]\n",
      "[0.63848853, 0.2, 0.22445427, 0.2035961]\n",
      "[0.6265667, 0.2, 0.20983286, 0.20630136]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12180 iterations: 2.985747198263804 mins\n",
      "Train Loss: [0.6265667, 0.2, 0.20983286, 0.20630136]\n",
      "[0.62285614, 0.2, 0.2093947, 0.20303516]\n",
      "[0.6178457, 0.2, 0.20525314, 0.20217273]\n",
      "[0.6242789, 0.2, 0.21001953, 0.20384602]\n",
      "[0.6204081, 0.2, 0.2083258, 0.20167542]\n",
      "[0.6169346, 0.2, 0.20249079, 0.20404279]\n",
      "[0.6173217, 0.2, 0.2043935, 0.20253313]\n",
      "[0.6189922, 0.2, 0.20436461, 0.20423914]\n",
      "[0.61863405, 0.2, 0.20183244, 0.20641965]\n",
      "[0.6603832, 0.2, 0.2109178, 0.23908922]\n",
      "[0.7165331, 0.2, 0.301655, 0.204512]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12190 iterations: 2.9877440174420675 mins\n",
      "Train Loss: [0.7165331, 0.2, 0.301655, 0.204512]\n",
      "[0.6211721, 0.2, 0.2079688, 0.20282556]\n",
      "[0.62028927, 0.2, 0.20641135, 0.20348856]\n",
      "[0.62289953, 0.2, 0.2105411, 0.20195764]\n",
      "[0.62604076, 0.2, 0.21339972, 0.2022296]\n",
      "[0.6185777, 0.2, 0.20546073, 0.20269528]\n",
      "[0.62343955, 0.2, 0.21059622, 0.20241216]\n",
      "[0.6186849, 0.2, 0.20622616, 0.2020195]\n",
      "[0.6230419, 0.2, 0.20754042, 0.20505603]\n",
      "[0.62984127, 0.2, 0.21584313, 0.20354705]\n",
      "[0.6162496, 0.2, 0.20376687, 0.20202938]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12200 iterations: 2.989693566163381 mins\n",
      "Train Loss: [0.6162496, 0.2, 0.20376687, 0.20202938]\n",
      "[0.619534, 0.2, 0.20704627, 0.2020336]\n",
      "[0.63128847, 0.2, 0.21740098, 0.20343344]\n",
      "[0.63008547, 0.2, 0.21780829, 0.2018227]\n",
      "[0.6193234, 0.2, 0.2035016, 0.2053669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62163854, 0.2, 0.20862818, 0.20255625]\n",
      "[0.6243358, 0.2, 0.21031834, 0.20356539]\n",
      "[0.62083507, 0.2, 0.20824906, 0.20213796]\n",
      "[0.6188558, 0.2, 0.20528044, 0.2031325]\n",
      "[0.6267249, 0.2, 0.21389593, 0.20239228]\n",
      "[0.6200037, 0.2, 0.2067764, 0.20279771]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12210 iterations: 2.991717517375946 mins\n",
      "Train Loss: [0.6200037, 0.2, 0.2067764, 0.20279771]\n",
      "[0.6346811, 0.2, 0.22013152, 0.2041276]\n",
      "[0.61594045, 0.2, 0.20281737, 0.20270859]\n",
      "[0.6152025, 0.2, 0.20263931, 0.20215708]\n",
      "[0.6180873, 0.2, 0.20568553, 0.20200472]\n",
      "[0.6210902, 0.2, 0.20784643, 0.20285656]\n",
      "[0.61998695, 0.2, 0.20759623, 0.20201337]\n",
      "[0.6157099, 0.2, 0.2038575, 0.20148586]\n",
      "[0.6164949, 0.2, 0.20375575, 0.2023838]\n",
      "[0.6194664, 0.2, 0.20555809, 0.2035643]\n",
      "[0.6599743, 0.2, 0.21473859, 0.23490296]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12220 iterations: 2.993649931748708 mins\n",
      "Train Loss: [0.6599743, 0.2, 0.21473859, 0.23490296]\n",
      "[0.6236362, 0.2, 0.21236125, 0.20094956]\n",
      "[0.61687154, 0.2, 0.20305024, 0.20350185]\n",
      "[0.618317, 0.2, 0.20567518, 0.20232776]\n",
      "[0.62064457, 0.2, 0.20853867, 0.20179671]\n",
      "[0.6190201, 0.2, 0.2059311, 0.20278452]\n",
      "[0.6210144, 0.2, 0.2076607, 0.20305322]\n",
      "[0.61597633, 0.2, 0.20415887, 0.20152135]\n",
      "[0.6214383, 0.2, 0.20966724, 0.2014806]\n",
      "[0.62018293, 0.2, 0.20666759, 0.20323072]\n",
      "[0.62150013, 0.2, 0.20817691, 0.20304486]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12230 iterations: 2.9956159830093383 mins\n",
      "Train Loss: [0.62150013, 0.2, 0.20817691, 0.20304486]\n",
      "[0.6236782, 0.2, 0.20912714, 0.20428003]\n",
      "[0.61878383, 0.2, 0.2060131, 0.20250872]\n",
      "[0.62009054, 0.2, 0.20634635, 0.20349051]\n",
      "[0.6169704, 0.2, 0.2029454, 0.2037808]\n",
      "[0.6170106, 0.2, 0.20351438, 0.20326169]\n",
      "[0.6211096, 0.2, 0.20734808, 0.20353957]\n",
      "[0.6303788, 0.2, 0.21870801, 0.20146061]\n",
      "[0.6286376, 0.2, 0.21237363, 0.20606636]\n",
      "[0.63113517, 0.2, 0.21024384, 0.21070503]\n",
      "[0.6323293, 0.2, 0.20597109, 0.21618469]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12240 iterations: 2.9981718977292378 mins\n",
      "Train Loss: [0.6323293, 0.2, 0.20597109, 0.21618469]\n",
      "[0.6202246, 0.2, 0.20703626, 0.20302671]\n",
      "[0.6214772, 0.2, 0.20590109, 0.20542388]\n",
      "[0.6222542, 0.2, 0.20916106, 0.20295162]\n",
      "[0.62109655, 0.2, 0.20822611, 0.20273817]\n",
      "[0.61479336, 0.2, 0.20225444, 0.20241423]\n",
      "[0.6196339, 0.2, 0.2065787, 0.20293815]\n",
      "[0.64000475, 0.2, 0.20978956, 0.22010547]\n",
      "[0.61608124, 0.2, 0.20292449, 0.20305327]\n",
      "[0.6295615, 0.2, 0.21655233, 0.2029116]\n",
      "[0.6222054, 0.2, 0.21027277, 0.20184104]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12250 iterations: 3.000055964787801 mins\n",
      "Train Loss: [0.6222054, 0.2, 0.21027277, 0.20184104]\n",
      "[0.6154866, 0.2, 0.20272598, 0.20267339]\n",
      "[0.6715528, 0.2, 0.2052844, 0.2561852]\n",
      "[0.61997545, 0.2, 0.20757535, 0.20232487]\n",
      "[0.614026, 0.2, 0.20251533, 0.2014447]\n",
      "[0.61680025, 0.2, 0.20362195, 0.20312124]\n",
      "[0.6227757, 0.2, 0.2068484, 0.20587891]\n",
      "[0.61660284, 0.2, 0.20417635, 0.20238805]\n",
      "[0.61615795, 0.2, 0.2043612, 0.20176812]\n",
      "[0.6164949, 0.2, 0.20211323, 0.20436262]\n",
      "[0.62357366, 0.2, 0.21034381, 0.20322062]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12260 iterations: 3.002022651831309 mins\n",
      "Train Loss: [0.62357366, 0.2, 0.21034381, 0.20322062]\n",
      "[0.64940625, 0.2, 0.2324918, 0.20691514]\n",
      "[0.62316936, 0.2, 0.21213207, 0.20104088]\n",
      "[0.61885077, 0.2, 0.20636402, 0.20249325]\n",
      "[0.61818296, 0.2, 0.20531106, 0.20288153]\n",
      "[0.6239595, 0.2, 0.21089718, 0.2030761]\n",
      "[0.62096006, 0.2, 0.20590696, 0.20507225]\n",
      "[0.6225116, 0.2, 0.20846827, 0.20406789]\n",
      "[0.6209743, 0.2, 0.20840946, 0.20259435]\n",
      "[0.6266361, 0.2, 0.21220528, 0.20446435]\n",
      "[0.62173265, 0.2, 0.21059194, 0.2011792]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12270 iterations: 3.0038540681203205 mins\n",
      "Train Loss: [0.62173265, 0.2, 0.21059194, 0.2011792]\n",
      "[0.61697626, 0.2, 0.20401068, 0.20300804]\n",
      "[0.61700785, 0.2, 0.20511174, 0.2019431]\n",
      "[0.61832625, 0.2, 0.20709735, 0.20128104]\n",
      "[0.6308549, 0.2, 0.21957193, 0.20134084]\n",
      "[0.6211825, 0.2, 0.2081323, 0.20311452]\n",
      "[0.62961584, 0.2, 0.21784729, 0.20184007]\n",
      "[0.6630992, 0.2, 0.21519318, 0.23798366]\n",
      "[0.61748, 0.2, 0.20473465, 0.20283028]\n",
      "[0.6223637, 0.2, 0.20560712, 0.20684758]\n",
      "[0.6201338, 0.2, 0.20759119, 0.20263925]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12280 iterations: 3.0132251977920532 mins\n",
      "Train Loss: [0.6201338, 0.2, 0.20759119, 0.20263925]\n",
      "[0.6593967, 0.2, 0.20899573, 0.24050306]\n",
      "[0.61950254, 0.2, 0.20689332, 0.20271245]\n",
      "[0.6184338, 0.2, 0.20442168, 0.20411356]\n",
      "[0.61664087, 0.2, 0.2048969, 0.20184258]\n",
      "[0.62543964, 0.2, 0.21218434, 0.20335141]\n",
      "[0.6273147, 0.2, 0.21267124, 0.20473623]\n",
      "[0.61883706, 0.2, 0.20356213, 0.20536605]\n",
      "[0.61734176, 0.2, 0.20407993, 0.2033526]\n",
      "[0.6185535, 0.2, 0.20414586, 0.20449851]\n",
      "[0.62207055, 0.2, 0.20882319, 0.20333874]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12290 iterations: 3.0160860816637673 mins\n",
      "Train Loss: [0.62207055, 0.2, 0.20882319, 0.20333874]\n",
      "[0.6280944, 0.2, 0.21243607, 0.2057511]\n",
      "[0.6176138, 0.2, 0.20516957, 0.2025392]\n",
      "[0.6209011, 0.2, 0.20871037, 0.2022898]\n",
      "[0.61971647, 0.2, 0.20752433, 0.20229469]\n",
      "[0.62205315, 0.2, 0.2098842, 0.20227629]\n",
      "[0.6172135, 0.2, 0.20396276, 0.20336202]\n",
      "[0.6257188, 0.2, 0.21420893, 0.20162597]\n",
      "[0.61974865, 0.2, 0.20702027, 0.20285067]\n",
      "[0.61916304, 0.2, 0.2065459, 0.20274666]\n",
      "[0.6209577, 0.2, 0.20886482, 0.20222986]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12300 iterations: 3.0189441641171775 mins\n",
      "Train Loss: [0.6209577, 0.2, 0.20886482, 0.20222986]\n",
      "[0.62401223, 0.2, 0.2105536, 0.20360488]\n",
      "[0.61898744, 0.2, 0.20329086, 0.20585391]\n",
      "[0.62256116, 0.2, 0.21073414, 0.20199527]\n",
      "[0.6227068, 0.2, 0.2098906, 0.20299564]\n",
      "[0.62667626, 0.2, 0.2123648, 0.20450251]\n",
      "[0.61592126, 0.2, 0.20424098, 0.20188218]\n",
      "[0.6282437, 0.2, 0.21594787, 0.20250806]\n",
      "[0.6228997, 0.2, 0.21137793, 0.20174408]\n",
      "[0.62416786, 0.2, 0.21177542, 0.2026249]\n",
      "[0.62097716, 0.2, 0.20904148, 0.20217782]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12310 iterations: 3.0218668659528096 mins\n",
      "Train Loss: [0.62097716, 0.2, 0.20904148, 0.20217782]\n",
      "[0.6144261, 0.2, 0.20278673, 0.20189163]\n",
      "[0.62117153, 0.2, 0.20880081, 0.20263384]\n",
      "[0.6173988, 0.2, 0.20337893, 0.20429318]\n",
      "[0.6215438, 0.2, 0.21029659, 0.20153145]\n",
      "[0.62615925, 0.2, 0.2135005, 0.20295423]\n",
      "[0.61670834, 0.2, 0.20424996, 0.20276381]\n",
      "[0.6244724, 0.2, 0.2129183, 0.20186971]\n",
      "[0.6221189, 0.2, 0.21003033, 0.20241432]\n",
      "[0.6261068, 0.2, 0.21152712, 0.20491455]\n",
      "[0.6185514, 0.2, 0.2066802, 0.20221442]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12320 iterations: 3.0243058959643045 mins\n",
      "Train Loss: [0.6185514, 0.2, 0.2066802, 0.20221442]\n",
      "[0.62664473, 0.2, 0.21467277, 0.20232311]\n",
      "[0.6155881, 0.2, 0.2026937, 0.20325582]\n",
      "[0.61742496, 0.2, 0.2057104, 0.20208594]\n",
      "[0.6221267, 0.2, 0.20928255, 0.20322494]\n",
      "[0.6160851, 0.2, 0.20344801, 0.20302843]\n",
      "[0.61978, 0.2, 0.20856805, 0.2016148]\n",
      "[0.62791234, 0.2, 0.21520256, 0.20312414]\n",
      "[0.62572837, 0.2, 0.21350218, 0.20265155]\n",
      "[0.6253331, 0.2, 0.21261556, 0.20315343]\n",
      "[0.62657946, 0.2, 0.21437229, 0.20265287]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12330 iterations: 3.026621997356415 mins\n",
      "Train Loss: [0.62657946, 0.2, 0.21437229, 0.20265287]\n",
      "[0.6207472, 0.2, 0.20876513, 0.2024372]\n",
      "[0.62996453, 0.2, 0.21709174, 0.20333692]\n",
      "[0.6242255, 0.2, 0.21108676, 0.2036122]\n",
      "[0.6218106, 0.2, 0.20956938, 0.20272306]\n",
      "[0.6298659, 0.2, 0.21701825, 0.20333727]\n",
      "[0.6291287, 0.2, 0.21603599, 0.20358995]\n",
      "[0.6273878, 0.2, 0.21397771, 0.20391403]\n",
      "[0.6173447, 0.2, 0.20486037, 0.2029941]\n",
      "[0.61939996, 0.2, 0.20648547, 0.20343006]\n",
      "[0.62798, 0.2, 0.21639892, 0.20210147]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12340 iterations: 3.0289897958437604 mins\n",
      "Train Loss: [0.62798, 0.2, 0.21639892, 0.20210147]\n",
      "[0.6174491, 0.2, 0.2050307, 0.20294306]\n",
      "[0.6259691, 0.2, 0.2139829, 0.20251518]\n",
      "[0.6230481, 0.2, 0.2109257, 0.20265612]\n",
      "[0.62156534, 0.2, 0.20910296, 0.2030021]\n",
      "[0.6300821, 0.2, 0.21727802, 0.20335042]\n",
      "[0.622567, 0.2, 0.21036085, 0.20275873]\n",
      "[0.6212407, 0.2, 0.20770723, 0.20409228]\n",
      "[0.62713796, 0.2, 0.21608149, 0.20162162]\n",
      "[0.6209082, 0.2, 0.20931643, 0.20216347]\n",
      "[0.6185943, 0.2, 0.20421907, 0.20495561]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12350 iterations: 3.031735614935557 mins\n",
      "Train Loss: [0.6185943, 0.2, 0.20421907, 0.20495561]\n",
      "[0.6258653, 0.2, 0.21219224, 0.20426187]\n",
      "[0.623232, 0.2, 0.21085095, 0.20297776]\n",
      "[0.6210147, 0.2, 0.20950207, 0.202117]\n",
      "[0.655053, 0.2, 0.21007685, 0.23558784]\n",
      "[0.6190778, 0.2, 0.20733693, 0.20236087]\n",
      "[0.620158, 0.2, 0.20812196, 0.20266397]\n",
      "[0.6141384, 0.2, 0.2033938, 0.20137928]\n",
      "[0.62943196, 0.2, 0.21551259, 0.20456074]\n",
      "[0.61529475, 0.2, 0.2048972, 0.20104441]\n",
      "[0.62588054, 0.2, 0.2129795, 0.20355383]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12360 iterations: 3.033927901585897 mins\n",
      "Train Loss: [0.62588054, 0.2, 0.2129795, 0.20355383]\n",
      "[0.63774323, 0.2, 0.20728356, 0.22111961]\n",
      "[0.62183654, 0.2, 0.2081012, 0.20440437]\n",
      "[0.63838863, 0.2, 0.22576135, 0.20330425]\n",
      "[0.6198888, 0.2, 0.20625815, 0.20431386]\n",
      "[0.6240818, 0.2, 0.2112189, 0.20355195]\n",
      "[0.625053, 0.2, 0.212431, 0.20331608]\n",
      "[0.63089305, 0.2, 0.20497799, 0.21661244]\n",
      "[0.6274096, 0.2, 0.21401681, 0.20409529]\n",
      "[0.6337049, 0.2, 0.21822391, 0.2061878]\n",
      "[0.61889344, 0.2, 0.20583957, 0.2037644]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12370 iterations: 3.0358290513356527 mins\n",
      "Train Loss: [0.61889344, 0.2, 0.20583957, 0.2037644]\n",
      "[0.6287549, 0.2, 0.21699345, 0.20247516]\n",
      "[0.62728167, 0.2, 0.21582308, 0.20217514]\n",
      "[0.62669814, 0.2, 0.21552014, 0.20189746]\n",
      "[0.64209306, 0.2, 0.20840959, 0.22440583]\n",
      "[0.6351975, 0.2, 0.22216584, 0.20375712]\n",
      "[0.618782, 0.2, 0.20697963, 0.20252894]\n",
      "[0.6533671, 0.2, 0.23977613, 0.20431961]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6233991, 0.2, 0.2100608, 0.20405933]\n",
      "[0.6154081, 0.2, 0.20363677, 0.20248596]\n",
      "[0.61883855, 0.2, 0.20692292, 0.2026243]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12380 iterations: 3.037989632288615 mins\n",
      "Train Loss: [0.61883855, 0.2, 0.20692292, 0.2026243]\n",
      "[0.6161408, 0.2, 0.2038539, 0.20299102]\n",
      "[0.62491983, 0.2, 0.21276894, 0.20285155]\n",
      "[0.62225085, 0.2, 0.20954254, 0.20340644]\n",
      "[0.62322956, 0.2, 0.21067527, 0.2032515]\n",
      "[0.6159683, 0.2, 0.20243682, 0.204229]\n",
      "[0.6260689, 0.2, 0.21469513, 0.20207286]\n",
      "[0.62355274, 0.2, 0.21192941, 0.20232533]\n",
      "[0.625828, 0.2, 0.21447326, 0.20205976]\n",
      "[0.61535364, 0.2, 0.20371222, 0.20234959]\n",
      "[0.6153958, 0.2, 0.20363496, 0.20247245]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12390 iterations: 3.0398207823435466 mins\n",
      "Train Loss: [0.6153958, 0.2, 0.20363496, 0.20247245]\n",
      "[0.62425286, 0.2, 0.20776479, 0.20720327]\n",
      "[0.6197444, 0.2, 0.20712243, 0.20334248]\n",
      "[0.63366705, 0.2, 0.22191845, 0.20247395]\n",
      "[0.62524885, 0.2, 0.21443602, 0.20154236]\n",
      "[0.6552835, 0.2, 0.24253206, 0.20348512]\n",
      "[0.63074964, 0.2, 0.21951625, 0.20197564]\n",
      "[0.62433994, 0.2, 0.21130675, 0.20378314]\n",
      "[0.61935586, 0.2, 0.20569399, 0.20442024]\n",
      "[0.6171664, 0.2, 0.20463933, 0.20329472]\n",
      "[0.622116, 0.2, 0.21017359, 0.2027187]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12400 iterations: 3.041943633556366 mins\n",
      "Train Loss: [0.622116, 0.2, 0.21017359, 0.2027187]\n",
      "[0.6216815, 0.2, 0.20903829, 0.20342723]\n",
      "[0.61887753, 0.2, 0.20638444, 0.20328394]\n",
      "[0.62044513, 0.2, 0.208552, 0.20269033]\n",
      "[0.62369376, 0.2, 0.21015048, 0.20434631]\n",
      "[0.6196843, 0.2, 0.20716505, 0.20332982]\n",
      "[0.6265336, 0.2, 0.21306631, 0.20428574]\n",
      "[0.629646, 0.2, 0.21807814, 0.20239371]\n",
      "[0.61911714, 0.2, 0.20812601, 0.20182247]\n",
      "[0.61788785, 0.2, 0.20552547, 0.20319907]\n",
      "[0.6147223, 0.2, 0.20430371, 0.20126027]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12410 iterations: 3.0438162167867024 mins\n",
      "Train Loss: [0.6147223, 0.2, 0.20430371, 0.20126027]\n",
      "[0.62051564, 0.2, 0.20736311, 0.20399922]\n",
      "[0.62225527, 0.2, 0.21049273, 0.20261529]\n",
      "[0.612471, 0.2, 0.20136704, 0.20196287]\n",
      "[0.6128054, 0.2, 0.20181997, 0.20185007]\n",
      "[0.6203507, 0.2, 0.20903736, 0.20218393]\n",
      "[0.62752277, 0.2, 0.21515012, 0.20324947]\n",
      "[0.64504045, 0.2, 0.20913893, 0.22678393]\n",
      "[0.62170947, 0.2, 0.2097047, 0.20289247]\n",
      "[0.6192431, 0.2, 0.2089365, 0.20119946]\n",
      "[0.62193424, 0.2, 0.21119557, 0.20163567]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12420 iterations: 3.0459829847017925 mins\n",
      "Train Loss: [0.62193424, 0.2, 0.21119557, 0.20163567]\n",
      "[0.61738366, 0.2, 0.20598067, 0.20230292]\n",
      "[0.62058675, 0.2, 0.20806295, 0.20342751]\n",
      "[0.6365046, 0.2, 0.20165631, 0.22575523]\n",
      "[0.6192951, 0.2, 0.20655395, 0.20365144]\n",
      "[0.618404, 0.2, 0.20655718, 0.20276444]\n",
      "[0.6135198, 0.2, 0.20201553, 0.20242763]\n",
      "[0.6196948, 0.2, 0.20901906, 0.20160481]\n",
      "[0.6204567, 0.2, 0.20758824, 0.203803]\n",
      "[0.6155769, 0.2, 0.20484784, 0.20166905]\n",
      "[0.6164969, 0.2, 0.20411661, 0.2033251]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12430 iterations: 3.04893780152003 mins\n",
      "Train Loss: [0.6164969, 0.2, 0.20411661, 0.2033251]\n",
      "[0.6200588, 0.2, 0.206575, 0.20443301]\n",
      "[0.6198232, 0.2, 0.20553552, 0.20524183]\n",
      "[0.6259235, 0.2, 0.2130478, 0.20383546]\n",
      "[0.6279245, 0.2, 0.21486561, 0.20402364]\n",
      "[0.6188434, 0.2, 0.20704825, 0.20276514]\n",
      "[0.6196924, 0.2, 0.20809682, 0.20257074]\n",
      "[0.62161964, 0.2, 0.20918871, 0.20341165]\n",
      "[0.62489307, 0.2, 0.21297614, 0.20290317]\n",
      "[0.64167774, 0.2, 0.22904167, 0.20362723]\n",
      "[0.61748725, 0.2, 0.20502701, 0.2034604]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12440 iterations: 3.0508238315582275 mins\n",
      "Train Loss: [0.61748725, 0.2, 0.20502701, 0.2034604]\n",
      "[0.6179086, 0.2, 0.20496522, 0.20395158]\n",
      "[0.6308877, 0.2, 0.22007397, 0.2018302]\n",
      "[0.6164301, 0.2, 0.20443611, 0.20301923]\n",
      "[0.61489975, 0.2, 0.20286196, 0.20307106]\n",
      "[0.6188559, 0.2, 0.20713596, 0.20276082]\n",
      "[0.6247617, 0.2, 0.21330352, 0.20250778]\n",
      "[0.62332636, 0.2, 0.21244355, 0.20193972]\n",
      "[0.6159692, 0.2, 0.20323488, 0.2037985]\n",
      "[0.6245477, 0.2, 0.21181308, 0.20380585]\n",
      "[0.62113523, 0.2, 0.20701094, 0.20520288]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12450 iterations: 3.052856167157491 mins\n",
      "Train Loss: [0.62113523, 0.2, 0.20701094, 0.20520288]\n",
      "[0.6352426, 0.2, 0.21058452, 0.21574478]\n",
      "[0.6157833, 0.2, 0.20448853, 0.2023894]\n",
      "[0.624019, 0.2, 0.20689358, 0.20822774]\n",
      "[0.6201311, 0.2, 0.20708607, 0.20415476]\n",
      "[0.6276166, 0.2, 0.2098979, 0.20883468]\n",
      "[0.618001, 0.2, 0.20414619, 0.20497501]\n",
      "[0.6242033, 0.2, 0.21221095, 0.2031166]\n",
      "[0.62409717, 0.2, 0.21299276, 0.20223242]\n",
      "[0.6232109, 0.2, 0.211589, 0.20275319]\n",
      "[0.6265428, 0.2, 0.21348874, 0.2041886]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12460 iterations: 3.0547614137331647 mins\n",
      "Train Loss: [0.6265428, 0.2, 0.21348874, 0.2041886]\n",
      "[0.64547265, 0.2, 0.23527005, 0.20134103]\n",
      "[0.65492874, 0.2, 0.23649065, 0.20958559]\n",
      "[0.6214146, 0.2, 0.21028683, 0.20228519]\n",
      "[0.6147015, 0.2, 0.20412843, 0.20173827]\n",
      "[0.62527394, 0.2, 0.2115328, 0.20491275]\n",
      "[0.6205419, 0.2, 0.20778406, 0.20393437]\n",
      "[0.62191236, 0.2, 0.2072225, 0.20587064]\n",
      "[0.629048, 0.2, 0.20951305, 0.21072017]\n",
      "[0.62386435, 0.2, 0.2099547, 0.20509788]\n",
      "[0.6429222, 0.2, 0.20840117, 0.22571222]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12470 iterations: 3.0567557493845623 mins\n",
      "Train Loss: [0.6429222, 0.2, 0.20840117, 0.22571222]\n",
      "[0.6253843, 0.2, 0.21245976, 0.20411943]\n",
      "[0.6454737, 0.2, 0.21312658, 0.22354417]\n",
      "[0.6224587, 0.2, 0.21059176, 0.203067]\n",
      "[0.6271739, 0.2, 0.21290873, 0.20546809]\n",
      "[0.6216708, 0.2, 0.20814563, 0.20472994]\n",
      "[0.62241364, 0.2, 0.2048179, 0.20880166]\n",
      "[0.6248973, 0.2, 0.21229298, 0.20381038]\n",
      "[0.6162461, 0.2, 0.2054606, 0.20199203]\n",
      "[0.61951935, 0.2, 0.20850521, 0.20222141]\n",
      "[0.6226115, 0.2, 0.20928557, 0.20453437]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12480 iterations: 3.058912452061971 mins\n",
      "Train Loss: [0.6226115, 0.2, 0.20928557, 0.20453437]\n",
      "[0.6202933, 0.2, 0.21032867, 0.20117444]\n",
      "[0.63182545, 0.2, 0.21991217, 0.20312528]\n",
      "[0.61473393, 0.2, 0.20260055, 0.20334528]\n",
      "[0.634044, 0.2, 0.22293516, 0.20232157]\n",
      "[0.61684483, 0.2, 0.20418791, 0.20387073]\n",
      "[0.65195435, 0.2, 0.2421889, 0.20098104]\n",
      "[0.6359991, 0.2, 0.22377759, 0.20342386]\n",
      "[0.6162595, 0.2, 0.20533134, 0.20211999]\n",
      "[0.6204104, 0.2, 0.20866235, 0.20293088]\n",
      "[0.61772466, 0.2, 0.20754334, 0.2013567]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12490 iterations: 3.0608194351196287 mins\n",
      "Train Loss: [0.61772466, 0.2, 0.20754334, 0.2013567]\n",
      "[0.62338775, 0.2, 0.21226922, 0.20228736]\n",
      "[0.6262562, 0.2, 0.20993692, 0.20748283]\n",
      "[0.62025017, 0.2, 0.20652494, 0.20488341]\n",
      "[0.6584315, 0.2, 0.2459238, 0.20366035]\n",
      "[0.6230519, 0.2, 0.21067913, 0.20351212]\n",
      "[0.61992043, 0.2, 0.20800649, 0.20304143]\n",
      "[0.61837, 0.2, 0.20282856, 0.20665918]\n",
      "[0.6221301, 0.2, 0.2072231, 0.2060169]\n",
      "[0.6224922, 0.2, 0.21034983, 0.20324448]\n",
      "[0.6220477, 0.2, 0.21108739, 0.20205581]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12500 iterations: 3.062888765335083 mins\n",
      "Train Loss: [0.6220477, 0.2, 0.21108739, 0.20205581]\n",
      "[0.6124686, 0.2, 0.20162748, 0.20193137]\n",
      "[0.6278314, 0.2, 0.21484917, 0.20406826]\n",
      "[0.67205334, 0.2, 0.20954865, 0.25358483]\n",
      "[0.72839475, 0.2, 0.31664062, 0.20282917]\n",
      "[0.62002426, 0.2, 0.2080863, 0.20301472]\n",
      "[0.6182107, 0.2, 0.20643069, 0.20285857]\n",
      "[0.61440814, 0.2, 0.20360945, 0.20187832]\n",
      "[0.6239347, 0.2, 0.2132961, 0.20171945]\n",
      "[0.61321, 0.2, 0.20235282, 0.20194009]\n",
      "[0.6270348, 0.2, 0.21363124, 0.20448852]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12510 iterations: 3.065354080994924 mins\n",
      "Train Loss: [0.6270348, 0.2, 0.21363124, 0.20448852]\n",
      "[0.6472277, 0.2, 0.21578114, 0.22253364]\n",
      "[0.61686677, 0.2, 0.2068305, 0.20112446]\n",
      "[0.6176241, 0.2, 0.20695038, 0.20176268]\n",
      "[0.62004673, 0.2, 0.20821355, 0.20292164]\n",
      "[0.61972076, 0.2, 0.20719007, 0.2036195]\n",
      "[0.63355505, 0.2, 0.22040394, 0.20424137]\n",
      "[0.62255275, 0.2, 0.20932248, 0.20432195]\n",
      "[0.62107235, 0.2, 0.20927815, 0.20288691]\n",
      "[0.6471434, 0.2, 0.21383281, 0.22440496]\n",
      "[0.6227899, 0.2, 0.20922728, 0.20465879]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12520 iterations: 3.0674345175425213 mins\n",
      "Train Loss: [0.6227899, 0.2, 0.20922728, 0.20465879]\n",
      "[0.6233256, 0.2, 0.21306294, 0.2013604]\n",
      "[0.6144835, 0.2, 0.20334184, 0.20224084]\n",
      "[0.61994237, 0.2, 0.20766553, 0.20337828]\n",
      "[0.6110411, 0.2, 0.20106848, 0.20107713]\n",
      "[0.6121992, 0.2, 0.20232359, 0.20098339]\n",
      "[0.62802166, 0.2, 0.21844622, 0.20068702]\n",
      "[0.6303165, 0.2, 0.21954042, 0.20189041]\n",
      "[0.6223553, 0.2, 0.20969836, 0.2037746]\n",
      "[0.6122705, 0.2, 0.20221896, 0.20117204]\n",
      "[0.6361008, 0.2, 0.22393939, 0.20328589]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12530 iterations: 3.069482700030009 mins\n",
      "Train Loss: [0.6361008, 0.2, 0.22393939, 0.20328589]\n",
      "[0.6245378, 0.2, 0.21079643, 0.20486915]\n",
      "[0.6495468, 0.2, 0.23828164, 0.20239665]\n",
      "[0.6211556, 0.2, 0.20975886, 0.20253561]\n",
      "[0.6222111, 0.2, 0.21144761, 0.20190933]\n",
      "[0.6155123, 0.2, 0.20380937, 0.20285596]\n",
      "[0.6198708, 0.2, 0.2087482, 0.2022824]\n",
      "[0.6198799, 0.2, 0.20811327, 0.20293325]\n",
      "[0.6179372, 0.2, 0.20545256, 0.20365748]\n",
      "[0.6228281, 0.2, 0.21236946, 0.20163713]\n",
      "[0.6288759, 0.2, 0.21632478, 0.20373407]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12540 iterations: 3.0714101513226826 mins\n",
      "Train Loss: [0.6288759, 0.2, 0.21632478, 0.20373407]\n",
      "[0.61874074, 0.2, 0.20628104, 0.20364717]\n",
      "[0.62034696, 0.2, 0.20659073, 0.20494871]\n",
      "[0.62225574, 0.2, 0.211492, 0.20196123]\n",
      "[0.6170546, 0.2, 0.20634016, 0.20191723]\n",
      "[0.64942807, 0.2, 0.23840527, 0.20223127]\n",
      "[0.62135035, 0.2, 0.21121229, 0.2013541]\n",
      "[0.62195337, 0.2, 0.20904268, 0.20413367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6138726, 0.2, 0.2036534, 0.20144865]\n",
      "[0.6245463, 0.2, 0.21118927, 0.20459418]\n",
      "[0.61899406, 0.2, 0.20651369, 0.20372559]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12550 iterations: 3.073496131102244 mins\n",
      "Train Loss: [0.61899406, 0.2, 0.20651369, 0.20372559]\n",
      "[0.62158585, 0.2, 0.21082073, 0.20201784]\n",
      "[0.62065005, 0.2, 0.20662056, 0.20528923]\n",
      "[0.62102926, 0.2, 0.20882417, 0.2034712]\n",
      "[0.6147692, 0.2, 0.20433775, 0.20170507]\n",
      "[0.6264629, 0.2, 0.21558942, 0.20215368]\n",
      "[0.6480998, 0.2, 0.23790224, 0.20148434]\n",
      "[0.622222, 0.2, 0.21097638, 0.20253205]\n",
      "[0.62438345, 0.2, 0.21160938, 0.20406002]\n",
      "[0.61832154, 0.2, 0.20788227, 0.20172359]\n",
      "[0.62189215, 0.2, 0.20781317, 0.20536321]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12560 iterations: 3.075508352120717 mins\n",
      "Train Loss: [0.62189215, 0.2, 0.20781317, 0.20536321]\n",
      "[0.63094914, 0.2, 0.20341581, 0.21881767]\n",
      "[0.6226817, 0.2, 0.21036369, 0.20360233]\n",
      "[0.6214892, 0.2, 0.20718676, 0.20558746]\n",
      "[0.62199134, 0.2, 0.21084945, 0.2024282]\n",
      "[0.6179778, 0.2, 0.2082064, 0.20105973]\n",
      "[0.61620826, 0.2, 0.20372476, 0.20377381]\n",
      "[0.61840665, 0.2, 0.2084734, 0.20122573]\n",
      "[0.61588776, 0.2, 0.20594634, 0.20123632]\n",
      "[0.61584187, 0.2, 0.20546392, 0.20167625]\n",
      "[0.6651882, 0.2, 0.22300349, 0.23348758]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12570 iterations: 3.077573068936666 mins\n",
      "Train Loss: [0.6651882, 0.2, 0.22300349, 0.23348758]\n",
      "[0.61368203, 0.2, 0.20221232, 0.20277272]\n",
      "[0.62714654, 0.2, 0.21481001, 0.20364055]\n",
      "[0.61962634, 0.2, 0.20756404, 0.20336667]\n",
      "[0.61394966, 0.2, 0.20344216, 0.20181292]\n",
      "[0.61817384, 0.2, 0.20758756, 0.20189337]\n",
      "[0.6314234, 0.2, 0.20488212, 0.21785036]\n",
      "[0.6298307, 0.2, 0.20436954, 0.21677093]\n",
      "[0.61198205, 0.2, 0.20196794, 0.20132674]\n",
      "[0.6158848, 0.2, 0.2055922, 0.20160627]\n",
      "[0.61419284, 0.2, 0.20194271, 0.20356365]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12580 iterations: 3.079509262243907 mins\n",
      "Train Loss: [0.61419284, 0.2, 0.20194271, 0.20356365]\n",
      "[0.61556864, 0.2, 0.2040717, 0.20281]\n",
      "[0.62290704, 0.2, 0.20815663, 0.20606299]\n",
      "[0.6730494, 0.2, 0.23010917, 0.23425241]\n",
      "[0.6253329, 0.2, 0.21487752, 0.20176393]\n",
      "[0.6158071, 0.2, 0.20429876, 0.20281112]\n",
      "[0.61889696, 0.2, 0.20799133, 0.20220283]\n",
      "[0.6144086, 0.2, 0.20257495, 0.2031259]\n",
      "[0.6198169, 0.2, 0.20853393, 0.20257115]\n",
      "[0.61521107, 0.2, 0.20413822, 0.20235826]\n",
      "[0.6203262, 0.2, 0.20491114, 0.20669906]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12590 iterations: 3.081978229681651 mins\n",
      "Train Loss: [0.6203262, 0.2, 0.20491114, 0.20669906]\n",
      "[0.62308484, 0.2, 0.20859547, 0.2057734]\n",
      "[0.61553854, 0.2, 0.20287953, 0.20394392]\n",
      "[0.6250443, 0.2, 0.21477054, 0.20156051]\n",
      "[0.6142929, 0.2, 0.20311582, 0.20246676]\n",
      "[0.61448526, 0.2, 0.20267934, 0.20309933]\n",
      "[0.61568934, 0.2, 0.20457724, 0.20241013]\n",
      "[0.6175051, 0.2, 0.2023936, 0.20641476]\n",
      "[0.61879665, 0.2, 0.20775673, 0.20234913]\n",
      "[0.6173017, 0.2, 0.20476915, 0.20384793]\n",
      "[0.672936, 0.2, 0.26012945, 0.20412937]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12600 iterations: 3.084079666932424 mins\n",
      "Train Loss: [0.672936, 0.2, 0.26012945, 0.20412937]\n",
      "[0.6204017, 0.2, 0.20830119, 0.20343512]\n",
      "[0.61953235, 0.2, 0.20472492, 0.20615214]\n",
      "[0.62631756, 0.2, 0.21524118, 0.2024304]\n",
      "[0.62139535, 0.2, 0.20760016, 0.20515923]\n",
      "[0.6156479, 0.2, 0.2049316, 0.20208979]\n",
      "[0.63585556, 0.2, 0.21123996, 0.21599762]\n",
      "[0.61291337, 0.2, 0.20226899, 0.20203465]\n",
      "[0.6149647, 0.2, 0.20410345, 0.20225899]\n",
      "[0.6209409, 0.2, 0.20993775, 0.20240761]\n",
      "[0.61905813, 0.2, 0.20930348, 0.2011645]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12610 iterations: 3.086014982064565 mins\n",
      "Train Loss: [0.61905813, 0.2, 0.20930348, 0.2011645]\n",
      "[0.6176902, 0.2, 0.20635962, 0.20274585]\n",
      "[0.63564485, 0.2, 0.20535648, 0.22170837]\n",
      "[0.62189186, 0.2, 0.2094174, 0.20390123]\n",
      "[0.61656594, 0.2, 0.20317322, 0.20482542]\n",
      "[0.620836, 0.2, 0.20737994, 0.20489421]\n",
      "[0.65642697, 0.2, 0.20397036, 0.24389991]\n",
      "[0.61456245, 0.2, 0.20270494, 0.20330822]\n",
      "[0.62107503, 0.2, 0.21033977, 0.20219332]\n",
      "[0.62401205, 0.2, 0.21386929, 0.20160793]\n",
      "[0.6208056, 0.2, 0.20808199, 0.20419568]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12620 iterations: 3.0879984974861143 mins\n",
      "Train Loss: [0.6208056, 0.2, 0.20808199, 0.20419568]\n",
      "[0.61598027, 0.2, 0.2047945, 0.20266338]\n",
      "[0.6222443, 0.2, 0.2119013, 0.20182559]\n",
      "[0.616449, 0.2, 0.20579296, 0.20214306]\n",
      "[0.61724705, 0.2, 0.2068451, 0.20189439]\n",
      "[0.6230497, 0.2, 0.21126483, 0.20328358]\n",
      "[0.6180664, 0.2, 0.20714477, 0.20242736]\n",
      "[0.61159813, 0.2, 0.20208214, 0.20102835]\n",
      "[0.6172832, 0.2, 0.2060971, 0.2027047]\n",
      "[0.61850333, 0.2, 0.2077552, 0.20227261]\n",
      "[0.6178774, 0.2, 0.2063716, 0.20303537]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12630 iterations: 3.0898844162623087 mins\n",
      "Train Loss: [0.6178774, 0.2, 0.2063716, 0.20303537]\n",
      "[0.6403767, 0.2, 0.23006724, 0.20184495]\n",
      "[0.6120074, 0.2, 0.20213436, 0.20140983]\n",
      "[0.64116424, 0.2, 0.2312081, 0.20149487]\n",
      "[0.62089366, 0.2, 0.20971183, 0.2027148]\n",
      "[0.62402517, 0.2, 0.20864381, 0.20691007]\n",
      "[0.6566802, 0.2, 0.24570116, 0.20250505]\n",
      "[0.6179116, 0.2, 0.2071926, 0.20224431]\n",
      "[0.62162197, 0.2, 0.20793566, 0.20521048]\n",
      "[0.63559407, 0.2, 0.2241557, 0.20296104]\n",
      "[0.61521876, 0.2, 0.20437662, 0.20236482]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12640 iterations: 3.092016100883484 mins\n",
      "Train Loss: [0.61521876, 0.2, 0.20437662, 0.20236482]\n",
      "[0.61604685, 0.2, 0.20568664, 0.20188314]\n",
      "[0.62609416, 0.2, 0.21320604, 0.2044114]\n",
      "[0.6329863, 0.2, 0.20886348, 0.2156474]\n",
      "[0.6163913, 0.2, 0.20508593, 0.20282705]\n",
      "[0.62643206, 0.2, 0.21577215, 0.20217615]\n",
      "[0.62403893, 0.2, 0.21218023, 0.20336708]\n",
      "[0.6137722, 0.2, 0.20374535, 0.20152652]\n",
      "[0.6374423, 0.2, 0.22609401, 0.20283876]\n",
      "[0.6280858, 0.2, 0.21471809, 0.2048419]\n",
      "[0.61934876, 0.2, 0.20816386, 0.20264176]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12650 iterations: 3.0939626812934877 mins\n",
      "Train Loss: [0.61934876, 0.2, 0.20816386, 0.20264176]\n",
      "[0.62825847, 0.2, 0.21642977, 0.20326926]\n",
      "[0.6201745, 0.2, 0.20979358, 0.2018058]\n",
      "[0.62390757, 0.2, 0.21011007, 0.2052084]\n",
      "[0.6164775, 0.2, 0.20618905, 0.2016866]\n",
      "[0.6152666, 0.2, 0.20446923, 0.20218389]\n",
      "[0.6196801, 0.2, 0.20773585, 0.2033212]\n",
      "[0.6206511, 0.2, 0.2101718, 0.2018484]\n",
      "[0.62251705, 0.2, 0.2094515, 0.20442773]\n",
      "[0.6131804, 0.2, 0.20226581, 0.20227264]\n",
      "[0.62019306, 0.2, 0.20860046, 0.20294797]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12660 iterations: 3.0960786660512287 mins\n",
      "Train Loss: [0.62019306, 0.2, 0.20860046, 0.20294797]\n",
      "[0.62276775, 0.2, 0.20845297, 0.20566805]\n",
      "[0.7092263, 0.2, 0.2977071, 0.20287149]\n",
      "[0.63684094, 0.2, 0.20303434, 0.2251613]\n",
      "[0.61297846, 0.2, 0.20245117, 0.20188396]\n",
      "[0.61396027, 0.2, 0.2036115, 0.20170754]\n",
      "[0.6148023, 0.2, 0.20416169, 0.20200187]\n",
      "[0.6315924, 0.2, 0.20891851, 0.21403754]\n",
      "[0.6165245, 0.2, 0.20495401, 0.20293522]\n",
      "[0.6179721, 0.2, 0.20571528, 0.20362234]\n",
      "[0.614999, 0.2, 0.20439981, 0.20196554]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12670 iterations: 3.098713449637095 mins\n",
      "Train Loss: [0.614999, 0.2, 0.20439981, 0.20196554]\n",
      "[0.6548789, 0.2, 0.24218366, 0.20406221]\n",
      "[0.6157749, 0.2, 0.20537987, 0.20175454]\n",
      "[0.6195379, 0.2, 0.20611215, 0.20477931]\n",
      "[0.62071234, 0.2, 0.2089699, 0.20309097]\n",
      "[0.61828655, 0.2, 0.20715542, 0.20247498]\n",
      "[0.6177203, 0.2, 0.20355338, 0.2055069]\n",
      "[0.6317514, 0.2, 0.20587613, 0.21721156]\n",
      "[0.6166104, 0.2, 0.20350076, 0.20444137]\n",
      "[0.62039566, 0.2, 0.2103907, 0.20133436]\n",
      "[0.618811, 0.2, 0.20856956, 0.20156913]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12680 iterations: 3.1005751689275107 mins\n",
      "Train Loss: [0.618811, 0.2, 0.20856956, 0.20156913]\n",
      "[0.62322235, 0.2, 0.21065734, 0.20389135]\n",
      "[0.62015057, 0.2, 0.20676425, 0.20471218]\n",
      "[0.6238188, 0.2, 0.21330826, 0.20183645]\n",
      "[0.61996615, 0.2, 0.20605631, 0.20523575]\n",
      "[0.62225467, 0.2, 0.20880842, 0.20477198]\n",
      "[0.6435415, 0.2, 0.2328009, 0.20206663]\n",
      "[0.6198454, 0.2, 0.209197, 0.20196724]\n",
      "[0.62294453, 0.2, 0.21131073, 0.20294604]\n",
      "[0.63681364, 0.2, 0.22131418, 0.20680666]\n",
      "[0.6190673, 0.2, 0.20754695, 0.20282453]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12690 iterations: 3.10269961754481 mins\n",
      "Train Loss: [0.6190673, 0.2, 0.20754695, 0.20282453]\n",
      "[0.62119144, 0.2, 0.2098087, 0.20268483]\n",
      "[0.626718, 0.2, 0.21686935, 0.20115012]\n",
      "[0.6152477, 0.2, 0.20453446, 0.20201434]\n",
      "[0.62087685, 0.2, 0.20678669, 0.20539187]\n",
      "[0.6347166, 0.2, 0.22227958, 0.20374079]\n",
      "[0.6202313, 0.2, 0.20868863, 0.20284906]\n",
      "[0.62436664, 0.2, 0.2136484, 0.20202805]\n",
      "[0.6189114, 0.2, 0.20883982, 0.20138544]\n",
      "[0.620181, 0.2, 0.2062018, 0.20529707]\n",
      "[0.61788017, 0.2, 0.20499791, 0.20420603]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12700 iterations: 3.1045366644859316 mins\n",
      "Train Loss: [0.61788017, 0.2, 0.20499791, 0.20420603]\n",
      "[0.61896473, 0.2, 0.20529501, 0.20499933]\n",
      "[0.61769724, 0.2, 0.20732738, 0.20170529]\n",
      "[0.62249124, 0.2, 0.21080144, 0.20303164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62153006, 0.2, 0.20914187, 0.20373559]\n",
      "[0.61825734, 0.2, 0.20754714, 0.20206244]\n",
      "[0.6196138, 0.2, 0.20834336, 0.20262772]\n",
      "[0.613103, 0.2, 0.20349737, 0.20096883]\n",
      "[0.63277346, 0.2, 0.21876435, 0.20537847]\n",
      "[0.618439, 0.2, 0.20826238, 0.20155334]\n",
      "[0.6229066, 0.2, 0.20889452, 0.205396]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12710 iterations: 3.1066567142804464 mins\n",
      "Train Loss: [0.6229066, 0.2, 0.20889452, 0.205396]\n",
      "[0.61552143, 0.2, 0.20383006, 0.20308173]\n",
      "[0.6150709, 0.2, 0.20345911, 0.20300797]\n",
      "[0.61940134, 0.2, 0.20802422, 0.20278005]\n",
      "[0.61377907, 0.2, 0.20310305, 0.20208618]\n",
      "[0.63335764, 0.2, 0.20951614, 0.21525896]\n",
      "[0.61950755, 0.2, 0.20835668, 0.20257382]\n",
      "[0.6317658, 0.2, 0.22162855, 0.20156568]\n",
      "[0.61920786, 0.2, 0.2084528, 0.20219077]\n",
      "[0.6198358, 0.2, 0.20797844, 0.20330043]\n",
      "[0.6160636, 0.2, 0.2047524, 0.2027606]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12720 iterations: 3.108679648240407 mins\n",
      "Train Loss: [0.6160636, 0.2, 0.2047524, 0.2027606]\n",
      "[0.63487774, 0.2, 0.22422078, 0.20211276]\n",
      "[0.61941767, 0.2, 0.20906381, 0.201818]\n",
      "[0.61582667, 0.2, 0.20393434, 0.2033646]\n",
      "[0.6172731, 0.2, 0.20703545, 0.20171738]\n",
      "[0.61867344, 0.2, 0.20676841, 0.20339116]\n",
      "[0.63453096, 0.2, 0.22389409, 0.2021288]\n",
      "[0.6187637, 0.2, 0.20879707, 0.2014615]\n",
      "[0.6200776, 0.2, 0.21028659, 0.20128842]\n",
      "[0.61624837, 0.2, 0.20273691, 0.20501156]\n",
      "[0.61747617, 0.2, 0.20720871, 0.20177056]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12730 iterations: 3.1106932004292807 mins\n",
      "Train Loss: [0.61747617, 0.2, 0.20720871, 0.20177056]\n",
      "[0.621483, 0.2, 0.21035078, 0.20263858]\n",
      "[0.6185341, 0.2, 0.20659068, 0.20345284]\n",
      "[0.6273167, 0.2, 0.2154788, 0.20335115]\n",
      "[0.6539706, 0.2, 0.210856, 0.23463191]\n",
      "[0.6163919, 0.2, 0.20625512, 0.2016572]\n",
      "[0.61800295, 0.2, 0.20599125, 0.20353489]\n",
      "[0.6166375, 0.2, 0.2063519, 0.20181115]\n",
      "[0.61791664, 0.2, 0.2080919, 0.20135242]\n",
      "[0.65109545, 0.2, 0.24032071, 0.20230433]\n",
      "[0.6167127, 0.2, 0.2052809, 0.20295438]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12740 iterations: 3.1127400318781535 mins\n",
      "Train Loss: [0.6167127, 0.2, 0.2052809, 0.20295438]\n",
      "[0.61576945, 0.2, 0.20556048, 0.20172547]\n",
      "[0.61411494, 0.2, 0.20414527, 0.2014812]\n",
      "[0.61483216, 0.2, 0.20301107, 0.20332807]\n",
      "[0.6200272, 0.2, 0.20968804, 0.2018422]\n",
      "[0.6198778, 0.2, 0.20981292, 0.20156498]\n",
      "[0.61788577, 0.2, 0.20682478, 0.20255911]\n",
      "[0.63807607, 0.2, 0.2277821, 0.20179088]\n",
      "[0.622508, 0.2, 0.20941836, 0.20458816]\n",
      "[0.61722016, 0.2, 0.20544356, 0.20327856]\n",
      "[0.66056687, 0.2, 0.24849518, 0.20357606]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12750 iterations: 3.1153515815734862 mins\n",
      "Train Loss: [0.66056687, 0.2, 0.24849518, 0.20357606]\n",
      "[0.6410349, 0.2, 0.22959927, 0.20293675]\n",
      "[0.61474925, 0.2, 0.20437315, 0.20187305]\n",
      "[0.6200213, 0.2, 0.20829941, 0.20321535]\n",
      "[0.6242392, 0.2, 0.21337947, 0.20235048]\n",
      "[0.62261975, 0.2, 0.21115196, 0.20295651]\n",
      "[0.61761636, 0.2, 0.20614235, 0.20296171]\n",
      "[0.61604, 0.2, 0.20577647, 0.20175067]\n",
      "[0.6131961, 0.2, 0.20150645, 0.2031771]\n",
      "[0.6174173, 0.2, 0.20546396, 0.20344172]\n",
      "[0.61465424, 0.2, 0.2042669, 0.20187731]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12760 iterations: 3.1174404501914976 mins\n",
      "Train Loss: [0.61465424, 0.2, 0.2042669, 0.20187731]\n",
      "[0.61545205, 0.2, 0.20536895, 0.20157543]\n",
      "[0.6228176, 0.2, 0.20860595, 0.20570599]\n",
      "[0.6152772, 0.2, 0.20451829, 0.20225623]\n",
      "[0.6152727, 0.2, 0.20456062, 0.20221272]\n",
      "[0.61705947, 0.2, 0.20559387, 0.20297001]\n",
      "[0.62021357, 0.2, 0.20746939, 0.20425266]\n",
      "[0.64306617, 0.2, 0.20879325, 0.22578508]\n",
      "[0.6180968, 0.2, 0.20750551, 0.20210665]\n",
      "[0.62496006, 0.2, 0.2097557, 0.206723]\n",
      "[0.62433, 0.2, 0.21367943, 0.20217307]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12770 iterations: 3.1194876511891683 mins\n",
      "Train Loss: [0.62433, 0.2, 0.21367943, 0.20217307]\n",
      "[0.6168405, 0.2, 0.20577566, 0.20259146]\n",
      "[0.6206323, 0.2, 0.20989904, 0.20226358]\n",
      "[0.61504894, 0.2, 0.20294182, 0.20364185]\n",
      "[0.62178874, 0.2, 0.21099024, 0.20233776]\n",
      "[0.62152493, 0.2, 0.21025155, 0.20281743]\n",
      "[0.6159818, 0.2, 0.20379256, 0.20373777]\n",
      "[0.61811674, 0.2, 0.20804274, 0.20162736]\n",
      "[0.61807483, 0.2, 0.20197438, 0.20765932]\n",
      "[0.61798257, 0.2, 0.20799337, 0.20155375]\n",
      "[0.61813945, 0.2, 0.20727931, 0.20243071]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12780 iterations: 3.1215195337931316 mins\n",
      "Train Loss: [0.61813945, 0.2, 0.20727931, 0.20243071]\n",
      "[0.6180462, 0.2, 0.203502, 0.20612085]\n",
      "[0.6179299, 0.2, 0.20849623, 0.20101623]\n",
      "[0.61769766, 0.2, 0.20681995, 0.20246638]\n",
      "[0.6189112, 0.2, 0.20717233, 0.20333363]\n",
      "[0.62216973, 0.2, 0.20898156, 0.20478834]\n",
      "[0.617635, 0.2, 0.2072003, 0.20203993]\n",
      "[0.62539274, 0.2, 0.21466817, 0.20233524]\n",
      "[0.61630726, 0.2, 0.20620206, 0.20172192]\n",
      "[0.6266985, 0.2, 0.21208693, 0.20623425]\n",
      "[0.61984235, 0.2, 0.20661184, 0.20485869]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12790 iterations: 3.123593850930532 mins\n",
      "Train Loss: [0.61984235, 0.2, 0.20661184, 0.20485869]\n",
      "[0.61503744, 0.2, 0.2043408, 0.20233081]\n",
      "[0.62149394, 0.2, 0.20984669, 0.20328726]\n",
      "[0.6220986, 0.2, 0.21251988, 0.20122501]\n",
      "[0.61806864, 0.2, 0.20601735, 0.20370264]\n",
      "[0.61455137, 0.2, 0.20455457, 0.20165353]\n",
      "[0.65105104, 0.2, 0.20456849, 0.2381451]\n",
      "[0.61644536, 0.2, 0.20625734, 0.20185742]\n",
      "[0.62032163, 0.2, 0.20829983, 0.2036975]\n",
      "[0.61937577, 0.2, 0.20932835, 0.20172869]\n",
      "[0.618336, 0.2, 0.20723993, 0.20278332]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12800 iterations: 3.1255585034688314 mins\n",
      "Train Loss: [0.618336, 0.2, 0.20723993, 0.20278332]\n",
      "[0.6185619, 0.2, 0.20757046, 0.20268486]\n",
      "[0.63402396, 0.2, 0.22281669, 0.20290679]\n",
      "[0.6193722, 0.2, 0.20796175, 0.20311752]\n",
      "[0.6141803, 0.2, 0.20281686, 0.20307764]\n",
      "[0.61981225, 0.2, 0.20852837, 0.20300467]\n",
      "[0.6184061, 0.2, 0.20724583, 0.20288819]\n",
      "[0.62755394, 0.2, 0.2169426, 0.20234638]\n",
      "[0.62209415, 0.2, 0.20896941, 0.2048663]\n",
      "[0.613972, 0.2, 0.20409636, 0.20162353]\n",
      "[0.64086854, 0.2, 0.23031917, 0.20230336]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12810 iterations: 3.1276387333869935 mins\n",
      "Train Loss: [0.64086854, 0.2, 0.23031917, 0.20230336]\n",
      "[0.6213529, 0.2, 0.21120028, 0.20190944]\n",
      "[0.6159107, 0.2, 0.20561425, 0.20205604]\n",
      "[0.6357963, 0.2, 0.20782994, 0.21972904]\n",
      "[0.6154255, 0.2, 0.20496114, 0.20222811]\n",
      "[0.6154756, 0.2, 0.20525463, 0.2019854]\n",
      "[0.6136146, 0.2, 0.20256676, 0.20281294]\n",
      "[0.61564463, 0.2, 0.20578718, 0.20162277]\n",
      "[0.6150605, 0.2, 0.20515989, 0.20166582]\n",
      "[0.62219924, 0.2, 0.2119998, 0.20196487]\n",
      "[0.6248818, 0.2, 0.21407972, 0.20256844]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12820 iterations: 3.1295514822006227 mins\n",
      "Train Loss: [0.6248818, 0.2, 0.21407972, 0.20256844]\n",
      "[0.61525136, 0.2, 0.20488438, 0.2021338]\n",
      "[0.6163262, 0.2, 0.20489244, 0.20320064]\n",
      "[0.61968964, 0.2, 0.2086516, 0.20280537]\n",
      "[0.618016, 0.2, 0.20753847, 0.20224468]\n",
      "[0.6166159, 0.2, 0.20570457, 0.20267874]\n",
      "[0.6317081, 0.2, 0.22103697, 0.20243853]\n",
      "[0.6206798, 0.2, 0.21121849, 0.20123143]\n",
      "[0.6188322, 0.2, 0.20885295, 0.20175219]\n",
      "[0.62087744, 0.2, 0.20928092, 0.20337212]\n",
      "[0.63448995, 0.2, 0.22358055, 0.20268786]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12830 iterations: 3.13224360148112 mins\n",
      "Train Loss: [0.63448995, 0.2, 0.22358055, 0.20268786]\n",
      "[0.6154346, 0.2, 0.20347841, 0.20373766]\n",
      "[0.6178904, 0.2, 0.20749263, 0.2021822]\n",
      "[0.61806035, 0.2, 0.20488247, 0.20496558]\n",
      "[0.6173653, 0.2, 0.20475864, 0.2043981]\n",
      "[0.6199161, 0.2, 0.20939976, 0.20231134]\n",
      "[0.61599594, 0.2, 0.20501064, 0.20278427]\n",
      "[0.61691207, 0.2, 0.20710617, 0.20160913]\n",
      "[0.6180838, 0.2, 0.20765752, 0.20223403]\n",
      "[0.62062657, 0.2, 0.20922637, 0.2032129]\n",
      "[0.61499375, 0.2, 0.20464027, 0.20217173]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12840 iterations: 3.134743781884511 mins\n",
      "Train Loss: [0.61499375, 0.2, 0.20464027, 0.20217173]\n",
      "[0.6181536, 0.2, 0.20790559, 0.2020719]\n",
      "[0.6198658, 0.2, 0.20834449, 0.20335117]\n",
      "[0.6326947, 0.2, 0.20600864, 0.218522]\n",
      "[0.62339646, 0.2, 0.2068744, 0.20836255]\n",
      "[0.62064195, 0.2, 0.21004687, 0.20244022]\n",
      "[0.61683095, 0.2, 0.20543078, 0.20325018]\n",
      "[0.61585903, 0.2, 0.20424269, 0.2034718]\n",
      "[0.61911064, 0.2, 0.20839964, 0.20257093]\n",
      "[0.6168362, 0.2, 0.20587723, 0.20282343]\n",
      "[0.63268965, 0.2, 0.20743726, 0.21712068]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12850 iterations: 3.137198030948639 mins\n",
      "Train Loss: [0.63268965, 0.2, 0.20743726, 0.21712068]\n",
      "[0.634, 0.2, 0.20603395, 0.21983647]\n",
      "[0.6155312, 0.2, 0.20585333, 0.20154856]\n",
      "[0.61867195, 0.2, 0.20605122, 0.20449181]\n",
      "[0.61575574, 0.2, 0.20661259, 0.20101395]\n",
      "[0.61900604, 0.2, 0.20884633, 0.20203021]\n",
      "[0.6180721, 0.2, 0.20822091, 0.20172155]\n",
      "[0.61633176, 0.2, 0.20661077, 0.20159116]\n",
      "[0.62149954, 0.2, 0.2116056, 0.20176397]\n",
      "[0.6163061, 0.2, 0.20455003, 0.20362583]\n",
      "[0.616042, 0.2, 0.20569094, 0.20222044]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12860 iterations: 3.139355182647705 mins\n",
      "Train Loss: [0.616042, 0.2, 0.20569094, 0.20222044]\n",
      "[0.616618, 0.2, 0.20433706, 0.20415004]\n",
      "[0.6583174, 0.2, 0.24683413, 0.20335284]\n",
      "[0.61961436, 0.2, 0.20918797, 0.20229086]\n",
      "[0.61760277, 0.2, 0.20461671, 0.20484644]\n",
      "[0.61775774, 0.2, 0.2071457, 0.20246881]\n",
      "[0.6171944, 0.2, 0.20671515, 0.2023331]\n",
      "[0.6566884, 0.2, 0.20918559, 0.23935437]\n",
      "[0.61810017, 0.2, 0.20711707, 0.20283353]\n",
      "[0.62856656, 0.2, 0.21753177, 0.20288382]\n",
      "[0.612112, 0.2, 0.20246512, 0.20149463]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12870 iterations: 3.1412346998850507 mins\n",
      "Train Loss: [0.612112, 0.2, 0.20246512, 0.20149463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.616968, 0.2, 0.20433782, 0.20447665]\n",
      "[0.6172682, 0.2, 0.20761602, 0.2014976]\n",
      "[0.61679906, 0.2, 0.20609717, 0.2025457]\n",
      "[0.6190098, 0.2, 0.20908396, 0.20176776]\n",
      "[0.61815155, 0.2, 0.20754881, 0.20244376]\n",
      "[0.65279686, 0.2, 0.23736723, 0.20727037]\n",
      "[0.6144101, 0.2, 0.20436603, 0.20188749]\n",
      "[0.6208643, 0.2, 0.20836833, 0.20434214]\n",
      "[0.6196779, 0.2, 0.20916279, 0.20236441]\n",
      "[0.6184012, 0.2, 0.20915648, 0.2010978]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12880 iterations: 3.143324665228526 mins\n",
      "Train Loss: [0.6184012, 0.2, 0.20915648, 0.2010978]\n",
      "[0.61688673, 0.2, 0.20654362, 0.20219962]\n",
      "[0.6195156, 0.2, 0.20836753, 0.20300868]\n",
      "[0.63294774, 0.2, 0.22269367, 0.2021188]\n",
      "[0.6229289, 0.2, 0.21274406, 0.20205484]\n",
      "[0.6494957, 0.2, 0.20548657, 0.23588412]\n",
      "[0.6155152, 0.2, 0.20582828, 0.20156933]\n",
      "[0.6420635, 0.2, 0.2096614, 0.22429135]\n",
      "[0.62074804, 0.2, 0.21061985, 0.20202379]\n",
      "[0.6103757, 0.2, 0.20079133, 0.20148411]\n",
      "[0.62059677, 0.2, 0.20844811, 0.20405139]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12890 iterations: 3.1453238169352216 mins\n",
      "Train Loss: [0.62059677, 0.2, 0.20844811, 0.20405139]\n",
      "[0.6205449, 0.2, 0.20913884, 0.20331067]\n",
      "[0.63456565, 0.2, 0.20690161, 0.21957059]\n",
      "[0.6156125, 0.2, 0.20579185, 0.20172666]\n",
      "[0.62602377, 0.2, 0.21544477, 0.20248388]\n",
      "[0.6119954, 0.2, 0.20221147, 0.20168899]\n",
      "[0.6436194, 0.2, 0.20739487, 0.2281296]\n",
      "[0.61759514, 0.2, 0.20527922, 0.20422162]\n",
      "[0.6126237, 0.2, 0.20181234, 0.20271797]\n",
      "[0.6147997, 0.2, 0.20431788, 0.20238988]\n",
      "[0.6279156, 0.2, 0.21675509, 0.20307028]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12900 iterations: 3.1478060324986776 mins\n",
      "Train Loss: [0.6279156, 0.2, 0.21675509, 0.20307028]\n",
      "[0.61957616, 0.2, 0.2103299, 0.20115757]\n",
      "[0.6269133, 0.2, 0.2162201, 0.20260704]\n",
      "[0.62258375, 0.2, 0.2115664, 0.202935]\n",
      "[0.6112456, 0.2, 0.20159227, 0.20157494]\n",
      "[0.62385696, 0.2, 0.21486844, 0.20091456]\n",
      "[0.62152165, 0.2, 0.21125776, 0.20219423]\n",
      "[0.61677957, 0.2, 0.20628263, 0.2024318]\n",
      "[0.6164092, 0.2, 0.20616579, 0.20218326]\n",
      "[0.62258893, 0.2, 0.2123842, 0.20214999]\n",
      "[0.616596, 0.2, 0.2063065, 0.20224011]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12910 iterations: 3.149844467639923 mins\n",
      "Train Loss: [0.616596, 0.2, 0.2063065, 0.20224011]\n",
      "[0.6155272, 0.2, 0.20493974, 0.20254323]\n",
      "[0.61329454, 0.2, 0.20159104, 0.20366484]\n",
      "[0.6213717, 0.2, 0.21077491, 0.20256376]\n",
      "[0.6519481, 0.2, 0.2078462, 0.23607539]\n",
      "[0.64841473, 0.2, 0.20346722, 0.23693019]\n",
      "[0.61591375, 0.2, 0.20510902, 0.20279643]\n",
      "[0.6240226, 0.2, 0.21267518, 0.20334724]\n",
      "[0.6166977, 0.2, 0.20680052, 0.20190433]\n",
      "[0.6145714, 0.2, 0.20484938, 0.2017354]\n",
      "[0.623442, 0.2, 0.21108668, 0.2043744]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12920 iterations: 3.151858079433441 mins\n",
      "Train Loss: [0.623442, 0.2, 0.21108668, 0.2043744]\n",
      "[0.6200273, 0.2, 0.210424, 0.20162788]\n",
      "[0.6382289, 0.2, 0.20682357, 0.22343515]\n",
      "[0.62212104, 0.2, 0.21250452, 0.20165049]\n",
      "[0.6165534, 0.2, 0.20637506, 0.20221645]\n",
      "[0.6185129, 0.2, 0.2082281, 0.20232674]\n",
      "[0.61528015, 0.2, 0.20526724, 0.20205878]\n",
      "[0.62129384, 0.2, 0.21111442, 0.20222883]\n",
      "[0.61995137, 0.2, 0.21078485, 0.20121863]\n",
      "[0.6183107, 0.2, 0.20736206, 0.2030034]\n",
      "[0.6473324, 0.2, 0.238264, 0.2011266]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12930 iterations: 3.1538668473561606 mins\n",
      "Train Loss: [0.6473324, 0.2, 0.238264, 0.2011266]\n",
      "[0.6196767, 0.2, 0.20998852, 0.20174588]\n",
      "[0.6179775, 0.2, 0.20704027, 0.20299502]\n",
      "[0.62035817, 0.2, 0.21005756, 0.20235965]\n",
      "[0.612728, 0.2, 0.20359677, 0.20119117]\n",
      "[0.62055963, 0.2, 0.21154223, 0.20107833]\n",
      "[0.6222921, 0.2, 0.21330139, 0.20105311]\n",
      "[0.6149004, 0.2, 0.20535685, 0.2016072]\n",
      "[0.6218175, 0.2, 0.21000047, 0.20388208]\n",
      "[0.61589575, 0.2, 0.20605311, 0.20191026]\n",
      "[0.61443055, 0.2, 0.20439552, 0.20210496]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12940 iterations: 3.1557621161142984 mins\n",
      "Train Loss: [0.61443055, 0.2, 0.20439552, 0.20210496]\n",
      "[0.61323744, 0.2, 0.2030823, 0.20222788]\n",
      "[0.6167248, 0.2, 0.20563948, 0.20316139]\n",
      "[0.6433057, 0.2, 0.23437436, 0.2010113]\n",
      "[0.6187054, 0.2, 0.20824337, 0.20254372]\n",
      "[0.6127313, 0.2, 0.20278455, 0.20203054]\n",
      "[0.6163544, 0.2, 0.20658258, 0.20185824]\n",
      "[0.6200896, 0.2, 0.20926638, 0.20291299]\n",
      "[0.61009455, 0.2, 0.20046276, 0.20172504]\n",
      "[0.61743593, 0.2, 0.20747839, 0.20205444]\n",
      "[0.61764324, 0.2, 0.20775782, 0.20198624]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12950 iterations: 3.157801866531372 mins\n",
      "Train Loss: [0.61764324, 0.2, 0.20775782, 0.20198624]\n",
      "[0.6178002, 0.2, 0.20745008, 0.20245525]\n",
      "[0.61974114, 0.2, 0.20675805, 0.20509274]\n",
      "[0.6172065, 0.2, 0.20716593, 0.2021547]\n",
      "[0.61859995, 0.2, 0.2091423, 0.20157602]\n",
      "[0.61662054, 0.2, 0.20690247, 0.2018412]\n",
      "[0.6152816, 0.2, 0.20555246, 0.2018568]\n",
      "[0.6124126, 0.2, 0.20243627, 0.20210873]\n",
      "[0.6381728, 0.2, 0.20222022, 0.22809015]\n",
      "[0.61632675, 0.2, 0.20718893, 0.20128071]\n",
      "[0.6118919, 0.2, 0.20238079, 0.20165882]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12960 iterations: 3.159833530584971 mins\n",
      "Train Loss: [0.6118919, 0.2, 0.20238079, 0.20165882]\n",
      "[0.6201654, 0.2, 0.2109373, 0.20138052]\n",
      "[0.61695737, 0.2, 0.20763649, 0.20147774]\n",
      "[0.6109423, 0.2, 0.20163354, 0.20147045]\n",
      "[0.6156025, 0.2, 0.20606793, 0.20170124]\n",
      "[0.62397975, 0.2, 0.20430076, 0.21185103]\n",
      "[0.6143302, 0.2, 0.20539387, 0.20111398]\n",
      "[0.614533, 0.2, 0.20518135, 0.20153484]\n",
      "[0.6159032, 0.2, 0.2049619, 0.20312992]\n",
      "[0.6200013, 0.2, 0.20901504, 0.20318134]\n",
      "[0.6298425, 0.2, 0.216708, 0.20533606]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12970 iterations: 3.162435313065847 mins\n",
      "Train Loss: [0.6298425, 0.2, 0.216708, 0.20533606]\n",
      "[0.62249345, 0.2, 0.21347, 0.20123233]\n",
      "[0.6157862, 0.2, 0.20657696, 0.20142455]\n",
      "[0.6176409, 0.2, 0.20773722, 0.20212486]\n",
      "[0.6161259, 0.2, 0.20644753, 0.2019047]\n",
      "[0.61879605, 0.2, 0.2094187, 0.20160873]\n",
      "[0.6162177, 0.2, 0.20638694, 0.20206653]\n",
      "[0.617978, 0.2, 0.2091971, 0.20102061]\n",
      "[0.6180168, 0.2, 0.20602241, 0.20423765]\n",
      "[0.61353135, 0.2, 0.2019135, 0.20386511]\n",
      "[0.61471677, 0.2, 0.2045676, 0.20239961]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12980 iterations: 3.1654471516609193 mins\n",
      "Train Loss: [0.61471677, 0.2, 0.2045676, 0.20239961]\n",
      "[0.61770755, 0.2, 0.20809437, 0.20186658]\n",
      "[0.61364496, 0.2, 0.2037041, 0.2021973]\n",
      "[0.616129, 0.2, 0.20718975, 0.20119886]\n",
      "[0.61203086, 0.2, 0.20176177, 0.2025319]\n",
      "[0.6178374, 0.2, 0.2064294, 0.2036748]\n",
      "[0.64209557, 0.2, 0.2028229, 0.2315436]\n",
      "[0.6231614, 0.2, 0.21308297, 0.20235349]\n",
      "[0.6129172, 0.2, 0.20451747, 0.20067908]\n",
      "[0.62219447, 0.2, 0.20900993, 0.20546778]\n",
      "[0.617026, 0.2, 0.20479415, 0.20451926]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12990 iterations: 3.1678988496462503 mins\n",
      "Train Loss: [0.617026, 0.2, 0.20479415, 0.20451926]\n",
      "[0.6122925, 0.2, 0.20203337, 0.20255087]\n",
      "[0.61345255, 0.2, 0.20386909, 0.20187935]\n",
      "[0.61709094, 0.2, 0.20731032, 0.20208071]\n",
      "[0.6217096, 0.2, 0.21125048, 0.20276348]\n",
      "[0.6165189, 0.2, 0.20690164, 0.20192598]\n",
      "[0.6219108, 0.2, 0.21078178, 0.20344137]\n",
      "[0.62095916, 0.2, 0.21160509, 0.20167027]\n",
      "[0.61570495, 0.2, 0.20727405, 0.20075]\n",
      "[0.61693525, 0.2, 0.20604664, 0.20321079]\n",
      "[0.61591434, 0.2, 0.2045199, 0.20371936]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13000 iterations: 3.1710316141446433 mins\n",
      "Train Loss: [0.61591434, 0.2, 0.2045199, 0.20371936]\n",
      "[0.62136024, 0.2, 0.21015666, 0.2035322]\n",
      "[0.61315346, 0.2, 0.2041002, 0.20138584]\n",
      "[0.6163337, 0.2, 0.20521206, 0.2034585]\n",
      "[0.616656, 0.2, 0.20524254, 0.20375428]\n",
      "[0.61233103, 0.2, 0.20171925, 0.20295611]\n",
      "[0.615559, 0.2, 0.20561312, 0.20229363]\n",
      "[0.6150811, 0.2, 0.20578371, 0.20164888]\n",
      "[0.611179, 0.2, 0.20181783, 0.20171699]\n",
      "[0.61545134, 0.2, 0.20607893, 0.20173265]\n",
      "[0.6194718, 0.2, 0.20848626, 0.20335017]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13010 iterations: 3.1730483492215473 mins\n",
      "Train Loss: [0.6194718, 0.2, 0.20848626, 0.20335017]\n",
      "[0.62018335, 0.2, 0.21113926, 0.20141335]\n",
      "[0.6176365, 0.2, 0.20802435, 0.20198618]\n",
      "[0.61423814, 0.2, 0.20566025, 0.20095669]\n",
      "[0.61280334, 0.2, 0.20406494, 0.20112254]\n",
      "[0.6130371, 0.2, 0.2035052, 0.20192112]\n",
      "[0.61148125, 0.2, 0.2030322, 0.20084336]\n",
      "[0.61497366, 0.2, 0.20625548, 0.2011177]\n",
      "[0.61178815, 0.2, 0.20282382, 0.20136946]\n",
      "[0.6133791, 0.2, 0.20431067, 0.20147924]\n",
      "[0.6145067, 0.2, 0.20585681, 0.20106654]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13020 iterations: 3.175189717610677 mins\n",
      "Train Loss: [0.6145067, 0.2, 0.20585681, 0.20106654]\n",
      "[0.6245752, 0.2, 0.21070927, 0.20628877]\n",
      "[0.623387, 0.2, 0.21211703, 0.20369983]\n",
      "[0.61564815, 0.2, 0.20594954, 0.20213424]\n",
      "[0.61674064, 0.2, 0.20765306, 0.20152882]\n",
      "[0.6196839, 0.2, 0.21030682, 0.20182362]\n",
      "[0.6285879, 0.2, 0.20507231, 0.2159672]\n",
      "[0.61299753, 0.2, 0.20350032, 0.20195177]\n",
      "[0.62778836, 0.2, 0.20777956, 0.21246547]\n",
      "[0.6123021, 0.2, 0.20202173, 0.2027385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61917573, 0.2, 0.2104288, 0.20120537]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13030 iterations: 3.177261515458425 mins\n",
      "Train Loss: [0.61917573, 0.2, 0.2104288, 0.20120537]\n",
      "[0.614416, 0.2, 0.20587417, 0.20099968]\n",
      "[0.61477935, 0.2, 0.20591652, 0.20131953]\n",
      "[0.6108231, 0.2, 0.2013421, 0.20193695]\n",
      "[0.613097, 0.2, 0.20369859, 0.20185369]\n",
      "[0.6363462, 0.2, 0.22597964, 0.20282105]\n",
      "[0.61354333, 0.2, 0.20318092, 0.20281303]\n",
      "[0.61870396, 0.2, 0.20764671, 0.20350572]\n",
      "[0.6135267, 0.2, 0.20498796, 0.20098545]\n",
      "[0.6147191, 0.2, 0.2041607, 0.2030033]\n",
      "[0.62771773, 0.2, 0.21720707, 0.2029548]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13040 iterations: 3.1792078336079914 mins\n",
      "Train Loss: [0.62771773, 0.2, 0.21720707, 0.2029548]\n",
      "[0.61725307, 0.2, 0.2081309, 0.20156679]\n",
      "[0.6156046, 0.2, 0.20626464, 0.2017852]\n",
      "[0.61187714, 0.2, 0.20278698, 0.20153642]\n",
      "[0.6178768, 0.2, 0.20805472, 0.20226946]\n",
      "[0.6242293, 0.2, 0.20607278, 0.21060479]\n",
      "[0.6162983, 0.2, 0.20464471, 0.20410107]\n",
      "[0.6331216, 0.2, 0.22339043, 0.20217788]\n",
      "[0.6171349, 0.2, 0.20700684, 0.20257449]\n",
      "[0.6133004, 0.2, 0.20377779, 0.2019686]\n",
      "[0.620101, 0.2, 0.20921767, 0.20332871]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13050 iterations: 3.1816489179929097 mins\n",
      "Train Loss: [0.620101, 0.2, 0.20921767, 0.20332871]\n",
      "[0.61439663, 0.2, 0.20501427, 0.2018259]\n",
      "[0.61237645, 0.2, 0.20323348, 0.20158613]\n",
      "[0.623657, 0.2, 0.21381466, 0.20228511]\n",
      "[0.62070554, 0.2, 0.20873965, 0.20440923]\n",
      "[0.62039673, 0.2, 0.21002321, 0.20281729]\n",
      "[0.6170984, 0.2, 0.20853087, 0.20101187]\n",
      "[0.60942835, 0.2, 0.2005433, 0.2013293]\n",
      "[0.6223096, 0.2, 0.20990364, 0.20485047]\n",
      "[0.6178159, 0.2, 0.20727956, 0.20298178]\n",
      "[0.61170727, 0.2, 0.20252135, 0.2016329]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13060 iterations: 3.1835697333017987 mins\n",
      "Train Loss: [0.61170727, 0.2, 0.20252135, 0.2016329]\n",
      "[0.62318385, 0.2, 0.21358535, 0.20204768]\n",
      "[0.62788683, 0.2, 0.21521115, 0.20512769]\n",
      "[0.6133614, 0.2, 0.20407474, 0.20174237]\n",
      "[0.6155744, 0.2, 0.20486008, 0.2031739]\n",
      "[0.6121515, 0.2, 0.20273912, 0.20187627]\n",
      "[0.61564046, 0.2, 0.20615673, 0.20195234]\n",
      "[0.62326974, 0.2, 0.21378337, 0.20195982]\n",
      "[0.6128367, 0.2, 0.2032307, 0.20208006]\n",
      "[0.6145984, 0.2, 0.20532389, 0.20174909]\n",
      "[0.6212902, 0.2, 0.20999257, 0.2037732]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13070 iterations: 3.1856330474217733 mins\n",
      "Train Loss: [0.6212902, 0.2, 0.20999257, 0.2037732]\n",
      "[0.6247015, 0.2, 0.21382737, 0.2033509]\n",
      "[0.6195058, 0.2, 0.20981728, 0.20216712]\n",
      "[0.6175313, 0.2, 0.20786817, 0.20214348]\n",
      "[0.61372536, 0.2, 0.20398258, 0.20222512]\n",
      "[0.6187106, 0.2, 0.20901027, 0.20218456]\n",
      "[0.62284386, 0.2, 0.21313657, 0.20219263]\n",
      "[0.6267582, 0.2, 0.21503055, 0.20421463]\n",
      "[0.6214619, 0.2, 0.21177259, 0.20217904]\n",
      "[0.6126567, 0.2, 0.20307447, 0.20207489]\n",
      "[0.6174582, 0.2, 0.20571592, 0.20423792]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13080 iterations: 3.1875908652941387 mins\n",
      "Train Loss: [0.6174582, 0.2, 0.20571592, 0.20423792]\n",
      "[0.6121315, 0.2, 0.20369081, 0.2009394]\n",
      "[0.6279366, 0.2, 0.21910132, 0.20133704]\n",
      "[0.61507845, 0.2, 0.2061674, 0.20141713]\n",
      "[0.61635226, 0.2, 0.20773299, 0.20112987]\n",
      "[0.61622113, 0.2, 0.20722628, 0.20151004]\n",
      "[0.6135581, 0.2, 0.2043769, 0.20170085]\n",
      "[0.61102164, 0.2, 0.201293, 0.20225288]\n",
      "[0.6219016, 0.2, 0.20914282, 0.20528802]\n",
      "[0.6433219, 0.2, 0.20277995, 0.23307668]\n",
      "[0.6157717, 0.2, 0.20641333, 0.20189944]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13090 iterations: 3.189609583218892 mins\n",
      "Train Loss: [0.6157717, 0.2, 0.20641333, 0.20189944]\n",
      "[0.6186317, 0.2, 0.20916753, 0.2020108]\n",
      "[0.62279993, 0.2, 0.21170935, 0.20364171]\n",
      "[0.6161841, 0.2, 0.2059963, 0.20274451]\n",
      "[0.6168458, 0.2, 0.2082444, 0.20116414]\n",
      "[0.6151898, 0.2, 0.20616122, 0.2015972]\n",
      "[0.6242775, 0.2, 0.21385448, 0.20299694]\n",
      "[0.61474663, 0.2, 0.20503183, 0.20229404]\n",
      "[0.6123856, 0.2, 0.20173395, 0.20323627]\n",
      "[0.61537063, 0.2, 0.2054647, 0.20249595]\n",
      "[0.6152557, 0.2, 0.20572612, 0.20212512]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13100 iterations: 3.191810182730357 mins\n",
      "Train Loss: [0.6152557, 0.2, 0.20572612, 0.20212512]\n",
      "[0.6158998, 0.2, 0.20693366, 0.20156716]\n",
      "[0.6231292, 0.2, 0.21121775, 0.20451793]\n",
      "[0.61598444, 0.2, 0.20524499, 0.20335124]\n",
      "[0.6167616, 0.2, 0.20778753, 0.20159139]\n",
      "[0.6188609, 0.2, 0.20842882, 0.20305489]\n",
      "[0.6160322, 0.2, 0.20561157, 0.20304865]\n",
      "[0.61583555, 0.2, 0.20584872, 0.20261984]\n",
      "[0.6114634, 0.2, 0.20362261, 0.20047861]\n",
      "[0.6155817, 0.2, 0.20623338, 0.20199087]\n",
      "[0.6111187, 0.2, 0.2025448, 0.20122148]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13110 iterations: 3.1937514821688335 mins\n",
      "Train Loss: [0.6111187, 0.2, 0.2025448, 0.20122148]\n",
      "[0.62109363, 0.2, 0.21090338, 0.2028431]\n",
      "[0.61899775, 0.2, 0.20942533, 0.2022306]\n",
      "[0.62074935, 0.2, 0.20948617, 0.20392741]\n",
      "[0.6222501, 0.2, 0.2131291, 0.20179102]\n",
      "[0.6214168, 0.2, 0.21122587, 0.20286642]\n",
      "[0.61535484, 0.2, 0.20694247, 0.20109391]\n",
      "[0.61057496, 0.2, 0.20165828, 0.20160422]\n",
      "[0.61241835, 0.2, 0.20371936, 0.20139179]\n",
      "[0.6115251, 0.2, 0.20200619, 0.20221685]\n",
      "[0.61315435, 0.2, 0.20441163, 0.20144585]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13120 iterations: 3.1958760658899945 mins\n",
      "Train Loss: [0.61315435, 0.2, 0.20441163, 0.20144585]\n",
      "[0.6101792, 0.2, 0.20095167, 0.20193595]\n",
      "[0.6161596, 0.2, 0.20722526, 0.20164822]\n",
      "[0.61391294, 0.2, 0.20522417, 0.20140815]\n",
      "[0.61091036, 0.2, 0.20146263, 0.20217313]\n",
      "[0.63587385, 0.2, 0.22610511, 0.20249982]\n",
      "[0.6193988, 0.2, 0.20961203, 0.20252056]\n",
      "[0.61546916, 0.2, 0.20710395, 0.2011017]\n",
      "[0.61311024, 0.2, 0.2032716, 0.20257747]\n",
      "[0.61554444, 0.2, 0.20626393, 0.20202185]\n",
      "[0.6205059, 0.2, 0.21057835, 0.20267157]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13130 iterations: 3.198468546072642 mins\n",
      "Train Loss: [0.6205059, 0.2, 0.21057835, 0.20267157]\n",
      "[0.61037284, 0.2, 0.2011073, 0.20201257]\n",
      "[0.6222713, 0.2, 0.21318954, 0.20183143]\n",
      "[0.6092432, 0.2, 0.20106922, 0.20092557]\n",
      "[0.61683935, 0.2, 0.20757131, 0.20202187]\n",
      "[0.6153396, 0.2, 0.2056389, 0.20245694]\n",
      "[0.6117222, 0.2, 0.20206454, 0.20241614]\n",
      "[0.6147114, 0.2, 0.20602459, 0.20144798]\n",
      "[0.61414254, 0.2, 0.20492151, 0.201985]\n",
      "[0.622217, 0.2, 0.20406365, 0.21092042]\n",
      "[0.6184195, 0.2, 0.20937534, 0.20181237]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13140 iterations: 3.200404230753581 mins\n",
      "Train Loss: [0.6184195, 0.2, 0.20937534, 0.20181237]\n",
      "[0.62437844, 0.2, 0.21451813, 0.20262907]\n",
      "[0.6119157, 0.2, 0.20128734, 0.20339842]\n",
      "[0.61941814, 0.2, 0.20994379, 0.20224535]\n",
      "[0.61824, 0.2, 0.20894817, 0.20206356]\n",
      "[0.615479, 0.2, 0.20583013, 0.20242174]\n",
      "[0.63543487, 0.2, 0.22600095, 0.20220752]\n",
      "[0.6141805, 0.2, 0.20451772, 0.20243917]\n",
      "[0.62243867, 0.2, 0.21148276, 0.20373456]\n",
      "[0.6192498, 0.2, 0.20834227, 0.20368823]\n",
      "[0.61627746, 0.2, 0.2075326, 0.20152749]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13150 iterations: 3.2024387319882712 mins\n",
      "Train Loss: [0.61627746, 0.2, 0.2075326, 0.20152749]\n",
      "[0.6130613, 0.2, 0.20146143, 0.20438465]\n",
      "[0.6164912, 0.2, 0.20823018, 0.20104791]\n",
      "[0.6123229, 0.2, 0.2022788, 0.20283335]\n",
      "[0.61391926, 0.2, 0.20449911, 0.20221308]\n",
      "[0.61828035, 0.2, 0.20900819, 0.202068]\n",
      "[0.6209735, 0.2, 0.21231908, 0.20145284]\n",
      "[0.6113835, 0.2, 0.20225915, 0.20192493]\n",
      "[0.6126354, 0.2, 0.2048693, 0.20056912]\n",
      "[0.6260919, 0.2, 0.21573476, 0.2031623]\n",
      "[0.6216412, 0.2, 0.21205822, 0.20239024]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13160 iterations: 3.204400984446208 mins\n",
      "Train Loss: [0.6216412, 0.2, 0.21205822, 0.20239024]\n",
      "[0.6095793, 0.2, 0.20143142, 0.20095748]\n",
      "[0.6252374, 0.2, 0.2120271, 0.20602207]\n",
      "[0.61910105, 0.2, 0.2096009, 0.2023151]\n",
      "[0.67463624, 0.2, 0.21957363, 0.24788073]\n",
      "[0.616319, 0.2, 0.20359729, 0.20554884]\n",
      "[0.62056166, 0.2, 0.21181025, 0.20158625]\n",
      "[0.6196061, 0.2, 0.21125738, 0.20118932]\n",
      "[0.6138834, 0.2, 0.20500122, 0.20172757]\n",
      "[0.6293858, 0.2, 0.21994162, 0.2022938]\n",
      "[0.62124366, 0.2, 0.21285653, 0.20124051]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13170 iterations: 3.2064549684524537 mins\n",
      "Train Loss: [0.62124366, 0.2, 0.21285653, 0.20124051]\n",
      "[0.6151346, 0.2, 0.20612448, 0.20186658]\n",
      "[0.62192243, 0.2, 0.21108775, 0.2036942]\n",
      "[0.61981183, 0.2, 0.21061516, 0.20205878]\n",
      "[0.6129159, 0.2, 0.20270154, 0.20307934]\n",
      "[0.6257601, 0.2, 0.21323723, 0.20539087]\n",
      "[0.6220013, 0.2, 0.2126924, 0.20218112]\n",
      "[0.61702526, 0.2, 0.20663154, 0.20326962]\n",
      "[0.62227637, 0.2, 0.21259364, 0.2025616]\n",
      "[0.62683123, 0.2, 0.2140616, 0.20565121]\n",
      "[0.61893374, 0.2, 0.2086228, 0.20319468]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13180 iterations: 3.2083529512087505 mins\n",
      "Train Loss: [0.61893374, 0.2, 0.2086228, 0.20319468]\n",
      "[0.61726564, 0.2, 0.20802566, 0.2021255]\n",
      "[0.6198432, 0.2, 0.20994851, 0.20278251]\n",
      "[0.61816585, 0.2, 0.20820375, 0.20285213]\n",
      "[0.6145038, 0.2, 0.20578398, 0.20161201]\n",
      "[0.61648375, 0.2, 0.20752005, 0.20185825]\n",
      "[0.62641567, 0.2, 0.20264341, 0.21666911]\n",
      "[0.61343795, 0.2, 0.2026131, 0.203723]\n",
      "[0.6201868, 0.2, 0.21012919, 0.20295732]\n",
      "[0.6101289, 0.2, 0.20100929, 0.20202033]\n",
      "[0.6478864, 0.2, 0.23905636, 0.20173222]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13190 iterations: 3.2104848861694335 mins\n",
      "Train Loss: [0.6478864, 0.2, 0.23905636, 0.20173222]\n",
      "[0.6176102, 0.2, 0.20766841, 0.20284049]\n",
      "[0.6196849, 0.2, 0.21046506, 0.20211424]\n",
      "[0.6172867, 0.2, 0.20672692, 0.20344992]\n",
      "[0.61662203, 0.2, 0.20649719, 0.20301019]\n",
      "[0.6190879, 0.2, 0.20980984, 0.20215803]\n",
      "[0.614266, 0.2, 0.20516902, 0.20197143]\n",
      "[0.6151006, 0.2, 0.20647545, 0.20149477]\n",
      "[0.6174019, 0.2, 0.20775668, 0.20251074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6338584, 0.2, 0.21450447, 0.21221544]\n",
      "[0.64959425, 0.2, 0.24072373, 0.20172517]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13200 iterations: 3.212486716111501 mins\n",
      "Train Loss: [0.64959425, 0.2, 0.24072373, 0.20172517]\n",
      "[0.61288434, 0.2, 0.20340401, 0.20232174]\n",
      "[0.61604714, 0.2, 0.20621647, 0.20265985]\n",
      "[0.6150166, 0.2, 0.20682272, 0.2010111]\n",
      "[0.62070966, 0.2, 0.21075204, 0.20276394]\n",
      "[0.61189616, 0.2, 0.20303683, 0.2016557]\n",
      "[0.6184234, 0.2, 0.20978399, 0.20142719]\n",
      "[0.61456126, 0.2, 0.20607217, 0.20126843]\n",
      "[0.616131, 0.2, 0.20458406, 0.2043188]\n",
      "[0.62110233, 0.2, 0.20949697, 0.20437065]\n",
      "[0.6132382, 0.2, 0.20202379, 0.20397423]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13210 iterations: 3.2148367802302045 mins\n",
      "Train Loss: [0.6132382, 0.2, 0.20202379, 0.20397423]\n",
      "[0.6131475, 0.2, 0.20387655, 0.20202579]\n",
      "[0.6206042, 0.2, 0.20868064, 0.20467387]\n",
      "[0.6175679, 0.2, 0.20746738, 0.20284685]\n",
      "[0.6181868, 0.2, 0.20776886, 0.20316187]\n",
      "[0.61673075, 0.2, 0.20543787, 0.20403548]\n",
      "[0.61428493, 0.2, 0.20604299, 0.20098382]\n",
      "[0.6360278, 0.2, 0.20688036, 0.22188947]\n",
      "[0.620591, 0.2, 0.20597318, 0.20736253]\n",
      "[0.62171227, 0.2, 0.21282648, 0.20163395]\n",
      "[0.6332231, 0.2, 0.20672911, 0.21924536]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13220 iterations: 3.2168975472450256 mins\n",
      "Train Loss: [0.6332231, 0.2, 0.20672911, 0.21924536]\n",
      "[0.61680895, 0.2, 0.20574276, 0.20381817]\n",
      "[0.64510435, 0.2, 0.20362827, 0.23422804]\n",
      "[0.61515886, 0.2, 0.20401135, 0.20390141]\n",
      "[0.6277153, 0.2, 0.21703629, 0.20343404]\n",
      "[0.6234297, 0.2, 0.21441975, 0.20176595]\n",
      "[0.61664706, 0.2, 0.2053534, 0.20405018]\n",
      "[0.61485237, 0.2, 0.20512308, 0.20248613]\n",
      "[0.6257799, 0.2, 0.21561272, 0.20292477]\n",
      "[0.61886805, 0.2, 0.20916185, 0.2024641]\n",
      "[0.6125116, 0.2, 0.20294352, 0.20232637]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13230 iterations: 3.218790853023529 mins\n",
      "Train Loss: [0.6125116, 0.2, 0.20294352, 0.20232637]\n",
      "[0.6319119, 0.2, 0.22139664, 0.20327395]\n",
      "[0.6132717, 0.2, 0.20170538, 0.20432915]\n",
      "[0.622419, 0.2, 0.21200366, 0.20318149]\n",
      "[0.61373043, 0.2, 0.20370784, 0.20279135]\n",
      "[0.6322172, 0.2, 0.22325635, 0.2017323]\n",
      "[0.6142211, 0.2, 0.20495893, 0.20203564]\n",
      "[0.62216103, 0.2, 0.20982967, 0.20510726]\n",
      "[0.6259211, 0.2, 0.21693276, 0.20176823]\n",
      "[0.6195046, 0.2, 0.20794466, 0.20434426]\n",
      "[0.62490517, 0.2, 0.21548598, 0.20220847]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13240 iterations: 3.2209339181582135 mins\n",
      "Train Loss: [0.62490517, 0.2, 0.21548598, 0.20220847]\n",
      "[0.6202453, 0.2, 0.21008284, 0.20295592]\n",
      "[0.6693588, 0.2, 0.25970882, 0.2024483]\n",
      "[0.6106973, 0.2, 0.20230319, 0.20119143]\n",
      "[0.6524361, 0.2, 0.21026483, 0.23496735]\n",
      "[0.6205797, 0.2, 0.20883153, 0.20454518]\n",
      "[0.6184189, 0.2, 0.2096541, 0.20156237]\n",
      "[0.6186695, 0.2, 0.21017432, 0.20129324]\n",
      "[0.61585, 0.2, 0.20705998, 0.20158866]\n",
      "[0.62574625, 0.2, 0.21495253, 0.2035931]\n",
      "[0.6214664, 0.2, 0.2131575, 0.2011093]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13250 iterations: 3.223139234383901 mins\n",
      "Train Loss: [0.6214664, 0.2, 0.2131575, 0.2011093]\n",
      "[0.62670296, 0.2, 0.21646737, 0.20303677]\n",
      "[0.6138875, 0.2, 0.20526609, 0.20142336]\n",
      "[0.6358033, 0.2, 0.20686838, 0.22173798]\n",
      "[0.62598145, 0.2, 0.20904076, 0.2097445]\n",
      "[0.6219636, 0.2, 0.21202232, 0.2027457]\n",
      "[0.6178337, 0.2, 0.20636049, 0.2042731]\n",
      "[0.6192614, 0.2, 0.20841101, 0.2036412]\n",
      "[0.6183615, 0.2, 0.20776902, 0.20337185]\n",
      "[0.61850756, 0.2, 0.20858644, 0.20268779]\n",
      "[0.633186, 0.2, 0.20508596, 0.22085306]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13260 iterations: 3.2250359336535137 mins\n",
      "Train Loss: [0.633186, 0.2, 0.20508596, 0.22085306]\n",
      "[0.61504155, 0.2, 0.20603707, 0.20174435]\n",
      "[0.61840135, 0.2, 0.20942755, 0.20170055]\n",
      "[0.6101641, 0.2, 0.20125107, 0.20162733]\n",
      "[0.6137722, 0.2, 0.20553784, 0.20093699]\n",
      "[0.6144873, 0.2, 0.20593795, 0.2012411]\n",
      "[0.6139761, 0.2, 0.20466979, 0.20198861]\n",
      "[0.6378674, 0.2, 0.21604657, 0.21449508]\n",
      "[0.6202868, 0.2, 0.20856678, 0.20438719]\n",
      "[0.6512338, 0.2, 0.20794962, 0.23594499]\n",
      "[0.6109581, 0.2, 0.2025431, 0.20106784]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13270 iterations: 3.2271173675855 mins\n",
      "Train Loss: [0.6109581, 0.2, 0.2025431, 0.20106784]\n",
      "[0.625564, 0.2, 0.21350105, 0.20470907]\n",
      "[0.6185278, 0.2, 0.20849247, 0.2026758]\n",
      "[0.61223567, 0.2, 0.20211917, 0.20275235]\n",
      "[0.6135844, 0.2, 0.20496903, 0.20124757]\n",
      "[0.6114347, 0.2, 0.20174122, 0.20232289]\n",
      "[0.6193455, 0.2, 0.20814162, 0.2038313]\n",
      "[0.6174835, 0.2, 0.20665632, 0.20345351]\n",
      "[0.6141895, 0.2, 0.20581062, 0.20100458]\n",
      "[0.65994567, 0.2, 0.25100747, 0.20156433]\n",
      "[0.6271376, 0.2, 0.21090476, 0.20885658]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13280 iterations: 3.2289998650550844 mins\n",
      "Train Loss: [0.6271376, 0.2, 0.21090476, 0.20885658]\n",
      "[0.6209093, 0.2, 0.20838882, 0.20514223]\n",
      "[0.61271065, 0.2, 0.20247719, 0.20285423]\n",
      "[0.6310642, 0.2, 0.221241, 0.2024437]\n",
      "[0.6196618, 0.2, 0.20802413, 0.20425683]\n",
      "[0.6195311, 0.2, 0.20975219, 0.20239814]\n",
      "[0.6264398, 0.2, 0.2143099, 0.20474993]\n",
      "[0.6176929, 0.2, 0.20784962, 0.2024645]\n",
      "[0.615588, 0.2, 0.20649153, 0.20171924]\n",
      "[0.6184062, 0.2, 0.20845553, 0.20257534]\n",
      "[0.6154189, 0.2, 0.20667005, 0.20137557]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13290 iterations: 3.231589615345001 mins\n",
      "Train Loss: [0.6154189, 0.2, 0.20667005, 0.20137557]\n",
      "[0.6125459, 0.2, 0.20340848, 0.20176601]\n",
      "[0.6160006, 0.2, 0.20575337, 0.20287812]\n",
      "[0.6198787, 0.2, 0.2064536, 0.2060581]\n",
      "[0.6160516, 0.2, 0.20661187, 0.20207599]\n",
      "[0.61491984, 0.2, 0.20544195, 0.2021181]\n",
      "[0.6179836, 0.2, 0.20949148, 0.20113695]\n",
      "[0.61183196, 0.2, 0.20336403, 0.20111787]\n",
      "[0.6176083, 0.2, 0.20877136, 0.20149262]\n",
      "[0.62028384, 0.2, 0.21050155, 0.20244412]\n",
      "[0.61706597, 0.2, 0.20730487, 0.20242879]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13300 iterations: 3.2335722843805947 mins\n",
      "Train Loss: [0.61706597, 0.2, 0.20730487, 0.20242879]\n",
      "[0.62098986, 0.2, 0.21135525, 0.20230898]\n",
      "[0.61875015, 0.2, 0.20915543, 0.20227513]\n",
      "[0.6147376, 0.2, 0.20581117, 0.20161287]\n",
      "[0.6132493, 0.2, 0.20487511, 0.20106713]\n",
      "[0.6161622, 0.2, 0.20709069, 0.20177077]\n",
      "[0.6145213, 0.2, 0.20533772, 0.20188922]\n",
      "[0.6195221, 0.2, 0.21006712, 0.20216636]\n",
      "[0.61384684, 0.2, 0.2051995, 0.20136426]\n",
      "[0.61120117, 0.2, 0.20253624, 0.20138721]\n",
      "[0.61220104, 0.2, 0.20309317, 0.20183574]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13310 iterations: 3.235561164220174 mins\n",
      "Train Loss: [0.61220104, 0.2, 0.20309317, 0.20183574]\n",
      "[0.6173867, 0.2, 0.20871687, 0.20140323]\n",
      "[0.6121216, 0.2, 0.20250095, 0.20235997]\n",
      "[0.6349273, 0.2, 0.22613186, 0.20154087]\n",
      "[0.6143361, 0.2, 0.20306304, 0.20402104]\n",
      "[0.61364084, 0.2, 0.2046129, 0.20177922]\n",
      "[0.6150795, 0.2, 0.20625007, 0.20158404]\n",
      "[0.6189488, 0.2, 0.21042085, 0.20128581]\n",
      "[0.6174629, 0.2, 0.20871815, 0.2015056]\n",
      "[0.6137796, 0.2, 0.20486039, 0.20168309]\n",
      "[0.6163477, 0.2, 0.20494764, 0.20416735]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13320 iterations: 3.23748596906662 mins\n",
      "Train Loss: [0.6163477, 0.2, 0.20494764, 0.20416735]\n",
      "[0.61886656, 0.2, 0.21033677, 0.20130205]\n",
      "[0.6121573, 0.2, 0.20252493, 0.20240937]\n",
      "[0.6166397, 0.2, 0.20704924, 0.20237274]\n",
      "[0.6146639, 0.2, 0.20615995, 0.20129132]\n",
      "[0.6147109, 0.2, 0.20539379, 0.20210952]\n",
      "[0.6096996, 0.2, 0.20079695, 0.20170003]\n",
      "[0.6184733, 0.2, 0.20952643, 0.20174927]\n",
      "[0.61190385, 0.2, 0.20358096, 0.2011302]\n",
      "[0.62728864, 0.2, 0.20764302, 0.21245798]\n",
      "[0.6200502, 0.2, 0.2100283, 0.20283763]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13330 iterations: 3.2396164496739703 mins\n",
      "Train Loss: [0.6200502, 0.2, 0.2100283, 0.20283763]\n",
      "[0.61566514, 0.2, 0.2070096, 0.20147507]\n",
      "[0.6135518, 0.2, 0.20453203, 0.20184347]\n",
      "[0.6234808, 0.2, 0.21386172, 0.20244618]\n",
      "[0.61586505, 0.2, 0.20685971, 0.20183575]\n",
      "[0.6183586, 0.2, 0.20773609, 0.20345655]\n",
      "[0.6201323, 0.2, 0.20882475, 0.20414555]\n",
      "[0.61646223, 0.2, 0.20771909, 0.20158514]\n",
      "[0.6165411, 0.2, 0.20734389, 0.20204343]\n",
      "[0.6182078, 0.2, 0.20728576, 0.20377253]\n",
      "[0.6152294, 0.2, 0.20671128, 0.20137268]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13340 iterations: 3.241707750161489 mins\n",
      "Train Loss: [0.6152294, 0.2, 0.20671128, 0.20137268]\n",
      "[0.6153912, 0.2, 0.2054894, 0.20276073]\n",
      "[0.61612093, 0.2, 0.20732734, 0.20165707]\n",
      "[0.61285824, 0.2, 0.20181388, 0.20391227]\n",
      "[0.64260507, 0.2, 0.20752123, 0.22795624]\n",
      "[0.6130707, 0.2, 0.20504054, 0.20090811]\n",
      "[0.61548865, 0.2, 0.20618832, 0.2021837]\n",
      "[0.6189751, 0.2, 0.20883699, 0.20302661]\n",
      "[0.61515385, 0.2, 0.20573056, 0.20231782]\n",
      "[0.6185662, 0.2, 0.20814879, 0.20331803]\n",
      "[0.61940616, 0.2, 0.21032411, 0.20198858]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13350 iterations: 3.24360906680425 mins\n",
      "Train Loss: [0.61940616, 0.2, 0.21032411, 0.20198858]\n",
      "[0.61398286, 0.2, 0.20599796, 0.20089526]\n",
      "[0.6320275, 0.2, 0.20370229, 0.2212396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6292409, 0.2, 0.20178941, 0.22036843]\n",
      "[0.6135368, 0.2, 0.2047879, 0.20166828]\n",
      "[0.62262267, 0.2, 0.2141003, 0.20144378]\n",
      "[0.61865604, 0.2, 0.20943643, 0.20214272]\n",
      "[0.6195935, 0.2, 0.21109636, 0.20142142]\n",
      "[0.6096546, 0.2, 0.20190826, 0.20067114]\n",
      "[0.6155543, 0.2, 0.20512874, 0.20335108]\n",
      "[0.6157298, 0.2, 0.20539697, 0.20325975]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13360 iterations: 3.245667799313863 mins\n",
      "Train Loss: [0.6157298, 0.2, 0.20539697, 0.20325975]\n",
      "[0.611483, 0.2, 0.20118333, 0.20322801]\n",
      "[0.62006485, 0.2, 0.20973818, 0.20325713]\n",
      "[0.6217316, 0.2, 0.21188092, 0.20278329]\n",
      "[0.6319598, 0.2, 0.22221713, 0.20267767]\n",
      "[0.6140368, 0.2, 0.20485014, 0.20212637]\n",
      "[0.61044514, 0.2, 0.20173557, 0.20165353]\n",
      "[0.62200767, 0.2, 0.2107193, 0.20423649]\n",
      "[0.6188038, 0.2, 0.20822887, 0.20352742]\n",
      "[0.6171811, 0.2, 0.20779759, 0.20234]\n",
      "[0.639361, 0.2, 0.20487635, 0.22744472]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13370 iterations: 3.2481991171836855 mins\n",
      "Train Loss: [0.639361, 0.2, 0.20487635, 0.22744472]\n",
      "[0.6179298, 0.2, 0.20946337, 0.20143104]\n",
      "[0.6153453, 0.2, 0.2066903, 0.20162381]\n",
      "[0.61521906, 0.2, 0.20649292, 0.20169912]\n",
      "[0.62271756, 0.2, 0.21359281, 0.20210192]\n",
      "[0.6172813, 0.2, 0.20884542, 0.20141722]\n",
      "[0.61256015, 0.2, 0.20379037, 0.20175502]\n",
      "[0.6168661, 0.2, 0.20676528, 0.20309003]\n",
      "[0.61394036, 0.2, 0.20485154, 0.2020819]\n",
      "[0.61730593, 0.2, 0.20680608, 0.20349738]\n",
      "[0.61381036, 0.2, 0.20300381, 0.20380831]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13380 iterations: 3.2502140323321025 mins\n",
      "Train Loss: [0.61381036, 0.2, 0.20300381, 0.20380831]\n",
      "[0.614866, 0.2, 0.20613027, 0.20174187]\n",
      "[0.6152707, 0.2, 0.20641117, 0.20187007]\n",
      "[0.6126378, 0.2, 0.20472719, 0.20092513]\n",
      "[0.62224287, 0.2, 0.21394125, 0.20132016]\n",
      "[0.61428595, 0.2, 0.20492238, 0.20238659]\n",
      "[0.62039155, 0.2, 0.21096121, 0.20245785]\n",
      "[0.6124238, 0.2, 0.20415892, 0.20129655]\n",
      "[0.61523575, 0.2, 0.20328964, 0.20498286]\n",
      "[0.617717, 0.2, 0.20583096, 0.204928]\n",
      "[0.619707, 0.2, 0.20893647, 0.2038177]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13390 iterations: 3.2522848010063172 mins\n",
      "Train Loss: [0.619707, 0.2, 0.20893647, 0.2038177]\n",
      "[0.6152347, 0.2, 0.20630318, 0.2019836]\n",
      "[0.6167887, 0.2, 0.2048873, 0.20495799]\n",
      "[0.6217264, 0.2, 0.21262734, 0.20216064]\n",
      "[0.62082714, 0.2, 0.21094672, 0.2029467]\n",
      "[0.6175982, 0.2, 0.2072628, 0.20340544]\n",
      "[0.6113909, 0.2, 0.2020161, 0.20244807]\n",
      "[0.6135034, 0.2, 0.20542239, 0.20115727]\n",
      "[0.6162461, 0.2, 0.20710273, 0.20222218]\n",
      "[0.61773103, 0.2, 0.20852157, 0.20229027]\n",
      "[0.61315, 0.2, 0.20474105, 0.2014915]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13400 iterations: 3.2541382193565367 mins\n",
      "Train Loss: [0.61315, 0.2, 0.20474105, 0.2014915]\n",
      "[0.6195928, 0.2, 0.20974058, 0.20293626]\n",
      "[0.6167112, 0.2, 0.20691773, 0.20287894]\n",
      "[0.6111954, 0.2, 0.2029476, 0.20133445]\n",
      "[0.61248285, 0.2, 0.20447965, 0.20109092]\n",
      "[0.62896514, 0.2, 0.20519277, 0.21686138]\n",
      "[0.61438805, 0.2, 0.20534232, 0.20213611]\n",
      "[0.612082, 0.2, 0.20422417, 0.20094953]\n",
      "[0.6154344, 0.2, 0.20711201, 0.20141567]\n",
      "[0.6168281, 0.2, 0.20682648, 0.20309666]\n",
      "[0.62123245, 0.2, 0.2132175, 0.2011114]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13410 iterations: 3.2562763492266336 mins\n",
      "Train Loss: [0.62123245, 0.2, 0.2132175, 0.2011114]\n",
      "[0.62376285, 0.2, 0.21130477, 0.20555572]\n",
      "[0.61412513, 0.2, 0.20493068, 0.20229411]\n",
      "[0.621071, 0.2, 0.21251462, 0.2016581]\n",
      "[0.6313463, 0.2, 0.2083285, 0.21612178]\n",
      "[0.6145407, 0.2, 0.20488214, 0.20276928]\n",
      "[0.6196199, 0.2, 0.21173896, 0.20099643]\n",
      "[0.6118127, 0.2, 0.2034771, 0.20145467]\n",
      "[0.61393833, 0.2, 0.20548773, 0.20157269]\n",
      "[0.617803, 0.2, 0.20859425, 0.20233305]\n",
      "[0.61563796, 0.2, 0.20615025, 0.2026146]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13420 iterations: 3.2583725810050965 mins\n",
      "Train Loss: [0.61563796, 0.2, 0.20615025, 0.2026146]\n",
      "[0.60930425, 0.2, 0.2010043, 0.20142977]\n",
      "[0.6124594, 0.2, 0.20283642, 0.20275536]\n",
      "[0.62570584, 0.2, 0.2150988, 0.20374204]\n",
      "[0.6135254, 0.2, 0.20256074, 0.20410217]\n",
      "[0.6156588, 0.2, 0.20501247, 0.20378664]\n",
      "[0.6136324, 0.2, 0.20376852, 0.20300749]\n",
      "[0.616418, 0.2, 0.20611803, 0.20344678]\n",
      "[0.6243374, 0.2, 0.21492718, 0.20256038]\n",
      "[0.6149144, 0.2, 0.20556656, 0.20250139]\n",
      "[0.61403394, 0.2, 0.20584747, 0.20134388]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13430 iterations: 3.2603243152300516 mins\n",
      "Train Loss: [0.61403394, 0.2, 0.20584747, 0.20134388]\n",
      "[0.61730224, 0.2, 0.20445737, 0.20600583]\n",
      "[0.61436725, 0.2, 0.20416206, 0.2033701]\n",
      "[0.616511, 0.2, 0.20815952, 0.20151536]\n",
      "[0.61908937, 0.2, 0.209564, 0.2026847]\n",
      "[0.62165695, 0.2, 0.2136525, 0.20115747]\n",
      "[0.61682147, 0.2, 0.20815581, 0.20181108]\n",
      "[0.6167109, 0.2, 0.2069553, 0.20289238]\n",
      "[0.6181312, 0.2, 0.2093189, 0.20194063]\n",
      "[0.6151619, 0.2, 0.20624651, 0.20203508]\n",
      "[0.61232513, 0.2, 0.20343898, 0.20199752]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13440 iterations: 3.26244029601415 mins\n",
      "Train Loss: [0.61232513, 0.2, 0.20343898, 0.20199752]\n",
      "[0.6118918, 0.2, 0.20320569, 0.20178983]\n",
      "[0.6259918, 0.2, 0.20546415, 0.2136244]\n",
      "[0.6124816, 0.2, 0.20299116, 0.20258044]\n",
      "[0.6139569, 0.2, 0.20464954, 0.20239154]\n",
      "[0.6184864, 0.2, 0.20864774, 0.2029179]\n",
      "[0.6343614, 0.2, 0.20989652, 0.21754009]\n",
      "[0.62176734, 0.2, 0.21348938, 0.20134859]\n",
      "[0.6179559, 0.2, 0.20876981, 0.20225291]\n",
      "[0.61919343, 0.2, 0.20828544, 0.2039716]\n",
      "[0.62314004, 0.2, 0.21448384, 0.2017174]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13450 iterations: 3.2649399677912396 mins\n",
      "Train Loss: [0.62314004, 0.2, 0.21448384, 0.2017174]\n",
      "[0.6166954, 0.2, 0.2075633, 0.20219105]\n",
      "[0.6286264, 0.2, 0.21917489, 0.20250806]\n",
      "[0.6106089, 0.2, 0.20187543, 0.20178822]\n",
      "[0.62181294, 0.2, 0.21292648, 0.20194007]\n",
      "[0.6136317, 0.2, 0.20502429, 0.2016617]\n",
      "[0.6188444, 0.2, 0.21022195, 0.20167796]\n",
      "[0.61202943, 0.2, 0.20369403, 0.20139322]\n",
      "[0.615015, 0.2, 0.20597301, 0.20210266]\n",
      "[0.6365303, 0.2, 0.22876406, 0.20083046]\n",
      "[0.6167988, 0.2, 0.20698887, 0.2028784]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13460 iterations: 3.2670103669166566 mins\n",
      "Train Loss: [0.6167988, 0.2, 0.20698887, 0.2028784]\n",
      "[0.6153212, 0.2, 0.2047565, 0.20363756]\n",
      "[0.61907357, 0.2, 0.21037751, 0.20177491]\n",
      "[0.6199868, 0.2, 0.21138157, 0.2016898]\n",
      "[0.6154752, 0.2, 0.20692824, 0.20163754]\n",
      "[0.62003267, 0.2, 0.21164393, 0.20148565]\n",
      "[0.6348815, 0.2, 0.20279947, 0.22518505]\n",
      "[0.61293983, 0.2, 0.20379618, 0.20225392]\n",
      "[0.6192323, 0.2, 0.21074463, 0.20160477]\n",
      "[0.6696385, 0.2, 0.25978872, 0.20297322]\n",
      "[0.6117553, 0.2, 0.2018564, 0.20302682]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13470 iterations: 3.2691726326942443 mins\n",
      "Train Loss: [0.6117553, 0.2, 0.2018564, 0.20302682]\n",
      "[0.614604, 0.2, 0.2058225, 0.2019138]\n",
      "[0.6117705, 0.2, 0.2026452, 0.20226152]\n",
      "[0.6171761, 0.2, 0.20873666, 0.20157975]\n",
      "[0.6188311, 0.2, 0.20970657, 0.2022688]\n",
      "[0.6194209, 0.2, 0.21000738, 0.20256238]\n",
      "[0.6132038, 0.2, 0.20517607, 0.20118156]\n",
      "[0.6191855, 0.2, 0.21015286, 0.20219067]\n",
      "[0.6384468, 0.2, 0.20491715, 0.2266914]\n",
      "[0.61912775, 0.2, 0.20917548, 0.20311704]\n",
      "[0.6122271, 0.2, 0.20366539, 0.20172915]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13480 iterations: 3.271135699748993 mins\n",
      "Train Loss: [0.6122271, 0.2, 0.20366539, 0.20172915]\n",
      "[0.6155766, 0.2, 0.20726973, 0.20147729]\n",
      "[0.6150326, 0.2, 0.20558429, 0.20262155]\n",
      "[0.61082834, 0.2, 0.20176892, 0.2022351]\n",
      "[0.6261363, 0.2, 0.21746372, 0.20185116]\n",
      "[0.613187, 0.2, 0.20368193, 0.20268744]\n",
      "[0.62679255, 0.2, 0.20619513, 0.21378349]\n",
      "[0.61654603, 0.2, 0.20771292, 0.20202295]\n",
      "[0.61310965, 0.2, 0.20499969, 0.20130338]\n",
      "[0.6105189, 0.2, 0.20151721, 0.20219828]\n",
      "[0.62880135, 0.2, 0.20450528, 0.21749558]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13490 iterations: 3.2732259313265484 mins\n",
      "Train Loss: [0.62880135, 0.2, 0.20450528, 0.21749558]\n",
      "[0.6120882, 0.2, 0.20439266, 0.20089702]\n",
      "[0.6153983, 0.2, 0.20680904, 0.20179217]\n",
      "[0.61010796, 0.2, 0.20178658, 0.20152576]\n",
      "[0.6190037, 0.2, 0.2104583, 0.20175135]\n",
      "[0.6127804, 0.2, 0.2039701, 0.20201771]\n",
      "[0.61217815, 0.2, 0.20301555, 0.20237136]\n",
      "[0.61852825, 0.2, 0.20940052, 0.20233876]\n",
      "[0.61171836, 0.2, 0.2021438, 0.20278804]\n",
      "[0.62613046, 0.2, 0.21848264, 0.2008635]\n",
      "[0.6174186, 0.2, 0.20844279, 0.20219374]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13500 iterations: 3.2752181847890216 mins\n",
      "Train Loss: [0.6174186, 0.2, 0.20844279, 0.20219374]\n",
      "[0.6129303, 0.2, 0.20190129, 0.20424964]\n",
      "[0.6116201, 0.2, 0.203363, 0.2014811]\n",
      "[0.61959004, 0.2, 0.21126337, 0.20155391]\n",
      "[0.61642605, 0.2, 0.2064817, 0.20317481]\n",
      "[0.6115531, 0.2, 0.20200743, 0.20277949]\n",
      "[0.6179089, 0.2, 0.2092949, 0.20185202]\n",
      "[0.61246645, 0.2, 0.2043931, 0.20131539]\n",
      "[0.6119708, 0.2, 0.20418733, 0.20102955]\n",
      "[0.62147784, 0.2, 0.20826063, 0.20646696]\n",
      "[0.6145748, 0.2, 0.20408198, 0.2037462]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13510 iterations: 3.277234963575999 mins\n",
      "Train Loss: [0.6145748, 0.2, 0.20408198, 0.2037462]\n",
      "[0.61372244, 0.2, 0.204249, 0.20273037]\n",
      "[0.61347276, 0.2, 0.20562452, 0.20110863]\n",
      "[0.61359644, 0.2, 0.20395538, 0.20290506]\n",
      "[0.62665904, 0.2, 0.21833466, 0.20159182]\n",
      "[0.6176378, 0.2, 0.2086876, 0.20222387]\n",
      "[0.61954427, 0.2, 0.21081609, 0.20200786]\n",
      "[0.6285764, 0.2, 0.21969962, 0.20216201]\n",
      "[0.616994, 0.2, 0.2073784, 0.20290667]\n",
      "[0.6130417, 0.2, 0.20324121, 0.20309666]\n",
      "[0.6102814, 0.2, 0.2025686, 0.20101461]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13520 iterations: 3.279069932301839 mins\n",
      "Train Loss: [0.6102814, 0.2, 0.2025686, 0.20101461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63972634, 0.2, 0.2028058, 0.23022822]\n",
      "[0.6357177, 0.2, 0.22755472, 0.20147493]\n",
      "[0.6168162, 0.2, 0.20801648, 0.20211399]\n",
      "[0.61822325, 0.2, 0.21010087, 0.20143864]\n",
      "[0.62136006, 0.2, 0.2111791, 0.20349877]\n",
      "[0.6191637, 0.2, 0.2080975, 0.20438498]\n",
      "[0.6145067, 0.2, 0.20449774, 0.20332849]\n",
      "[0.61723024, 0.2, 0.20879504, 0.20175506]\n",
      "[0.61485374, 0.2, 0.20703878, 0.2011351]\n",
      "[0.67500407, 0.2, 0.24200395, 0.22632015]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13530 iterations: 3.2816320657730103 mins\n",
      "Train Loss: [0.67500407, 0.2, 0.24200395, 0.22632015]\n",
      "[0.61477655, 0.2, 0.20619184, 0.20190501]\n",
      "[0.6190626, 0.2, 0.21096207, 0.2014211]\n",
      "[0.61521083, 0.2, 0.20707366, 0.20145804]\n",
      "[0.6133192, 0.2, 0.20483565, 0.20180495]\n",
      "[0.6156146, 0.2, 0.20652373, 0.20241217]\n",
      "[0.6184014, 0.2, 0.21012153, 0.20160186]\n",
      "[0.61649144, 0.2, 0.20767142, 0.20214258]\n",
      "[0.611533, 0.2, 0.20284127, 0.20201504]\n",
      "[0.61179125, 0.2, 0.20267451, 0.20244081]\n",
      "[0.6140564, 0.2, 0.20455319, 0.20282815]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13540 iterations: 3.283715581893921 mins\n",
      "Train Loss: [0.6140564, 0.2, 0.20455319, 0.20282815]\n",
      "[0.6138395, 0.2, 0.20532258, 0.2018427]\n",
      "[0.6434033, 0.2, 0.21210684, 0.22462311]\n",
      "[0.6183463, 0.2, 0.20936422, 0.2023113]\n",
      "[0.61652935, 0.2, 0.20359935, 0.20626138]\n",
      "[0.61221343, 0.2, 0.20414245, 0.20140451]\n",
      "[0.61129135, 0.2, 0.20235628, 0.20227072]\n",
      "[0.6163991, 0.2, 0.20625664, 0.2034805]\n",
      "[0.623611, 0.2, 0.21412195, 0.20282859]\n",
      "[0.61506003, 0.2, 0.20517182, 0.20322768]\n",
      "[0.6105456, 0.2, 0.20251475, 0.2013707]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13550 iterations: 3.285612416267395 mins\n",
      "Train Loss: [0.6105456, 0.2, 0.20251475, 0.2013707]\n",
      "[0.6180838, 0.2, 0.21038501, 0.20103976]\n",
      "[0.61239487, 0.2, 0.20421223, 0.20152478]\n",
      "[0.6229379, 0.2, 0.21366686, 0.20261489]\n",
      "[0.6146389, 0.2, 0.20574577, 0.20223787]\n",
      "[0.6104906, 0.2, 0.2016274, 0.20220882]\n",
      "[0.61189365, 0.2, 0.20318416, 0.20205629]\n",
      "[0.6140323, 0.2, 0.20578729, 0.20159356]\n",
      "[0.64536625, 0.2, 0.21229671, 0.22641987]\n",
      "[0.62973386, 0.2, 0.22056597, 0.20252174]\n",
      "[0.63146245, 0.2, 0.20772792, 0.21709159]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13560 iterations: 3.2877384463946027 mins\n",
      "Train Loss: [0.63146245, 0.2, 0.20772792, 0.21709159]\n",
      "[0.6216534, 0.2, 0.21342406, 0.20158932]\n",
      "[0.61693096, 0.2, 0.20824507, 0.20204844]\n",
      "[0.61319906, 0.2, 0.20535302, 0.2012112]\n",
      "[0.6174436, 0.2, 0.20935652, 0.20145488]\n",
      "[0.6165928, 0.2, 0.20725551, 0.20270751]\n",
      "[0.61437994, 0.2, 0.20640013, 0.20135275]\n",
      "[0.6218525, 0.2, 0.21288094, 0.2023471]\n",
      "[0.6086852, 0.2, 0.20106998, 0.20099308]\n",
      "[0.6184059, 0.2, 0.20960109, 0.20218523]\n",
      "[0.6209209, 0.2, 0.21013427, 0.20417]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13570 iterations: 3.289688034852346 mins\n",
      "Train Loss: [0.6209209, 0.2, 0.21013427, 0.20417]\n",
      "[0.6210574, 0.2, 0.21201412, 0.20242998]\n",
      "[0.61327046, 0.2, 0.20378295, 0.20287554]\n",
      "[0.6200305, 0.2, 0.21078159, 0.2026382]\n",
      "[0.6147008, 0.2, 0.20520423, 0.2028871]\n",
      "[0.61389387, 0.2, 0.2059384, 0.20134744]\n",
      "[0.61531633, 0.2, 0.20668763, 0.20202182]\n",
      "[0.61440223, 0.2, 0.20588975, 0.20190705]\n",
      "[0.61113703, 0.2, 0.20297961, 0.20155406]\n",
      "[0.6197448, 0.2, 0.21073535, 0.20240822]\n",
      "[0.611692, 0.2, 0.20247743, 0.20261538]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13580 iterations: 3.2917556524276734 mins\n",
      "Train Loss: [0.611692, 0.2, 0.20247743, 0.20261538]\n",
      "[0.61714524, 0.2, 0.20770052, 0.2028478]\n",
      "[0.6200684, 0.2, 0.21118262, 0.20229135]\n",
      "[0.6145479, 0.2, 0.20605163, 0.20190503]\n",
      "[0.6099109, 0.2, 0.20112847, 0.2021941]\n",
      "[0.6103627, 0.2, 0.20206088, 0.20171647]\n",
      "[0.614128, 0.2, 0.20541218, 0.20213379]\n",
      "[0.61164886, 0.2, 0.20371477, 0.2013557]\n",
      "[0.61407214, 0.2, 0.2055449, 0.20195246]\n",
      "[0.6131857, 0.2, 0.20394348, 0.20267108]\n",
      "[0.61573297, 0.2, 0.20512229, 0.20404314]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13590 iterations: 3.293751533826192 mins\n",
      "Train Loss: [0.61573297, 0.2, 0.20512229, 0.20404314]\n",
      "[0.61387205, 0.2, 0.20593931, 0.2013685]\n",
      "[0.61923873, 0.2, 0.21130162, 0.20137626]\n",
      "[0.6169116, 0.2, 0.20800813, 0.20234583]\n",
      "[0.6623535, 0.2, 0.21109335, 0.24470557]\n",
      "[0.6151004, 0.2, 0.20654102, 0.2020087]\n",
      "[0.6164621, 0.2, 0.20836022, 0.20155361]\n",
      "[0.6125294, 0.2, 0.20476413, 0.20121796]\n",
      "[0.6128223, 0.2, 0.20434321, 0.20193224]\n",
      "[0.6112111, 0.2, 0.20247497, 0.20218958]\n",
      "[0.610532, 0.2, 0.20218045, 0.20180528]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13600 iterations: 3.295757532119751 mins\n",
      "Train Loss: [0.610532, 0.2, 0.20218045, 0.20180528]\n",
      "[0.62708616, 0.2, 0.21873252, 0.20180756]\n",
      "[0.62140685, 0.2, 0.21303347, 0.20182669]\n",
      "[0.615635, 0.2, 0.20254216, 0.20654461]\n",
      "[0.61331755, 0.2, 0.2050545, 0.20171162]\n",
      "[0.6161344, 0.2, 0.20715894, 0.20241813]\n",
      "[0.61323833, 0.2, 0.20564403, 0.20102905]\n",
      "[0.61360013, 0.2, 0.20505424, 0.20197175]\n",
      "[0.6138745, 0.2, 0.2041902, 0.20310073]\n",
      "[0.6132249, 0.2, 0.20417857, 0.20245339]\n",
      "[0.6173775, 0.2, 0.20789506, 0.20288049]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13610 iterations: 3.298575532436371 mins\n",
      "Train Loss: [0.6173775, 0.2, 0.20789506, 0.20288049]\n",
      "[0.61356384, 0.2, 0.2042361, 0.20271783]\n",
      "[0.6285246, 0.2, 0.2060294, 0.21587826]\n",
      "[0.6148923, 0.2, 0.20605655, 0.20221369]\n",
      "[0.61234754, 0.2, 0.20390922, 0.20181139]\n",
      "[0.6142476, 0.2, 0.20574822, 0.2018684]\n",
      "[0.6146194, 0.2, 0.20655029, 0.20143493]\n",
      "[0.6132804, 0.2, 0.2048336, 0.20181061]\n",
      "[0.6212984, 0.2, 0.21354988, 0.2011112]\n",
      "[0.6154341, 0.2, 0.20751444, 0.2012821]\n",
      "[0.6102471, 0.2, 0.20259096, 0.20101878]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13620 iterations: 3.3004778822263083 mins\n",
      "Train Loss: [0.6102471, 0.2, 0.20259096, 0.20101878]\n",
      "[0.60893047, 0.2, 0.20084763, 0.20144647]\n",
      "[0.6115738, 0.2, 0.2024742, 0.20246474]\n",
      "[0.61198884, 0.2, 0.20366405, 0.20169246]\n",
      "[0.61245346, 0.2, 0.20293474, 0.2028896]\n",
      "[0.6146191, 0.2, 0.20653442, 0.20145917]\n",
      "[0.61809355, 0.2, 0.20881632, 0.2026556]\n",
      "[0.6154636, 0.2, 0.20539108, 0.20345502]\n",
      "[0.6125955, 0.2, 0.20332286, 0.20265919]\n",
      "[0.61289775, 0.2, 0.20450199, 0.2017865]\n",
      "[0.6152689, 0.2, 0.20776302, 0.20090094]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13630 iterations: 3.302520434061686 mins\n",
      "Train Loss: [0.6152689, 0.2, 0.20776302, 0.20090094]\n",
      "[0.6134064, 0.2, 0.20564242, 0.2011636]\n",
      "[0.6178278, 0.2, 0.21015085, 0.20108154]\n",
      "[0.61581266, 0.2, 0.20673189, 0.20249052]\n",
      "[0.6122268, 0.2, 0.20407382, 0.20156774]\n",
      "[0.6134394, 0.2, 0.20525666, 0.20160282]\n",
      "[0.6143903, 0.2, 0.20654927, 0.20126648]\n",
      "[0.61285853, 0.2, 0.20477152, 0.20151785]\n",
      "[0.6142106, 0.2, 0.20542064, 0.2022262]\n",
      "[0.6268906, 0.2, 0.20539811, 0.21493445]\n",
      "[0.6112939, 0.2, 0.20234497, 0.20239703]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13640 iterations: 3.304401747385661 mins\n",
      "Train Loss: [0.6112939, 0.2, 0.20234497, 0.20239703]\n",
      "[0.61580217, 0.2, 0.20869003, 0.2005661]\n",
      "[0.61019397, 0.2, 0.20209347, 0.20156018]\n",
      "[0.61257464, 0.2, 0.20419239, 0.20184785]\n",
      "[0.6104697, 0.2, 0.2022075, 0.20173365]\n",
      "[0.6144354, 0.2, 0.2050658, 0.20284708]\n",
      "[0.6194907, 0.2, 0.20283921, 0.21013579]\n",
      "[0.6150395, 0.2, 0.20614807, 0.20238361]\n",
      "[0.61185, 0.2, 0.20374598, 0.20160478]\n",
      "[0.6122873, 0.2, 0.20456867, 0.20122725]\n",
      "[0.61411834, 0.2, 0.20448323, 0.20315127]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13650 iterations: 3.306513233979543 mins\n",
      "Train Loss: [0.61411834, 0.2, 0.20448323, 0.20315127]\n",
      "[0.61469674, 0.2, 0.20617995, 0.20204014]\n",
      "[0.61967224, 0.2, 0.2107104, 0.20249198]\n",
      "[0.6112231, 0.2, 0.2030813, 0.20167796]\n",
      "[0.61436194, 0.2, 0.20529021, 0.2026137]\n",
      "[0.61420226, 0.2, 0.20666781, 0.20108217]\n",
      "[0.61758834, 0.2, 0.20903921, 0.20210251]\n",
      "[0.6195588, 0.2, 0.21216938, 0.20094801]\n",
      "[0.62407404, 0.2, 0.21563701, 0.20200025]\n",
      "[0.6185467, 0.2, 0.2108525, 0.20126158]\n",
      "[0.61173815, 0.2, 0.20366181, 0.20164752]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13660 iterations: 3.3086726983388264 mins\n",
      "Train Loss: [0.61173815, 0.2, 0.20366181, 0.20164752]\n",
      "[0.611534, 0.2, 0.2038418, 0.20126691]\n",
      "[0.6252767, 0.2, 0.20351991, 0.21533458]\n",
      "[0.6196473, 0.2, 0.21137325, 0.20185494]\n",
      "[0.61758363, 0.2, 0.20924732, 0.20191944]\n",
      "[0.6134295, 0.2, 0.20552556, 0.20148905]\n",
      "[0.61522806, 0.2, 0.2067903, 0.20202501]\n",
      "[0.6113916, 0.2, 0.20361461, 0.20136678]\n",
      "[0.61471105, 0.2, 0.20706452, 0.20123905]\n",
      "[0.6177, 0.2, 0.20820445, 0.2030911]\n",
      "[0.61322695, 0.2, 0.20553575, 0.20128979]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13670 iterations: 3.3113553126653037 mins\n",
      "Train Loss: [0.61322695, 0.2, 0.20553575, 0.20128979]\n",
      "[0.6251051, 0.2, 0.21622558, 0.20248087]\n",
      "[0.6241273, 0.2, 0.21486786, 0.20286378]\n",
      "[0.6171126, 0.2, 0.20831549, 0.20240436]\n",
      "[0.61524934, 0.2, 0.20731376, 0.20154575]\n",
      "[0.62084275, 0.2, 0.21198186, 0.20247382]\n",
      "[0.6108783, 0.2, 0.20351973, 0.20097412]\n",
      "[0.61064786, 0.2, 0.202119, 0.20214726]\n",
      "[0.61198944, 0.2, 0.20387954, 0.20173189]\n",
      "[0.6105009, 0.2, 0.20315313, 0.20097364]\n",
      "[0.612671, 0.2, 0.20497255, 0.20132841]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13680 iterations: 3.3139456152915954 mins\n",
      "Train Loss: [0.612671, 0.2, 0.20497255, 0.20132841]\n",
      "[0.6151693, 0.2, 0.2066778, 0.20212524]\n",
      "[0.6199204, 0.2, 0.21170492, 0.20185283]\n",
      "[0.6159913, 0.2, 0.20867744, 0.20095478]\n",
      "[0.6188689, 0.2, 0.21021134, 0.20230187]\n",
      "[0.61205876, 0.2, 0.20485725, 0.2008495]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61736935, 0.2, 0.20891152, 0.20210904]\n",
      "[0.61685795, 0.2, 0.20802616, 0.20248616]\n",
      "[0.60863096, 0.2, 0.2016019, 0.20068663]\n",
      "[0.60977983, 0.2, 0.20173788, 0.20170279]\n",
      "[0.6135913, 0.2, 0.20512441, 0.20213081]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13690 iterations: 3.31599839925766 mins\n",
      "Train Loss: [0.6135913, 0.2, 0.20512441, 0.20213081]\n",
      "[0.6229025, 0.2, 0.20749734, 0.20907222]\n",
      "[0.6189788, 0.2, 0.21147794, 0.20117116]\n",
      "[0.6319865, 0.2, 0.20257628, 0.22308381]\n",
      "[0.62509406, 0.2, 0.2148825, 0.20388883]\n",
      "[0.61212254, 0.2, 0.20438461, 0.20141816]\n",
      "[0.624858, 0.2, 0.20590863, 0.21263209]\n",
      "[0.6448253, 0.2, 0.21241844, 0.22609288]\n",
      "[0.61832845, 0.2, 0.21029212, 0.20172262]\n",
      "[0.61410564, 0.2, 0.20594311, 0.20184863]\n",
      "[0.61001873, 0.2, 0.2013609, 0.20234324]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13700 iterations: 3.317982864379883 mins\n",
      "Train Loss: [0.61001873, 0.2, 0.2013609, 0.20234324]\n",
      "[0.6094309, 0.2, 0.20205058, 0.20106503]\n",
      "[0.61862266, 0.2, 0.21067823, 0.20162848]\n",
      "[0.632688, 0.2, 0.21001874, 0.21635267]\n",
      "[0.61349994, 0.2, 0.20424104, 0.20294221]\n",
      "[0.61533695, 0.2, 0.20804648, 0.2009739]\n",
      "[0.61274385, 0.2, 0.20473768, 0.20168917]\n",
      "[0.6150251, 0.2, 0.20684917, 0.2018588]\n",
      "[0.6104435, 0.2, 0.20251755, 0.20160875]\n",
      "[0.62101865, 0.2, 0.21107593, 0.20362611]\n",
      "[0.61691105, 0.2, 0.20845863, 0.20213544]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13710 iterations: 3.3200296481450398 mins\n",
      "Train Loss: [0.61691105, 0.2, 0.20845863, 0.20213544]\n",
      "[0.61551225, 0.2, 0.2065171, 0.20267801]\n",
      "[0.6128899, 0.2, 0.20450164, 0.2020712]\n",
      "[0.61469805, 0.2, 0.20711793, 0.20126358]\n",
      "[0.6150836, 0.2, 0.20619209, 0.20257565]\n",
      "[0.6160536, 0.2, 0.20621058, 0.20352857]\n",
      "[0.6120668, 0.2, 0.20397645, 0.20177723]\n",
      "[0.6128208, 0.2, 0.20432302, 0.20218574]\n",
      "[0.6233928, 0.2, 0.21353061, 0.2035512]\n",
      "[0.6471553, 0.2, 0.20450167, 0.23634404]\n",
      "[0.6160185, 0.2, 0.206468, 0.20324263]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13720 iterations: 3.3219347834587096 mins\n",
      "Train Loss: [0.6160185, 0.2, 0.206468, 0.20324263]\n",
      "[0.6155404, 0.2, 0.20800747, 0.20122696]\n",
      "[0.62974286, 0.2, 0.2217282, 0.20171101]\n",
      "[0.61440605, 0.2, 0.20645224, 0.20165047]\n",
      "[0.6147979, 0.2, 0.20610856, 0.20238668]\n",
      "[0.615463, 0.2, 0.2072173, 0.20194407]\n",
      "[0.6097247, 0.2, 0.20200673, 0.20141748]\n",
      "[0.6107298, 0.2, 0.2029826, 0.20144796]\n",
      "[0.6154685, 0.2, 0.20732392, 0.2018468]\n",
      "[0.61208344, 0.2, 0.20453359, 0.20125385]\n",
      "[0.62049884, 0.2, 0.21294966, 0.20125514]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13730 iterations: 3.323839016755422 mins\n",
      "Train Loss: [0.62049884, 0.2, 0.21294966, 0.20125514]\n",
      "[0.61446184, 0.2, 0.20710617, 0.20106404]\n",
      "[0.61501026, 0.2, 0.20594008, 0.20278166]\n",
      "[0.6104011, 0.2, 0.20266831, 0.20144828]\n",
      "[0.61375284, 0.2, 0.20611486, 0.2013574]\n",
      "[0.6146076, 0.2, 0.20677447, 0.20155662]\n",
      "[0.6181235, 0.2, 0.20895508, 0.20289637]\n",
      "[0.61779165, 0.2, 0.20876613, 0.20275801]\n",
      "[0.6657353, 0.2, 0.21014376, 0.24932815]\n",
      "[0.61399525, 0.2, 0.20707865, 0.20065606]\n",
      "[0.6124788, 0.2, 0.20513298, 0.20108797]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13740 iterations: 3.3259468992551167 mins\n",
      "Train Loss: [0.6124788, 0.2, 0.20513298, 0.20108797]\n",
      "[0.6098128, 0.2, 0.20199993, 0.20155776]\n",
      "[0.6156129, 0.2, 0.20738542, 0.20197526]\n",
      "[0.60901403, 0.2, 0.20155217, 0.20121235]\n",
      "[0.6199355, 0.2, 0.21234997, 0.20133868]\n",
      "[0.6095895, 0.2, 0.20170699, 0.20163865]\n",
      "[0.6137408, 0.2, 0.20580755, 0.20169255]\n",
      "[0.6164717, 0.2, 0.20892659, 0.20130745]\n",
      "[0.6126748, 0.2, 0.2053277, 0.20111263]\n",
      "[0.61178255, 0.2, 0.20424852, 0.2013031]\n",
      "[0.6131332, 0.2, 0.20398186, 0.20292397]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13750 iterations: 3.32786461909612 mins\n",
      "Train Loss: [0.6131332, 0.2, 0.20398186, 0.20292397]\n",
      "[0.6146347, 0.2, 0.20640126, 0.20200996]\n",
      "[0.61302644, 0.2, 0.2043857, 0.20242111]\n",
      "[0.6345962, 0.2, 0.20856008, 0.2198207]\n",
      "[0.6273596, 0.2, 0.20811005, 0.21303675]\n",
      "[0.6164158, 0.2, 0.20873065, 0.20147482]\n",
      "[0.61354476, 0.2, 0.20510264, 0.20223348]\n",
      "[0.62780905, 0.2, 0.2010421, 0.22056006]\n",
      "[0.61322737, 0.2, 0.20497802, 0.20204304]\n",
      "[0.609514, 0.2, 0.2017468, 0.20156169]\n",
      "[0.6088158, 0.2, 0.20082015, 0.20179082]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13760 iterations: 3.3299826979637146 mins\n",
      "Train Loss: [0.6088158, 0.2, 0.20082015, 0.20179082]\n",
      "[0.61711794, 0.2, 0.20805298, 0.20286123]\n",
      "[0.61361027, 0.2, 0.2054431, 0.20196436]\n",
      "[0.6198126, 0.2, 0.21141723, 0.20219375]\n",
      "[0.6163046, 0.2, 0.20745738, 0.2026476]\n",
      "[0.6179963, 0.2, 0.2107914, 0.20100738]\n",
      "[0.61666477, 0.2, 0.20753148, 0.20293775]\n",
      "[0.6170614, 0.2, 0.2086717, 0.20219624]\n",
      "[0.61203164, 0.2, 0.20253412, 0.20330639]\n",
      "[0.61152107, 0.2, 0.20376891, 0.20156352]\n",
      "[0.61084867, 0.2, 0.20204347, 0.20261896]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13770 iterations: 3.3323903640111285 mins\n",
      "Train Loss: [0.61084867, 0.2, 0.20204347, 0.20261896]\n",
      "[0.6086918, 0.2, 0.2012342, 0.20127405]\n",
      "[0.62758523, 0.2, 0.20471777, 0.2166865]\n",
      "[0.62037313, 0.2, 0.213372, 0.20082337]\n",
      "[0.6157637, 0.2, 0.20850433, 0.20108528]\n",
      "[0.61626506, 0.2, 0.20661263, 0.2034814]\n",
      "[0.61760974, 0.2, 0.20987847, 0.20156327]\n",
      "[0.6174972, 0.2, 0.20949037, 0.20184156]\n",
      "[0.6234953, 0.2, 0.21546373, 0.20186853]\n",
      "[0.61371773, 0.2, 0.2058971, 0.20165963]\n",
      "[0.61721826, 0.2, 0.20894095, 0.20211811]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13780 iterations: 3.3344816327095033 mins\n",
      "Train Loss: [0.61721826, 0.2, 0.20894095, 0.20211811]\n",
      "[0.610115, 0.2, 0.20165642, 0.20230123]\n",
      "[0.6109593, 0.2, 0.20289557, 0.20190936]\n",
      "[0.6131101, 0.2, 0.20391794, 0.203041]\n",
      "[0.62122077, 0.2, 0.21250413, 0.20256853]\n",
      "[0.6099678, 0.2, 0.20150176, 0.20231831]\n",
      "[0.61881065, 0.2, 0.2099755, 0.20268792]\n",
      "[0.6187914, 0.2, 0.21103741, 0.20160674]\n",
      "[0.6125158, 0.2, 0.20512049, 0.20124796]\n",
      "[0.6106702, 0.2, 0.20312886, 0.20139408]\n",
      "[0.6129873, 0.2, 0.20534895, 0.20149124]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13790 iterations: 3.336505881945292 mins\n",
      "Train Loss: [0.6129873, 0.2, 0.20534895, 0.20149124]\n",
      "[0.6145055, 0.2, 0.20566152, 0.20269708]\n",
      "[0.6168135, 0.2, 0.20797361, 0.20269312]\n",
      "[0.6126793, 0.2, 0.20526196, 0.20127065]\n",
      "[0.6122252, 0.2, 0.20426366, 0.20181502]\n",
      "[0.6357358, 0.2, 0.20509118, 0.22449851]\n",
      "[0.61277795, 0.2, 0.20393325, 0.20269957]\n",
      "[0.6108761, 0.2, 0.20289254, 0.20183946]\n",
      "[0.6109171, 0.2, 0.20354524, 0.20122895]\n",
      "[0.61325985, 0.2, 0.20527115, 0.2018471]\n",
      "[0.610532, 0.2, 0.20328984, 0.20110193]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13800 iterations: 3.3384485165278117 mins\n",
      "Train Loss: [0.610532, 0.2, 0.20328984, 0.20110193]\n",
      "[0.619212, 0.2, 0.21149944, 0.20157388]\n",
      "[0.6097951, 0.2, 0.20281135, 0.20084651]\n",
      "[0.6118756, 0.2, 0.20365311, 0.20208661]\n",
      "[0.61044383, 0.2, 0.20172516, 0.20258445]\n",
      "[0.61321545, 0.2, 0.20627287, 0.20081018]\n",
      "[0.6115467, 0.2, 0.20288093, 0.20253512]\n",
      "[0.6152354, 0.2, 0.20836328, 0.20074344]\n",
      "[0.6111647, 0.2, 0.20416304, 0.20087485]\n",
      "[0.61140287, 0.2, 0.20322871, 0.20204948]\n",
      "[0.6136234, 0.2, 0.20363306, 0.20386824]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13810 iterations: 3.340484631061554 mins\n",
      "Train Loss: [0.6136234, 0.2, 0.20363306, 0.20386824]\n",
      "[0.62998754, 0.2, 0.20611016, 0.21775824]\n",
      "[0.61847246, 0.2, 0.20872992, 0.20362547]\n",
      "[0.6155315, 0.2, 0.20839663, 0.20101902]\n",
      "[0.6128022, 0.2, 0.20399505, 0.20269233]\n",
      "[0.6189284, 0.2, 0.21168937, 0.2011252]\n",
      "[0.6145041, 0.2, 0.20564036, 0.20275116]\n",
      "[0.6139507, 0.2, 0.20634873, 0.20149079]\n",
      "[0.6171567, 0.2, 0.20847122, 0.20257579]\n",
      "[0.61163294, 0.2, 0.20381054, 0.2017144]\n",
      "[0.6545416, 0.2, 0.21260862, 0.23582697]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13820 iterations: 3.342447201410929 mins\n",
      "Train Loss: [0.6545416, 0.2, 0.21260862, 0.23582697]\n",
      "[0.6123336, 0.2, 0.20300326, 0.2032289]\n",
      "[0.6125502, 0.2, 0.20442954, 0.20202346]\n",
      "[0.6127383, 0.2, 0.20394969, 0.20269585]\n",
      "[0.6223921, 0.2, 0.20417464, 0.2121291]\n",
      "[0.6167, 0.2, 0.20679481, 0.20381972]\n",
      "[0.6323464, 0.2, 0.20784847, 0.21841489]\n",
      "[0.6114789, 0.2, 0.20377879, 0.20161861]\n",
      "[0.6158025, 0.2, 0.20832297, 0.20139888]\n",
      "[0.61294836, 0.2, 0.20511825, 0.20175046]\n",
      "[0.6128603, 0.2, 0.2055843, 0.20119712]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13830 iterations: 3.3445438504219056 mins\n",
      "Train Loss: [0.6128603, 0.2, 0.2055843, 0.20119712]\n",
      "[0.6140761, 0.2, 0.20534989, 0.2026478]\n",
      "[0.61240077, 0.2, 0.20492992, 0.20139323]\n",
      "[0.61921257, 0.2, 0.21243171, 0.20070368]\n",
      "[0.6127961, 0.2, 0.20474157, 0.20197813]\n",
      "[0.6159883, 0.2, 0.20831355, 0.2015996]\n",
      "[0.64572424, 0.2, 0.21180776, 0.22784278]\n",
      "[0.63071746, 0.2, 0.2237228, 0.20092432]\n",
      "[0.6139468, 0.2, 0.20579089, 0.20209067]\n",
      "[0.62782717, 0.2, 0.22001487, 0.20175156]\n",
      "[0.61358577, 0.2, 0.20500319, 0.20252606]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13840 iterations: 3.3464088638623557 mins\n",
      "Train Loss: [0.61358577, 0.2, 0.20500319, 0.20252606]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6151391, 0.2, 0.20337698, 0.20570967]\n",
      "[0.60924846, 0.2, 0.20104979, 0.20215017]\n",
      "[0.61672735, 0.2, 0.20934539, 0.20133717]\n",
      "[0.6189479, 0.2, 0.21211952, 0.20078719]\n",
      "[0.62264824, 0.2, 0.21406354, 0.20254692]\n",
      "[0.6134873, 0.2, 0.2059197, 0.20153306]\n",
      "[0.6127278, 0.2, 0.20514072, 0.2015554]\n",
      "[0.61401045, 0.2, 0.20648189, 0.2014994]\n",
      "[0.61390126, 0.2, 0.2063784, 0.2014956]\n",
      "[0.61413074, 0.2, 0.20587263, 0.20223223]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13850 iterations: 3.349140763282776 mins\n",
      "Train Loss: [0.61413074, 0.2, 0.20587263, 0.20223223]\n",
      "[0.613009, 0.2, 0.20538126, 0.20160326]\n",
      "[0.61276424, 0.2, 0.20561768, 0.20112339]\n",
      "[0.6144361, 0.2, 0.20660846, 0.20180574]\n",
      "[0.61769944, 0.2, 0.2090922, 0.20258617]\n",
      "[0.61439943, 0.2, 0.20587668, 0.2025023]\n",
      "[0.61158645, 0.2, 0.20315488, 0.20241198]\n",
      "[0.6107315, 0.2, 0.20377535, 0.20093758]\n",
      "[0.6254844, 0.2, 0.20554526, 0.21392179]\n",
      "[0.61641574, 0.2, 0.2085741, 0.20182332]\n",
      "[0.6103573, 0.2, 0.20212193, 0.20221618]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13860 iterations: 3.35123366912206 mins\n",
      "Train Loss: [0.6103573, 0.2, 0.20212193, 0.20221618]\n",
      "[0.616965, 0.2, 0.20917939, 0.20176545]\n",
      "[0.6187439, 0.2, 0.21193193, 0.20079087]\n",
      "[0.61395645, 0.2, 0.20478289, 0.20315151]\n",
      "[0.6121528, 0.2, 0.20397498, 0.20215493]\n",
      "[0.64972246, 0.2, 0.20603253, 0.2376663]\n",
      "[0.62703216, 0.2, 0.2197037, 0.20130697]\n",
      "[0.6089604, 0.2, 0.20203684, 0.20090458]\n",
      "[0.6138264, 0.2, 0.20489186, 0.20291822]\n",
      "[0.61395115, 0.2, 0.2055302, 0.2024054]\n",
      "[0.6279715, 0.2, 0.22004186, 0.2019111]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13870 iterations: 3.353174897034963 mins\n",
      "Train Loss: [0.6279715, 0.2, 0.22004186, 0.2019111]\n",
      "[0.6163159, 0.2, 0.20944737, 0.20084107]\n",
      "[0.6095411, 0.2, 0.20165485, 0.20184815]\n",
      "[0.6091857, 0.2, 0.2012276, 0.20190874]\n",
      "[0.6119668, 0.2, 0.2046592, 0.20124678]\n",
      "[0.6188531, 0.2, 0.21190244, 0.20087887]\n",
      "[0.6120564, 0.2, 0.20495895, 0.20101413]\n",
      "[0.61320245, 0.2, 0.20545156, 0.20165692]\n",
      "[0.6198313, 0.2, 0.21242337, 0.20130421]\n",
      "[0.61021745, 0.2, 0.20234711, 0.20175803]\n",
      "[0.6257956, 0.2, 0.20659447, 0.21308103]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13880 iterations: 3.3552587151527407 mins\n",
      "Train Loss: [0.6257956, 0.2, 0.20659447, 0.21308103]\n",
      "[0.609502, 0.2, 0.20204508, 0.20132935]\n",
      "[0.6105048, 0.2, 0.20295833, 0.20141256]\n",
      "[0.6149281, 0.2, 0.20672542, 0.20206356]\n",
      "[0.613823, 0.2, 0.20545338, 0.2022262]\n",
      "[0.61269945, 0.2, 0.20488752, 0.20166534]\n",
      "[0.6160384, 0.2, 0.20867687, 0.20121296]\n",
      "[0.61302245, 0.2, 0.20523511, 0.2016368]\n",
      "[0.632417, 0.2, 0.22423181, 0.20203406]\n",
      "[0.6136752, 0.2, 0.20600732, 0.20151547]\n",
      "[0.6106354, 0.2, 0.2029764, 0.201506]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13890 iterations: 3.3571722825368244 mins\n",
      "Train Loss: [0.6106354, 0.2, 0.2029764, 0.201506]\n",
      "[0.6144894, 0.2, 0.20529082, 0.2030454]\n",
      "[0.62797976, 0.2, 0.22042501, 0.2014018]\n",
      "[0.6440304, 0.2, 0.23614892, 0.20172656]\n",
      "[0.60800654, 0.2, 0.20104738, 0.2008033]\n",
      "[0.61663836, 0.2, 0.2096015, 0.2008802]\n",
      "[0.6161585, 0.2, 0.20839396, 0.20160805]\n",
      "[0.61296535, 0.2, 0.20551783, 0.20129181]\n",
      "[0.61011183, 0.2, 0.20273823, 0.20121908]\n",
      "[0.61535615, 0.2, 0.20655769, 0.20264547]\n",
      "[0.6128713, 0.2, 0.20603693, 0.20068336]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13900 iterations: 3.3592182993888855 mins\n",
      "Train Loss: [0.6128713, 0.2, 0.20603693, 0.20068336]\n",
      "[0.61884755, 0.2, 0.21150656, 0.2011925]\n",
      "[0.6274692, 0.2, 0.22036494, 0.20095864]\n",
      "[0.6111967, 0.2, 0.2031142, 0.20193975]\n",
      "[0.60986435, 0.2, 0.20171008, 0.20201495]\n",
      "[0.6145483, 0.2, 0.2055497, 0.20286308]\n",
      "[0.6097407, 0.2, 0.20262651, 0.2009824]\n",
      "[0.61319214, 0.2, 0.2045694, 0.2024951]\n",
      "[0.66438186, 0.2, 0.25658202, 0.20167676]\n",
      "[0.6131134, 0.2, 0.20588274, 0.20111409]\n",
      "[0.61257446, 0.2, 0.20485507, 0.20160934]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13910 iterations: 3.3610710461934405 mins\n",
      "Train Loss: [0.61257446, 0.2, 0.20485507, 0.20160934]\n",
      "[0.61479336, 0.2, 0.20634742, 0.20234235]\n",
      "[0.614728, 0.2, 0.20694669, 0.20168415]\n",
      "[0.6107987, 0.2, 0.2037033, 0.20100509]\n",
      "[0.61251444, 0.2, 0.2042534, 0.20217745]\n",
      "[0.61686754, 0.2, 0.20936723, 0.20142332]\n",
      "[0.61589354, 0.2, 0.20812362, 0.20169927]\n",
      "[0.6133055, 0.2, 0.20466015, 0.20258045]\n",
      "[0.6137627, 0.2, 0.20588084, 0.20182261]\n",
      "[0.61460006, 0.2, 0.20643719, 0.20210904]\n",
      "[0.6152513, 0.2, 0.20793924, 0.20126323]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13920 iterations: 3.3630611817042033 mins\n",
      "Train Loss: [0.6152513, 0.2, 0.20793924, 0.20126323]\n",
      "[0.615721, 0.2, 0.20730607, 0.20237058]\n",
      "[0.6084275, 0.2, 0.20007156, 0.20231584]\n",
      "[0.61591816, 0.2, 0.20701404, 0.20286845]\n",
      "[0.60981256, 0.2, 0.2028143, 0.20096658]\n",
      "[0.61600375, 0.2, 0.20901044, 0.20096575]\n",
      "[0.61658716, 0.2, 0.20821492, 0.20234852]\n",
      "[0.61703146, 0.2, 0.20603639, 0.20497492]\n",
      "[0.61683166, 0.2, 0.20963202, 0.20118454]\n",
      "[0.6120471, 0.2, 0.20360638, 0.2024299]\n",
      "[0.6085514, 0.2, 0.20183988, 0.20070507]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13930 iterations: 3.3659478664398192 mins\n",
      "Train Loss: [0.6085514, 0.2, 0.20183988, 0.20070507]\n",
      "[0.6159153, 0.2, 0.20875198, 0.2011611]\n",
      "[0.6218227, 0.2, 0.21406245, 0.20176181]\n",
      "[0.61246306, 0.2, 0.20531464, 0.20115341]\n",
      "[0.6118234, 0.2, 0.20430008, 0.20153207]\n",
      "[0.6085295, 0.2, 0.2012088, 0.20133312]\n",
      "[0.612005, 0.2, 0.20354351, 0.2024778]\n",
      "[0.61387783, 0.2, 0.20699088, 0.20090836]\n",
      "[0.6144612, 0.2, 0.20652325, 0.20196404]\n",
      "[0.62943536, 0.2, 0.22156845, 0.2018974]\n",
      "[0.60998285, 0.2, 0.2025299, 0.20148924]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13940 iterations: 3.367868916193644 mins\n",
      "Train Loss: [0.60998285, 0.2, 0.2025299, 0.20148924]\n",
      "[0.61463785, 0.2, 0.20793743, 0.20074224]\n",
      "[0.62097913, 0.2, 0.20312515, 0.21190108]\n",
      "[0.6199226, 0.2, 0.21312407, 0.20085008]\n",
      "[0.6174648, 0.2, 0.20996732, 0.201553]\n",
      "[0.6099882, 0.2, 0.20220262, 0.20184478]\n",
      "[0.60975546, 0.2, 0.20239668, 0.20142129]\n",
      "[0.61326265, 0.2, 0.2062216, 0.20110708]\n",
      "[0.6172408, 0.2, 0.20951705, 0.20179302]\n",
      "[0.62107766, 0.2, 0.21339497, 0.20175503]\n",
      "[0.61453664, 0.2, 0.20711769, 0.2014945]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13950 iterations: 3.3698928316434222 mins\n",
      "Train Loss: [0.61453664, 0.2, 0.20711769, 0.2014945]\n",
      "[0.6138308, 0.2, 0.20677203, 0.20113736]\n",
      "[0.6086772, 0.2, 0.20203641, 0.20072265]\n",
      "[0.61778563, 0.2, 0.20872027, 0.20315057]\n",
      "[0.6269206, 0.2, 0.21808447, 0.20292476]\n",
      "[0.6182012, 0.2, 0.21074738, 0.20154606]\n",
      "[0.60933346, 0.2, 0.20181638, 0.20161302]\n",
      "[0.6117805, 0.2, 0.20440273, 0.20147742]\n",
      "[0.6207463, 0.2, 0.2129815, 0.20186828]\n",
      "[0.61648035, 0.2, 0.20932022, 0.20126781]\n",
      "[0.61501306, 0.2, 0.20561789, 0.20350684]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13960 iterations: 3.3718564828236897 mins\n",
      "Train Loss: [0.61501306, 0.2, 0.20561789, 0.20350684]\n",
      "[0.62259346, 0.2, 0.21273117, 0.2039778]\n",
      "[0.61684453, 0.2, 0.20722494, 0.20373866]\n",
      "[0.6303876, 0.2, 0.22084513, 0.2036648]\n",
      "[0.6139407, 0.2, 0.20712075, 0.20094506]\n",
      "[0.61004674, 0.2, 0.20324227, 0.2009321]\n",
      "[0.6122443, 0.2, 0.20467593, 0.2016982]\n",
      "[0.6108184, 0.2, 0.20325083, 0.20169929]\n",
      "[0.6353276, 0.2, 0.20900199, 0.22045922]\n",
      "[0.61068195, 0.2, 0.20350285, 0.20131435]\n",
      "[0.6234416, 0.2, 0.20428865, 0.2132898]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13970 iterations: 3.373790248235067 mins\n",
      "Train Loss: [0.6234416, 0.2, 0.20428865, 0.2132898]\n",
      "[0.61005753, 0.2, 0.20338197, 0.20081489]\n",
      "[0.6193335, 0.2, 0.21196058, 0.20151447]\n",
      "[0.61786664, 0.2, 0.20973587, 0.20227452]\n",
      "[0.61386824, 0.2, 0.2059965, 0.2020168]\n",
      "[0.6131092, 0.2, 0.20523998, 0.20201562]\n",
      "[0.614024, 0.2, 0.20718926, 0.20098265]\n",
      "[0.6110247, 0.2, 0.20346116, 0.2017129]\n",
      "[0.61299545, 0.2, 0.2052593, 0.20188728]\n",
      "[0.63244885, 0.2, 0.21104348, 0.21555829]\n",
      "[0.61522174, 0.2, 0.20735073, 0.2020247]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13980 iterations: 3.375865999857585 mins\n",
      "Train Loss: [0.61522174, 0.2, 0.20735073, 0.2020247]\n",
      "[0.61997825, 0.2, 0.21277104, 0.20136146]\n",
      "[0.61669123, 0.2, 0.20815639, 0.20268947]\n",
      "[0.6142509, 0.2, 0.20631081, 0.20209518]\n",
      "[0.6118453, 0.2, 0.2040729, 0.20192806]\n",
      "[0.61245114, 0.2, 0.20494395, 0.20166364]\n",
      "[0.6150587, 0.2, 0.20811526, 0.20110093]\n",
      "[0.61050427, 0.2, 0.2033888, 0.20127428]\n",
      "[0.6241457, 0.2, 0.21611507, 0.20219113]\n",
      "[0.6129906, 0.2, 0.20477681, 0.20237659]\n",
      "[0.61611754, 0.2, 0.20644537, 0.2038373]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13990 iterations: 3.3777924180030823 mins\n",
      "Train Loss: [0.61611754, 0.2, 0.20644537, 0.2038373]\n",
      "[0.61214674, 0.2, 0.20503584, 0.20127815]\n",
      "[0.6135521, 0.2, 0.20682174, 0.20090011]\n",
      "[0.6110489, 0.2, 0.20437016, 0.20085111]\n",
      "[0.6106746, 0.2, 0.20339952, 0.20145029]\n",
      "[0.6093115, 0.2, 0.20285252, 0.20063685]\n",
      "[0.61176014, 0.2, 0.20444603, 0.20149481]\n",
      "[0.61456597, 0.2, 0.20661463, 0.20213462]\n",
      "[0.62014335, 0.2, 0.21277434, 0.20155506]\n",
      "[0.61798847, 0.2, 0.20983627, 0.20234019]\n",
      "[0.60922074, 0.2, 0.20214006, 0.2012704]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14000 iterations: 3.379835816224416 mins\n",
      "Train Loss: [0.60922074, 0.2, 0.20214006, 0.2012704]\n",
      "[0.62904793, 0.2, 0.20340383, 0.21983714]\n",
      "[0.6095097, 0.2, 0.20202528, 0.20167978]\n",
      "[0.6110124, 0.2, 0.203874, 0.20133582]\n",
      "[0.6116807, 0.2, 0.20533322, 0.2005468]\n",
      "[0.61221766, 0.2, 0.20537831, 0.20104045]\n",
      "[0.609539, 0.2, 0.20241778, 0.20132373]\n",
      "[0.61150455, 0.2, 0.20343365, 0.20227498]\n",
      "[0.61433643, 0.2, 0.20788744, 0.20065436]\n",
      "[0.61138684, 0.2, 0.20422918, 0.20136435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6133838, 0.2, 0.2068853, 0.20070632]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14010 iterations: 3.3822063326835634 mins\n",
      "Train Loss: [0.6133838, 0.2, 0.2068853, 0.20070632]\n",
      "[0.6294929, 0.2, 0.21058297, 0.21311921]\n",
      "[0.61412597, 0.2, 0.20590444, 0.20243184]\n",
      "[0.6086367, 0.2, 0.20115355, 0.201694]\n",
      "[0.61113816, 0.2, 0.20410538, 0.20124434]\n",
      "[0.6135241, 0.2, 0.20637727, 0.20135921]\n",
      "[0.61163193, 0.2, 0.20464604, 0.20119934]\n",
      "[0.6127769, 0.2, 0.20578082, 0.20121051]\n",
      "[0.60959554, 0.2, 0.20129189, 0.20251893]\n",
      "[0.61800104, 0.2, 0.20858234, 0.20363498]\n",
      "[0.62105495, 0.2, 0.2136475, 0.20162475]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14020 iterations: 3.3842477480570476 mins\n",
      "Train Loss: [0.62105495, 0.2, 0.2136475, 0.20162475]\n",
      "[0.61012864, 0.2, 0.203579, 0.2007681]\n",
      "[0.61913484, 0.2, 0.21231331, 0.20104134]\n",
      "[0.6142171, 0.2, 0.20724194, 0.20119645]\n",
      "[0.6134005, 0.2, 0.20670184, 0.20092136]\n",
      "[0.61618185, 0.2, 0.20946115, 0.20094517]\n",
      "[0.6130843, 0.2, 0.20489368, 0.20241776]\n",
      "[0.6113729, 0.2, 0.20285438, 0.20274854]\n",
      "[0.6166835, 0.2, 0.20741175, 0.20350437]\n",
      "[0.6127603, 0.2, 0.20458786, 0.20240839]\n",
      "[0.61254084, 0.2, 0.20563646, 0.20114343]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14030 iterations: 3.3862854798634845 mins\n",
      "Train Loss: [0.61254084, 0.2, 0.20563646, 0.20114343]\n",
      "[0.6230601, 0.2, 0.21619855, 0.20110318]\n",
      "[0.63821363, 0.2, 0.20654066, 0.22591527]\n",
      "[0.6209977, 0.2, 0.21405466, 0.20118614]\n",
      "[0.61278605, 0.2, 0.20411631, 0.20291385]\n",
      "[0.6202277, 0.2, 0.21178044, 0.2026922]\n",
      "[0.6152832, 0.2, 0.20775312, 0.20177563]\n",
      "[0.6166281, 0.2, 0.20894764, 0.20192607]\n",
      "[0.6098655, 0.2, 0.2022541, 0.20185679]\n",
      "[0.617039, 0.2, 0.20820598, 0.20307826]\n",
      "[0.6129226, 0.2, 0.20553806, 0.20162928]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14040 iterations: 3.3881645361582438 mins\n",
      "Train Loss: [0.6129226, 0.2, 0.20553806, 0.20162928]\n",
      "[0.61356145, 0.2, 0.20668586, 0.20112029]\n",
      "[0.62519366, 0.2, 0.203165, 0.21627352]\n",
      "[0.6162132, 0.2, 0.20940241, 0.20105727]\n",
      "[0.6146537, 0.2, 0.20811291, 0.20078874]\n",
      "[0.61137635, 0.2, 0.20398727, 0.20163782]\n",
      "[0.6134111, 0.2, 0.20706484, 0.20059559]\n",
      "[0.6122741, 0.2, 0.20531154, 0.20121233]\n",
      "[0.6127364, 0.2, 0.20581219, 0.20117417]\n",
      "[0.63770366, 0.2, 0.23028807, 0.20166583]\n",
      "[0.6114117, 0.2, 0.20446542, 0.20119761]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14050 iterations: 3.390266466140747 mins\n",
      "Train Loss: [0.6114117, 0.2, 0.20446542, 0.20119761]\n",
      "[0.61412466, 0.2, 0.20476615, 0.20361078]\n",
      "[0.6080041, 0.2, 0.20131332, 0.20094243]\n",
      "[0.620136, 0.2, 0.21071684, 0.20366782]\n",
      "[0.6184117, 0.2, 0.21099837, 0.20165738]\n",
      "[0.61274564, 0.2, 0.20513152, 0.20185253]\n",
      "[0.6167691, 0.2, 0.20757899, 0.20342232]\n",
      "[0.61573076, 0.2, 0.20749596, 0.20246203]\n",
      "[0.61357826, 0.2, 0.20662677, 0.20117334]\n",
      "[0.61407506, 0.2, 0.20517263, 0.20311895]\n",
      "[0.6152786, 0.2, 0.20744272, 0.20204744]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14060 iterations: 3.3921799341837566 mins\n",
      "Train Loss: [0.6152786, 0.2, 0.20744272, 0.20204744]\n",
      "[0.612873, 0.2, 0.2053834, 0.20169678]\n",
      "[0.6096851, 0.2, 0.20141567, 0.20247284]\n",
      "[0.61843735, 0.2, 0.20877796, 0.20385958]\n",
      "[0.61594135, 0.2, 0.20935702, 0.20078178]\n",
      "[0.61611533, 0.2, 0.20842844, 0.2018822]\n",
      "[0.6305547, 0.2, 0.21999884, 0.2047494]\n",
      "[0.61238885, 0.2, 0.20518515, 0.20139575]\n",
      "[0.6082764, 0.2, 0.20135204, 0.20111561]\n",
      "[0.6131538, 0.2, 0.20489393, 0.20245093]\n",
      "[0.6155906, 0.2, 0.2079646, 0.20181757]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14070 iterations: 3.3942672967910767 mins\n",
      "Train Loss: [0.6155906, 0.2, 0.2079646, 0.20181757]\n",
      "[0.61651576, 0.2, 0.20863578, 0.20207253]\n",
      "[0.61182684, 0.2, 0.20188121, 0.20413971]\n",
      "[0.6312681, 0.2, 0.22348605, 0.20197807]\n",
      "[0.6171995, 0.2, 0.20901641, 0.20238158]\n",
      "[0.61232173, 0.2, 0.20416632, 0.2023567]\n",
      "[0.6132441, 0.2, 0.20520522, 0.20224312]\n",
      "[0.6126356, 0.2, 0.20578247, 0.20106035]\n",
      "[0.6196002, 0.2, 0.20336972, 0.21044101]\n",
      "[0.61041564, 0.2, 0.20296584, 0.20166337]\n",
      "[0.61088777, 0.2, 0.20433258, 0.20077185]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14080 iterations: 3.3965708136558534 mins\n",
      "Train Loss: [0.61088777, 0.2, 0.20433258, 0.20077185]\n",
      "[0.6139686, 0.2, 0.20548232, 0.20270616]\n",
      "[0.61276186, 0.2, 0.20575497, 0.20122977]\n",
      "[0.6149738, 0.2, 0.207025, 0.20217438]\n",
      "[0.61069506, 0.2, 0.20236306, 0.20256074]\n",
      "[0.61363894, 0.2, 0.20647657, 0.20139392]\n",
      "[0.60917085, 0.2, 0.20238155, 0.20102344]\n",
      "[0.6125145, 0.2, 0.20327294, 0.20347832]\n",
      "[0.6136423, 0.2, 0.20632757, 0.20155402]\n",
      "[0.6088217, 0.2, 0.201662, 0.2014019]\n",
      "[0.6118788, 0.2, 0.20408502, 0.20203894]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14090 iterations: 3.399686618645986 mins\n",
      "Train Loss: [0.6118788, 0.2, 0.20408502, 0.20203894]\n",
      "[0.6109434, 0.2, 0.204275, 0.20091645]\n",
      "[0.60932827, 0.2, 0.20248319, 0.20109625]\n",
      "[0.6134872, 0.2, 0.20428562, 0.203456]\n",
      "[0.6110626, 0.2, 0.20262529, 0.20269492]\n",
      "[0.609518, 0.2, 0.20260261, 0.2011764]\n",
      "[0.6099351, 0.2, 0.20290996, 0.20128982]\n",
      "[0.61779565, 0.2, 0.21023758, 0.2018266]\n",
      "[0.61599654, 0.2, 0.208505, 0.20176382]\n",
      "[0.6091684, 0.2, 0.20167169, 0.20177272]\n",
      "[0.6126002, 0.2, 0.2055696, 0.20131052]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14100 iterations: 3.4018202662467956 mins\n",
      "Train Loss: [0.6126002, 0.2, 0.2055696, 0.20131052]\n",
      "[0.61569965, 0.2, 0.20720093, 0.20278274]\n",
      "[0.6143292, 0.2, 0.2063958, 0.20222232]\n",
      "[0.6156139, 0.2, 0.20831396, 0.20159347]\n",
      "[0.6108306, 0.2, 0.20377827, 0.20134984]\n",
      "[0.61364067, 0.2, 0.20689179, 0.20105001]\n",
      "[0.6339068, 0.2, 0.20865679, 0.21955454]\n",
      "[0.6084352, 0.2, 0.2014541, 0.20128886]\n",
      "[0.6099831, 0.2, 0.20350376, 0.20079045]\n",
      "[0.615148, 0.2, 0.2073661, 0.20209627]\n",
      "[0.6236924, 0.2, 0.21486653, 0.20314343]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14110 iterations: 3.4038448333740234 mins\n",
      "Train Loss: [0.6236924, 0.2, 0.21486653, 0.20314343]\n",
      "[0.61305314, 0.2, 0.20506398, 0.20230812]\n",
      "[0.6131996, 0.2, 0.20563327, 0.20188165]\n",
      "[0.6152994, 0.2, 0.20769432, 0.20191342]\n",
      "[0.61650413, 0.2, 0.20971574, 0.20108783]\n",
      "[0.6128545, 0.2, 0.20550139, 0.20164251]\n",
      "[0.6416708, 0.2, 0.20620653, 0.2297433]\n",
      "[0.62092054, 0.2, 0.2139514, 0.20123765]\n",
      "[0.6143445, 0.2, 0.20743702, 0.20116535]\n",
      "[0.6282677, 0.2, 0.21074753, 0.21176805]\n",
      "[0.61215985, 0.2, 0.2055435, 0.20085688]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14120 iterations: 3.4058733185132346 mins\n",
      "Train Loss: [0.61215985, 0.2, 0.2055435, 0.20085688]\n",
      "[0.610944, 0.2, 0.2043459, 0.20083176]\n",
      "[0.61179185, 0.2, 0.20441236, 0.20160714]\n",
      "[0.6142688, 0.2, 0.20551397, 0.20297724]\n",
      "[0.6115346, 0.2, 0.20361346, 0.2021395]\n",
      "[0.62173074, 0.2, 0.21445991, 0.2014858]\n",
      "[0.6173336, 0.2, 0.21020764, 0.20133835]\n",
      "[0.6175207, 0.2, 0.21017562, 0.2015554]\n",
      "[0.61497223, 0.2, 0.20782724, 0.20135336]\n",
      "[0.62786067, 0.2, 0.20411842, 0.21794958]\n",
      "[0.615562, 0.2, 0.20895846, 0.20081057]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14130 iterations: 3.4079376657803855 mins\n",
      "Train Loss: [0.615562, 0.2, 0.20895846, 0.20081057]\n",
      "[0.61715144, 0.2, 0.21034683, 0.20101185]\n",
      "[0.6095818, 0.2, 0.20304517, 0.20074506]\n",
      "[0.61354744, 0.2, 0.20687842, 0.20087914]\n",
      "[0.6157732, 0.2, 0.20849206, 0.2014934]\n",
      "[0.61100113, 0.2, 0.20369698, 0.20151877]\n",
      "[0.61186934, 0.2, 0.20416372, 0.20192331]\n",
      "[0.637063, 0.2, 0.20503546, 0.22624855]\n",
      "[0.6130468, 0.2, 0.20574316, 0.20152813]\n",
      "[0.6144661, 0.2, 0.20600398, 0.20269057]\n",
      "[0.6109848, 0.2, 0.20350516, 0.2017119]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14140 iterations: 3.4098952651023864 mins\n",
      "Train Loss: [0.6109848, 0.2, 0.20350516, 0.2017119]\n",
      "[0.6097845, 0.2, 0.20258623, 0.20143452]\n",
      "[0.6145118, 0.2, 0.20693327, 0.20181905]\n",
      "[0.6101304, 0.2, 0.20264573, 0.20172937]\n",
      "[0.6095708, 0.2, 0.20220573, 0.20161426]\n",
      "[0.61726016, 0.2, 0.20985028, 0.2016636]\n",
      "[0.6106579, 0.2, 0.20352262, 0.20139357]\n",
      "[0.6105153, 0.2, 0.20350702, 0.20127138]\n",
      "[0.61383295, 0.2, 0.205824, 0.20227686]\n",
      "[0.6124393, 0.2, 0.20533106, 0.20138076]\n",
      "[0.6142835, 0.2, 0.2070759, 0.20148511]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14150 iterations: 3.4123081962267556 mins\n",
      "Train Loss: [0.6142835, 0.2, 0.2070759, 0.20148511]\n",
      "[0.61244786, 0.2, 0.20610788, 0.20062205]\n",
      "[0.6116811, 0.2, 0.20449461, 0.20147331]\n",
      "[0.6154219, 0.2, 0.20766528, 0.20204826]\n",
      "[0.6125304, 0.2, 0.20587514, 0.2009517]\n",
      "[0.61206484, 0.2, 0.20269763, 0.20366848]\n",
      "[0.61754835, 0.2, 0.20786715, 0.20398723]\n",
      "[0.61601824, 0.2, 0.2095427, 0.20078623]\n",
      "[0.6160115, 0.2, 0.20968276, 0.2006446]\n",
      "[0.61782455, 0.2, 0.2098034, 0.20234248]\n",
      "[0.6123132, 0.2, 0.20528758, 0.20135213]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14160 iterations: 3.415727798144023 mins\n",
      "Train Loss: [0.6123132, 0.2, 0.20528758, 0.20135213]\n",
      "[0.6277379, 0.2, 0.22049081, 0.20157838]\n",
      "[0.6109066, 0.2, 0.20344263, 0.20179795]\n",
      "[0.612331, 0.2, 0.20502253, 0.20164534]\n",
      "[0.61357576, 0.2, 0.20654999, 0.2013659]\n",
      "[0.6083679, 0.2, 0.2003559, 0.20235561]\n",
      "[0.615006, 0.2, 0.20819359, 0.20115964]\n",
      "[0.6258125, 0.2, 0.20535906, 0.2148039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6155169, 0.2, 0.20754659, 0.20232368]\n",
      "[0.62866235, 0.2, 0.22201714, 0.20100093]\n",
      "[0.61315525, 0.2, 0.20611697, 0.20139402]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14170 iterations: 3.4179112831751506 mins\n",
      "Train Loss: [0.61315525, 0.2, 0.20611697, 0.20139402]\n",
      "[0.61584586, 0.2, 0.20944561, 0.2007556]\n",
      "[0.60878307, 0.2, 0.20224588, 0.20089217]\n",
      "[0.61633337, 0.2, 0.20802838, 0.20265971]\n",
      "[0.6173586, 0.2, 0.20946264, 0.20225084]\n",
      "[0.6095929, 0.2, 0.20252453, 0.20142312]\n",
      "[0.61147386, 0.2, 0.2046979, 0.20113122]\n",
      "[0.6105638, 0.2, 0.20321538, 0.2017047]\n",
      "[0.62752837, 0.2, 0.22104493, 0.200841]\n",
      "[0.61852366, 0.2, 0.20975286, 0.20313047]\n",
      "[0.6227808, 0.2, 0.21483909, 0.20230341]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14180 iterations: 3.419865302244822 mins\n",
      "Train Loss: [0.6227808, 0.2, 0.21483909, 0.20230341]\n",
      "[0.616774, 0.2, 0.20864002, 0.20249821]\n",
      "[0.6164733, 0.2, 0.20995978, 0.20088011]\n",
      "[0.6182581, 0.2, 0.21106988, 0.20155734]\n",
      "[0.6107829, 0.2, 0.20472425, 0.20043007]\n",
      "[0.6177234, 0.2, 0.21002786, 0.20206927]\n",
      "[0.6110582, 0.2, 0.20464858, 0.20078571]\n",
      "[0.6106942, 0.2, 0.2041854, 0.20088755]\n",
      "[0.612704, 0.2, 0.20567438, 0.201411]\n",
      "[0.61670184, 0.2, 0.20962426, 0.20146231]\n",
      "[0.61394334, 0.2, 0.20716587, 0.20116462]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14190 iterations: 3.4219172994295755 mins\n",
      "Train Loss: [0.61394334, 0.2, 0.20716587, 0.20116462]\n",
      "[0.6165622, 0.2, 0.20811243, 0.20283915]\n",
      "[0.61659807, 0.2, 0.20954455, 0.20144528]\n",
      "[0.6176662, 0.2, 0.210652, 0.20140812]\n",
      "[0.6139635, 0.2, 0.20616323, 0.20219642]\n",
      "[0.63118184, 0.2, 0.22438051, 0.20119977]\n",
      "[0.61820364, 0.2, 0.20935634, 0.20324501]\n",
      "[0.61169547, 0.2, 0.20484369, 0.2012488]\n",
      "[0.61882305, 0.2, 0.21245332, 0.20076577]\n",
      "[0.6312269, 0.2, 0.20559858, 0.2200237]\n",
      "[0.6114266, 0.2, 0.20363885, 0.20218119]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14200 iterations: 3.423904565970103 mins\n",
      "Train Loss: [0.6114266, 0.2, 0.20363885, 0.20218119]\n",
      "[0.60878414, 0.2, 0.20107605, 0.20209982]\n",
      "[0.61941516, 0.2, 0.21253763, 0.20126782]\n",
      "[0.61053675, 0.2, 0.20275709, 0.20216866]\n",
      "[0.61663276, 0.2, 0.20966949, 0.20135112]\n",
      "[0.6515455, 0.2, 0.24501829, 0.2009141]\n",
      "[0.61542267, 0.2, 0.20884863, 0.20096186]\n",
      "[0.61527157, 0.2, 0.20814389, 0.2015169]\n",
      "[0.61253715, 0.2, 0.20328446, 0.20364347]\n",
      "[0.61939573, 0.2, 0.21249804, 0.2012901]\n",
      "[0.61177135, 0.2, 0.20448, 0.20168549]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14210 iterations: 3.4262179334958396 mins\n",
      "Train Loss: [0.61177135, 0.2, 0.20448, 0.20168549]\n",
      "[0.6086276, 0.2, 0.2013943, 0.2016295]\n",
      "[0.6124552, 0.2, 0.20514551, 0.20170805]\n",
      "[0.6128379, 0.2, 0.20585391, 0.20138495]\n",
      "[0.6101225, 0.2, 0.20284575, 0.20168051]\n",
      "[0.6146466, 0.2, 0.20667458, 0.2023788]\n",
      "[0.61547214, 0.2, 0.207318, 0.20256375]\n",
      "[0.6131427, 0.2, 0.20659162, 0.20096345]\n",
      "[0.62493044, 0.2, 0.21804814, 0.20129763]\n",
      "[0.61243683, 0.2, 0.20414764, 0.2027077]\n",
      "[0.6173848, 0.2, 0.21012332, 0.20168328]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14220 iterations: 3.428405201435089 mins\n",
      "Train Loss: [0.6173848, 0.2, 0.21012332, 0.20168328]\n",
      "[0.6121477, 0.2, 0.2057622, 0.20081103]\n",
      "[0.6135127, 0.2, 0.20690994, 0.20103185]\n",
      "[0.61179996, 0.2, 0.20489188, 0.20134042]\n",
      "[0.6126422, 0.2, 0.20586859, 0.20120937]\n",
      "[0.61515987, 0.2, 0.20715128, 0.20244765]\n",
      "[0.61431724, 0.2, 0.20700788, 0.2017517]\n",
      "[0.6113732, 0.2, 0.20496407, 0.20085457]\n",
      "[0.61407065, 0.2, 0.20559178, 0.20292775]\n",
      "[0.61070794, 0.2, 0.20386721, 0.20129281]\n",
      "[0.61580944, 0.2, 0.20910911, 0.20115574]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14230 iterations: 3.43077871799469 mins\n",
      "Train Loss: [0.61580944, 0.2, 0.20910911, 0.20115574]\n",
      "[0.6112233, 0.2, 0.20467861, 0.20100272]\n",
      "[0.6092116, 0.2, 0.2028067, 0.20086572]\n",
      "[0.6098527, 0.2, 0.20161436, 0.20270167]\n",
      "[0.6384122, 0.2, 0.23101236, 0.20186588]\n",
      "[0.61143017, 0.2, 0.20466854, 0.20122892]\n",
      "[0.6129402, 0.2, 0.20594585, 0.20146288]\n",
      "[0.6196561, 0.2, 0.21210013, 0.20202583]\n",
      "[0.61224735, 0.2, 0.20553923, 0.20117916]\n",
      "[0.6126186, 0.2, 0.20521842, 0.20187221]\n",
      "[0.6168744, 0.2, 0.20837842, 0.20296936]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14240 iterations: 3.4329408327738444 mins\n",
      "Train Loss: [0.6168744, 0.2, 0.20837842, 0.20296936]\n",
      "[0.6121198, 0.2, 0.20471394, 0.20188001]\n",
      "[0.61049175, 0.2, 0.20322697, 0.20173958]\n",
      "[0.6142323, 0.2, 0.20731708, 0.20139065]\n",
      "[0.6100255, 0.2, 0.20302612, 0.20147535]\n",
      "[0.60876864, 0.2, 0.20173733, 0.20150782]\n",
      "[0.6078305, 0.2, 0.2016071, 0.2007009]\n",
      "[0.61525846, 0.2, 0.20882994, 0.20090716]\n",
      "[0.6223327, 0.2, 0.20547856, 0.21133372]\n",
      "[0.61666244, 0.2, 0.20291027, 0.20823337]\n",
      "[0.6131493, 0.2, 0.20600045, 0.20163201]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14250 iterations: 3.434805182615916 mins\n",
      "Train Loss: [0.6131493, 0.2, 0.20600045, 0.20163201]\n",
      "[0.61316806, 0.2, 0.20707151, 0.20058136]\n",
      "[0.613783, 0.2, 0.2076987, 0.20057108]\n",
      "[0.61264056, 0.2, 0.20597209, 0.20115726]\n",
      "[0.614734, 0.2, 0.2071816, 0.20204306]\n",
      "[0.61045545, 0.2, 0.20419611, 0.20075195]\n",
      "[0.60947174, 0.2, 0.20257358, 0.20139271]\n",
      "[0.61570764, 0.2, 0.20917355, 0.20103067]\n",
      "[0.6323979, 0.2, 0.22609933, 0.20079729]\n",
      "[0.63078845, 0.2, 0.20271012, 0.22257894]\n",
      "[0.61323935, 0.2, 0.20657772, 0.20116349]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14260 iterations: 3.4368824481964113 mins\n",
      "Train Loss: [0.61323935, 0.2, 0.20657772, 0.20116349]\n",
      "[0.6114872, 0.2, 0.20449339, 0.20149663]\n",
      "[0.6129489, 0.2, 0.20565678, 0.20179598]\n",
      "[0.6111395, 0.2, 0.20462291, 0.20102157]\n",
      "[0.6179135, 0.2, 0.21132995, 0.20108943]\n",
      "[0.60791934, 0.2, 0.20123346, 0.20119287]\n",
      "[0.6123717, 0.2, 0.20532413, 0.20155619]\n",
      "[0.611116, 0.2, 0.20470306, 0.20092338]\n",
      "[0.6114092, 0.2, 0.20501012, 0.20091216]\n",
      "[0.6099516, 0.2, 0.20342077, 0.20104642]\n",
      "[0.6141643, 0.2, 0.20639566, 0.20228666]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14270 iterations: 3.4389127333958944 mins\n",
      "Train Loss: [0.6141643, 0.2, 0.20639566, 0.20228666]\n",
      "[0.6114701, 0.2, 0.20441462, 0.20157531]\n",
      "[0.6132906, 0.2, 0.20570017, 0.20211214]\n",
      "[0.6080306, 0.2, 0.20118462, 0.20136952]\n",
      "[0.6176194, 0.2, 0.20223463, 0.2099103]\n",
      "[0.6188761, 0.2, 0.21221182, 0.20119166]\n",
      "[0.61215156, 0.2, 0.20453073, 0.20215027]\n",
      "[0.6112879, 0.2, 0.20421666, 0.20160282]\n",
      "[0.6128798, 0.2, 0.20632918, 0.201084]\n",
      "[0.6126712, 0.2, 0.20536263, 0.20184365]\n",
      "[0.62335837, 0.2, 0.20385776, 0.21403739]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14280 iterations: 3.440824298063914 mins\n",
      "Train Loss: [0.62335837, 0.2, 0.20385776, 0.21403739]\n",
      "[0.61121136, 0.2, 0.20448473, 0.20126529]\n",
      "[0.615723, 0.2, 0.20883825, 0.20142506]\n",
      "[0.6301807, 0.2, 0.20814866, 0.21657403]\n",
      "[0.6085395, 0.2, 0.20165308, 0.20143004]\n",
      "[0.61334497, 0.2, 0.20703138, 0.20085886]\n",
      "[0.61123556, 0.2, 0.20503767, 0.20074499]\n",
      "[0.61694354, 0.2, 0.21033466, 0.20115764]\n",
      "[0.6085333, 0.2, 0.20173627, 0.20134746]\n",
      "[0.61295694, 0.2, 0.20616186, 0.20134723]\n",
      "[0.6131292, 0.2, 0.20397691, 0.20370589]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14290 iterations: 3.4429950157801312 mins\n",
      "Train Loss: [0.6131292, 0.2, 0.20397691, 0.20370589]\n",
      "[0.6133588, 0.2, 0.20539635, 0.20251739]\n",
      "[0.61132354, 0.2, 0.20489715, 0.20098266]\n",
      "[0.6151548, 0.2, 0.20847212, 0.20124047]\n",
      "[0.61499244, 0.2, 0.2079939, 0.201558]\n",
      "[0.61153096, 0.2, 0.20478328, 0.20130834]\n",
      "[0.6126367, 0.2, 0.20578353, 0.2014152]\n",
      "[0.6127738, 0.2, 0.20645443, 0.20088273]\n",
      "[0.6180225, 0.2, 0.21176413, 0.20082323]\n",
      "[0.61007434, 0.2, 0.20355701, 0.2010838]\n",
      "[0.6088057, 0.2, 0.2020444, 0.20132932]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14300 iterations: 3.4450536807378134 mins\n",
      "Train Loss: [0.6088057, 0.2, 0.2020444, 0.20132932]\n",
      "[0.6444129, 0.2, 0.22007908, 0.21890369]\n",
      "[0.62451416, 0.2, 0.21752535, 0.20156083]\n",
      "[0.6114355, 0.2, 0.20398146, 0.20202748]\n",
      "[0.61048955, 0.2, 0.20287165, 0.20219296]\n",
      "[0.6157397, 0.2, 0.20932645, 0.20098995]\n",
      "[0.6131993, 0.2, 0.20716707, 0.20060997]\n",
      "[0.6187651, 0.2, 0.21106765, 0.20227627]\n",
      "[0.6106969, 0.2, 0.20339799, 0.20187911]\n",
      "[0.6129581, 0.2, 0.20659503, 0.2009447]\n",
      "[0.61799747, 0.2, 0.21062776, 0.20195301]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14310 iterations: 3.4475054661432902 mins\n",
      "Train Loss: [0.61799747, 0.2, 0.21062776, 0.20195301]\n",
      "[0.6236148, 0.2, 0.20591104, 0.21228875]\n",
      "[0.6110727, 0.2, 0.20444708, 0.20121235]\n",
      "[0.61282206, 0.2, 0.20579119, 0.20161927]\n",
      "[0.6096174, 0.2, 0.20223597, 0.2019715]\n",
      "[0.6124655, 0.2, 0.20580924, 0.20124812]\n",
      "[0.60900384, 0.2, 0.20211723, 0.20148031]\n",
      "[0.610261, 0.2, 0.20396173, 0.20089544]\n",
      "[0.614979, 0.2, 0.20903705, 0.20054048]\n",
      "[0.60996217, 0.2, 0.20362711, 0.20093594]\n",
      "[0.6122217, 0.2, 0.20495346, 0.2018718]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14320 iterations: 3.4496517817179364 mins\n",
      "Train Loss: [0.6122217, 0.2, 0.20495346, 0.2018718]\n",
      "[0.611596, 0.2, 0.20386283, 0.20233935]\n",
      "[0.6124356, 0.2, 0.20551041, 0.20153384]\n",
      "[0.61652035, 0.2, 0.21056846, 0.20056303]\n",
      "[0.6139298, 0.2, 0.20729122, 0.20125172]\n",
      "[0.6095356, 0.2, 0.2029868, 0.2011637]\n",
      "[0.6129214, 0.2, 0.20639446, 0.20114352]\n",
      "[0.61454016, 0.2, 0.20805694, 0.20110154]\n",
      "[0.6154226, 0.2, 0.20901828, 0.20102432]\n",
      "[0.61127424, 0.2, 0.2049799, 0.20091544]\n",
      "[0.61441547, 0.2, 0.20487392, 0.2041637]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14330 iterations: 3.451602884133657 mins\n",
      "Train Loss: [0.61441547, 0.2, 0.20487392, 0.2041637]\n",
      "[0.62674147, 0.2, 0.20126913, 0.22009411]\n",
      "[0.62301946, 0.2, 0.2048318, 0.21280485]\n",
      "[0.61312014, 0.2, 0.2070395, 0.20069017]\n",
      "[0.6221433, 0.2, 0.21634951, 0.2003942]\n",
      "[0.61523527, 0.2, 0.20905554, 0.20077153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6177211, 0.2, 0.2110977, 0.2012059]\n",
      "[0.61155564, 0.2, 0.20536608, 0.20076248]\n",
      "[0.6083573, 0.2, 0.20091759, 0.2020032]\n",
      "[0.61428136, 0.2, 0.207402, 0.20143355]\n",
      "[0.6202769, 0.2, 0.20424654, 0.21057571]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14340 iterations: 3.4537149628003436 mins\n",
      "Train Loss: [0.6202769, 0.2, 0.20424654, 0.21057571]\n",
      "[0.6115848, 0.2, 0.2044868, 0.20163606]\n",
      "[0.6112553, 0.2, 0.204991, 0.20079567]\n",
      "[0.6194735, 0.2, 0.20166086, 0.21233821]\n",
      "[0.61022323, 0.2, 0.20349133, 0.20125271]\n",
      "[0.6166461, 0.2, 0.2098872, 0.20127559]\n",
      "[0.6197923, 0.2, 0.21377963, 0.20052561]\n",
      "[0.61530936, 0.2, 0.2054149, 0.20440453]\n",
      "[0.6149342, 0.2, 0.20761164, 0.2018306]\n",
      "[0.6095433, 0.2, 0.2032108, 0.20083885]\n",
      "[0.6116298, 0.2, 0.20461605, 0.20151873]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14350 iterations: 3.4567055185635884 mins\n",
      "Train Loss: [0.6116298, 0.2, 0.20461605, 0.20151873]\n",
      "[0.61147046, 0.2, 0.20476782, 0.20120688]\n",
      "[0.6119351, 0.2, 0.2037192, 0.20271982]\n",
      "[0.6098225, 0.2, 0.20332626, 0.2010004]\n",
      "[0.60916024, 0.2, 0.20178115, 0.2018841]\n",
      "[0.6091912, 0.2, 0.20242545, 0.20127204]\n",
      "[0.61288357, 0.2, 0.20607343, 0.20131832]\n",
      "[0.61492854, 0.2, 0.20727144, 0.20216782]\n",
      "[0.61634344, 0.2, 0.20983279, 0.20102452]\n",
      "[0.61589307, 0.2, 0.20900637, 0.2014039]\n",
      "[0.62004626, 0.2, 0.21265829, 0.20190857]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14360 iterations: 3.4587145964304606 mins\n",
      "Train Loss: [0.62004626, 0.2, 0.21265829, 0.20190857]\n",
      "[0.6193155, 0.2, 0.21217744, 0.20166197]\n",
      "[0.6111399, 0.2, 0.20287134, 0.20279557]\n",
      "[0.6189149, 0.2, 0.21087594, 0.20256935]\n",
      "[0.60909575, 0.2, 0.20175458, 0.20187512]\n",
      "[0.6078883, 0.2, 0.20138864, 0.20103715]\n",
      "[0.61477184, 0.2, 0.20820771, 0.20110528]\n",
      "[0.6148867, 0.2, 0.20766903, 0.20176251]\n",
      "[0.6118323, 0.2, 0.20568968, 0.2006915]\n",
      "[0.6177858, 0.2, 0.20995906, 0.20237987]\n",
      "[0.6140048, 0.2, 0.20693234, 0.20163077]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14370 iterations: 3.460707346598307 mins\n",
      "Train Loss: [0.6140048, 0.2, 0.20693234, 0.20163077]\n",
      "[0.61061794, 0.2, 0.20364092, 0.20154086]\n",
      "[0.6078601, 0.2, 0.20113534, 0.20129392]\n",
      "[0.6123946, 0.2, 0.20543529, 0.2015336]\n",
      "[0.61265737, 0.2, 0.20548995, 0.20174694]\n",
      "[0.64050657, 0.2, 0.20964688, 0.22544444]\n",
      "[0.6127568, 0.2, 0.20602383, 0.20132266]\n",
      "[0.613931, 0.2, 0.20537461, 0.20315044]\n",
      "[0.60972613, 0.2, 0.20304848, 0.20127624]\n",
      "[0.6075787, 0.2, 0.20085101, 0.20133066]\n",
      "[0.6112312, 0.2, 0.20507683, 0.20076159]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14380 iterations: 3.462628165880839 mins\n",
      "Train Loss: [0.6112312, 0.2, 0.20507683, 0.20076159]\n",
      "[0.6109588, 0.2, 0.20473674, 0.20083347]\n",
      "[0.63570565, 0.2, 0.21714044, 0.21318069]\n",
      "[0.6141226, 0.2, 0.20799433, 0.20074481]\n",
      "[0.61027145, 0.2, 0.20336524, 0.20152362]\n",
      "[0.61099213, 0.2, 0.20471148, 0.20089883]\n",
      "[0.617038, 0.2, 0.21086678, 0.20079039]\n",
      "[0.6119231, 0.2, 0.20494986, 0.20159271]\n",
      "[0.6121234, 0.2, 0.20460467, 0.20213862]\n",
      "[0.61022043, 0.2, 0.20390345, 0.20093718]\n",
      "[0.61088747, 0.2, 0.204479, 0.20102875]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14390 iterations: 3.466558865706126 mins\n",
      "Train Loss: [0.61088747, 0.2, 0.204479, 0.20102875]\n",
      "[0.61294585, 0.2, 0.20601392, 0.20155154]\n",
      "[0.6154237, 0.2, 0.20670445, 0.20333852]\n",
      "[0.63025314, 0.2, 0.22260107, 0.20227171]\n",
      "[0.6204582, 0.2, 0.21320598, 0.20187353]\n",
      "[0.6212696, 0.2, 0.21301448, 0.2028777]\n",
      "[0.615391, 0.2, 0.20907922, 0.20093572]\n",
      "[0.61263144, 0.2, 0.20343253, 0.20382449]\n",
      "[0.6116669, 0.2, 0.20543213, 0.20086043]\n",
      "[0.6128147, 0.2, 0.20226146, 0.20517567]\n",
      "[0.6162888, 0.2, 0.20647697, 0.20442885]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14400 iterations: 3.4688647349675494 mins\n",
      "Train Loss: [0.6162888, 0.2, 0.20647697, 0.20442885]\n",
      "[0.6148911, 0.2, 0.20790347, 0.20159808]\n",
      "[0.6276221, 0.2, 0.22022194, 0.20200354]\n",
      "[0.6135196, 0.2, 0.20711406, 0.2010015]\n",
      "[0.6128648, 0.2, 0.20541142, 0.20204201]\n",
      "[0.6091101, 0.2, 0.20255834, 0.20113362]\n",
      "[0.61974794, 0.2, 0.21306229, 0.20126106]\n",
      "[0.62069327, 0.2, 0.2142938, 0.20096941]\n",
      "[0.64645946, 0.2, 0.20971662, 0.23130794]\n",
      "[0.6142247, 0.2, 0.2063886, 0.20239705]\n",
      "[0.61772346, 0.2, 0.21152015, 0.20076096]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14410 iterations: 3.4709063172340393 mins\n",
      "Train Loss: [0.61772346, 0.2, 0.21152015, 0.20076096]\n",
      "[0.6117626, 0.2, 0.2035981, 0.20271933]\n",
      "[0.6148651, 0.2, 0.20742051, 0.20199732]\n",
      "[0.6714759, 0.2, 0.26464987, 0.20137733]\n",
      "[0.6113283, 0.2, 0.2040615, 0.20181929]\n",
      "[0.6103115, 0.2, 0.20270032, 0.20216447]\n",
      "[0.61404055, 0.2, 0.20780122, 0.2007936]\n",
      "[0.6080295, 0.2, 0.20136446, 0.20122032]\n",
      "[0.6116572, 0.2, 0.20512398, 0.20108981]\n",
      "[0.62593395, 0.2, 0.2067245, 0.21376766]\n",
      "[0.61877, 0.2, 0.21171242, 0.20161864]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14420 iterations: 3.472735047340393 mins\n",
      "Train Loss: [0.61877, 0.2, 0.21171242, 0.20161864]\n",
      "[0.6114484, 0.2, 0.20394778, 0.20206477]\n",
      "[0.61482126, 0.2, 0.2068251, 0.20256332]\n",
      "[0.61843365, 0.2, 0.20996873, 0.20303519]\n",
      "[0.60808146, 0.2, 0.20171182, 0.20094314]\n",
      "[0.61874276, 0.2, 0.21165046, 0.20166905]\n",
      "[0.6099928, 0.2, 0.20241494, 0.20215826]\n",
      "[0.61296886, 0.2, 0.20486589, 0.20268695]\n",
      "[0.62571824, 0.2, 0.21741633, 0.2028896]\n",
      "[0.6214287, 0.2, 0.21383466, 0.202185]\n",
      "[0.61011815, 0.2, 0.20416458, 0.2005473]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14430 iterations: 3.474781799316406 mins\n",
      "Train Loss: [0.61011815, 0.2, 0.20416458, 0.2005473]\n",
      "[0.61142224, 0.2, 0.20441014, 0.20160884]\n",
      "[0.6086396, 0.2, 0.20093708, 0.20230211]\n",
      "[0.6401163, 0.2, 0.20545594, 0.2292628]\n",
      "[0.6076137, 0.2, 0.20155916, 0.20065947]\n",
      "[0.62169766, 0.2, 0.2149673, 0.20133777]\n",
      "[0.6103004, 0.2, 0.20342846, 0.201481]\n",
      "[0.6129505, 0.2, 0.20623727, 0.20132415]\n",
      "[0.64253306, 0.2, 0.23289205, 0.20425388]\n",
      "[0.6294695, 0.2, 0.20396686, 0.22011584]\n",
      "[0.60727245, 0.2, 0.20116395, 0.2007213]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14440 iterations: 3.4766352852185567 mins\n",
      "Train Loss: [0.60727245, 0.2, 0.20116395, 0.2007213]\n",
      "[0.612645, 0.2, 0.20632796, 0.20092958]\n",
      "[0.6121868, 0.2, 0.20483062, 0.20196865]\n",
      "[0.6125207, 0.2, 0.20613156, 0.20100154]\n",
      "[0.6116914, 0.2, 0.20454833, 0.20175526]\n",
      "[0.61059237, 0.2, 0.20395194, 0.20125295]\n",
      "[0.61820763, 0.2, 0.2111892, 0.20163128]\n",
      "[0.6252124, 0.2, 0.20789583, 0.21193027]\n",
      "[0.6129276, 0.2, 0.20658289, 0.20095986]\n",
      "[0.6119929, 0.2, 0.20434949, 0.20225996]\n",
      "[0.6118001, 0.2, 0.20453784, 0.20187972]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14450 iterations: 3.478755513827006 mins\n",
      "Train Loss: [0.6118001, 0.2, 0.20453784, 0.20187972]\n",
      "[0.62178934, 0.2, 0.21397544, 0.2024322]\n",
      "[0.6100552, 0.2, 0.20274617, 0.20192848]\n",
      "[0.6133506, 0.2, 0.20615946, 0.20181188]\n",
      "[0.60991204, 0.2, 0.20384863, 0.20068498]\n",
      "[0.613179, 0.2, 0.20674989, 0.2010517]\n",
      "[0.61590284, 0.2, 0.20613652, 0.20438986]\n",
      "[0.6122378, 0.2, 0.20578133, 0.20108]\n",
      "[0.60988384, 0.2, 0.20348758, 0.2010199]\n",
      "[0.6196046, 0.2, 0.21314049, 0.20108788]\n",
      "[0.64334255, 0.2, 0.20489506, 0.23307177]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14460 iterations: 3.4819181164105735 mins\n",
      "Train Loss: [0.64334255, 0.2, 0.20489506, 0.23307177]\n",
      "[0.62035006, 0.2, 0.21392663, 0.20104888]\n",
      "[0.6091322, 0.2, 0.20145108, 0.20230769]\n",
      "[0.6146046, 0.2, 0.20757072, 0.20166197]\n",
      "[0.6527994, 0.2, 0.20498055, 0.24244852]\n",
      "[0.6159043, 0.2, 0.20951304, 0.20102212]\n",
      "[0.6117765, 0.2, 0.20543294, 0.20097557]\n",
      "[0.61526275, 0.2, 0.20850758, 0.20138843]\n",
      "[0.61128235, 0.2, 0.20476717, 0.20114978]\n",
      "[0.61437654, 0.2, 0.20835392, 0.20065856]\n",
      "[0.6125679, 0.2, 0.20607735, 0.20112777]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14470 iterations: 3.4837684830029807 mins\n",
      "Train Loss: [0.6125679, 0.2, 0.20607735, 0.20112777]\n",
      "[0.61462545, 0.2, 0.20824207, 0.20102201]\n",
      "[0.6132402, 0.2, 0.20641723, 0.20146292]\n",
      "[0.6164878, 0.2, 0.20918034, 0.20194858]\n",
      "[0.6184738, 0.2, 0.211203, 0.20191287]\n",
      "[0.6173284, 0.2, 0.20830907, 0.20366207]\n",
      "[0.6125878, 0.2, 0.20593914, 0.20129174]\n",
      "[0.6163908, 0.2, 0.20971665, 0.20131755]\n",
      "[0.6082657, 0.2, 0.20107645, 0.20183326]\n",
      "[0.6137811, 0.2, 0.20712535, 0.20130032]\n",
      "[0.62607056, 0.2, 0.20818269, 0.21253328]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14480 iterations: 3.4858483831087748 mins\n",
      "Train Loss: [0.62607056, 0.2, 0.20818269, 0.21253328]\n",
      "[0.6175075, 0.2, 0.20836301, 0.2037907]\n",
      "[0.61233974, 0.2, 0.20502457, 0.201962]\n",
      "[0.61192864, 0.2, 0.20558849, 0.20098788]\n",
      "[0.6225427, 0.2, 0.21566193, 0.20152967]\n",
      "[0.6149812, 0.2, 0.20793734, 0.20169361]\n",
      "[0.6196091, 0.2, 0.21209122, 0.20216845]\n",
      "[0.61190563, 0.2, 0.20535144, 0.20120485]\n",
      "[0.6166858, 0.2, 0.21032627, 0.20101054]\n",
      "[0.61414605, 0.2, 0.20659514, 0.20220208]\n",
      "[0.6112135, 0.2, 0.20336498, 0.20249948]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14490 iterations: 3.4878361860911054 mins\n",
      "Train Loss: [0.6112135, 0.2, 0.20336498, 0.20249948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6071479, 0.2, 0.20084876, 0.2009497]\n",
      "[0.6107575, 0.2, 0.20354159, 0.2018658]\n",
      "[0.6391896, 0.2, 0.20372532, 0.23011357]\n",
      "[0.61520624, 0.2, 0.20742656, 0.20242815]\n",
      "[0.6118624, 0.2, 0.20269457, 0.20381558]\n",
      "[0.609958, 0.2, 0.20345595, 0.20114838]\n",
      "[0.61940175, 0.2, 0.20296702, 0.21107963]\n",
      "[0.6079795, 0.2, 0.20203424, 0.20058845]\n",
      "[0.6082512, 0.2, 0.20142473, 0.20146807]\n",
      "[0.6102842, 0.2, 0.20345365, 0.20147067]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14500 iterations: 3.4898658355077106 mins\n",
      "Train Loss: [0.6102842, 0.2, 0.20345365, 0.20147067]\n",
      "[0.61820877, 0.2, 0.21170655, 0.2011413]\n",
      "[0.61122274, 0.2, 0.2042108, 0.2016502]\n",
      "[0.6583043, 0.2, 0.20421763, 0.24872452]\n",
      "[0.6089153, 0.2, 0.20211832, 0.20143335]\n",
      "[0.6160959, 0.2, 0.20796686, 0.20276321]\n",
      "[0.6133355, 0.2, 0.20709942, 0.20086814]\n",
      "[0.6454463, 0.2, 0.23769924, 0.202377]\n",
      "[0.6087693, 0.2, 0.2016956, 0.20170155]\n",
      "[0.61277276, 0.2, 0.20629846, 0.2010998]\n",
      "[0.6127256, 0.2, 0.20425613, 0.20309286]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14510 iterations: 3.491821551322937 mins\n",
      "Train Loss: [0.6127256, 0.2, 0.20425613, 0.20309286]\n",
      "[0.6192545, 0.2, 0.21273911, 0.20113699]\n",
      "[0.61314964, 0.2, 0.20520702, 0.20256352]\n",
      "[0.60906756, 0.2, 0.20168592, 0.2020024]\n",
      "[0.6130684, 0.2, 0.20572871, 0.20196144]\n",
      "[0.6139604, 0.2, 0.20662697, 0.20195629]\n",
      "[0.613513, 0.2, 0.20693767, 0.20119907]\n",
      "[0.62619495, 0.2, 0.20829752, 0.21252148]\n",
      "[0.61118597, 0.2, 0.2032668, 0.20254536]\n",
      "[0.61153334, 0.2, 0.20536602, 0.20079538]\n",
      "[0.61080545, 0.2, 0.2038264, 0.20160845]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14520 iterations: 3.4937695185343425 mins\n",
      "Train Loss: [0.61080545, 0.2, 0.2038264, 0.20160845]\n",
      "[0.6112724, 0.2, 0.203223, 0.20267944]\n",
      "[0.61182123, 0.2, 0.20354164, 0.20290986]\n",
      "[0.6132254, 0.2, 0.20713794, 0.20071776]\n",
      "[0.61778176, 0.2, 0.21053633, 0.20187543]\n",
      "[0.6182929, 0.2, 0.2091368, 0.20378612]\n",
      "[0.6114078, 0.2, 0.20450282, 0.20153505]\n",
      "[0.61546034, 0.2, 0.20622338, 0.20386703]\n",
      "[0.6124526, 0.2, 0.20528603, 0.20179705]\n",
      "[0.6245169, 0.2, 0.21812001, 0.20102777]\n",
      "[0.6133303, 0.2, 0.20690069, 0.20106089]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14530 iterations: 3.495865348974864 mins\n",
      "Train Loss: [0.6133303, 0.2, 0.20690069, 0.20106089]\n",
      "[0.6138726, 0.2, 0.20692164, 0.20158298]\n",
      "[0.6215036, 0.2, 0.21419817, 0.20193836]\n",
      "[0.6228653, 0.2, 0.21515772, 0.20234218]\n",
      "[0.6311132, 0.2, 0.2048031, 0.22094649]\n",
      "[0.60982496, 0.2, 0.2030702, 0.20139411]\n",
      "[0.6160175, 0.2, 0.20860253, 0.20205703]\n",
      "[0.61389434, 0.2, 0.205628, 0.20291127]\n",
      "[0.6222772, 0.2, 0.21500894, 0.20191668]\n",
      "[0.6097557, 0.2, 0.20239133, 0.20201574]\n",
      "[0.6270376, 0.2, 0.20561258, 0.21607898]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14540 iterations: 3.498171699047089 mins\n",
      "Train Loss: [0.6270376, 0.2, 0.20561258, 0.21607898]\n",
      "[0.61413133, 0.2, 0.20615481, 0.20263326]\n",
      "[0.60906446, 0.2, 0.20259523, 0.20112966]\n",
      "[0.62095964, 0.2, 0.21480827, 0.20081487]\n",
      "[0.61385065, 0.2, 0.20679025, 0.20172605]\n",
      "[0.6083819, 0.2, 0.20203651, 0.20101362]\n",
      "[0.6121653, 0.2, 0.20548522, 0.20135035]\n",
      "[0.6098569, 0.2, 0.20186554, 0.20266342]\n",
      "[0.61138445, 0.2, 0.20375744, 0.20230114]\n",
      "[0.6103762, 0.2, 0.20378986, 0.20126204]\n",
      "[0.62764126, 0.2, 0.22062813, 0.20169112]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14550 iterations: 3.5002950469652814 mins\n",
      "Train Loss: [0.62764126, 0.2, 0.22062813, 0.20169112]\n",
      "[0.6126165, 0.2, 0.2057781, 0.20151836]\n",
      "[0.61340076, 0.2, 0.20590368, 0.20217885]\n",
      "[0.62262875, 0.2, 0.21563944, 0.20167263]\n",
      "[0.6267037, 0.2, 0.2190672, 0.20232119]\n",
      "[0.6431026, 0.2, 0.20976445, 0.22802529]\n",
      "[0.62764347, 0.2, 0.2172201, 0.20511119]\n",
      "[0.6099051, 0.2, 0.20374279, 0.2008506]\n",
      "[0.6132659, 0.2, 0.20631735, 0.201637]\n",
      "[0.6135586, 0.2, 0.2062988, 0.20194821]\n",
      "[0.61379516, 0.2, 0.20732829, 0.20115604]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14560 iterations: 3.502219863732656 mins\n",
      "Train Loss: [0.61379516, 0.2, 0.20732829, 0.20115604]\n",
      "[0.6114435, 0.2, 0.20383132, 0.20230201]\n",
      "[0.6112379, 0.2, 0.2041686, 0.20175982]\n",
      "[0.6261224, 0.2, 0.20956528, 0.2112486]\n",
      "[0.612072, 0.2, 0.20414378, 0.20262003]\n",
      "[0.61388886, 0.2, 0.20470831, 0.20387235]\n",
      "[0.6127948, 0.2, 0.2059542, 0.20153259]\n",
      "[0.6120118, 0.2, 0.20472075, 0.20198318]\n",
      "[0.6093553, 0.2, 0.2028722, 0.2011753]\n",
      "[0.6096149, 0.2, 0.20375632, 0.20055111]\n",
      "[0.60988164, 0.2, 0.20277646, 0.20179805]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14570 iterations: 3.50428698460261 mins\n",
      "Train Loss: [0.60988164, 0.2, 0.20277646, 0.20179805]\n",
      "[0.6267377, 0.2, 0.20332314, 0.21810804]\n",
      "[0.6128569, 0.2, 0.20420061, 0.20335016]\n",
      "[0.61187255, 0.2, 0.20543683, 0.20113008]\n",
      "[0.6113549, 0.2, 0.20437732, 0.20167258]\n",
      "[0.6160794, 0.2, 0.2101266, 0.20064843]\n",
      "[0.60864824, 0.2, 0.20232011, 0.20102425]\n",
      "[0.61814785, 0.2, 0.21156299, 0.20128177]\n",
      "[0.6126425, 0.2, 0.20573348, 0.20160665]\n",
      "[0.6131133, 0.2, 0.20637758, 0.20143381]\n",
      "[0.6181725, 0.2, 0.21176945, 0.20110166]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14580 iterations: 3.506227652231852 mins\n",
      "Train Loss: [0.6181725, 0.2, 0.21176945, 0.20110166]\n",
      "[0.6130055, 0.2, 0.20605025, 0.20165691]\n",
      "[0.62367165, 0.2, 0.21656778, 0.2018082]\n",
      "[0.6091304, 0.2, 0.20265688, 0.20118025]\n",
      "[0.6767372, 0.2, 0.26940706, 0.20203891]\n",
      "[0.6157779, 0.2, 0.20841148, 0.20207463]\n",
      "[0.61733687, 0.2, 0.21019363, 0.20185106]\n",
      "[0.61135685, 0.2, 0.20407192, 0.20199242]\n",
      "[0.6141468, 0.2, 0.20566946, 0.20318446]\n",
      "[0.6117032, 0.2, 0.20453781, 0.20187248]\n",
      "[0.61103225, 0.2, 0.20477961, 0.20095994]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14590 iterations: 3.5083205342292785 mins\n",
      "Train Loss: [0.61103225, 0.2, 0.20477961, 0.20095994]\n",
      "[0.6145452, 0.2, 0.20652848, 0.20272426]\n",
      "[0.6141505, 0.2, 0.20683365, 0.20202431]\n",
      "[0.61333203, 0.2, 0.20666014, 0.20137967]\n",
      "[0.6114278, 0.2, 0.20536561, 0.20077012]\n",
      "[0.6175809, 0.2, 0.21082379, 0.20146523]\n",
      "[0.61594117, 0.2, 0.20952848, 0.20112103]\n",
      "[0.611158, 0.2, 0.20411235, 0.20175435]\n",
      "[0.61311907, 0.2, 0.20545802, 0.20237005]\n",
      "[0.6126859, 0.2, 0.20520721, 0.20218839]\n",
      "[0.61124593, 0.2, 0.20401548, 0.20194124]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14600 iterations: 3.510491633415222 mins\n",
      "Train Loss: [0.61124593, 0.2, 0.20401548, 0.20194124]\n",
      "[0.608118, 0.2, 0.20194735, 0.20088223]\n",
      "[0.61216104, 0.2, 0.20502874, 0.20184466]\n",
      "[0.6162226, 0.2, 0.20947118, 0.20146474]\n",
      "[0.6125696, 0.2, 0.20664571, 0.20063837]\n",
      "[0.60881764, 0.2, 0.20179665, 0.20173678]\n",
      "[0.62542886, 0.2, 0.21829487, 0.20185113]\n",
      "[0.62588, 0.2, 0.21715452, 0.20344351]\n",
      "[0.6089312, 0.2, 0.20257679, 0.20107289]\n",
      "[0.6112307, 0.2, 0.20525654, 0.2006935]\n",
      "[0.6103768, 0.2, 0.20377837, 0.20131871]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14610 iterations: 3.512381585439046 mins\n",
      "Train Loss: [0.6103768, 0.2, 0.20377837, 0.20131871]\n",
      "[0.6172984, 0.2, 0.21032912, 0.20169084]\n",
      "[0.61096007, 0.2, 0.20349938, 0.20218359]\n",
      "[0.61577094, 0.2, 0.20841011, 0.20208506]\n",
      "[0.61414087, 0.2, 0.20744403, 0.20142247]\n",
      "[0.6143946, 0.2, 0.20800471, 0.201117]\n",
      "[0.6143882, 0.2, 0.20812969, 0.20098718]\n",
      "[0.6204097, 0.2, 0.21369821, 0.20144194]\n",
      "[0.6101798, 0.2, 0.20154189, 0.20336966]\n",
      "[0.6181864, 0.2, 0.21172136, 0.2011981]\n",
      "[0.61071545, 0.2, 0.20316757, 0.20228216]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14620 iterations: 3.515031866232554 mins\n",
      "Train Loss: [0.61071545, 0.2, 0.20316757, 0.20228216]\n",
      "[0.6200698, 0.2, 0.21280903, 0.20199674]\n",
      "[0.61606324, 0.2, 0.20871802, 0.20208272]\n",
      "[0.62172717, 0.2, 0.21544915, 0.20101774]\n",
      "[0.6114009, 0.2, 0.20540063, 0.20074196]\n",
      "[0.61304957, 0.2, 0.20715617, 0.20063694]\n",
      "[0.6281664, 0.2, 0.20773785, 0.21517378]\n",
      "[0.6230041, 0.2, 0.21642472, 0.2013256]\n",
      "[0.6188901, 0.2, 0.21221034, 0.20142715]\n",
      "[0.6265026, 0.2, 0.22059341, 0.20065767]\n",
      "[0.61794895, 0.2, 0.21174963, 0.20095259]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14630 iterations: 3.5170618812243144 mins\n",
      "Train Loss: [0.61794895, 0.2, 0.21174963, 0.20095259]\n",
      "[0.6174719, 0.2, 0.21014252, 0.20208679]\n",
      "[0.6137879, 0.2, 0.20693833, 0.20161021]\n",
      "[0.6139402, 0.2, 0.20800543, 0.20069844]\n",
      "[0.6139482, 0.2, 0.20755209, 0.2011623]\n",
      "[0.61034006, 0.2, 0.2034879, 0.20162039]\n",
      "[0.61209846, 0.2, 0.20538518, 0.2014837]\n",
      "[0.61820036, 0.2, 0.2122446, 0.20072825]\n",
      "[0.6104662, 0.2, 0.20392922, 0.20131122]\n",
      "[0.6117324, 0.2, 0.20366651, 0.20284219]\n",
      "[0.6130148, 0.2, 0.20698527, 0.20080748]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14640 iterations: 3.5190512498219806 mins\n",
      "Train Loss: [0.6130148, 0.2, 0.20698527, 0.20080748]\n",
      "[0.61081576, 0.2, 0.20451725, 0.20107807]\n",
      "[0.6143589, 0.2, 0.20740719, 0.20173247]\n",
      "[0.61422944, 0.2, 0.20758778, 0.20142348]\n",
      "[0.6122246, 0.2, 0.20620574, 0.20080148]\n",
      "[0.6263412, 0.2, 0.20569059, 0.21543418]\n",
      "[0.63998, 0.2, 0.2329218, 0.20184213]\n",
      "[0.61358804, 0.2, 0.2068747, 0.20149784]\n",
      "[0.61218154, 0.2, 0.20517914, 0.2017869]\n",
      "[0.6144738, 0.2, 0.20750876, 0.20174944]\n",
      "[0.61496973, 0.2, 0.2080368, 0.20171683]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14650 iterations: 3.5212198297182717 mins\n",
      "Train Loss: [0.61496973, 0.2, 0.2080368, 0.20171683]\n",
      "[0.62046725, 0.2, 0.21437027, 0.20087922]\n",
      "[0.6204625, 0.2, 0.21462362, 0.20061937]\n",
      "[0.6201091, 0.2, 0.20170817, 0.21318004]\n",
      "[0.60980856, 0.2, 0.20313032, 0.20145534]\n",
      "[0.61396605, 0.2, 0.20555483, 0.20318654]\n",
      "[0.6141503, 0.2, 0.2077648, 0.2011594]\n",
      "[0.61557376, 0.2, 0.2078318, 0.20251478]\n",
      "[0.61873394, 0.2, 0.21155225, 0.20195362]\n",
      "[0.6132187, 0.2, 0.2071369, 0.2008538]\n",
      "[0.6246574, 0.2, 0.20522565, 0.21420401]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14660 iterations: 3.5230703314145404 mins\n",
      "Train Loss: [0.6246574, 0.2, 0.20522565, 0.21420401]\n",
      "[0.61312824, 0.2, 0.20571755, 0.20218296]\n",
      "[0.6150597, 0.2, 0.20810845, 0.20172338]\n",
      "[0.6314574, 0.2, 0.2254141, 0.20081533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6117459, 0.2, 0.20435505, 0.20216332]\n",
      "[0.61285865, 0.2, 0.20615998, 0.20147316]\n",
      "[0.6231241, 0.2, 0.21638817, 0.20151202]\n",
      "[0.6223462, 0.2, 0.21631533, 0.20080842]\n",
      "[0.60881597, 0.2, 0.2020511, 0.20154394]\n",
      "[0.62823284, 0.2, 0.22221015, 0.20080315]\n",
      "[0.6155401, 0.2, 0.20868136, 0.20164067]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14670 iterations: 3.5252524336179096 mins\n",
      "Train Loss: [0.6155401, 0.2, 0.20868136, 0.20164067]\n",
      "[0.6160096, 0.2, 0.20977218, 0.20102054]\n",
      "[0.61161256, 0.2, 0.20500383, 0.20139314]\n",
      "[0.61664534, 0.2, 0.20996311, 0.20146747]\n",
      "[0.61231714, 0.2, 0.20617409, 0.20092952]\n",
      "[0.6175996, 0.2, 0.21107809, 0.20130922]\n",
      "[0.61340696, 0.2, 0.20733508, 0.2008609]\n",
      "[0.6090959, 0.2, 0.2033524, 0.20053367]\n",
      "[0.6140505, 0.2, 0.20746285, 0.20137893]\n",
      "[0.6527036, 0.2, 0.24616657, 0.20132922]\n",
      "[0.6092172, 0.2, 0.20241766, 0.20159031]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14680 iterations: 3.527070101102193 mins\n",
      "Train Loss: [0.6092172, 0.2, 0.20241766, 0.20159031]\n",
      "[0.6119897, 0.2, 0.2054892, 0.20128956]\n",
      "[0.61628, 0.2, 0.21001136, 0.20105664]\n",
      "[0.62229866, 0.2, 0.21542887, 0.20165686]\n",
      "[0.6177114, 0.2, 0.21172084, 0.20077622]\n",
      "[0.6135711, 0.2, 0.20748562, 0.2008703]\n",
      "[0.6146094, 0.2, 0.20823462, 0.20115864]\n",
      "[0.6093416, 0.2, 0.20245056, 0.20167437]\n",
      "[0.6153806, 0.2, 0.20906535, 0.20109798]\n",
      "[0.6129787, 0.2, 0.20714636, 0.20061494]\n",
      "[0.6137862, 0.2, 0.20567726, 0.20289172]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14690 iterations: 3.5291095336278278 mins\n",
      "Train Loss: [0.6137862, 0.2, 0.20567726, 0.20289172]\n",
      "[0.6104574, 0.2, 0.2048632, 0.20037714]\n",
      "[0.60940105, 0.2, 0.20313719, 0.20104702]\n",
      "[0.6146777, 0.2, 0.20778298, 0.20167808]\n",
      "[0.6100405, 0.2, 0.20385738, 0.20096709]\n",
      "[0.61256665, 0.2, 0.2059634, 0.20138758]\n",
      "[0.61182153, 0.2, 0.2059029, 0.20070334]\n",
      "[0.6080389, 0.2, 0.2020291, 0.20079502]\n",
      "[0.6080259, 0.2, 0.20211606, 0.2006957]\n",
      "[0.6116863, 0.2, 0.20566143, 0.20081134]\n",
      "[0.6115394, 0.2, 0.20546006, 0.20086683]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14700 iterations: 3.531877565383911 mins\n",
      "Train Loss: [0.6115394, 0.2, 0.20546006, 0.20086683]\n",
      "[0.6095523, 0.2, 0.20339943, 0.20094149]\n",
      "[0.6138229, 0.2, 0.20760567, 0.20100711]\n",
      "[0.60903156, 0.2, 0.20269795, 0.20112514]\n",
      "[0.6348863, 0.2, 0.20624422, 0.22343527]\n",
      "[0.62400126, 0.2, 0.21742956, 0.20136672]\n",
      "[0.61497056, 0.2, 0.20905575, 0.2007139]\n",
      "[0.61549634, 0.2, 0.20883285, 0.20146644]\n",
      "[0.61520064, 0.2, 0.20685156, 0.20315573]\n",
      "[0.6178332, 0.2, 0.21109919, 0.20154431]\n",
      "[0.6134741, 0.2, 0.20654292, 0.20174427]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14710 iterations: 3.5336954673131307 mins\n",
      "Train Loss: [0.6134741, 0.2, 0.20654292, 0.20174427]\n",
      "[0.61249524, 0.2, 0.20461978, 0.20269102]\n",
      "[0.607954, 0.2, 0.2020332, 0.20073853]\n",
      "[0.60911614, 0.2, 0.2028861, 0.2010499]\n",
      "[0.614908, 0.2, 0.20842552, 0.2013044]\n",
      "[0.6074779, 0.2, 0.20088784, 0.20141394]\n",
      "[0.6128154, 0.2, 0.2060936, 0.20154773]\n",
      "[0.61599106, 0.2, 0.2088632, 0.20195584]\n",
      "[0.6088222, 0.2, 0.2030005, 0.20065187]\n",
      "[0.61958086, 0.2, 0.2131269, 0.2012864]\n",
      "[0.6091721, 0.2, 0.20353806, 0.2004686]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14720 iterations: 3.5358095804850262 mins\n",
      "Train Loss: [0.6091721, 0.2, 0.20353806, 0.2004686]\n",
      "[0.61022913, 0.2, 0.20437787, 0.20068805]\n",
      "[0.61021906, 0.2, 0.20393643, 0.20112148]\n",
      "[0.615562, 0.2, 0.20927824, 0.20112474]\n",
      "[0.60972816, 0.2, 0.20334698, 0.20122422]\n",
      "[0.61618304, 0.2, 0.2105431, 0.20048496]\n",
      "[0.6131275, 0.2, 0.20717403, 0.20080009]\n",
      "[0.61069554, 0.2, 0.20478332, 0.20076051]\n",
      "[0.6111208, 0.2, 0.20494935, 0.20102139]\n",
      "[0.6117045, 0.2, 0.20551084, 0.20104565]\n",
      "[0.6186377, 0.2, 0.21193199, 0.20155923]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14730 iterations: 3.5377291679382323 mins\n",
      "Train Loss: [0.6186377, 0.2, 0.21193199, 0.20155923]\n",
      "[0.6103996, 0.2, 0.20423509, 0.2010194]\n",
      "[0.60784465, 0.2, 0.20173231, 0.20096886]\n",
      "[0.61194545, 0.2, 0.20629653, 0.20050697]\n",
      "[0.61511594, 0.2, 0.20896253, 0.20101301]\n",
      "[0.63343745, 0.2, 0.20526779, 0.22303085]\n",
      "[0.60811824, 0.2, 0.20199378, 0.20098738]\n",
      "[0.6151834, 0.2, 0.20889302, 0.20115453]\n",
      "[0.6111722, 0.2, 0.20545752, 0.20058021]\n",
      "[0.61121154, 0.2, 0.20552425, 0.200554]\n",
      "[0.6231358, 0.2, 0.21737354, 0.20062955]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14740 iterations: 3.5397403995196024 mins\n",
      "Train Loss: [0.6231358, 0.2, 0.21737354, 0.20062955]\n",
      "[0.61210686, 0.2, 0.20622224, 0.20075223]\n",
      "[0.61960185, 0.2, 0.21413091, 0.20033823]\n",
      "[0.62836653, 0.2, 0.2034071, 0.21982588]\n",
      "[0.61829984, 0.2, 0.21263085, 0.20053342]\n",
      "[0.610349, 0.2, 0.20443852, 0.20077291]\n",
      "[0.6150097, 0.2, 0.20897643, 0.20089376]\n",
      "[0.6169638, 0.2, 0.20956251, 0.20226029]\n",
      "[0.6077552, 0.2, 0.20189963, 0.20071273]\n",
      "[0.6114791, 0.2, 0.2051461, 0.20118858]\n",
      "[0.60970575, 0.2, 0.20374185, 0.20081824]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14750 iterations: 3.541840700308482 mins\n",
      "Train Loss: [0.60970575, 0.2, 0.20374185, 0.20081824]\n",
      "[0.61210054, 0.2, 0.20579442, 0.20115957]\n",
      "[0.61431307, 0.2, 0.20796032, 0.20120531]\n",
      "[0.6144394, 0.2, 0.20848788, 0.20080365]\n",
      "[0.6182584, 0.2, 0.21152812, 0.20158206]\n",
      "[0.6155442, 0.2, 0.20966794, 0.200728]\n",
      "[0.6095568, 0.2, 0.20345454, 0.2009538]\n",
      "[0.6119947, 0.2, 0.20555836, 0.20128779]\n",
      "[0.611814, 0.2, 0.20572256, 0.20094295]\n",
      "[0.6133161, 0.2, 0.20450331, 0.2036645]\n",
      "[0.6121152, 0.2, 0.20602153, 0.20094596]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14760 iterations: 3.5436680833498637 mins\n",
      "Train Loss: [0.6121152, 0.2, 0.20602153, 0.20094596]\n",
      "[0.6279133, 0.2, 0.22203296, 0.20073296]\n",
      "[0.6101478, 0.2, 0.2036069, 0.20139149]\n",
      "[0.60851276, 0.2, 0.20192729, 0.20143412]\n",
      "[0.6165683, 0.2, 0.21073014, 0.20068529]\n",
      "[0.614526, 0.2, 0.20865615, 0.20071556]\n",
      "[0.60952526, 0.2, 0.20355979, 0.20081028]\n",
      "[0.6130147, 0.2, 0.20695724, 0.20090191]\n",
      "[0.6114769, 0.2, 0.20549588, 0.20082486]\n",
      "[0.61054766, 0.2, 0.20458144, 0.20080976]\n",
      "[0.61112475, 0.2, 0.20552602, 0.20044214]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14770 iterations: 3.546081546942393 mins\n",
      "Train Loss: [0.61112475, 0.2, 0.20552602, 0.20044214]\n",
      "[0.64940953, 0.2, 0.24244913, 0.20180397]\n",
      "[0.612036, 0.2, 0.20647243, 0.20041019]\n",
      "[0.6098425, 0.2, 0.20382658, 0.20086555]\n",
      "[0.62150633, 0.2, 0.20542803, 0.21093099]\n",
      "[0.61125714, 0.2, 0.20546003, 0.20065224]\n",
      "[0.6176166, 0.2, 0.21136802, 0.20110567]\n",
      "[0.62811995, 0.2, 0.22232693, 0.20065206]\n",
      "[0.611405, 0.2, 0.20477466, 0.20149137]\n",
      "[0.6088464, 0.2, 0.20296782, 0.2007415]\n",
      "[0.61594236, 0.2, 0.2097257, 0.2010813]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14780 iterations: 3.548529116312663 mins\n",
      "Train Loss: [0.61594236, 0.2, 0.2097257, 0.2010813]\n",
      "[0.61352056, 0.2, 0.20719853, 0.20118837]\n",
      "[0.6141377, 0.2, 0.20838821, 0.20061764]\n",
      "[0.6118894, 0.2, 0.2051878, 0.20157161]\n",
      "[0.60941, 0.2, 0.20369576, 0.20058616]\n",
      "[0.61595607, 0.2, 0.20851849, 0.20231134]\n",
      "[0.6149374, 0.2, 0.2075027, 0.20231038]\n",
      "[0.61993843, 0.2, 0.21390367, 0.20091228]\n",
      "[0.61095744, 0.2, 0.20455195, 0.20128436]\n",
      "[0.6121414, 0.2, 0.20553513, 0.20148675]\n",
      "[0.61546427, 0.2, 0.2096877, 0.20065852]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14790 iterations: 3.550521651903788 mins\n",
      "Train Loss: [0.61546427, 0.2, 0.2096877, 0.20065852]\n",
      "[0.60922927, 0.2, 0.20228398, 0.2018289]\n",
      "[0.6122994, 0.2, 0.20668535, 0.20049934]\n",
      "[0.639055, 0.2, 0.20562844, 0.22831371]\n",
      "[0.6102446, 0.2, 0.20430897, 0.20082532]\n",
      "[0.61212873, 0.2, 0.2051654, 0.2018555]\n",
      "[0.6159997, 0.2, 0.20953724, 0.2013568]\n",
      "[0.61629945, 0.2, 0.2100656, 0.20113032]\n",
      "[0.61335105, 0.2, 0.20702848, 0.20122096]\n",
      "[0.6155177, 0.2, 0.20967336, 0.2007444]\n",
      "[0.61089146, 0.2, 0.20504302, 0.20075066]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14800 iterations: 3.5525403658548993 mins\n",
      "Train Loss: [0.61089146, 0.2, 0.20504302, 0.20075066]\n",
      "[0.6138184, 0.2, 0.20816164, 0.20056105]\n",
      "[0.6120725, 0.2, 0.20491123, 0.2020676]\n",
      "[0.6122146, 0.2, 0.20609154, 0.2010309]\n",
      "[0.6113281, 0.2, 0.2054773, 0.20075983]\n",
      "[0.6128041, 0.2, 0.20681179, 0.20090248]\n",
      "[0.6116772, 0.2, 0.2058601, 0.20072837]\n",
      "[0.61166805, 0.2, 0.20578542, 0.20079537]\n",
      "[0.62220955, 0.2, 0.2160323, 0.20109098]\n",
      "[0.6174043, 0.2, 0.2117728, 0.20054726]\n",
      "[0.6112959, 0.2, 0.20575199, 0.20046104]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14810 iterations: 3.5544536471366883 mins\n",
      "Train Loss: [0.6112959, 0.2, 0.20575199, 0.20046104]\n",
      "[0.6090152, 0.2, 0.2032058, 0.20072785]\n",
      "[0.61094415, 0.2, 0.20457064, 0.20129342]\n",
      "[0.61634666, 0.2, 0.21035504, 0.20091283]\n",
      "[0.6115886, 0.2, 0.20613919, 0.20037161]\n",
      "[0.6112847, 0.2, 0.20573834, 0.2004695]\n",
      "[0.6118087, 0.2, 0.2052477, 0.20148522]\n",
      "[0.6070574, 0.2, 0.20138855, 0.20059401]\n",
      "[0.6126134, 0.2, 0.20689291, 0.20064673]\n",
      "[0.6151628, 0.2, 0.20942713, 0.20066305]\n",
      "[0.60789835, 0.2, 0.20165506, 0.2011719]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14820 iterations: 3.5565133174260457 mins\n",
      "Train Loss: [0.60789835, 0.2, 0.20165506, 0.2011719]\n",
      "[0.61179614, 0.2, 0.2057932, 0.20093285]\n",
      "[0.6078982, 0.2, 0.20174296, 0.2010867]\n",
      "[0.6131588, 0.2, 0.20750493, 0.20058711]\n",
      "[0.6123601, 0.2, 0.20627055, 0.20102432]\n",
      "[0.6126082, 0.2, 0.20704445, 0.20050006]\n",
      "[0.6170558, 0.2, 0.21012795, 0.20186554]\n",
      "[0.6275836, 0.2, 0.20638908, 0.21613328]\n",
      "[0.61142343, 0.2, 0.20555836, 0.20080413]\n",
      "[0.61449623, 0.2, 0.20820133, 0.2012343]\n",
      "[0.61227995, 0.2, 0.20614469, 0.20107505]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14830 iterations: 3.5584844668706257 mins\n",
      "Train Loss: [0.61227995, 0.2, 0.20614469, 0.20107505]\n",
      "[0.6156059, 0.2, 0.21011236, 0.20043316]\n",
      "[0.61377186, 0.2, 0.20635556, 0.2023556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61694354, 0.2, 0.21104875, 0.20083359]\n",
      "[0.60762346, 0.2, 0.20218827, 0.20037365]\n",
      "[0.61315125, 0.2, 0.20704073, 0.20104884]\n",
      "[0.61309004, 0.2, 0.20692043, 0.20110774]\n",
      "[0.6104337, 0.2, 0.2047405, 0.2006311]\n",
      "[0.61140496, 0.2, 0.20587447, 0.20046823]\n",
      "[0.6073394, 0.2, 0.201884, 0.2003931]\n",
      "[0.6479885, 0.2, 0.24219632, 0.20073001]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14840 iterations: 3.5605745991071065 mins\n",
      "Train Loss: [0.6479885, 0.2, 0.24219632, 0.20073001]\n",
      "[0.60879314, 0.2, 0.2024073, 0.2013218]\n",
      "[0.61589444, 0.2, 0.20979972, 0.20102921]\n",
      "[0.6072505, 0.2, 0.20151617, 0.20066763]\n",
      "[0.6108904, 0.2, 0.20514666, 0.20067589]\n",
      "[0.6108915, 0.2, 0.20512652, 0.20069626]\n",
      "[0.60936916, 0.2, 0.20378034, 0.20051944]\n",
      "[0.61092234, 0.2, 0.20470808, 0.20114455]\n",
      "[0.6092568, 0.2, 0.20367672, 0.20051026]\n",
      "[0.6123612, 0.2, 0.20668642, 0.20060538]\n",
      "[0.6068378, 0.2, 0.20092052, 0.20084871]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14850 iterations: 3.5625213464101155 mins\n",
      "Train Loss: [0.6068378, 0.2, 0.20092052, 0.20084871]\n",
      "[0.61768186, 0.2, 0.21200632, 0.2006079]\n",
      "[0.60943776, 0.2, 0.20354845, 0.20082292]\n",
      "[0.6064856, 0.2, 0.20083065, 0.20058985]\n",
      "[0.61760724, 0.2, 0.2110164, 0.20152724]\n",
      "[0.6109564, 0.2, 0.20530556, 0.20058954]\n",
      "[0.60903895, 0.2, 0.20268367, 0.2012962]\n",
      "[0.61104554, 0.2, 0.20512293, 0.20086597]\n",
      "[0.61524695, 0.2, 0.20931767, 0.20087524]\n",
      "[0.6096311, 0.2, 0.20362957, 0.2009499]\n",
      "[0.6124275, 0.2, 0.20677572, 0.20060256]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14860 iterations: 3.5650267521540324 mins\n",
      "Train Loss: [0.6124275, 0.2, 0.20677572, 0.20060256]\n",
      "[0.61185586, 0.2, 0.20613164, 0.20067725]\n",
      "[0.61859703, 0.2, 0.21299335, 0.20055917]\n",
      "[0.61154366, 0.2, 0.20566858, 0.20083292]\n",
      "[0.60777223, 0.2, 0.2018469, 0.20088576]\n",
      "[0.608141, 0.2, 0.20218968, 0.20091522]\n",
      "[0.61549735, 0.2, 0.2088724, 0.20159219]\n",
      "[0.6133882, 0.2, 0.20794302, 0.20041604]\n",
      "[0.6132312, 0.2, 0.20740606, 0.2007992]\n",
      "[0.61167103, 0.2, 0.20629574, 0.20035194]\n",
      "[0.6076169, 0.2, 0.20160347, 0.20099226]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14870 iterations: 3.5670934478441874 mins\n",
      "Train Loss: [0.6076169, 0.2, 0.20160347, 0.20099226]\n",
      "[0.63812906, 0.2, 0.23218651, 0.20092355]\n",
      "[0.61316663, 0.2, 0.20738845, 0.20075971]\n",
      "[0.6115474, 0.2, 0.20526831, 0.20126115]\n",
      "[0.61113745, 0.2, 0.2050288, 0.20109083]\n",
      "[0.6098103, 0.2, 0.20421961, 0.20057331]\n",
      "[0.61206776, 0.2, 0.20594695, 0.20110379]\n",
      "[0.607307, 0.2, 0.20169145, 0.20059885]\n",
      "[0.6217623, 0.2, 0.21563727, 0.20110855]\n",
      "[0.60953945, 0.2, 0.20323908, 0.20128402]\n",
      "[0.60815597, 0.2, 0.20220298, 0.20093705]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14880 iterations: 3.5689165194829306 mins\n",
      "Train Loss: [0.60815597, 0.2, 0.20220298, 0.20093705]\n",
      "[0.6468144, 0.2, 0.24107173, 0.2007271]\n",
      "[0.61243486, 0.2, 0.20583142, 0.20158921]\n",
      "[0.61471903, 0.2, 0.20906875, 0.20063728]\n",
      "[0.627332, 0.2, 0.20344247, 0.21887761]\n",
      "[0.60888094, 0.2, 0.2031603, 0.2007097]\n",
      "[0.61769533, 0.2, 0.21180776, 0.20087746]\n",
      "[0.61135226, 0.2, 0.20451519, 0.20182726]\n",
      "[0.61797434, 0.2, 0.21197362, 0.20099138]\n",
      "[0.6063741, 0.2, 0.20095286, 0.20041184]\n",
      "[0.6088694, 0.2, 0.20326893, 0.20059094]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14890 iterations: 3.570923634370168 mins\n",
      "Train Loss: [0.6088694, 0.2, 0.20326893, 0.20059094]\n",
      "[0.61499, 0.2, 0.20843792, 0.20154248]\n",
      "[0.6108982, 0.2, 0.20477495, 0.20111366]\n",
      "[0.6083091, 0.2, 0.20260856, 0.20069087]\n",
      "[0.616913, 0.2, 0.21097524, 0.20092818]\n",
      "[0.61286014, 0.2, 0.20649227, 0.20135766]\n",
      "[0.60971916, 0.2, 0.20328625, 0.20142184]\n",
      "[0.61984843, 0.2, 0.21413346, 0.20070297]\n",
      "[0.61060613, 0.2, 0.20526, 0.20033288]\n",
      "[0.60802484, 0.2, 0.20200604, 0.20100401]\n",
      "[0.61554796, 0.2, 0.209846, 0.20068653]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14900 iterations: 3.572835131486257 mins\n",
      "Train Loss: [0.61554796, 0.2, 0.209846, 0.20068653]\n",
      "[0.61187965, 0.2, 0.20557137, 0.20129265]\n",
      "[0.60994244, 0.2, 0.2031105, 0.20181632]\n",
      "[0.614116, 0.2, 0.20775081, 0.20135063]\n",
      "[0.6075486, 0.2, 0.20135999, 0.201175]\n",
      "[0.6172886, 0.2, 0.20213547, 0.21014059]\n",
      "[0.62472135, 0.2, 0.20902401, 0.21068591]\n",
      "[0.60870117, 0.2, 0.20281728, 0.20087335]\n",
      "[0.62055403, 0.2, 0.20485653, 0.21068771]\n",
      "[0.61346585, 0.2, 0.20703596, 0.201421]\n",
      "[0.61414784, 0.2, 0.20843467, 0.20070545]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14910 iterations: 3.5749095837275187 mins\n",
      "Train Loss: [0.61414784, 0.2, 0.20843467, 0.20070545]\n",
      "[0.6109279, 0.2, 0.20507059, 0.20085095]\n",
      "[0.6206925, 0.2, 0.21495596, 0.20073128]\n",
      "[0.62364876, 0.2, 0.20597923, 0.21266548]\n",
      "[0.6122333, 0.2, 0.20607413, 0.2011554]\n",
      "[0.6104688, 0.2, 0.20465891, 0.20080574]\n",
      "[0.6165213, 0.2, 0.21116117, 0.20035535]\n",
      "[0.6181708, 0.2, 0.21243554, 0.20072968]\n",
      "[0.6113257, 0.2, 0.20560768, 0.20071147]\n",
      "[0.61571366, 0.2, 0.20968252, 0.20102404]\n",
      "[0.626639, 0.2, 0.22061925, 0.20101254]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14920 iterations: 3.5768101652463278 mins\n",
      "Train Loss: [0.626639, 0.2, 0.22061925, 0.20101254]\n",
      "[0.61380005, 0.2, 0.20843071, 0.20036061]\n",
      "[0.6115157, 0.2, 0.20578732, 0.20071843]\n",
      "[0.60933316, 0.2, 0.20304891, 0.20127359]\n",
      "[0.61690354, 0.2, 0.21153605, 0.20035657]\n",
      "[0.61299866, 0.2, 0.20696339, 0.2010244]\n",
      "[0.61083007, 0.2, 0.20490403, 0.20091568]\n",
      "[0.6118226, 0.2, 0.20604451, 0.20076825]\n",
      "[0.6102617, 0.2, 0.20456822, 0.20068453]\n",
      "[0.60651094, 0.2, 0.20048329, 0.2010197]\n",
      "[0.6104917, 0.2, 0.20464152, 0.20084348]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14930 iterations: 3.57893944978714 mins\n",
      "Train Loss: [0.6104917, 0.2, 0.20464152, 0.20084348]\n",
      "[0.60689527, 0.2, 0.20119317, 0.20069642]\n",
      "[0.60992384, 0.2, 0.20425296, 0.20066652]\n",
      "[0.6101611, 0.2, 0.20463233, 0.2005258]\n",
      "[0.61217344, 0.2, 0.20633222, 0.20084019]\n",
      "[0.6311369, 0.2, 0.22512768, 0.20101044]\n",
      "[0.61230236, 0.2, 0.20644978, 0.20085423]\n",
      "[0.61145204, 0.2, 0.20588687, 0.2005671]\n",
      "[0.6214084, 0.2, 0.20670933, 0.20970191]\n",
      "[0.61131686, 0.2, 0.20447639, 0.2018433]\n",
      "[0.61050314, 0.2, 0.20485917, 0.20064688]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14940 iterations: 3.5814506649971007 mins\n",
      "Train Loss: [0.61050314, 0.2, 0.20485917, 0.20064688]\n",
      "[0.60727257, 0.2, 0.20170626, 0.20056915]\n",
      "[0.6101877, 0.2, 0.20377935, 0.20141134]\n",
      "[0.6111501, 0.2, 0.20556268, 0.20059074]\n",
      "[0.6088761, 0.2, 0.20338018, 0.20049949]\n",
      "[0.61081314, 0.2, 0.20511621, 0.20070083]\n",
      "[0.6136909, 0.2, 0.20803702, 0.2006585]\n",
      "[0.6103325, 0.2, 0.20486404, 0.200474]\n",
      "[0.6090672, 0.2, 0.20368972, 0.20038402]\n",
      "[0.60785544, 0.2, 0.20199175, 0.20087156]\n",
      "[0.6133481, 0.2, 0.20746115, 0.20089635]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14950 iterations: 3.583305529753367 mins\n",
      "Train Loss: [0.6133481, 0.2, 0.20746115, 0.20089635]\n",
      "[0.6153099, 0.2, 0.20815396, 0.2021671]\n",
      "[0.6116039, 0.2, 0.20384662, 0.20277037]\n",
      "[0.6083888, 0.2, 0.20279546, 0.20060873]\n",
      "[0.6130148, 0.2, 0.20710582, 0.20092691]\n",
      "[0.61108553, 0.2, 0.20456827, 0.20153764]\n",
      "[0.6127021, 0.2, 0.2073822, 0.2003429]\n",
      "[0.6104267, 0.2, 0.20404725, 0.20140502]\n",
      "[0.61335975, 0.2, 0.20745501, 0.20093282]\n",
      "[0.60853255, 0.2, 0.20231873, 0.2012443]\n",
      "[0.61302125, 0.2, 0.20669253, 0.20136166]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14960 iterations: 3.585426449775696 mins\n",
      "Train Loss: [0.61302125, 0.2, 0.20669253, 0.20136166]\n",
      "[0.61268604, 0.2, 0.20666057, 0.20106067]\n",
      "[0.6091463, 0.2, 0.20343222, 0.20075132]\n",
      "[0.6273804, 0.2, 0.22089104, 0.20152852]\n",
      "[0.60993695, 0.2, 0.20365968, 0.20131603]\n",
      "[0.6100204, 0.2, 0.20460394, 0.20045471]\n",
      "[0.6152991, 0.2, 0.20977925, 0.2005575]\n",
      "[0.6110283, 0.2, 0.20520115, 0.20086409]\n",
      "[0.6158596, 0.2, 0.2088002, 0.20209596]\n",
      "[0.6077103, 0.2, 0.20236121, 0.20038475]\n",
      "[0.6299957, 0.2, 0.21051046, 0.2145204]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14970 iterations: 3.5873727480570476 mins\n",
      "Train Loss: [0.6299957, 0.2, 0.21051046, 0.2145204]\n",
      "[0.6079996, 0.2, 0.20171173, 0.20132375]\n",
      "[0.6104878, 0.2, 0.20518604, 0.20033784]\n",
      "[0.61240095, 0.2, 0.20708975, 0.20034711]\n",
      "[0.6139275, 0.2, 0.20537138, 0.2035915]\n",
      "[0.6099283, 0.2, 0.2043451, 0.20061798]\n",
      "[0.6140522, 0.2, 0.20805852, 0.20102766]\n",
      "[0.60891676, 0.2, 0.20275135, 0.2011991]\n",
      "[0.6102572, 0.2, 0.20330974, 0.20198078]\n",
      "[0.61037713, 0.2, 0.2040836, 0.20132644]\n",
      "[0.6099051, 0.2, 0.20407614, 0.20086166]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14980 iterations: 3.589668063322703 mins\n",
      "Train Loss: [0.6099051, 0.2, 0.20407614, 0.20086166]\n",
      "[0.60691476, 0.2, 0.20110968, 0.2008375]\n",
      "[0.6106609, 0.2, 0.2054497, 0.20024367]\n",
      "[0.6128189, 0.2, 0.20507525, 0.20277591]\n",
      "[0.6099176, 0.2, 0.20458521, 0.20036553]\n",
      "[0.6098426, 0.2, 0.20401819, 0.20085827]\n",
      "[0.61127025, 0.2, 0.20575416, 0.20055057]\n",
      "[0.60751784, 0.2, 0.20174782, 0.20080481]\n",
      "[0.61642194, 0.2, 0.2105265, 0.20093064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6101198, 0.2, 0.20406304, 0.2010924]\n",
      "[0.61134857, 0.2, 0.20554717, 0.20083748]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14990 iterations: 3.5917699654897053 mins\n",
      "Train Loss: [0.61134857, 0.2, 0.20554717, 0.20083748]\n",
      "[0.61289865, 0.2, 0.20668384, 0.2012514]\n",
      "[0.6128359, 0.2, 0.20703863, 0.20083453]\n",
      "[0.61137176, 0.2, 0.20583451, 0.20057537]\n",
      "[0.60693246, 0.2, 0.20161977, 0.20035183]\n",
      "[0.614032, 0.2, 0.20836663, 0.20070578]\n",
      "[0.61197066, 0.2, 0.2065106, 0.2005019]\n",
      "[0.60866666, 0.2, 0.20287319, 0.20083703]\n",
      "[0.6094278, 0.2, 0.20371477, 0.20075808]\n",
      "[0.6096318, 0.2, 0.20374233, 0.20093626]\n",
      "[0.61351025, 0.2, 0.20721938, 0.2013396]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15000 iterations: 3.593716597557068 mins\n",
      "Train Loss: [0.61351025, 0.2, 0.20721938, 0.2013396]\n",
      "[0.61839396, 0.2, 0.21261637, 0.20082861]\n",
      "[0.60914403, 0.2, 0.20304905, 0.20114823]\n",
      "[0.6159622, 0.2, 0.20995873, 0.2010587]\n",
      "[0.60999864, 0.2, 0.20375231, 0.20130382]\n",
      "[0.63213885, 0.2, 0.22597437, 0.2012242]\n",
      "[0.63882554, 0.2, 0.2041839, 0.2297015]\n",
      "[0.61872464, 0.2, 0.21277446, 0.20100902]\n",
      "[0.6070893, 0.2, 0.20089234, 0.20125416]\n",
      "[0.60878164, 0.2, 0.20276515, 0.20107186]\n",
      "[0.61081576, 0.2, 0.20470642, 0.201163]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15010 iterations: 3.59573100010554 mins\n",
      "Train Loss: [0.61081576, 0.2, 0.20470642, 0.201163]\n",
      "[0.61085284, 0.2, 0.20508853, 0.2008159]\n",
      "[0.6098622, 0.2, 0.20441405, 0.20049785]\n",
      "[0.6093574, 0.2, 0.20396787, 0.20043766]\n",
      "[0.61117166, 0.2, 0.20548898, 0.20072915]\n",
      "[0.60990024, 0.2, 0.20388782, 0.20105737]\n",
      "[0.62222475, 0.2, 0.21626967, 0.20099822]\n",
      "[0.6059501, 0.2, 0.2005277, 0.2004641]\n",
      "[0.60966694, 0.2, 0.20379762, 0.20090967]\n",
      "[0.6090039, 0.2, 0.20306407, 0.2009801]\n",
      "[0.61014646, 0.2, 0.2045096, 0.20067702]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15020 iterations: 3.598109165827433 mins\n",
      "Train Loss: [0.61014646, 0.2, 0.2045096, 0.20067702]\n",
      "[0.61370426, 0.2, 0.20829904, 0.20044535]\n",
      "[0.61922795, 0.2, 0.21385069, 0.20041744]\n",
      "[0.61483973, 0.2, 0.2087836, 0.2010963]\n",
      "[0.6117924, 0.2, 0.20578179, 0.2010502]\n",
      "[0.6104697, 0.2, 0.20482713, 0.20068194]\n",
      "[0.61698055, 0.2, 0.21127717, 0.20074266]\n",
      "[0.6175791, 0.2, 0.20323637, 0.20938174]\n",
      "[0.60820574, 0.2, 0.20185864, 0.20138712]\n",
      "[0.6180828, 0.2, 0.21052861, 0.20259482]\n",
      "[0.61513114, 0.2, 0.20934561, 0.20082642]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15030 iterations: 3.600160233179728 mins\n",
      "Train Loss: [0.61513114, 0.2, 0.20934561, 0.20082642]\n",
      "[0.6195213, 0.2, 0.2134923, 0.20106985]\n",
      "[0.6120766, 0.2, 0.20597973, 0.20113714]\n",
      "[0.6096622, 0.2, 0.20419428, 0.20050733]\n",
      "[0.6631216, 0.2, 0.23041101, 0.22774905]\n",
      "[0.60915, 0.2, 0.20352592, 0.20066187]\n",
      "[0.61136705, 0.2, 0.20591733, 0.20048638]\n",
      "[0.6080486, 0.2, 0.20272984, 0.20035392]\n",
      "[0.61867434, 0.2, 0.21243133, 0.20127667]\n",
      "[0.6171401, 0.2, 0.21051423, 0.20165798]\n",
      "[0.61396563, 0.2, 0.20876534, 0.2002307]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15040 iterations: 3.602024734020233 mins\n",
      "Train Loss: [0.61396563, 0.2, 0.20876534, 0.2002307]\n",
      "[0.61008286, 0.2, 0.20407946, 0.2010317]\n",
      "[0.635555, 0.2, 0.22975947, 0.20082135]\n",
      "[0.6103148, 0.2, 0.20467539, 0.20066178]\n",
      "[0.628899, 0.2, 0.20220518, 0.22171251]\n",
      "[0.6181462, 0.2, 0.21161312, 0.20154732]\n",
      "[0.6228363, 0.2, 0.21673048, 0.2011161]\n",
      "[0.62067974, 0.2, 0.21512295, 0.20056307]\n",
      "[0.61104155, 0.2, 0.2048383, 0.20120628]\n",
      "[0.6111925, 0.2, 0.2056027, 0.20059]\n",
      "[0.6080791, 0.2, 0.20166586, 0.2014107]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15050 iterations: 3.6039864500363668 mins\n",
      "Train Loss: [0.6080791, 0.2, 0.20166586, 0.2014107]\n",
      "[0.6094544, 0.2, 0.20348983, 0.20095974]\n",
      "[0.61250573, 0.2, 0.20676278, 0.20073591]\n",
      "[0.62017876, 0.2, 0.21453124, 0.20063911]\n",
      "[0.61736256, 0.2, 0.21058258, 0.20176998]\n",
      "[0.61384165, 0.2, 0.2075489, 0.20128122]\n",
      "[0.6113627, 0.2, 0.20525497, 0.20109475]\n",
      "[0.6109939, 0.2, 0.2053479, 0.2006316]\n",
      "[0.61294544, 0.2, 0.20640959, 0.2015204]\n",
      "[0.61194915, 0.2, 0.20627105, 0.20066231]\n",
      "[0.6160262, 0.2, 0.20979494, 0.20121513]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15060 iterations: 3.606031334400177 mins\n",
      "Train Loss: [0.6160262, 0.2, 0.20979494, 0.20121513]\n",
      "[0.61483145, 0.2, 0.20811589, 0.2016992]\n",
      "[0.6150618, 0.2, 0.20912512, 0.20092066]\n",
      "[0.6154561, 0.2, 0.20882812, 0.2016123]\n",
      "[0.6087446, 0.2, 0.20253257, 0.20119634]\n",
      "[0.6186237, 0.2, 0.21267286, 0.20093513]\n",
      "[0.6138445, 0.2, 0.20817143, 0.20065741]\n",
      "[0.61391056, 0.2, 0.2067523, 0.20214231]\n",
      "[0.60871536, 0.2, 0.20306782, 0.20063134]\n",
      "[0.6108905, 0.2, 0.20509432, 0.20077957]\n",
      "[0.6074736, 0.2, 0.20158128, 0.2008757]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15070 iterations: 3.6078658660252887 mins\n",
      "Train Loss: [0.6074736, 0.2, 0.20158128, 0.2008757]\n",
      "[0.6227076, 0.2, 0.2036939, 0.21399684]\n",
      "[0.61359406, 0.2, 0.20791699, 0.20065935]\n",
      "[0.6093894, 0.2, 0.20377302, 0.2005981]\n",
      "[0.6075097, 0.2, 0.2015036, 0.20098707]\n",
      "[0.6122609, 0.2, 0.20602994, 0.20121138]\n",
      "[0.6105714, 0.2, 0.20444335, 0.2011086]\n",
      "[0.61321265, 0.2, 0.20784257, 0.20035093]\n",
      "[0.62010443, 0.2, 0.214061, 0.20102444]\n",
      "[0.6095629, 0.2, 0.20337594, 0.20116818]\n",
      "[0.6171275, 0.2, 0.21109264, 0.20101693]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15080 iterations: 3.6098970333735148 mins\n",
      "Train Loss: [0.6171275, 0.2, 0.21109264, 0.20101693]\n",
      "[0.61129904, 0.2, 0.20510928, 0.20117334]\n",
      "[0.6142301, 0.2, 0.20755534, 0.20165946]\n",
      "[0.6209962, 0.2, 0.21498571, 0.20099692]\n",
      "[0.63825464, 0.2, 0.20194744, 0.23129612]\n",
      "[0.6069078, 0.2, 0.2013011, 0.20059767]\n",
      "[0.6150884, 0.2, 0.20958789, 0.20049359]\n",
      "[0.60840166, 0.2, 0.20259474, 0.20080204]\n",
      "[0.6098316, 0.2, 0.2040982, 0.20073135]\n",
      "[0.61117977, 0.2, 0.2056774, 0.20050323]\n",
      "[0.6102825, 0.2, 0.20373648, 0.20154972]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15090 iterations: 3.6117859840393067 mins\n",
      "Train Loss: [0.6102825, 0.2, 0.20373648, 0.20154972]\n",
      "[0.6120868, 0.2, 0.20644702, 0.20064618]\n",
      "[0.61235166, 0.2, 0.20698652, 0.20037416]\n",
      "[0.60833615, 0.2, 0.20241626, 0.2009318]\n",
      "[0.60957354, 0.2, 0.2033885, 0.20119981]\n",
      "[0.6090789, 0.2, 0.2023726, 0.20172401]\n",
      "[0.62283397, 0.2, 0.21726437, 0.20059003]\n",
      "[0.6107697, 0.2, 0.20416692, 0.201626]\n",
      "[0.60998315, 0.2, 0.20338295, 0.20162633]\n",
      "[0.62752485, 0.2, 0.22109817, 0.20145576]\n",
      "[0.64060193, 0.2, 0.2027096, 0.23292476]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15100 iterations: 3.6147759636243184 mins\n",
      "Train Loss: [0.64060193, 0.2, 0.2027096, 0.23292476]\n",
      "[0.6126297, 0.2, 0.20711873, 0.2005475]\n",
      "[0.61013913, 0.2, 0.20476447, 0.20041505]\n",
      "[0.6108385, 0.2, 0.20524833, 0.20063454]\n",
      "[0.60873365, 0.2, 0.20323, 0.20055172]\n",
      "[0.6107882, 0.2, 0.2049684, 0.20087133]\n",
      "[0.61625326, 0.2, 0.21053739, 0.20077117]\n",
      "[0.6111498, 0.2, 0.20561281, 0.20059626]\n",
      "[0.6065271, 0.2, 0.2013385, 0.20025149]\n",
      "[0.60901624, 0.2, 0.20371673, 0.20036605]\n",
      "[0.6106812, 0.2, 0.20530741, 0.20044404]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15110 iterations: 3.6184133648872376 mins\n",
      "Train Loss: [0.6106812, 0.2, 0.20530741, 0.20044404]\n",
      "[0.615023, 0.2, 0.20961371, 0.20048317]\n",
      "[0.6098242, 0.2, 0.20451367, 0.2003879]\n",
      "[0.60924387, 0.2, 0.20355266, 0.20077202]\n",
      "[0.61212873, 0.2, 0.20638858, 0.20082426]\n",
      "[0.6126136, 0.2, 0.20700613, 0.20069501]\n",
      "[0.61145943, 0.2, 0.2060471, 0.20050308]\n",
      "[0.6168316, 0.2, 0.21094722, 0.20097826]\n",
      "[0.60888296, 0.2, 0.20297147, 0.20100898]\n",
      "[0.61840004, 0.2, 0.21254876, 0.20095254]\n",
      "[0.6075641, 0.2, 0.20219475, 0.20047398]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15120 iterations: 3.621081082026164 mins\n",
      "Train Loss: [0.6075641, 0.2, 0.20219475, 0.20047398]\n",
      "[0.6136087, 0.2, 0.20805512, 0.20066155]\n",
      "[0.60837173, 0.2, 0.20300858, 0.20047472]\n",
      "[0.61328685, 0.2, 0.20777024, 0.20063157]\n",
      "[0.6085964, 0.2, 0.20322102, 0.20049392]\n",
      "[0.61329377, 0.2, 0.20790981, 0.20050584]\n",
      "[0.60669684, 0.2, 0.20126918, 0.2005527]\n",
      "[0.6086438, 0.2, 0.2029421, 0.20082965]\n",
      "[0.613092, 0.2, 0.20730065, 0.20092218]\n",
      "[0.60982704, 0.2, 0.20451339, 0.20044728]\n",
      "[0.6105811, 0.2, 0.20514119, 0.20057638]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15130 iterations: 3.6249943653742474 mins\n",
      "Train Loss: [0.6105811, 0.2, 0.20514119, 0.20057638]\n",
      "[0.6124781, 0.2, 0.20713341, 0.20048387]\n",
      "[0.61063975, 0.2, 0.20511988, 0.2006617]\n",
      "[0.6089578, 0.2, 0.2035289, 0.20057331]\n",
      "[0.6078383, 0.2, 0.20248505, 0.20050006]\n",
      "[0.6235959, 0.2, 0.21835303, 0.20039225]\n",
      "[0.6137717, 0.2, 0.20810916, 0.20081554]\n",
      "[0.6080989, 0.2, 0.20257677, 0.20067875]\n",
      "[0.60941714, 0.2, 0.20427662, 0.20030072]\n",
      "[0.6224844, 0.2, 0.21726654, 0.20038141]\n",
      "[0.6108274, 0.2, 0.20531692, 0.20067699]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15140 iterations: 3.6271942178408305 mins\n",
      "Train Loss: [0.6108274, 0.2, 0.20531692, 0.20067699]\n",
      "[0.61459434, 0.2, 0.20922329, 0.2005406]\n",
      "[0.6079163, 0.2, 0.20247796, 0.20061032]\n",
      "[0.60737705, 0.2, 0.20194079, 0.20061079]\n",
      "[0.6159686, 0.2, 0.21055299, 0.20059262]\n",
      "[0.6161926, 0.2, 0.21044315, 0.20092891]\n",
      "[0.61820585, 0.2, 0.21306428, 0.20032339]\n",
      "[0.6316672, 0.2, 0.20914355, 0.21770778]\n",
      "[0.6085292, 0.2, 0.2032991, 0.20041637]\n",
      "[0.61155564, 0.2, 0.20623177, 0.20051213]\n",
      "[0.61095965, 0.2, 0.20567712, 0.20047279]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15150 iterations: 3.6292509476343793 mins\n",
      "Train Loss: [0.61095965, 0.2, 0.20567712, 0.20047279]\n",
      "[0.6124204, 0.2, 0.20726852, 0.20034407]\n",
      "[0.6219312, 0.2, 0.21668208, 0.2004432]\n",
      "[0.6065552, 0.2, 0.20109549, 0.20065461]\n",
      "[0.6106528, 0.2, 0.2053773, 0.20047133]\n",
      "[0.6144055, 0.2, 0.20926629, 0.20033601]\n",
      "[0.6083126, 0.2, 0.2025966, 0.20091347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.608949, 0.2, 0.20393504, 0.20021212]\n",
      "[0.611218, 0.2, 0.20577239, 0.20064425]\n",
      "[0.61063945, 0.2, 0.2053494, 0.20048945]\n",
      "[0.60722375, 0.2, 0.20161739, 0.2008067]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15160 iterations: 3.631786533196767 mins\n",
      "Train Loss: [0.60722375, 0.2, 0.20161739, 0.2008067]\n",
      "[0.613959, 0.2, 0.2085293, 0.20063132]\n",
      "[0.6133473, 0.2, 0.20811996, 0.2004304]\n",
      "[0.62602055, 0.2, 0.22060768, 0.200617]\n",
      "[0.61264056, 0.2, 0.20747598, 0.2003718]\n",
      "[0.61336404, 0.2, 0.20749974, 0.20107435]\n",
      "[0.60939527, 0.2, 0.20405555, 0.20055234]\n",
      "[0.612937, 0.2, 0.20752767, 0.20062427]\n",
      "[0.6116738, 0.2, 0.20624964, 0.20064135]\n",
      "[0.6133061, 0.2, 0.20764463, 0.2008807]\n",
      "[0.6068175, 0.2, 0.20173195, 0.20030668]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15170 iterations: 3.6336671312650046 mins\n",
      "Train Loss: [0.6068175, 0.2, 0.20173195, 0.20030668]\n",
      "[0.6089997, 0.2, 0.20369942, 0.20052338]\n",
      "[0.6256378, 0.2, 0.20337577, 0.217487]\n",
      "[0.60789657, 0.2, 0.20242281, 0.20070179]\n",
      "[0.6224469, 0.2, 0.21717869, 0.20049916]\n",
      "[0.60805625, 0.2, 0.20252581, 0.2007651]\n",
      "[0.6108325, 0.2, 0.20545001, 0.20062043]\n",
      "[0.6089231, 0.2, 0.20328389, 0.20088036]\n",
      "[0.6119867, 0.2, 0.20671718, 0.20051357]\n",
      "[0.60984474, 0.2, 0.20454764, 0.20054372]\n",
      "[0.61015636, 0.2, 0.20431389, 0.20109133]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15180 iterations: 3.635692516962687 mins\n",
      "Train Loss: [0.61015636, 0.2, 0.20431389, 0.20109133]\n",
      "[0.6079801, 0.2, 0.20249471, 0.20073661]\n",
      "[0.6080484, 0.2, 0.20242035, 0.20088154]\n",
      "[0.6100044, 0.2, 0.20432355, 0.20093647]\n",
      "[0.6107918, 0.2, 0.20575301, 0.20029636]\n",
      "[0.6115627, 0.2, 0.2062446, 0.2005776]\n",
      "[0.6076179, 0.2, 0.20250629, 0.20037259]\n",
      "[0.61502814, 0.2, 0.20985636, 0.20043418]\n",
      "[0.6094277, 0.2, 0.2041315, 0.2005598]\n",
      "[0.61157936, 0.2, 0.20577462, 0.20106949]\n",
      "[0.61421645, 0.2, 0.20879212, 0.20069075]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15190 iterations: 3.6375614484151204 mins\n",
      "Train Loss: [0.61421645, 0.2, 0.20879212, 0.20069075]\n",
      "[0.61204296, 0.2, 0.20621695, 0.20109378]\n",
      "[0.6081852, 0.2, 0.2030292, 0.2004247]\n",
      "[0.6117208, 0.2, 0.20641635, 0.20057346]\n",
      "[0.6125116, 0.2, 0.20654705, 0.20123331]\n",
      "[0.6131598, 0.2, 0.20802669, 0.20040147]\n",
      "[0.61384225, 0.2, 0.2078805, 0.20122936]\n",
      "[0.6076895, 0.2, 0.20212506, 0.20083109]\n",
      "[0.66266465, 0.2, 0.20758323, 0.25034717]\n",
      "[0.6368648, 0.2, 0.21544343, 0.21668556]\n",
      "[0.61343914, 0.2, 0.20810284, 0.20059842]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15200 iterations: 3.6395491480827333 mins\n",
      "Train Loss: [0.61343914, 0.2, 0.20810284, 0.20059842]\n",
      "[0.6093471, 0.2, 0.20393819, 0.2006689]\n",
      "[0.6164717, 0.2, 0.2109868, 0.20074278]\n",
      "[0.6142871, 0.2, 0.20933154, 0.20021111]\n",
      "[0.6163144, 0.2, 0.2112477, 0.20032021]\n",
      "[0.60816914, 0.2, 0.20308796, 0.20033261]\n",
      "[0.6126028, 0.2, 0.20726578, 0.20058677]\n",
      "[0.60895085, 0.2, 0.20371854, 0.20048074]\n",
      "[0.62076825, 0.2, 0.21530761, 0.20070799]\n",
      "[0.6158091, 0.2, 0.21081726, 0.20023844]\n",
      "[0.6096103, 0.2, 0.20453547, 0.20032102]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15210 iterations: 3.6415715138117473 mins\n",
      "Train Loss: [0.6096103, 0.2, 0.20453547, 0.20032102]\n",
      "[0.6144276, 0.2, 0.2089908, 0.20068257]\n",
      "[0.6134013, 0.2, 0.2079505, 0.20069641]\n",
      "[0.6119318, 0.2, 0.2064755, 0.20070188]\n",
      "[0.6231574, 0.2, 0.21813194, 0.20027126]\n",
      "[0.6135724, 0.2, 0.20846006, 0.20035776]\n",
      "[0.63256717, 0.2, 0.20736562, 0.22044668]\n",
      "[0.60748225, 0.2, 0.20224059, 0.20048785]\n",
      "[0.60713726, 0.2, 0.20185986, 0.20052448]\n",
      "[0.60919094, 0.2, 0.20403618, 0.20040303]\n",
      "[0.6113905, 0.2, 0.20585956, 0.20078029]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15220 iterations: 3.643440131346385 mins\n",
      "Train Loss: [0.6113905, 0.2, 0.20585956, 0.20078029]\n",
      "[0.6136075, 0.2, 0.20793365, 0.20092447]\n",
      "[0.6170917, 0.2, 0.21150735, 0.20083627]\n",
      "[0.6227136, 0.2, 0.20346728, 0.2144998]\n",
      "[0.6093248, 0.2, 0.20383431, 0.20074505]\n",
      "[0.6158423, 0.2, 0.21045123, 0.20064631]\n",
      "[0.6121132, 0.2, 0.2064809, 0.20088802]\n",
      "[0.6155058, 0.2, 0.20981601, 0.20094614]\n",
      "[0.62350637, 0.2, 0.21797949, 0.20078373]\n",
      "[0.6116821, 0.2, 0.20652723, 0.20041218]\n",
      "[0.6103226, 0.2, 0.20540175, 0.2001788]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15230 iterations: 3.645506183306376 mins\n",
      "Train Loss: [0.6103226, 0.2, 0.20540175, 0.2001788]\n",
      "[0.6079385, 0.2, 0.2029021, 0.20029524]\n",
      "[0.61238503, 0.2, 0.20716368, 0.20048088]\n",
      "[0.6072807, 0.2, 0.2019938, 0.20054705]\n",
      "[0.60715586, 0.2, 0.20178677, 0.20063005]\n",
      "[0.613085, 0.2, 0.20786653, 0.20048025]\n",
      "[0.610839, 0.2, 0.20538166, 0.20072009]\n",
      "[0.610388, 0.2, 0.20528577, 0.20036636]\n",
      "[0.61256284, 0.2, 0.20723987, 0.20058839]\n",
      "[0.61427975, 0.2, 0.20899713, 0.20054916]\n",
      "[0.6136647, 0.2, 0.2084176, 0.20051472]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15240 iterations: 3.6477916677792868 mins\n",
      "Train Loss: [0.6136647, 0.2, 0.2084176, 0.20051472]\n",
      "[0.61232036, 0.2, 0.20705543, 0.20053348]\n",
      "[0.6148866, 0.2, 0.20952553, 0.2006303]\n",
      "[0.6120502, 0.2, 0.20662361, 0.2006968]\n",
      "[0.6287939, 0.2, 0.22334448, 0.20072055]\n",
      "[0.612166, 0.2, 0.20634969, 0.20108873]\n",
      "[0.60850143, 0.2, 0.20228748, 0.20148702]\n",
      "[0.6316007, 0.2, 0.22656603, 0.20030868]\n",
      "[0.612402, 0.2, 0.2071919, 0.20048268]\n",
      "[0.6155599, 0.2, 0.2106283, 0.20020267]\n",
      "[0.6165404, 0.2, 0.2114668, 0.20034324]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15250 iterations: 3.649806531270345 mins\n",
      "Train Loss: [0.6165404, 0.2, 0.2114668, 0.20034324]\n",
      "[0.6264621, 0.2, 0.2076965, 0.21403359]\n",
      "[0.6125387, 0.2, 0.2072598, 0.20054567]\n",
      "[0.61289614, 0.2, 0.20781282, 0.20034915]\n",
      "[0.61262095, 0.2, 0.20716311, 0.20072244]\n",
      "[0.6113767, 0.2, 0.20631598, 0.20032409]\n",
      "[0.6099489, 0.2, 0.20474936, 0.20046172]\n",
      "[0.6137972, 0.2, 0.20877121, 0.20028679]\n",
      "[0.60934496, 0.2, 0.20414022, 0.2004645]\n",
      "[0.6115179, 0.2, 0.20622921, 0.20054787]\n",
      "[0.6115007, 0.2, 0.20586038, 0.20089883]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15260 iterations: 3.6517915964126586 mins\n",
      "Train Loss: [0.6115007, 0.2, 0.20586038, 0.20089883]\n",
      "[0.6290477, 0.2, 0.21096103, 0.21334615]\n",
      "[0.61570215, 0.2, 0.21055298, 0.20040919]\n",
      "[0.6148175, 0.2, 0.20977272, 0.20030564]\n",
      "[0.6130483, 0.2, 0.20777081, 0.20053883]\n",
      "[0.6094404, 0.2, 0.20431833, 0.200384]\n",
      "[0.60819876, 0.2, 0.2032262, 0.2002347]\n",
      "[0.61001617, 0.2, 0.20481563, 0.20046292]\n",
      "[0.60774547, 0.2, 0.20267875, 0.20032917]\n",
      "[0.609127, 0.2, 0.20399259, 0.20039715]\n",
      "[0.6083333, 0.2, 0.20329322, 0.20030367]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15270 iterations: 3.653839615980784 mins\n",
      "Train Loss: [0.6083333, 0.2, 0.20329322, 0.20030367]\n",
      "[0.61145717, 0.2, 0.20587985, 0.2008419]\n",
      "[0.6113096, 0.2, 0.20611824, 0.2004569]\n",
      "[0.6096333, 0.2, 0.2046455, 0.20025392]\n",
      "[0.61264515, 0.2, 0.20751481, 0.20039701]\n",
      "[0.6137763, 0.2, 0.20826027, 0.20078325]\n",
      "[0.6148419, 0.2, 0.20954546, 0.20056388]\n",
      "[0.6111723, 0.2, 0.20612842, 0.20031215]\n",
      "[0.6120241, 0.2, 0.20667957, 0.20061354]\n",
      "[0.6123944, 0.2, 0.20726778, 0.20039612]\n",
      "[0.6102039, 0.2, 0.20498794, 0.20048596]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15280 iterations: 3.655750115712484 mins\n",
      "Train Loss: [0.6102039, 0.2, 0.20498794, 0.20048596]\n",
      "[0.6302051, 0.2, 0.22495072, 0.20052463]\n",
      "[0.6665252, 0.2, 0.21250018, 0.24929276]\n",
      "[0.62409836, 0.2, 0.21902181, 0.20034315]\n",
      "[0.61277676, 0.2, 0.20748492, 0.20055738]\n",
      "[0.6109128, 0.2, 0.20526932, 0.2009078]\n",
      "[0.60956514, 0.2, 0.20453653, 0.20029157]\n",
      "[0.61275274, 0.2, 0.20771451, 0.20029996]\n",
      "[0.6197295, 0.2, 0.21408716, 0.20090283]\n",
      "[0.6090558, 0.2, 0.20370303, 0.20061214]\n",
      "[0.6128192, 0.2, 0.20759356, 0.20048411]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15290 iterations: 3.65778413216273 mins\n",
      "Train Loss: [0.6128192, 0.2, 0.20759356, 0.20048411]\n",
      "[0.61219305, 0.2, 0.20689432, 0.20055597]\n",
      "[0.61243474, 0.2, 0.2072274, 0.20046404]\n",
      "[0.6161344, 0.2, 0.21064226, 0.20074837]\n",
      "[0.64668286, 0.2, 0.2229606, 0.21897855]\n",
      "[0.6297464, 0.2, 0.20857337, 0.21642886]\n",
      "[0.6089616, 0.2, 0.20369917, 0.20051695]\n",
      "[0.6190358, 0.2, 0.21391153, 0.20037684]\n",
      "[0.6106948, 0.2, 0.20562716, 0.20031813]\n",
      "[0.6244288, 0.2, 0.20418832, 0.2154885]\n",
      "[0.613654, 0.2, 0.20801905, 0.20088172]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15300 iterations: 3.659800330797831 mins\n",
      "Train Loss: [0.613654, 0.2, 0.20801905, 0.20088172]\n",
      "[0.6143959, 0.2, 0.2091432, 0.20049793]\n",
      "[0.6080979, 0.2, 0.20269963, 0.20064157]\n",
      "[0.61331123, 0.2, 0.20789142, 0.20066185]\n",
      "[0.61704326, 0.2, 0.21182674, 0.20045714]\n",
      "[0.6060049, 0.2, 0.20068909, 0.2005551]\n",
      "[0.62004596, 0.2, 0.21488455, 0.20039956]\n",
      "[0.61017936, 0.2, 0.20485288, 0.2005637]\n",
      "[0.61281335, 0.2, 0.2077944, 0.2002551]\n",
      "[0.60833, 0.2, 0.20307381, 0.20049143]\n",
      "[0.6132104, 0.2, 0.20767403, 0.2007709]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15310 iterations: 3.6618944009145102 mins\n",
      "Train Loss: [0.6132104, 0.2, 0.20767403, 0.2007709]\n",
      "[0.6086552, 0.2, 0.20350258, 0.20038679]\n",
      "[0.6101001, 0.2, 0.204429, 0.20090504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6178975, 0.2, 0.212648, 0.2004833]\n",
      "[0.60935676, 0.2, 0.20317744, 0.20141283]\n",
      "[0.61250246, 0.2, 0.20727402, 0.20046146]\n",
      "[0.6113109, 0.2, 0.20608422, 0.20045964]\n",
      "[0.61044836, 0.2, 0.20424682, 0.20143454]\n",
      "[0.61506057, 0.2, 0.2095995, 0.20069477]\n",
      "[0.61728024, 0.2, 0.2121412, 0.20037322]\n",
      "[0.62661785, 0.2, 0.22136284, 0.20048977]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15320 iterations: 3.6645084659258527 mins\n",
      "Train Loss: [0.62661785, 0.2, 0.22136284, 0.20048977]\n",
      "[0.6136889, 0.2, 0.20873559, 0.20018841]\n",
      "[0.61953986, 0.2, 0.21429399, 0.20048141]\n",
      "[0.62490904, 0.2, 0.21967547, 0.20046954]\n",
      "[0.60832477, 0.2, 0.20263931, 0.20092137]\n",
      "[0.60721517, 0.2, 0.20176047, 0.20069048]\n",
      "[0.6135514, 0.2, 0.2084489, 0.2003385]\n",
      "[0.61973387, 0.2, 0.21444373, 0.2005269]\n",
      "[0.61036646, 0.2, 0.20524068, 0.20036331]\n",
      "[0.6129572, 0.2, 0.2052773, 0.20291866]\n",
      "[0.6156024, 0.2, 0.21025154, 0.20059136]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15330 iterations: 3.667378282546997 mins\n",
      "Train Loss: [0.6156024, 0.2, 0.21025154, 0.20059136]\n",
      "[0.61274564, 0.2, 0.20724188, 0.20074615]\n",
      "[0.6102801, 0.2, 0.20525561, 0.20026888]\n",
      "[0.62514234, 0.2, 0.22005594, 0.2003327]\n",
      "[0.61030686, 0.2, 0.2051316, 0.20042302]\n",
      "[0.6080292, 0.2, 0.20283325, 0.20044528]\n",
      "[0.60901743, 0.2, 0.2038254, 0.20044287]\n",
      "[0.61253595, 0.2, 0.20642088, 0.20136738]\n",
      "[0.61387277, 0.2, 0.20800406, 0.20112245]\n",
      "[0.611536, 0.2, 0.20470929, 0.20208175]\n",
      "[0.6105178, 0.2, 0.20427434, 0.2014992]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15340 iterations: 3.6693564653396606 mins\n",
      "Train Loss: [0.6105178, 0.2, 0.20427434, 0.2014992]\n",
      "[0.61832803, 0.2, 0.21242778, 0.20115635]\n",
      "[0.6125409, 0.2, 0.20692545, 0.2008713]\n",
      "[0.6114423, 0.2, 0.20612177, 0.20057604]\n",
      "[0.61448944, 0.2, 0.20923784, 0.20050617]\n",
      "[0.6077228, 0.2, 0.20271482, 0.20026127]\n",
      "[0.61386245, 0.2, 0.20886874, 0.20024529]\n",
      "[0.61014, 0.2, 0.20501554, 0.2003743]\n",
      "[0.6109141, 0.2, 0.20563854, 0.20052332]\n",
      "[0.61266506, 0.2, 0.20731848, 0.20059225]\n",
      "[0.61166525, 0.2, 0.20665526, 0.20025367]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15350 iterations: 3.671353300412496 mins\n",
      "Train Loss: [0.61166525, 0.2, 0.20665526, 0.20025367]\n",
      "[0.6126098, 0.2, 0.20712826, 0.2007234]\n",
      "[0.6145066, 0.2, 0.20944554, 0.20030123]\n",
      "[0.6098042, 0.2, 0.20400493, 0.20103784]\n",
      "[0.6086046, 0.2, 0.20303701, 0.20080465]\n",
      "[0.6097692, 0.2, 0.20452024, 0.20048513]\n",
      "[0.6117473, 0.2, 0.2068005, 0.20018229]\n",
      "[0.6189715, 0.2, 0.21385425, 0.20035192]\n",
      "[0.6086045, 0.2, 0.20344682, 0.20039123]\n",
      "[0.6152097, 0.2, 0.20959325, 0.20084946]\n",
      "[0.6274399, 0.2, 0.20862101, 0.21405157]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15360 iterations: 3.6731557846069336 mins\n",
      "Train Loss: [0.6274399, 0.2, 0.20862101, 0.21405157]\n",
      "[0.6090328, 0.2, 0.20401607, 0.20024867]\n",
      "[0.6078391, 0.2, 0.20238316, 0.20068657]\n",
      "[0.6089726, 0.2, 0.20370999, 0.20049158]\n",
      "[0.6160652, 0.2, 0.21033333, 0.20095888]\n",
      "[0.6100367, 0.2, 0.2048917, 0.20036995]\n",
      "[0.62809217, 0.2, 0.2103338, 0.21298121]\n",
      "[0.609431, 0.2, 0.20368066, 0.20096946]\n",
      "[0.61282516, 0.2, 0.20683466, 0.20120504]\n",
      "[0.616614, 0.2, 0.21144979, 0.20037438]\n",
      "[0.6075029, 0.2, 0.20231393, 0.20039457]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15370 iterations: 3.675156100591024 mins\n",
      "Train Loss: [0.6075029, 0.2, 0.20231393, 0.20039457]\n",
      "[0.60844004, 0.2, 0.20322977, 0.2004112]\n",
      "[0.6128373, 0.2, 0.20769253, 0.2003411]\n",
      "[0.6087549, 0.2, 0.2026864, 0.20126009]\n",
      "[0.63487595, 0.2, 0.20944995, 0.22061363]\n",
      "[0.6108158, 0.2, 0.20550038, 0.20050249]\n",
      "[0.6119901, 0.2, 0.20596537, 0.20121141]\n",
      "[0.6153806, 0.2, 0.21016842, 0.2003993]\n",
      "[0.6253194, 0.2, 0.22015786, 0.20034869]\n",
      "[0.64062196, 0.2, 0.20165049, 0.23415752]\n",
      "[0.61242604, 0.2, 0.20721258, 0.20039901]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15380 iterations: 3.6770720998446147 mins\n",
      "Train Loss: [0.61242604, 0.2, 0.20721258, 0.20039901]\n",
      "[0.6344979, 0.2, 0.20628874, 0.22339472]\n",
      "[0.6092032, 0.2, 0.20291176, 0.201476]\n",
      "[0.6175065, 0.2, 0.21241802, 0.20027182]\n",
      "[0.6088726, 0.2, 0.2037492, 0.20030707]\n",
      "[0.60831773, 0.2, 0.20311652, 0.20038499]\n",
      "[0.61009955, 0.2, 0.2048236, 0.2004599]\n",
      "[0.6113158, 0.2, 0.20616631, 0.20033401]\n",
      "[0.6147986, 0.2, 0.20951001, 0.20047402]\n",
      "[0.61514354, 0.2, 0.21006115, 0.2002686]\n",
      "[0.6190131, 0.2, 0.21361946, 0.20058075]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15390 iterations: 3.679121283690135 mins\n",
      "Train Loss: [0.6190131, 0.2, 0.21361946, 0.20058075]\n",
      "[0.6116095, 0.2, 0.2057658, 0.20103192]\n",
      "[0.6372685, 0.2, 0.20552158, 0.22693619]\n",
      "[0.6099384, 0.2, 0.20441654, 0.20071346]\n",
      "[0.61077577, 0.2, 0.2045292, 0.20144017]\n",
      "[0.6113622, 0.2, 0.20607595, 0.20048164]\n",
      "[0.6169288, 0.2, 0.21097359, 0.20115244]\n",
      "[0.6200949, 0.2, 0.21342391, 0.20186979]\n",
      "[0.612576, 0.2, 0.2066908, 0.20108545]\n",
      "[0.6133899, 0.2, 0.2058287, 0.20276323]\n",
      "[0.6329148, 0.2, 0.2265585, 0.20156007]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15400 iterations: 3.681783596674601 mins\n",
      "Train Loss: [0.6329148, 0.2, 0.2265585, 0.20156007]\n",
      "[0.61135924, 0.2, 0.20552969, 0.2010334]\n",
      "[0.61066794, 0.2, 0.20343056, 0.2024408]\n",
      "[0.60986865, 0.2, 0.20332615, 0.20174491]\n",
      "[0.6095198, 0.2, 0.20333652, 0.20138444]\n",
      "[0.6085011, 0.2, 0.20208456, 0.20161618]\n",
      "[0.61555296, 0.2, 0.20955531, 0.20119585]\n",
      "[0.61067337, 0.2, 0.20488307, 0.20098694]\n",
      "[0.61130226, 0.2, 0.20558539, 0.20091186]\n",
      "[0.6214753, 0.2, 0.2156667, 0.20100176]\n",
      "[0.6191434, 0.2, 0.21254069, 0.20179558]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15410 iterations: 3.683660431702932 mins\n",
      "Train Loss: [0.6191434, 0.2, 0.21254069, 0.20179558]\n",
      "[0.60786706, 0.2, 0.2019021, 0.20115729]\n",
      "[0.6102134, 0.2, 0.20458166, 0.20082338]\n",
      "[0.6194946, 0.2, 0.21339962, 0.20128578]\n",
      "[0.6079825, 0.2, 0.20248172, 0.20069093]\n",
      "[0.6163255, 0.2, 0.2109497, 0.20056552]\n",
      "[0.61211294, 0.2, 0.2055456, 0.2017568]\n",
      "[0.62490714, 0.2, 0.20458542, 0.21551149]\n",
      "[0.6090852, 0.2, 0.20346706, 0.20080762]\n",
      "[0.608767, 0.2, 0.20341963, 0.20053662]\n",
      "[0.60597533, 0.2, 0.20058632, 0.20057808]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15420 iterations: 3.685689302285512 mins\n",
      "Train Loss: [0.60597533, 0.2, 0.20058632, 0.20057808]\n",
      "[0.6087728, 0.2, 0.20206688, 0.20189509]\n",
      "[0.60664725, 0.2, 0.20096134, 0.20087528]\n",
      "[0.6100335, 0.2, 0.20468418, 0.20053911]\n",
      "[0.61968267, 0.2, 0.21437176, 0.20050137]\n",
      "[0.6092715, 0.2, 0.2040676, 0.20039557]\n",
      "[0.6189094, 0.2, 0.2137002, 0.2004024]\n",
      "[0.60862035, 0.2, 0.20285416, 0.20096157]\n",
      "[0.6088846, 0.2, 0.20378995, 0.20029289]\n",
      "[0.612126, 0.2, 0.20709604, 0.20023139]\n",
      "[0.61330307, 0.2, 0.20811133, 0.20039605]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15430 iterations: 3.6875714818636576 mins\n",
      "Train Loss: [0.61330307, 0.2, 0.20811133, 0.20039605]\n",
      "[0.6117069, 0.2, 0.20633292, 0.20058118]\n",
      "[0.6165817, 0.2, 0.21153636, 0.20025541]\n",
      "[0.6084415, 0.2, 0.20344566, 0.20020913]\n",
      "[0.609894, 0.2, 0.20459214, 0.20051834]\n",
      "[0.60878533, 0.2, 0.20372131, 0.20028397]\n",
      "[0.6113459, 0.2, 0.20570284, 0.20086621]\n",
      "[0.60822713, 0.2, 0.20306592, 0.20038766]\n",
      "[0.60709554, 0.2, 0.20210451, 0.2002209]\n",
      "[0.60968107, 0.2, 0.20439982, 0.20051461]\n",
      "[0.6240502, 0.2, 0.20516564, 0.21412133]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15440 iterations: 3.6896714131037394 mins\n",
      "Train Loss: [0.6240502, 0.2, 0.20516564, 0.21412133]\n",
      "[0.6111751, 0.2, 0.20595276, 0.20046236]\n",
      "[0.6094317, 0.2, 0.20439246, 0.20028207]\n",
      "[0.6119554, 0.2, 0.20648788, 0.20071323]\n",
      "[0.6135358, 0.2, 0.20801923, 0.20076503]\n",
      "[0.6060342, 0.2, 0.20092005, 0.20036559]\n",
      "[0.62880987, 0.2, 0.22310586, 0.20095837]\n",
      "[0.6118792, 0.2, 0.20684794, 0.20028912]\n",
      "[0.61403596, 0.2, 0.20858817, 0.2007089]\n",
      "[0.61675304, 0.2, 0.21180123, 0.20021598]\n",
      "[0.61162573, 0.2, 0.20655248, 0.20034051]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15450 iterations: 3.691813365618388 mins\n",
      "Train Loss: [0.61162573, 0.2, 0.20655248, 0.20034051]\n",
      "[0.61571723, 0.2, 0.21045288, 0.20053451]\n",
      "[0.6091104, 0.2, 0.20418432, 0.20019922]\n",
      "[0.6135546, 0.2, 0.2085165, 0.20031402]\n",
      "[0.61298543, 0.2, 0.20783925, 0.20042488]\n",
      "[0.6105013, 0.2, 0.20523497, 0.2005474]\n",
      "[0.6117878, 0.2, 0.20663475, 0.20043644]\n",
      "[0.6127599, 0.2, 0.20701908, 0.2010264]\n",
      "[0.6190504, 0.2, 0.21325469, 0.20108348]\n",
      "[0.6106129, 0.2, 0.2052312, 0.20067237]\n",
      "[0.6125398, 0.2, 0.20747188, 0.20036109]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15460 iterations: 3.6936920007069904 mins\n",
      "Train Loss: [0.6125398, 0.2, 0.20747188, 0.20036109]\n",
      "[0.61138356, 0.2, 0.20641015, 0.20026897]\n",
      "[0.61049473, 0.2, 0.20515168, 0.20064081]\n",
      "[0.62159616, 0.2, 0.21587954, 0.20101652]\n",
      "[0.61837226, 0.2, 0.21332048, 0.2003535]\n",
      "[0.61275285, 0.2, 0.20736095, 0.2006951]\n",
      "[0.6088216, 0.2, 0.2037611, 0.2003648]\n",
      "[0.6094659, 0.2, 0.20430116, 0.20047008]\n",
      "[0.64807606, 0.2, 0.24281901, 0.20056349]\n",
      "[0.6073116, 0.2, 0.20221019, 0.20041102]\n",
      "[0.61165124, 0.2, 0.20657484, 0.20038883]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15470 iterations: 3.69573868115743 mins\n",
      "Train Loss: [0.61165124, 0.2, 0.20657484, 0.20038883]\n",
      "[0.61036617, 0.2, 0.205223, 0.20045832]\n",
      "[0.61231416, 0.2, 0.20725775, 0.20037402]\n",
      "[0.626968, 0.2, 0.20495643, 0.21733177]\n",
      "[0.6126319, 0.2, 0.20752461, 0.20042919]\n",
      "[0.6160939, 0.2, 0.21080567, 0.20061187]\n",
      "[0.61244863, 0.2, 0.20747802, 0.20029569]\n",
      "[0.6099829, 0.2, 0.2049066, 0.20040281]\n",
      "[0.61188406, 0.2, 0.20670597, 0.20050588]\n",
      "[0.61339515, 0.2, 0.20770763, 0.2010164]\n",
      "[0.61223215, 0.2, 0.20665772, 0.20090398]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15480 iterations: 3.6981876810391743 mins\n",
      "Train Loss: [0.61223215, 0.2, 0.20665772, 0.20090398]\n",
      "[0.6094976, 0.2, 0.20433888, 0.20048901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61240363, 0.2, 0.20701373, 0.20072085]\n",
      "[0.6090394, 0.2, 0.20338054, 0.20099004]\n",
      "[0.6114531, 0.2, 0.20598352, 0.20080113]\n",
      "[0.60928404, 0.2, 0.20364004, 0.20097591]\n",
      "[0.615482, 0.2, 0.2102089, 0.20060524]\n",
      "[0.6220356, 0.2, 0.20664209, 0.21072601]\n",
      "[0.6086345, 0.2, 0.20288366, 0.20108245]\n",
      "[0.61709684, 0.2, 0.21139824, 0.20102951]\n",
      "[0.61545765, 0.2, 0.2097538, 0.20103367]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15490 iterations: 3.700236149628957 mins\n",
      "Train Loss: [0.61545765, 0.2, 0.2097538, 0.20103367]\n",
      "[0.6141129, 0.2, 0.20858826, 0.20085318]\n",
      "[0.61473083, 0.2, 0.20854244, 0.2015157]\n",
      "[0.62125283, 0.2, 0.20147945, 0.21509969]\n",
      "[0.6161271, 0.2, 0.21088974, 0.20056227]\n",
      "[0.6267563, 0.2, 0.22079699, 0.20128275]\n",
      "[0.611016, 0.2, 0.20553829, 0.20079991]\n",
      "[0.6105921, 0.2, 0.2054216, 0.20049158]\n",
      "[0.60867876, 0.2, 0.20254712, 0.20145127]\n",
      "[0.6141341, 0.2, 0.20726728, 0.20218523]\n",
      "[0.6159348, 0.2, 0.21002913, 0.20122266]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15500 iterations: 3.7021283825238545 mins\n",
      "Train Loss: [0.6159348, 0.2, 0.21002913, 0.20122266]\n",
      "[0.6107515, 0.2, 0.20564476, 0.20042199]\n",
      "[0.61354804, 0.2, 0.20804895, 0.20081285]\n",
      "[0.6126469, 0.2, 0.20475745, 0.20320167]\n",
      "[0.6103768, 0.2, 0.2044195, 0.20126796]\n",
      "[0.6112447, 0.2, 0.2054646, 0.20108926]\n",
      "[0.6144454, 0.2, 0.20929177, 0.20046127]\n",
      "[0.60834247, 0.2, 0.20301056, 0.2006382]\n",
      "[0.65700316, 0.2, 0.25170612, 0.2006022]\n",
      "[0.613871, 0.2, 0.20832989, 0.20084237]\n",
      "[0.6092116, 0.2, 0.2037277, 0.20078179]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15510 iterations: 3.7041639486948648 mins\n",
      "Train Loss: [0.6092116, 0.2, 0.2037277, 0.20078179]\n",
      "[0.617226, 0.2, 0.21056858, 0.2019523]\n",
      "[0.60973704, 0.2, 0.20407121, 0.20095845]\n",
      "[0.62590677, 0.2, 0.22038248, 0.20081486]\n",
      "[0.6130368, 0.2, 0.20748593, 0.20083866]\n",
      "[0.61195046, 0.2, 0.2066169, 0.20061968]\n",
      "[0.6107995, 0.2, 0.20549071, 0.20059407]\n",
      "[0.60942924, 0.2, 0.20436887, 0.20034486]\n",
      "[0.63466436, 0.2, 0.22928749, 0.20066085]\n",
      "[0.60960245, 0.2, 0.20445085, 0.20043436]\n",
      "[0.6163095, 0.2, 0.2108256, 0.20076574]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15520 iterations: 3.7060467481613157 mins\n",
      "Train Loss: [0.6163095, 0.2, 0.2108256, 0.20076574]\n",
      "[0.6105971, 0.2, 0.20512038, 0.20075756]\n",
      "[0.6089869, 0.2, 0.20394903, 0.2003181]\n",
      "[0.613526, 0.2, 0.20864433, 0.20016158]\n",
      "[0.61794317, 0.2, 0.2128623, 0.20036054]\n",
      "[0.61714613, 0.2, 0.21214283, 0.20028275]\n",
      "[0.61172754, 0.2, 0.2061129, 0.20089386]\n",
      "[0.6079468, 0.2, 0.20283675, 0.20038964]\n",
      "[0.61282647, 0.2, 0.20758177, 0.20052448]\n",
      "[0.61327326, 0.2, 0.2075342, 0.20101894]\n",
      "[0.61189234, 0.2, 0.20618202, 0.20098996]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15530 iterations: 3.7079879999160767 mins\n",
      "Train Loss: [0.61189234, 0.2, 0.20618202, 0.20098996]\n",
      "[0.6067687, 0.2, 0.20134585, 0.20070276]\n",
      "[0.61054385, 0.2, 0.20403746, 0.20178592]\n",
      "[0.62822014, 0.2, 0.20104857, 0.22245032]\n",
      "[0.6079041, 0.2, 0.20181763, 0.20136534]\n",
      "[0.6081002, 0.2, 0.20232323, 0.20105502]\n",
      "[0.6234931, 0.2, 0.20429248, 0.2144767]\n",
      "[0.61665887, 0.2, 0.21128792, 0.20064363]\n",
      "[0.61041933, 0.2, 0.20411396, 0.20157355]\n",
      "[0.61729306, 0.2, 0.21144943, 0.20110625]\n",
      "[0.6107611, 0.2, 0.20528406, 0.20073529]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15540 iterations: 3.7101635336875916 mins\n",
      "Train Loss: [0.6107611, 0.2, 0.20528406, 0.20073529]\n",
      "[0.62781584, 0.2, 0.2067752, 0.21629272]\n",
      "[0.6089463, 0.2, 0.20294966, 0.20123981]\n",
      "[0.6080679, 0.2, 0.2016016, 0.2016982]\n",
      "[0.6064251, 0.2, 0.20129196, 0.20035389]\n",
      "[0.6096637, 0.2, 0.20380583, 0.20106593]\n",
      "[0.607896, 0.2, 0.20246226, 0.20062783]\n",
      "[0.612832, 0.2, 0.20649755, 0.2015149]\n",
      "[0.61729735, 0.2, 0.2102302, 0.2022334]\n",
      "[0.6415723, 0.2, 0.20800339, 0.22872357]\n",
      "[0.61538815, 0.2, 0.20929095, 0.20124294]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15550 iterations: 3.712040082613627 mins\n",
      "Train Loss: [0.61538815, 0.2, 0.20929095, 0.20124294]\n",
      "[0.6114024, 0.2, 0.20529386, 0.20124628]\n",
      "[0.6121396, 0.2, 0.206575, 0.20069326]\n",
      "[0.61053133, 0.2, 0.20434824, 0.20130223]\n",
      "[0.62510395, 0.2, 0.21897982, 0.20123348]\n",
      "[0.61301935, 0.2, 0.20711896, 0.20100105]\n",
      "[0.6104116, 0.2, 0.20362572, 0.20187789]\n",
      "[0.61201316, 0.2, 0.20620103, 0.20089634]\n",
      "[0.61107504, 0.2, 0.2052295, 0.20092244]\n",
      "[0.6084417, 0.2, 0.20289703, 0.20061488]\n",
      "[0.61206675, 0.2, 0.20591234, 0.20121849]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15560 iterations: 3.714583134651184 mins\n",
      "Train Loss: [0.61206675, 0.2, 0.20591234, 0.20121849]\n",
      "[0.6109795, 0.2, 0.20534906, 0.20068897]\n",
      "[0.6095254, 0.2, 0.20235398, 0.2022256]\n",
      "[0.6115281, 0.2, 0.20528795, 0.20129113]\n",
      "[0.6137597, 0.2, 0.20757176, 0.201237]\n",
      "[0.62939906, 0.2, 0.22335623, 0.20109102]\n",
      "[0.6108332, 0.2, 0.20477007, 0.20111002]\n",
      "[0.6097362, 0.2, 0.20358604, 0.20119655]\n",
      "[0.6124117, 0.2, 0.20541209, 0.2020465]\n",
      "[0.61826015, 0.2, 0.21224897, 0.20105946]\n",
      "[0.61059135, 0.2, 0.20325549, 0.20238657]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15570 iterations: 3.716629366079966 mins\n",
      "Train Loss: [0.61059135, 0.2, 0.20325549, 0.20238657]\n",
      "[0.6106717, 0.2, 0.20416686, 0.20155852]\n",
      "[0.6148077, 0.2, 0.2092499, 0.20061503]\n",
      "[0.61365235, 0.2, 0.2075228, 0.20119068]\n",
      "[0.6128166, 0.2, 0.20689926, 0.20098265]\n",
      "[0.60782254, 0.2, 0.20117483, 0.20171738]\n",
      "[0.6080996, 0.2, 0.20141038, 0.20176382]\n",
      "[0.6158197, 0.2, 0.20991372, 0.20098579]\n",
      "[0.61265916, 0.2, 0.20679651, 0.20094799]\n",
      "[0.6123148, 0.2, 0.20673762, 0.2006683]\n",
      "[0.6130447, 0.2, 0.20742948, 0.20071225]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15580 iterations: 3.718564983208974 mins\n",
      "Train Loss: [0.6130447, 0.2, 0.20742948, 0.20071225]\n",
      "[0.60917455, 0.2, 0.20307857, 0.20119923]\n",
      "[0.61398274, 0.2, 0.20835496, 0.20073715]\n",
      "[0.6132072, 0.2, 0.20677313, 0.20154957]\n",
      "[0.62285095, 0.2, 0.21693312, 0.20103964]\n",
      "[0.61413825, 0.2, 0.20833117, 0.20093358]\n",
      "[0.6108212, 0.2, 0.20480794, 0.20114431]\n",
      "[0.6128442, 0.2, 0.20715018, 0.20082963]\n",
      "[0.6066735, 0.2, 0.20114647, 0.20066708]\n",
      "[0.60634047, 0.2, 0.20057735, 0.20090772]\n",
      "[0.6070857, 0.2, 0.20139787, 0.20083705]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15590 iterations: 3.720681949456533 mins\n",
      "Train Loss: [0.6070857, 0.2, 0.20139787, 0.20083705]\n",
      "[0.6129678, 0.2, 0.20674095, 0.201381]\n",
      "[0.61030245, 0.2, 0.20471446, 0.20074698]\n",
      "[0.6090986, 0.2, 0.20357165, 0.20069087]\n",
      "[0.6120885, 0.2, 0.20652042, 0.20073695]\n",
      "[0.60931253, 0.2, 0.20388578, 0.20060082]\n",
      "[0.61740744, 0.2, 0.21110895, 0.20147756]\n",
      "[0.62363094, 0.2, 0.20551388, 0.21330126]\n",
      "[0.6130337, 0.2, 0.20729698, 0.20092528]\n",
      "[0.6164329, 0.2, 0.21022384, 0.20140201]\n",
      "[0.6105829, 0.2, 0.20473664, 0.20104374]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15600 iterations: 3.72250440120697 mins\n",
      "Train Loss: [0.6105829, 0.2, 0.20473664, 0.20104374]\n",
      "[0.6141989, 0.2, 0.20851919, 0.20088154]\n",
      "[0.60896605, 0.2, 0.2038113, 0.20036109]\n",
      "[0.62154037, 0.2, 0.21597871, 0.20077267]\n",
      "[0.6088414, 0.2, 0.2028918, 0.20116518]\n",
      "[0.6159705, 0.2, 0.20973274, 0.201458]\n",
      "[0.61156845, 0.2, 0.20526545, 0.20152815]\n",
      "[0.61050355, 0.2, 0.2044812, 0.20125228]\n",
      "[0.61342126, 0.2, 0.20754349, 0.20111245]\n",
      "[0.6169282, 0.2, 0.2103445, 0.20182282]\n",
      "[0.6099626, 0.2, 0.20421243, 0.20099407]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15610 iterations: 3.724523663520813 mins\n",
      "Train Loss: [0.6099626, 0.2, 0.20421243, 0.20099407]\n",
      "[0.6091443, 0.2, 0.20329013, 0.2011027]\n",
      "[0.6103009, 0.2, 0.2048399, 0.20071435]\n",
      "[0.6258504, 0.2, 0.20297691, 0.2181314]\n",
      "[0.60701257, 0.2, 0.20170476, 0.20057002]\n",
      "[0.6098358, 0.2, 0.20433609, 0.20076595]\n",
      "[0.6143631, 0.2, 0.20873071, 0.20090255]\n",
      "[0.6114758, 0.2, 0.2060356, 0.20071407]\n",
      "[0.61150914, 0.2, 0.20624858, 0.20053777]\n",
      "[0.6125174, 0.2, 0.20712401, 0.20067407]\n",
      "[0.63009006, 0.2, 0.22394724, 0.20142709]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15620 iterations: 3.7264503320058187 mins\n",
      "Train Loss: [0.63009006, 0.2, 0.22394724, 0.20142709]\n",
      "[0.6092327, 0.2, 0.20357886, 0.20093805]\n",
      "[0.6127564, 0.2, 0.20715839, 0.20088232]\n",
      "[0.63810235, 0.2, 0.23261292, 0.20077394]\n",
      "[0.6130695, 0.2, 0.20762675, 0.20072606]\n",
      "[0.60900813, 0.2, 0.20393817, 0.20035237]\n",
      "[0.6094174, 0.2, 0.20413832, 0.20056088]\n",
      "[0.6069298, 0.2, 0.20162466, 0.20058653]\n",
      "[0.6391983, 0.2, 0.20475288, 0.22972687]\n",
      "[0.609082, 0.2, 0.20347646, 0.2008872]\n",
      "[0.61186695, 0.2, 0.20638783, 0.20076153]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15630 iterations: 3.728578964869181 mins\n",
      "Train Loss: [0.61186695, 0.2, 0.20638783, 0.20076153]\n",
      "[0.6074857, 0.2, 0.2023054, 0.20046352]\n",
      "[0.6113316, 0.2, 0.20615013, 0.20046557]\n",
      "[0.6110719, 0.2, 0.20519121, 0.20116583]\n",
      "[0.6077712, 0.2, 0.2024931, 0.20056437]\n",
      "[0.6087064, 0.2, 0.20370147, 0.20029265]\n",
      "[0.611702, 0.2, 0.20636526, 0.20062587]\n",
      "[0.61052233, 0.2, 0.20468527, 0.20112792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6095998, 0.2, 0.20372611, 0.2011663]\n",
      "[0.6094676, 0.2, 0.20385264, 0.2009092]\n",
      "[0.61250395, 0.2, 0.20697471, 0.20082502]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15640 iterations: 3.7313246846199037 mins\n",
      "Train Loss: [0.61250395, 0.2, 0.20697471, 0.20082502]\n",
      "[0.6069181, 0.2, 0.20126343, 0.20095216]\n",
      "[0.6107135, 0.2, 0.20505156, 0.20096111]\n",
      "[0.6095383, 0.2, 0.20361784, 0.2012214]\n",
      "[0.6088466, 0.2, 0.20316632, 0.20098308]\n",
      "[0.60996014, 0.2, 0.20455109, 0.20071362]\n",
      "[0.61349994, 0.2, 0.20839168, 0.20041521]\n",
      "[0.62619084, 0.2, 0.20653, 0.21497]\n",
      "[0.60897017, 0.2, 0.20387235, 0.20040826]\n",
      "[0.6070366, 0.2, 0.20182012, 0.20052831]\n",
      "[0.61689144, 0.2, 0.21133481, 0.20086993]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15650 iterations: 3.733188545703888 mins\n",
      "Train Loss: [0.61689144, 0.2, 0.21133481, 0.20086993]\n",
      "[0.60876125, 0.2, 0.20337203, 0.20070331]\n",
      "[0.6100673, 0.2, 0.20485382, 0.20052862]\n",
      "[0.6146192, 0.2, 0.20965095, 0.20028432]\n",
      "[0.6126974, 0.2, 0.20740187, 0.20061274]\n",
      "[0.6086379, 0.2, 0.20333916, 0.20061705]\n",
      "[0.6082197, 0.2, 0.20295405, 0.20058501]\n",
      "[0.609838, 0.2, 0.2048246, 0.20033443]\n",
      "[0.60812974, 0.2, 0.20283969, 0.20061293]\n",
      "[0.6108685, 0.2, 0.20561035, 0.20058265]\n",
      "[0.60938334, 0.2, 0.2041856, 0.20052366]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15660 iterations: 3.7353177865346274 mins\n",
      "Train Loss: [0.60938334, 0.2, 0.2041856, 0.20052366]\n",
      "[0.6146251, 0.2, 0.20937575, 0.20057663]\n",
      "[0.60891426, 0.2, 0.20382129, 0.20042141]\n",
      "[0.60998875, 0.2, 0.20468065, 0.20063774]\n",
      "[0.6318524, 0.2, 0.20237048, 0.22481272]\n",
      "[0.6123307, 0.2, 0.20748408, 0.20017919]\n",
      "[0.60751307, 0.2, 0.20247835, 0.20036893]\n",
      "[0.60778886, 0.2, 0.2027743, 0.20035027]\n",
      "[0.6133848, 0.2, 0.20837817, 0.20034373]\n",
      "[0.6119047, 0.2, 0.20667905, 0.20056412]\n",
      "[0.6247115, 0.2, 0.20758854, 0.2124628]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15670 iterations: 3.7371834993362425 mins\n",
      "Train Loss: [0.6247115, 0.2, 0.20758854, 0.2124628]\n",
      "[0.6071027, 0.2, 0.20219909, 0.20024414]\n",
      "[0.6103882, 0.2, 0.20538034, 0.20034921]\n",
      "[0.6100745, 0.2, 0.20496699, 0.20044991]\n",
      "[0.61122984, 0.2, 0.206249, 0.20032395]\n",
      "[0.6079648, 0.2, 0.20292464, 0.20038387]\n",
      "[0.60643804, 0.2, 0.20109336, 0.20068921]\n",
      "[0.6129969, 0.2, 0.20777409, 0.20056812]\n",
      "[0.6107787, 0.2, 0.20564577, 0.20047937]\n",
      "[0.6295404, 0.2, 0.22430286, 0.20058507]\n",
      "[0.6123009, 0.2, 0.20732231, 0.2003247]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15680 iterations: 3.739259914557139 mins\n",
      "Train Loss: [0.6123009, 0.2, 0.20732231, 0.2003247]\n",
      "[0.6066755, 0.2, 0.20171882, 0.2003016]\n",
      "[0.61721516, 0.2, 0.21203686, 0.20052224]\n",
      "[0.61077106, 0.2, 0.2057287, 0.20038578]\n",
      "[0.61288387, 0.2, 0.20811844, 0.20010869]\n",
      "[0.60952044, 0.2, 0.20415676, 0.20070702]\n",
      "[0.60668814, 0.2, 0.20181364, 0.20021819]\n",
      "[0.61078686, 0.2, 0.20581709, 0.20031397]\n",
      "[0.6094434, 0.2, 0.20457515, 0.20021328]\n",
      "[0.6095974, 0.2, 0.20427732, 0.20066608]\n",
      "[0.60989267, 0.2, 0.20476541, 0.2004744]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15690 iterations: 3.7413283507029216 mins\n",
      "Train Loss: [0.60989267, 0.2, 0.20476541, 0.2004744]\n",
      "[0.60962033, 0.2, 0.20400207, 0.20096657]\n",
      "[0.61036915, 0.2, 0.20545201, 0.20026675]\n",
      "[0.6088947, 0.2, 0.20376134, 0.2004846]\n",
      "[0.6117171, 0.2, 0.20676123, 0.20030887]\n",
      "[0.6208252, 0.2, 0.21477476, 0.20140491]\n",
      "[0.616335, 0.2, 0.2100479, 0.20164321]\n",
      "[0.6076252, 0.2, 0.20219745, 0.2007852]\n",
      "[0.6125707, 0.2, 0.20715548, 0.2007738]\n",
      "[0.61364436, 0.2, 0.2066078, 0.20239587]\n",
      "[0.6157798, 0.2, 0.20893717, 0.20220251]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15700 iterations: 3.7432533661524454 mins\n",
      "Train Loss: [0.6157798, 0.2, 0.20893717, 0.20220251]\n",
      "[0.6085765, 0.2, 0.2029535, 0.20098336]\n",
      "[0.62286276, 0.2, 0.21726367, 0.20096001]\n",
      "[0.60799974, 0.2, 0.20245644, 0.20090424]\n",
      "[0.6124143, 0.2, 0.20711303, 0.20066203]\n",
      "[0.61059564, 0.2, 0.20546864, 0.20048709]\n",
      "[0.6064815, 0.2, 0.20145643, 0.20038421]\n",
      "[0.61163616, 0.2, 0.20649327, 0.20050083]\n",
      "[0.62004805, 0.2, 0.21434824, 0.20105633]\n",
      "[0.61006254, 0.2, 0.20450819, 0.20090938]\n",
      "[0.6085666, 0.2, 0.20358576, 0.2003341]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15710 iterations: 3.745308001836141 mins\n",
      "Train Loss: [0.6085666, 0.2, 0.20358576, 0.2003341]\n",
      "[0.61203253, 0.2, 0.20683436, 0.2005498]\n",
      "[0.60898083, 0.2, 0.20342696, 0.20090397]\n",
      "[0.61817724, 0.2, 0.21286367, 0.20066223]\n",
      "[0.61095995, 0.2, 0.2058201, 0.20048724]\n",
      "[0.6137282, 0.2, 0.20852703, 0.20054747]\n",
      "[0.6123859, 0.2, 0.2069745, 0.20075661]\n",
      "[0.61672246, 0.2, 0.21067153, 0.20139515]\n",
      "[0.608111, 0.2, 0.20272943, 0.20072539]\n",
      "[0.61195314, 0.2, 0.20676303, 0.20053367]\n",
      "[0.61819816, 0.2, 0.21309485, 0.20044678]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15720 iterations: 3.7477240840593975 mins\n",
      "Train Loss: [0.61819816, 0.2, 0.21309485, 0.20044678]\n",
      "[0.60996336, 0.2, 0.2046575, 0.20064959]\n",
      "[0.61402816, 0.2, 0.20904484, 0.20032741]\n",
      "[0.6128761, 0.2, 0.20759234, 0.20062855]\n",
      "[0.60936767, 0.2, 0.20417657, 0.20053731]\n",
      "[0.6094038, 0.2, 0.20394577, 0.20080599]\n",
      "[0.6075229, 0.2, 0.20251742, 0.20035496]\n",
      "[0.61076164, 0.2, 0.20580137, 0.20031139]\n",
      "[0.6145075, 0.2, 0.20907608, 0.20078403]\n",
      "[0.61409056, 0.2, 0.20898685, 0.20045781]\n",
      "[0.6109082, 0.2, 0.20589514, 0.20036843]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15730 iterations: 3.749798897902171 mins\n",
      "Train Loss: [0.6109082, 0.2, 0.20589514, 0.20036843]\n",
      "[0.61077017, 0.2, 0.2057302, 0.2003962]\n",
      "[0.6096756, 0.2, 0.20476003, 0.2002727]\n",
      "[0.61282974, 0.2, 0.20783785, 0.20035005]\n",
      "[0.60871434, 0.2, 0.20370589, 0.20036758]\n",
      "[0.611365, 0.2, 0.20648694, 0.20023805]\n",
      "[0.6222088, 0.2, 0.20536174, 0.2122079]\n",
      "[0.6066925, 0.2, 0.20177914, 0.20027527]\n",
      "[0.61022925, 0.2, 0.2052672, 0.2003253]\n",
      "[0.6069925, 0.2, 0.20193093, 0.20042609]\n",
      "[0.6102296, 0.2, 0.2051805, 0.20041479]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15740 iterations: 3.751612301667531 mins\n",
      "Train Loss: [0.6102296, 0.2, 0.2051805, 0.20041479]\n",
      "[0.6114643, 0.2, 0.20657381, 0.2002575]\n",
      "[0.6101432, 0.2, 0.20520245, 0.20030876]\n",
      "[0.6124231, 0.2, 0.20729212, 0.20050004]\n",
      "[0.60914236, 0.2, 0.20430657, 0.20020548]\n",
      "[0.61203855, 0.2, 0.20706594, 0.20034319]\n",
      "[0.61248165, 0.2, 0.20757562, 0.20027755]\n",
      "[0.6066985, 0.2, 0.20161784, 0.20045319]\n",
      "[0.6086003, 0.2, 0.20370227, 0.20027179]\n",
      "[0.6079068, 0.2, 0.20292403, 0.20035766]\n",
      "[0.60725945, 0.2, 0.20241502, 0.20022058]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15750 iterations: 3.7537025491396587 mins\n",
      "Train Loss: [0.60725945, 0.2, 0.20241502, 0.20022058]\n",
      "[0.6077369, 0.2, 0.20283943, 0.20027494]\n",
      "[0.61080813, 0.2, 0.2056137, 0.20057327]\n",
      "[0.6120162, 0.2, 0.2065869, 0.20080973]\n",
      "[0.6163917, 0.2, 0.2111186, 0.20065518]\n",
      "[0.60915893, 0.2, 0.20407228, 0.20047028]\n",
      "[0.611833, 0.2, 0.20688906, 0.20032915]\n",
      "[0.6097602, 0.2, 0.20477824, 0.20036912]\n",
      "[0.60961807, 0.2, 0.20453861, 0.20046864]\n",
      "[0.6081436, 0.2, 0.20321272, 0.20032237]\n",
      "[0.6095786, 0.2, 0.20465109, 0.20032138]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15760 iterations: 3.755754816532135 mins\n",
      "Train Loss: [0.6095786, 0.2, 0.20465109, 0.20032138]\n",
      "[0.61166275, 0.2, 0.20654047, 0.20051849]\n",
      "[0.60956585, 0.2, 0.20452948, 0.20043488]\n",
      "[0.60864335, 0.2, 0.20370032, 0.20034386]\n",
      "[0.61277574, 0.2, 0.20748284, 0.20069613]\n",
      "[0.6115006, 0.2, 0.2063139, 0.20059218]\n",
      "[0.6094147, 0.2, 0.20357266, 0.20124947]\n",
      "[0.6121472, 0.2, 0.20682275, 0.20073399]\n",
      "[0.62527543, 0.2, 0.20457958, 0.21610712]\n",
      "[0.607594, 0.2, 0.20243248, 0.20057371]\n",
      "[0.60666096, 0.2, 0.20158537, 0.20048867]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15770 iterations: 3.7576359510421753 mins\n",
      "Train Loss: [0.60666096, 0.2, 0.20158537, 0.20048867]\n",
      "[0.6096943, 0.2, 0.20453818, 0.20056993]\n",
      "[0.6096628, 0.2, 0.20469175, 0.2003855]\n",
      "[0.6107786, 0.2, 0.2058867, 0.2003069]\n",
      "[0.6127885, 0.2, 0.20741224, 0.20079182]\n",
      "[0.6067731, 0.2, 0.20183434, 0.20035511]\n",
      "[0.6121686, 0.2, 0.20704307, 0.20054291]\n",
      "[0.6158311, 0.2, 0.21094641, 0.20030333]\n",
      "[0.6103787, 0.2, 0.20519073, 0.20060797]\n",
      "[0.60825557, 0.2, 0.20336746, 0.2003097]\n",
      "[0.6096512, 0.2, 0.2041158, 0.20095822]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15780 iterations: 3.759690781434377 mins\n",
      "Train Loss: [0.6096512, 0.2, 0.2041158, 0.20095822]\n",
      "[0.607996, 0.2, 0.20302513, 0.20039494]\n",
      "[0.6246873, 0.2, 0.2036563, 0.21645637]\n",
      "[0.60741305, 0.2, 0.20195824, 0.20088142]\n",
      "[0.61166584, 0.2, 0.20663132, 0.20046209]\n",
      "[0.6077718, 0.2, 0.2027444, 0.20045587]\n",
      "[0.6334807, 0.2, 0.22833198, 0.20057887]\n",
      "[0.6109071, 0.2, 0.20564045, 0.20069697]\n",
      "[0.6101366, 0.2, 0.20511083, 0.20045643]\n",
      "[0.6099274, 0.2, 0.20446016, 0.20089807]\n",
      "[0.60976577, 0.2, 0.20476727, 0.20042978]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15790 iterations: 3.761500867207845 mins\n",
      "Train Loss: [0.60976577, 0.2, 0.20476727, 0.20042978]\n",
      "[0.61191714, 0.2, 0.20691775, 0.20043111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6119385, 0.2, 0.206939, 0.20043169]\n",
      "[0.6067626, 0.2, 0.20156966, 0.2006255]\n",
      "[0.61411244, 0.2, 0.20912041, 0.20042475]\n",
      "[0.61569613, 0.2, 0.21062814, 0.20050092]\n",
      "[0.6094225, 0.2, 0.20449251, 0.20036331]\n",
      "[0.6109447, 0.2, 0.20574814, 0.20063023]\n",
      "[0.6106619, 0.2, 0.20577084, 0.20032492]\n",
      "[0.613036, 0.2, 0.20817134, 0.20029876]\n",
      "[0.608509, 0.2, 0.20358652, 0.20035692]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15800 iterations: 3.7642932653427126 mins\n",
      "Train Loss: [0.608509, 0.2, 0.20358652, 0.20035692]\n",
      "[0.61252755, 0.2, 0.20732509, 0.20063724]\n",
      "[0.6096239, 0.2, 0.20464003, 0.20041882]\n",
      "[0.613275, 0.2, 0.20805962, 0.20065089]\n",
      "[0.60988575, 0.2, 0.20501886, 0.20030327]\n",
      "[0.6107487, 0.2, 0.20550218, 0.20068383]\n",
      "[0.61150956, 0.2, 0.20652494, 0.20042287]\n",
      "[0.6119335, 0.2, 0.20689186, 0.20048098]\n",
      "[0.60847217, 0.2, 0.2036137, 0.20029871]\n",
      "[0.6082984, 0.2, 0.20336518, 0.20037416]\n",
      "[0.6135758, 0.2, 0.20855452, 0.20046344]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15810 iterations: 3.7663480480511984 mins\n",
      "Train Loss: [0.6135758, 0.2, 0.20855452, 0.20046344]\n",
      "[0.6337788, 0.2, 0.22877063, 0.20045167]\n",
      "[0.60621375, 0.2, 0.20131736, 0.20033994]\n",
      "[0.61286885, 0.2, 0.20814928, 0.20016359]\n",
      "[0.61221164, 0.2, 0.20719887, 0.20045719]\n",
      "[0.6119883, 0.2, 0.20720206, 0.2002313]\n",
      "[0.6081314, 0.2, 0.20323305, 0.20034415]\n",
      "[0.60972214, 0.2, 0.20477198, 0.20039673]\n",
      "[0.60834295, 0.2, 0.20348713, 0.2003036]\n",
      "[0.6116009, 0.2, 0.20652875, 0.20052141]\n",
      "[0.61194366, 0.2, 0.20689291, 0.20050183]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15820 iterations: 3.7682608167330423 mins\n",
      "Train Loss: [0.61194366, 0.2, 0.20689291, 0.20050183]\n",
      "[0.610852, 0.2, 0.20560025, 0.2007042]\n",
      "[0.6085413, 0.2, 0.20375675, 0.20023829]\n",
      "[0.60794926, 0.2, 0.20301704, 0.20038731]\n",
      "[0.6095425, 0.2, 0.20468493, 0.20031396]\n",
      "[0.61168593, 0.2, 0.20687376, 0.20027013]\n",
      "[0.6103014, 0.2, 0.20543717, 0.20032375]\n",
      "[0.6187682, 0.2, 0.21388257, 0.20034677]\n",
      "[0.60955083, 0.2, 0.20453654, 0.20047754]\n",
      "[0.61270833, 0.2, 0.20771128, 0.2004623]\n",
      "[0.611216, 0.2, 0.20634378, 0.20033999]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15830 iterations: 3.770372684796651 mins\n",
      "Train Loss: [0.611216, 0.2, 0.20634378, 0.20033999]\n",
      "[0.6118907, 0.2, 0.20706058, 0.20030013]\n",
      "[0.614429, 0.2, 0.20950972, 0.20039128]\n",
      "[0.60938597, 0.2, 0.20445006, 0.20040964]\n",
      "[0.6110843, 0.2, 0.20625605, 0.20030323]\n",
      "[0.6123458, 0.2, 0.20740949, 0.2004123]\n",
      "[0.61011034, 0.2, 0.20530976, 0.20027757]\n",
      "[0.6059372, 0.2, 0.20120862, 0.20020631]\n",
      "[0.6171323, 0.2, 0.21224669, 0.20036368]\n",
      "[0.6080942, 0.2, 0.20334776, 0.20022409]\n",
      "[0.61336434, 0.2, 0.20817105, 0.20066985]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15840 iterations: 3.7722513834635416 mins\n",
      "Train Loss: [0.61336434, 0.2, 0.20817105, 0.20066985]\n",
      "[0.6058675, 0.2, 0.20100786, 0.20033506]\n",
      "[0.6388851, 0.2, 0.20786028, 0.22649853]\n",
      "[0.6089373, 0.2, 0.20422193, 0.20018609]\n",
      "[0.61049455, 0.2, 0.20575446, 0.20020741]\n",
      "[0.60884154, 0.2, 0.2036915, 0.20061338]\n",
      "[0.611935, 0.2, 0.20686194, 0.20053372]\n",
      "[0.6123286, 0.2, 0.20670284, 0.2010841]\n",
      "[0.60912263, 0.2, 0.20418805, 0.20039177]\n",
      "[0.6173546, 0.2, 0.21250196, 0.20030834]\n",
      "[0.61317116, 0.2, 0.20816155, 0.2004635]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15850 iterations: 3.7743268171946207 mins\n",
      "Train Loss: [0.61317116, 0.2, 0.20816155, 0.2004635]\n",
      "[0.61556464, 0.2, 0.21075147, 0.20026533]\n",
      "[0.6103374, 0.2, 0.20549986, 0.20028771]\n",
      "[0.61005574, 0.2, 0.20491946, 0.2005847]\n",
      "[0.60966486, 0.2, 0.20481959, 0.20029233]\n",
      "[0.6071622, 0.2, 0.20228082, 0.20032722]\n",
      "[0.60833085, 0.2, 0.20347361, 0.2003023]\n",
      "[0.6196785, 0.2, 0.21480703, 0.20031576]\n",
      "[0.60986465, 0.2, 0.20494495, 0.20036331]\n",
      "[0.60762525, 0.2, 0.2026756, 0.20039344]\n",
      "[0.6062843, 0.2, 0.20127483, 0.20045331]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15860 iterations: 3.7762693842252095 mins\n",
      "Train Loss: [0.6062843, 0.2, 0.20127483, 0.20045331]\n",
      "[0.60963005, 0.2, 0.20473507, 0.20033881]\n",
      "[0.6092028, 0.2, 0.20436889, 0.20027795]\n",
      "[0.61316335, 0.2, 0.20834953, 0.20025754]\n",
      "[0.60592574, 0.2, 0.20115185, 0.20021755]\n",
      "[0.622623, 0.2, 0.2039222, 0.21414445]\n",
      "[0.60813355, 0.2, 0.20337498, 0.20020239]\n",
      "[0.6109572, 0.2, 0.20608492, 0.2003161]\n",
      "[0.60722744, 0.2, 0.20174684, 0.20092517]\n",
      "[0.60677326, 0.2, 0.20171344, 0.20050603]\n",
      "[0.60950637, 0.2, 0.2045236, 0.20043077]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15870 iterations: 3.778218166033427 mins\n",
      "Train Loss: [0.60950637, 0.2, 0.2045236, 0.20043077]\n",
      "[0.61162674, 0.2, 0.2067404, 0.20033616]\n",
      "[0.60696614, 0.2, 0.20212795, 0.20028962]\n",
      "[0.6090945, 0.2, 0.20419006, 0.20035774]\n",
      "[0.61030346, 0.2, 0.20544082, 0.20031787]\n",
      "[0.60763115, 0.2, 0.20282336, 0.20026477]\n",
      "[0.6080316, 0.2, 0.20325147, 0.20023939]\n",
      "[0.61532605, 0.2, 0.21038443, 0.20040302]\n",
      "[0.60703105, 0.2, 0.20203541, 0.2004596]\n",
      "[0.61346376, 0.2, 0.20862848, 0.20030175]\n",
      "[0.6106242, 0.2, 0.20563544, 0.20045769]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15880 iterations: 3.7808016657829286 mins\n",
      "Train Loss: [0.6106242, 0.2, 0.20563544, 0.20045769]\n",
      "[0.6083701, 0.2, 0.2036653, 0.20017621]\n",
      "[0.6094194, 0.2, 0.20461789, 0.20027536]\n",
      "[0.6129542, 0.2, 0.2079516, 0.2004791]\n",
      "[0.6120841, 0.2, 0.20609212, 0.2014716]\n",
      "[0.6093705, 0.2, 0.20456347, 0.20028988]\n",
      "[0.60802895, 0.2, 0.20216073, 0.2013541]\n",
      "[0.60899, 0.2, 0.20409653, 0.2003826]\n",
      "[0.6105705, 0.2, 0.20572759, 0.20033526]\n",
      "[0.60732377, 0.2, 0.20257479, 0.20024465]\n",
      "[0.6161993, 0.2, 0.21124686, 0.20045117]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15890 iterations: 3.783721967538198 mins\n",
      "Train Loss: [0.6161993, 0.2, 0.21124686, 0.20045117]\n",
      "[0.6261153, 0.2, 0.2213637, 0.20025294]\n",
      "[0.61293244, 0.2, 0.20808384, 0.2003508]\n",
      "[0.61348534, 0.2, 0.20848326, 0.20050511]\n",
      "[0.60796434, 0.2, 0.20317148, 0.20029719]\n",
      "[0.61252207, 0.2, 0.20761214, 0.20041537]\n",
      "[0.61364, 0.2, 0.20878103, 0.20036553]\n",
      "[0.62852365, 0.2, 0.22353536, 0.20049584]\n",
      "[0.6084233, 0.2, 0.20355754, 0.20037273]\n",
      "[0.6143354, 0.2, 0.20930615, 0.20053571]\n",
      "[0.60925686, 0.2, 0.20445798, 0.2003054]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15900 iterations: 3.7856120983759562 mins\n",
      "Train Loss: [0.60925686, 0.2, 0.20445798, 0.2003054]\n",
      "[0.6112103, 0.2, 0.20636019, 0.2003566]\n",
      "[0.6136206, 0.2, 0.20891738, 0.20020993]\n",
      "[0.60952246, 0.2, 0.20474146, 0.20028803]\n",
      "[0.6177846, 0.2, 0.2129487, 0.20034331]\n",
      "[0.60839283, 0.2, 0.20362511, 0.20027602]\n",
      "[0.6159056, 0.2, 0.21093175, 0.20048273]\n",
      "[0.6112752, 0.2, 0.20634454, 0.20044032]\n",
      "[0.6127429, 0.2, 0.20779929, 0.20045368]\n",
      "[0.60823894, 0.2, 0.20331201, 0.20043789]\n",
      "[0.6058644, 0.2, 0.2008986, 0.2004775]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15910 iterations: 3.7876816153526307 mins\n",
      "Train Loss: [0.6058644, 0.2, 0.2008986, 0.2004775]\n",
      "[0.60559756, 0.2, 0.20035197, 0.20075813]\n",
      "[0.6059448, 0.2, 0.20069753, 0.20076075]\n",
      "[0.6050664, 0.2, 0.20038593, 0.20019329]\n",
      "[0.6051, 0.2, 0.20037396, 0.2002352]\n",
      "[0.6050269, 0.2, 0.20015031, 0.20038146]\n",
      "[0.6055589, 0.2, 0.20051163, 0.20054553]\n",
      "[0.6052608, 0.2, 0.20031458, 0.20043606]\n",
      "[0.6051583, 0.2, 0.20032693, 0.2003126]\n",
      "[0.6052924, 0.2, 0.2005727, 0.20019114]\n",
      "[0.60483736, 0.2, 0.20016886, 0.2001307]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15920 iterations: 3.7895702799161275 mins\n",
      "Train Loss: [0.60483736, 0.2, 0.20016886, 0.2001307]\n",
      "[0.6049732, 0.2, 0.20016843, 0.20025714]\n",
      "[0.6053238, 0.2, 0.20024666, 0.2005194]\n",
      "[0.60486996, 0.2, 0.20020719, 0.200096]\n",
      "[0.60489327, 0.2, 0.20016961, 0.20014887]\n",
      "[0.6050948, 0.2, 0.20017694, 0.2003362]\n",
      "[0.6051531, 0.2, 0.20030263, 0.20026338]\n",
      "[0.6052769, 0.2, 0.20035213, 0.20033407]\n",
      "[0.6050983, 0.2, 0.20032035, 0.20018533]\n",
      "[0.6054476, 0.2, 0.20031017, 0.2005445]\n",
      "[0.6049158, 0.2, 0.20011473, 0.20020957]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15930 iterations: 3.7917049010594686 mins\n",
      "Train Loss: [0.6049158, 0.2, 0.20011473, 0.20020957]\n",
      "[0.6048007, 0.2, 0.20010607, 0.20010568]\n",
      "[0.60480773, 0.2, 0.20009455, 0.20012775]\n",
      "[0.8355851, 0.2, 0.4308487, 0.2001556]\n",
      "[0.6048511, 0.2, 0.2001376, 0.20005147]\n",
      "[0.60528654, 0.2, 0.20029041, 0.20013356]\n",
      "[0.60566777, 0.2, 0.20040868, 0.20011386]\n",
      "[0.6056898, 0.2, 0.20007092, 0.20013769]\n",
      "[0.6063357, 0.2, 0.20025182, 0.20023519]\n",
      "[0.6068237, 0.2, 0.20012134, 0.20047128]\n",
      "[0.6072975, 0.2, 0.20020902, 0.2004727]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15940 iterations: 3.793547801176707 mins\n",
      "Train Loss: [0.6072975, 0.2, 0.20020902, 0.2004727]\n",
      "[0.6071661, 0.2, 0.20006725, 0.20010522]\n",
      "[0.60785973, 0.2, 0.20010464, 0.20039687]\n",
      "[0.6080619, 0.2, 0.20011726, 0.2002398]\n",
      "[0.6084959, 0.2, 0.20016931, 0.20029604]\n",
      "[0.6091355, 0.2, 0.20009781, 0.20070437]\n",
      "[0.6092284, 0.2, 0.20013513, 0.20048092]\n",
      "[0.60965997, 0.2, 0.20024624, 0.20054635]\n",
      "[0.60978353, 0.2, 0.2001747, 0.20051011]\n",
      "[0.6098322, 0.2, 0.20010357, 0.20042163]\n",
      "[0.60999095, 0.2, 0.2003083, 0.2001893]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15950 iterations: 3.795647998650869 mins\n",
      "Train Loss: [0.60999095, 0.2, 0.2003083, 0.2001893]\n",
      "[0.6099771, 0.2, 0.20000003, 0.20031829]\n",
      "[0.6106071, 0.2, 0.2002822, 0.20052019]\n",
      "[0.61013037, 0.2, 0.20006004, 0.20013829]\n",
      "[0.61074483, 0.2, 0.20025678, 0.2004454]\n",
      "[0.61044806, 0.2, 0.20012738, 0.20018303]\n",
      "[0.6103923, 0.2, 0.20007335, 0.2001006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61051655, 0.2, 0.20006415, 0.20016636]\n",
      "[0.6110309, 0.2, 0.20033623, 0.20035276]\n",
      "[0.6106534, 0.2, 0.20005445, 0.20021202]\n",
      "[0.6108093, 0.2, 0.20016399, 0.20022327]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15960 iterations: 3.798224381605784 mins\n",
      "Train Loss: [0.6108093, 0.2, 0.20016399, 0.20022327]\n",
      "[0.61089903, 0.2, 0.20022419, 0.20022652]\n",
      "[0.6107405, 0.2, 0.20008317, 0.20019078]\n",
      "[0.61073524, 0.2, 0.20013192, 0.20012572]\n",
      "[0.6108882, 0.2, 0.2002281, 0.20017795]\n",
      "[0.6107659, 0.2, 0.20013495, 0.20015003]\n",
      "[0.6108504, 0.2, 0.20010291, 0.20027304]\n",
      "[0.61078775, 0.2, 0.20012733, 0.20019689]\n",
      "[0.61092365, 0.2, 0.20017463, 0.20030068]\n",
      "[0.6106523, 0.2, 0.20011844, 0.20010424]\n",
      "[0.6105051, 0.2, 0.20006445, 0.20003287]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15970 iterations: 3.8000283002853394 mins\n",
      "Train Loss: [0.6105051, 0.2, 0.20006445, 0.20003287]\n",
      "[0.6105534, 0.2, 0.20005363, 0.20011668]\n",
      "[0.6110253, 0.2, 0.20039883, 0.20027055]\n",
      "[0.6104849, 0.2, 0.20004879, 0.2001096]\n",
      "[0.61037, 0.2, 0.20000002, 0.20007461]\n",
      "[0.61051524, 0.2, 0.20006076, 0.20019183]\n",
      "[0.61039513, 0.2, 0.20005105, 0.2001156]\n",
      "[0.6121563, 0.2, 0.20175669, 0.20020638]\n",
      "[0.610525, 0.2, 0.20016333, 0.20020464]\n",
      "[0.6104445, 0.2, 0.20008464, 0.20023984]\n",
      "[0.61047035, 0.2, 0.20005412, 0.20033392]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15980 iterations: 3.802079184850057 mins\n",
      "Train Loss: [0.61047035, 0.2, 0.20005412, 0.20033392]\n",
      "[0.61084133, 0.2, 0.20032582, 0.20047139]\n",
      "[0.6107642, 0.2, 0.20021167, 0.20054713]\n",
      "[0.61952156, 0.2, 0.20861608, 0.20093924]\n",
      "[0.61364263, 0.2, 0.20033804, 0.20337781]\n",
      "[0.6134253, 0.2, 0.20272778, 0.20081095]\n",
      "[0.6126517, 0.2, 0.20045805, 0.20234744]\n",
      "[0.6133245, 0.2, 0.20080592, 0.20271242]\n",
      "[0.62133914, 0.2, 0.20925912, 0.20231345]\n",
      "[0.617892, 0.2, 0.20715833, 0.20100598]\n",
      "[0.62351453, 0.2, 0.21303107, 0.20079368]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15990 iterations: 3.804002833366394 mins\n",
      "Train Loss: [0.62351453, 0.2, 0.21303107, 0.20079368]\n",
      "[0.62142396, 0.2, 0.21055683, 0.2012146]\n",
      "[0.61772245, 0.2, 0.20654841, 0.20155792]\n",
      "[0.6158225, 0.2, 0.20502305, 0.20121904]\n",
      "[0.61637807, 0.2, 0.20578828, 0.20104453]\n",
      "[0.62489194, 0.2, 0.21342073, 0.201961]\n",
      "[0.62021077, 0.2, 0.21008027, 0.20065479]\n",
      "[0.6217599, 0.2, 0.2110611, 0.20125738]\n",
      "[0.6330396, 0.2, 0.20469865, 0.21893366]\n",
      "[0.6174049, 0.2, 0.20705289, 0.2009797]\n",
      "[0.6148311, 0.2, 0.2047717, 0.200721]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16000 iterations: 3.8062864661216738 mins\n",
      "Train Loss: [0.6148311, 0.2, 0.2047717, 0.200721]\n",
      "[0.6277698, 0.2, 0.2171498, 0.20131548]\n",
      "[0.6218411, 0.2, 0.20659333, 0.20597713]\n",
      "[0.6133082, 0.2, 0.20310536, 0.20096567]\n",
      "[0.61997545, 0.2, 0.20914698, 0.20162421]\n",
      "[0.61564344, 0.2, 0.20530832, 0.20116292]\n",
      "[0.619626, 0.2, 0.20970099, 0.20078449]\n",
      "[0.6142318, 0.2, 0.20380503, 0.20131731]\n",
      "[0.61444074, 0.2, 0.20431668, 0.20104496]\n",
      "[0.61640877, 0.2, 0.20609298, 0.20126678]\n",
      "[0.6171742, 0.2, 0.20777385, 0.20038068]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16010 iterations: 3.809094766775767 mins\n",
      "Train Loss: [0.6171742, 0.2, 0.20777385, 0.20038068]\n",
      "[0.6184205, 0.2, 0.20824987, 0.20118009]\n",
      "[0.62021786, 0.2, 0.20979896, 0.20145716]\n",
      "[0.61706483, 0.2, 0.20708615, 0.20104541]\n",
      "[0.62047803, 0.2, 0.20949703, 0.20207632]\n",
      "[0.61549133, 0.2, 0.20468292, 0.20193167]\n",
      "[0.6129567, 0.2, 0.2031783, 0.20092916]\n",
      "[0.6159375, 0.2, 0.20589413, 0.20122138]\n",
      "[0.6193687, 0.2, 0.20985383, 0.20071995]\n",
      "[0.6129683, 0.2, 0.20320308, 0.20099752]\n",
      "[0.613606, 0.2, 0.20313233, 0.20173319]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16020 iterations: 3.8111289342244468 mins\n",
      "Train Loss: [0.613606, 0.2, 0.20313233, 0.20173319]\n",
      "[0.61798453, 0.2, 0.20871986, 0.20055051]\n",
      "[0.6130433, 0.2, 0.20394558, 0.20040923]\n",
      "[0.6137425, 0.2, 0.20450754, 0.20057124]\n",
      "[0.61199707, 0.2, 0.20262758, 0.20073059]\n",
      "[0.6150675, 0.2, 0.20604058, 0.20041294]\n",
      "[0.61867994, 0.2, 0.20807886, 0.20201151]\n",
      "[0.6144764, 0.2, 0.20531668, 0.20059402]\n",
      "[0.6139168, 0.2, 0.20476665, 0.20060776]\n",
      "[0.61470234, 0.2, 0.20556657, 0.20061551]\n",
      "[0.61286217, 0.2, 0.20385766, 0.20050524]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16030 iterations: 3.8132890661557517 mins\n",
      "Train Loss: [0.61286217, 0.2, 0.20385766, 0.20050524]\n",
      "[0.6152105, 0.2, 0.20623414, 0.20049727]\n",
      "[0.6126412, 0.2, 0.20358437, 0.20059752]\n",
      "[0.6175318, 0.2, 0.20863457, 0.20045659]\n",
      "[0.610703, 0.2, 0.20118758, 0.20109452]\n",
      "[0.6154884, 0.2, 0.20652492, 0.20056237]\n",
      "[0.63591856, 0.2, 0.20852537, 0.21901195]\n",
      "[0.61578286, 0.2, 0.20657451, 0.2008471]\n",
      "[0.61376595, 0.2, 0.20449638, 0.20092815]\n",
      "[0.6148777, 0.2, 0.20571677, 0.20083944]\n",
      "[0.62163156, 0.2, 0.21271919, 0.2006109]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16040 iterations: 3.815765150388082 mins\n",
      "Train Loss: [0.62163156, 0.2, 0.21271919, 0.2006109]\n",
      "[0.6189237, 0.2, 0.2099368, 0.20070514]\n",
      "[0.61359096, 0.2, 0.2047828, 0.20054723]\n",
      "[0.6170369, 0.2, 0.20827863, 0.20051745]\n",
      "[0.6142302, 0.2, 0.20557368, 0.20043512]\n",
      "[0.6149677, 0.2, 0.20618413, 0.2005818]\n",
      "[0.6272005, 0.2, 0.21865945, 0.20036021]\n",
      "[0.627699, 0.2, 0.21916972, 0.20036781]\n",
      "[0.6103945, 0.2, 0.20201795, 0.20023252]\n",
      "[0.6122477, 0.2, 0.20365089, 0.20047031]\n",
      "[0.61953366, 0.2, 0.2109676, 0.20045725]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16050 iterations: 3.8177188793818155 mins\n",
      "Train Loss: [0.61953366, 0.2, 0.2109676, 0.20045725]\n",
      "[0.61860764, 0.2, 0.21029781, 0.20021868]\n",
      "[0.6154147, 0.2, 0.2071696, 0.20017219]\n",
      "[0.6120312, 0.2, 0.203523, 0.20045379]\n",
      "[0.6085949, 0.2, 0.20017, 0.2003891]\n",
      "[0.6093918, 0.2, 0.20056878, 0.20080614]\n",
      "[0.6087775, 0.2, 0.20035909, 0.2004209]\n",
      "[0.60901016, 0.2, 0.20022593, 0.20080605]\n",
      "[0.6087003, 0.2, 0.20026012, 0.20048152]\n",
      "[0.60844857, 0.2, 0.20019111, 0.20031814]\n",
      "[0.6088578, 0.2, 0.20016682, 0.20077114]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16060 iterations: 3.8197442491849265 mins\n",
      "Train Loss: [0.6088578, 0.2, 0.20016682, 0.20077114]\n",
      "[0.6091702, 0.2, 0.20095961, 0.20030998]\n",
      "[0.6087939, 0.2, 0.20049056, 0.20042169]\n",
      "[0.6086334, 0.2, 0.20047735, 0.20029305]\n",
      "[0.6084051, 0.2, 0.20034179, 0.20021895]\n",
      "[0.6082384, 0.2, 0.20000024, 0.20041227]\n",
      "[0.6087275, 0.2, 0.20045626, 0.20046334]\n",
      "[0.6083319, 0.2, 0.20028585, 0.20025603]\n",
      "[0.6081042, 0.2, 0.20011766, 0.20021436]\n",
      "[0.6086856, 0.2, 0.20029089, 0.20064032]\n",
      "[0.6085975, 0.2, 0.2004051, 0.20045614]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16070 iterations: 3.821629552046458 mins\n",
      "Train Loss: [0.6085975, 0.2, 0.2004051, 0.20045614]\n",
      "[0.6084384, 0.2, 0.20036218, 0.20035824]\n",
      "[0.6080046, 0.2, 0.20013486, 0.20017008]\n",
      "[0.6083647, 0.2, 0.20028429, 0.20039889]\n",
      "[0.60803294, 0.2, 0.20019136, 0.2001786]\n",
      "[0.6081068, 0.2, 0.20012774, 0.20033449]\n",
      "[0.6080649, 0.2, 0.20015168, 0.20028716]\n",
      "[0.6084986, 0.2, 0.20029835, 0.20059277]\n",
      "[0.60796106, 0.2, 0.20018622, 0.20018612]\n",
      "[0.60780144, 0.2, 0.20010151, 0.20012987]\n",
      "[0.6078103, 0.2, 0.20006171, 0.20019725]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16080 iterations: 3.823695516586304 mins\n",
      "Train Loss: [0.6078103, 0.2, 0.20006171, 0.20019725]\n",
      "[0.61348414, 0.2, 0.20575249, 0.20019898]\n",
      "[0.6080094, 0.2, 0.20013346, 0.20036212]\n",
      "[0.6082678, 0.2, 0.20046045, 0.20031239]\n",
      "[0.60824823, 0.2, 0.20040396, 0.20036855]\n",
      "[0.60874283, 0.2, 0.20075786, 0.20052826]\n",
      "[0.6090643, 0.2, 0.20067877, 0.20094776]\n",
      "[0.6086684, 0.2, 0.2006907, 0.20055878]\n",
      "[0.6089183, 0.2, 0.20054582, 0.2009724]\n",
      "[0.6089865, 0.2, 0.20077169, 0.20083301]\n",
      "[0.6088547, 0.2, 0.20066893, 0.20082167]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16090 iterations: 3.825574783484141 mins\n",
      "Train Loss: [0.6088547, 0.2, 0.20066893, 0.20082167]\n",
      "[0.6101523, 0.2, 0.20208442, 0.20072015]\n",
      "[0.60844517, 0.2, 0.20030059, 0.20081155]\n",
      "[0.60980093, 0.2, 0.20113093, 0.20134991]\n",
      "[0.6098642, 0.2, 0.20080516, 0.2017498]\n",
      "[0.609631, 0.2, 0.20138596, 0.20094542]\n",
      "[0.61717176, 0.2, 0.20823662, 0.20164265]\n",
      "[0.6133806, 0.2, 0.20564672, 0.20044595]\n",
      "[0.612864, 0.2, 0.20471779, 0.2008616]\n",
      "[0.61164546, 0.2, 0.20359088, 0.20077258]\n",
      "[0.6171214, 0.2, 0.20848711, 0.20135476]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16100 iterations: 3.8276455481847127 mins\n",
      "Train Loss: [0.6171214, 0.2, 0.20848711, 0.20135476]\n",
      "[0.6150696, 0.2, 0.20709807, 0.20069513]\n",
      "[0.6201476, 0.2, 0.21112508, 0.20174988]\n",
      "[0.61256564, 0.2, 0.20421939, 0.20107822]\n",
      "[0.61502516, 0.2, 0.20725214, 0.2005107]\n",
      "[0.6160201, 0.2, 0.20726952, 0.20149498]\n",
      "[0.6203812, 0.2, 0.2118637, 0.20126982]\n",
      "[0.63112074, 0.2, 0.22252534, 0.20135665]\n",
      "[0.61419135, 0.2, 0.20596308, 0.20100059]\n",
      "[0.6338771, 0.2, 0.22526197, 0.20139939]\n",
      "[0.6131973, 0.2, 0.20455089, 0.20144399]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16110 iterations: 3.8295244852701824 mins\n",
      "Train Loss: [0.6131973, 0.2, 0.20455089, 0.20144399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6160517, 0.2, 0.20777403, 0.2010895]\n",
      "[0.6122824, 0.2, 0.20443621, 0.20067288]\n",
      "[0.6158679, 0.2, 0.20815466, 0.20055546]\n",
      "[0.61113375, 0.2, 0.20181578, 0.202176]\n",
      "[0.6123475, 0.2, 0.2042481, 0.20097438]\n",
      "[0.61705947, 0.2, 0.20871763, 0.20123373]\n",
      "[0.6120219, 0.2, 0.20408882, 0.20084223]\n",
      "[0.6223622, 0.2, 0.21436065, 0.20092751]\n",
      "[0.6330609, 0.2, 0.20478494, 0.22121818]\n",
      "[0.61705923, 0.2, 0.20930664, 0.20071043]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16120 iterations: 3.8321558992067972 mins\n",
      "Train Loss: [0.61705923, 0.2, 0.20930664, 0.20071043]\n",
      "[0.6135613, 0.2, 0.20546596, 0.2010681]\n",
      "[0.6115566, 0.2, 0.20385107, 0.20069255]\n",
      "[0.61384374, 0.2, 0.20564552, 0.20119901]\n",
      "[0.6104433, 0.2, 0.20242406, 0.2010336]\n",
      "[0.6127497, 0.2, 0.2042425, 0.20153534]\n",
      "[0.6151358, 0.2, 0.207205, 0.20097287]\n",
      "[0.6143677, 0.2, 0.20623682, 0.201187]\n",
      "[0.6104771, 0.2, 0.20266698, 0.20088021]\n",
      "[0.6256899, 0.2, 0.20298515, 0.21578906]\n",
      "[0.61316854, 0.2, 0.20471431, 0.2015532]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16130 iterations: 3.8341883341471354 mins\n",
      "Train Loss: [0.61316854, 0.2, 0.20471431, 0.2015532]\n",
      "[0.6130633, 0.2, 0.20585333, 0.20032361]\n",
      "[0.6142567, 0.2, 0.20619641, 0.20118836]\n",
      "[0.6149308, 0.2, 0.20506735, 0.2030058]\n",
      "[0.626768, 0.2, 0.2182157, 0.20170918]\n",
      "[0.6143693, 0.2, 0.20667657, 0.20086387]\n",
      "[0.6104722, 0.2, 0.20292392, 0.20073405]\n",
      "[0.6362853, 0.2, 0.22692466, 0.20256105]\n",
      "[0.61028624, 0.2, 0.20227358, 0.20122883]\n",
      "[0.6126998, 0.2, 0.20523535, 0.20069616]\n",
      "[0.63702136, 0.2, 0.21046752, 0.21980107]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16140 iterations: 3.836188634236654 mins\n",
      "Train Loss: [0.63702136, 0.2, 0.21046752, 0.21980107]\n",
      "[0.61231154, 0.2, 0.2042531, 0.20132078]\n",
      "[0.61252785, 0.2, 0.20463753, 0.2011678]\n",
      "[0.6112754, 0.2, 0.20380884, 0.20075911]\n",
      "[0.6110783, 0.2, 0.20356953, 0.20081633]\n",
      "[0.61162585, 0.2, 0.20437552, 0.2005727]\n",
      "[0.62593967, 0.2, 0.20459896, 0.21467784]\n",
      "[0.61655015, 0.2, 0.20809613, 0.20180438]\n",
      "[0.6128291, 0.2, 0.20492592, 0.20126651]\n",
      "[0.61254317, 0.2, 0.2048658, 0.2010533]\n",
      "[0.6110931, 0.2, 0.20383997, 0.20064147]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16150 iterations: 3.838247899214427 mins\n",
      "Train Loss: [0.6110931, 0.2, 0.20383997, 0.20064147]\n",
      "[0.61559695, 0.2, 0.20786211, 0.20113555]\n",
      "[0.61919874, 0.2, 0.21114568, 0.20146614]\n",
      "[0.6094661, 0.2, 0.20202988, 0.20086198]\n",
      "[0.6210272, 0.2, 0.21357921, 0.20088638]\n",
      "[0.6293254, 0.2, 0.22136141, 0.20141491]\n",
      "[0.6130713, 0.2, 0.20564504, 0.20088969]\n",
      "[0.6126679, 0.2, 0.20504151, 0.20110223]\n",
      "[0.61727715, 0.2, 0.2095284, 0.20123675]\n",
      "[0.6137801, 0.2, 0.20534389, 0.2019366]\n",
      "[0.61319345, 0.2, 0.20607385, 0.20063245]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16160 iterations: 3.8400394320487976 mins\n",
      "Train Loss: [0.61319345, 0.2, 0.20607385, 0.20063245]\n",
      "[0.6166559, 0.2, 0.20875627, 0.20142516]\n",
      "[0.61532146, 0.2, 0.20724925, 0.20161057]\n",
      "[0.60915816, 0.2, 0.202024, 0.2006853]\n",
      "[0.61758024, 0.2, 0.21044964, 0.20069447]\n",
      "[0.6577451, 0.2, 0.25005034, 0.2012707]\n",
      "[0.6157536, 0.2, 0.2080939, 0.2012447]\n",
      "[0.60880435, 0.2, 0.20139241, 0.2010064]\n",
      "[0.6094499, 0.2, 0.20129566, 0.20175783]\n",
      "[0.6089146, 0.2, 0.20153524, 0.2009921]\n",
      "[0.6082039, 0.2, 0.20097552, 0.2008495]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16170 iterations: 3.842111082871755 mins\n",
      "Train Loss: [0.6082039, 0.2, 0.20097552, 0.2008495]\n",
      "[0.6081013, 0.2, 0.20119898, 0.20053005]\n",
      "[0.6080113, 0.2, 0.20080547, 0.20083745]\n",
      "[0.60839695, 0.2, 0.20057157, 0.2014592]\n",
      "[0.6071962, 0.2, 0.20044366, 0.20038658]\n",
      "[0.6080252, 0.2, 0.20104474, 0.20061319]\n",
      "[0.6081122, 0.2, 0.20058377, 0.20115861]\n",
      "[0.611844, 0.2, 0.20452042, 0.20095134]\n",
      "[0.6084564, 0.2, 0.20135304, 0.20072891]\n",
      "[0.60972846, 0.2, 0.20155966, 0.20179324]\n",
      "[0.6106806, 0.2, 0.20144266, 0.20286404]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16180 iterations: 3.8441006501515704 mins\n",
      "Train Loss: [0.6106806, 0.2, 0.20144266, 0.20286404]\n",
      "[0.61035544, 0.2, 0.20178552, 0.20219937]\n",
      "[0.61121774, 0.2, 0.20274451, 0.20210366]\n",
      "[0.6117544, 0.2, 0.20265797, 0.20272599]\n",
      "[0.61116964, 0.2, 0.20267631, 0.20211972]\n",
      "[0.6097798, 0.2, 0.20147373, 0.20192865]\n",
      "[0.6107431, 0.2, 0.20306306, 0.2012946]\n",
      "[0.6175496, 0.2, 0.20770349, 0.20344771]\n",
      "[0.6125876, 0.2, 0.20279607, 0.203375]\n",
      "[0.61218977, 0.2, 0.20100875, 0.20473978]\n",
      "[0.61100614, 0.2, 0.20101026, 0.20352189]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16190 iterations: 3.8460351983706156 mins\n",
      "Train Loss: [0.61100614, 0.2, 0.20101026, 0.20352189]\n",
      "[0.6129854, 0.2, 0.20303693, 0.20343344]\n",
      "[0.61269176, 0.2, 0.20410748, 0.20202416]\n",
      "[0.6171355, 0.2, 0.20613067, 0.20439927]\n",
      "[0.6168243, 0.2, 0.20343073, 0.20674434]\n",
      "[0.61117834, 0.2, 0.20273107, 0.20175046]\n",
      "[0.6133586, 0.2, 0.20262478, 0.20398696]\n",
      "[0.6130378, 0.2, 0.2003019, 0.20594263]\n",
      "[0.6128059, 0.2, 0.20344546, 0.20252705]\n",
      "[0.61075044, 0.2, 0.20193675, 0.20194718]\n",
      "[0.6116029, 0.2, 0.20224704, 0.2024609]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16200 iterations: 3.8485876520474753 mins\n",
      "Train Loss: [0.6116029, 0.2, 0.20224704, 0.2024609]\n",
      "[0.6097824, 0.2, 0.20161101, 0.20125009]\n",
      "[0.6104739, 0.2, 0.20195566, 0.20157509]\n",
      "[0.60998976, 0.2, 0.20161979, 0.20141016]\n",
      "[0.60912585, 0.2, 0.20156722, 0.20058677]\n",
      "[0.6081702, 0.2, 0.200455, 0.20073554]\n",
      "[0.60872805, 0.2, 0.20091689, 0.20082812]\n",
      "[0.60865843, 0.2, 0.20061962, 0.20105661]\n",
      "[0.6098454, 0.2, 0.20191725, 0.20095085]\n",
      "[0.6086544, 0.2, 0.20087104, 0.20081341]\n",
      "[0.61034065, 0.2, 0.20070377, 0.20267746]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16210 iterations: 3.8505003968874614 mins\n",
      "Train Loss: [0.61034065, 0.2, 0.20070377, 0.20267746]\n",
      "[0.6084399, 0.2, 0.20070222, 0.20079133]\n",
      "[0.60823196, 0.2, 0.20051087, 0.20078991]\n",
      "[0.6102163, 0.2, 0.20155825, 0.20174395]\n",
      "[0.6089044, 0.2, 0.20057438, 0.20143461]\n",
      "[0.60843253, 0.2, 0.2008951, 0.20066169]\n",
      "[0.6085128, 0.2, 0.20101534, 0.20064224]\n",
      "[0.60827523, 0.2, 0.20075087, 0.20068984]\n",
      "[0.60898614, 0.2, 0.20147564, 0.20069711]\n",
      "[0.6076422, 0.2, 0.2003216, 0.20052855]\n",
      "[0.60835385, 0.2, 0.20084602, 0.2007373]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16220 iterations: 3.8525116165479023 mins\n",
      "Train Loss: [0.60835385, 0.2, 0.20084602, 0.2007373]\n",
      "[0.6077941, 0.2, 0.2005675, 0.20047799]\n",
      "[0.6084863, 0.2, 0.2009011, 0.20085853]\n",
      "[0.60836864, 0.2, 0.2007178, 0.20094627]\n",
      "[0.60785306, 0.2, 0.20071179, 0.20045905]\n",
      "[0.60749686, 0.2, 0.20030229, 0.20053494]\n",
      "[0.6075557, 0.2, 0.20062253, 0.200296]\n",
      "[0.6082073, 0.2, 0.20072012, 0.2008727]\n",
      "[0.60812193, 0.2, 0.20070453, 0.20082526]\n",
      "[0.60803735, 0.2, 0.20057495, 0.20089298]\n",
      "[0.6074399, 0.2, 0.20033646, 0.20055617]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16230 iterations: 3.85443678299586 mins\n",
      "Train Loss: [0.6074399, 0.2, 0.20033646, 0.20055617]\n",
      "[0.6074809, 0.2, 0.20052697, 0.20042834]\n",
      "[0.6089297, 0.2, 0.20069423, 0.20173123]\n",
      "[0.60803837, 0.2, 0.20044382, 0.20111157]\n",
      "[0.6073365, 0.2, 0.2003815, 0.20049286]\n",
      "[0.6079039, 0.2, 0.20109655, 0.2003658]\n",
      "[0.6077141, 0.2, 0.20088762, 0.20040533]\n",
      "[0.6077459, 0.2, 0.20074137, 0.2006031]\n",
      "[0.6074058, 0.2, 0.20055841, 0.20046525]\n",
      "[0.60784185, 0.2, 0.2009673, 0.20051138]\n",
      "[0.60712314, 0.2, 0.20049742, 0.20028129]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16240 iterations: 3.856432731946309 mins\n",
      "Train Loss: [0.60712314, 0.2, 0.20049742, 0.20028129]\n",
      "[0.6077299, 0.2, 0.20045187, 0.20095216]\n",
      "[0.60798496, 0.2, 0.20020509, 0.20147231]\n",
      "[0.6077209, 0.2, 0.20050964, 0.20092173]\n",
      "[0.60702896, 0.2, 0.20029102, 0.20046622]\n",
      "[0.6069242, 0.2, 0.20032382, 0.20034626]\n",
      "[0.6069769, 0.2, 0.20035268, 0.20038761]\n",
      "[0.6067581, 0.2, 0.20016739, 0.20037124]\n",
      "[0.6070504, 0.2, 0.20047872, 0.2003693]\n",
      "[0.6070949, 0.2, 0.20041852, 0.20049118]\n",
      "[0.6067497, 0.2, 0.20018785, 0.20039377]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16250 iterations: 3.8585713664690653 mins\n",
      "Train Loss: [0.6067497, 0.2, 0.20018785, 0.20039377]\n",
      "[0.60677516, 0.2, 0.20021027, 0.20041433]\n",
      "[0.6069075, 0.2, 0.20033623, 0.20043817]\n",
      "[0.60682344, 0.2, 0.20032535, 0.20038278]\n",
      "[0.6068782, 0.2, 0.20045, 0.20033054]\n",
      "[0.6070304, 0.2, 0.2004, 0.20055039]\n",
      "[0.60685617, 0.2, 0.20035425, 0.20043923]\n",
      "[0.6068238, 0.2, 0.20038702, 0.20039159]\n",
      "[0.6067924, 0.2, 0.20029417, 0.20047036]\n",
      "[0.606592, 0.2, 0.20021501, 0.20036633]\n",
      "[0.60676587, 0.2, 0.20023298, 0.20053913]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16260 iterations: 3.8604577660560606 mins\n",
      "Train Loss: [0.60676587, 0.2, 0.20023298, 0.20053913]\n",
      "[0.6066529, 0.2, 0.20022999, 0.20044579]\n",
      "[0.60646236, 0.2, 0.2002171, 0.20028426]\n",
      "[0.60642576, 0.2, 0.20022793, 0.20025301]\n",
      "[0.60705805, 0.2, 0.20075, 0.20037907]\n",
      "[0.6066299, 0.2, 0.20049909, 0.20021737]\n",
      "[0.6067687, 0.2, 0.2003194, 0.20055127]\n",
      "[0.6063794, 0.2, 0.20029277, 0.20020376]\n",
      "[0.60671586, 0.2, 0.2002662, 0.20058197]\n",
      "[0.6063734, 0.2, 0.20021044, 0.20031036]\n",
      "[0.6063137, 0.2, 0.20018886, 0.20028713]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16270 iterations: 3.862531900405884 mins\n",
      "Train Loss: [0.6063137, 0.2, 0.20018886, 0.20028713]\n",
      "[0.60636544, 0.2, 0.2002746, 0.20026796]\n",
      "[0.6062163, 0.2, 0.20020117, 0.20020697]\n",
      "[0.6061924, 0.2, 0.20018947, 0.20020962]\n",
      "[0.60627365, 0.2, 0.20027786, 0.20021704]\n",
      "[0.606499, 0.2, 0.20041016, 0.20032434]\n",
      "[0.60650706, 0.2, 0.20024149, 0.20051554]\n",
      "[0.60620016, 0.2, 0.20025368, 0.20021072]\n",
      "[0.6062294, 0.2, 0.20013465, 0.20037314]\n",
      "[0.60638684, 0.2, 0.20036955, 0.20030959]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6062735, 0.2, 0.20023978, 0.20033966]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16280 iterations: 3.8650243163108824 mins\n",
      "Train Loss: [0.6062735, 0.2, 0.20023978, 0.20033966]\n",
      "[0.6061533, 0.2, 0.20026015, 0.20021282]\n",
      "[0.6059295, 0.2, 0.20000003, 0.20026268]\n",
      "[0.6061344, 0.2, 0.20027234, 0.2002087]\n",
      "[0.60600257, 0.2, 0.20012814, 0.20023432]\n",
      "[0.606083, 0.2, 0.2001706, 0.20028524]\n",
      "[0.60600865, 0.2, 0.20019339, 0.20020111]\n",
      "[0.6061013, 0.2, 0.20019047, 0.20030946]\n",
      "[0.60594034, 0.2, 0.20011254, 0.20023914]\n",
      "[0.6059187, 0.2, 0.2001406, 0.20020191]\n",
      "[0.60608864, 0.2, 0.20022453, 0.2003002]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16290 iterations: 3.8669697483380636 mins\n",
      "Train Loss: [0.60608864, 0.2, 0.20022453, 0.2003002]\n",
      "[0.6058912, 0.2, 0.20016436, 0.2001751]\n",
      "[0.6058907, 0.2, 0.20019828, 0.20015274]\n",
      "[0.60589063, 0.2, 0.2001836, 0.20017934]\n",
      "[0.6059329, 0.2, 0.20014033, 0.20027682]\n",
      "[0.60597885, 0.2, 0.2002661, 0.2002087]\n",
      "[0.6057411, 0.2, 0.20007712, 0.20017156]\n",
      "[0.6060139, 0.2, 0.20020072, 0.20033239]\n",
      "[0.60595024, 0.2, 0.20020384, 0.20027697]\n",
      "[0.6059106, 0.2, 0.2001559, 0.20029637]\n",
      "[0.6063274, 0.2, 0.20058428, 0.20029587]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16300 iterations: 3.8689636826515197 mins\n",
      "Train Loss: [0.6063274, 0.2, 0.20058428, 0.20029587]\n",
      "[0.60569096, 0.2, 0.20008387, 0.20017076]\n",
      "[0.60575914, 0.2, 0.20019242, 0.20014131]\n",
      "[0.6057023, 0.2, 0.20013072, 0.20015706]\n",
      "[0.6058117, 0.2, 0.2000601, 0.20034789]\n",
      "[0.6058518, 0.2, 0.20014845, 0.20031033]\n",
      "[0.6056457, 0.2, 0.20012486, 0.20013838]\n",
      "[0.605798, 0.2, 0.2001303, 0.20029566]\n",
      "[0.6057001, 0.2, 0.20007505, 0.20026328]\n",
      "[0.6056904, 0.2, 0.2002035, 0.20013535]\n",
      "[0.60570216, 0.2, 0.20011275, 0.20024781]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16310 iterations: 3.870902681350708 mins\n",
      "Train Loss: [0.60570216, 0.2, 0.20011275, 0.20024781]\n",
      "[0.6056165, 0.2, 0.2000603, 0.2002246]\n",
      "[0.6058107, 0.2, 0.2001423, 0.20034654]\n",
      "[0.6057256, 0.2, 0.20020649, 0.2002068]\n",
      "[0.6055691, 0.2, 0.20009743, 0.20016882]\n",
      "[0.6056153, 0.2, 0.20008782, 0.20023385]\n",
      "[0.60556996, 0.2, 0.20015687, 0.2001284]\n",
      "[0.60558766, 0.2, 0.20009461, 0.20021725]\n",
      "[0.6056068, 0.2, 0.20009895, 0.20024088]\n",
      "[0.60554904, 0.2, 0.2000526, 0.20023824]\n",
      "[0.60560656, 0.2, 0.20013876, 0.2002183]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16320 iterations: 3.872922166188558 mins\n",
      "Train Loss: [0.60560656, 0.2, 0.20013876, 0.2002183]\n",
      "[0.6055554, 0.2, 0.20016702, 0.20014746]\n",
      "[0.60569286, 0.2, 0.20008998, 0.20037037]\n",
      "[0.6055001, 0.2, 0.20013936, 0.20013651]\n",
      "[0.6054695, 0.2, 0.20009203, 0.2001615]\n",
      "[0.6054382, 0.2, 0.20007423, 0.20015617]\n",
      "[0.60546076, 0.2, 0.20013857, 0.20012261]\n",
      "[0.605591, 0.2, 0.20012169, 0.20027784]\n",
      "[0.60543346, 0.2, 0.20004788, 0.20020217]\n",
      "[0.6054398, 0.2, 0.20015638, 0.20010813]\n",
      "[0.6054934, 0.2, 0.20012133, 0.20020485]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16330 iterations: 3.8747819979985554 mins\n",
      "Train Loss: [0.6054934, 0.2, 0.20012133, 0.20020485]\n",
      "[0.6055037, 0.2, 0.20010448, 0.20023999]\n",
      "[0.6054818, 0.2, 0.20010747, 0.20022301]\n",
      "[0.6055217, 0.2, 0.20012666, 0.20025147]\n",
      "[0.60547394, 0.2, 0.20009382, 0.20024426]\n",
      "[0.60628337, 0.2, 0.20088147, 0.20027389]\n",
      "[0.605461, 0.2, 0.20014094, 0.20019986]\n",
      "[0.6053401, 0.2, 0.20010774, 0.20011997]\n",
      "[0.6054372, 0.2, 0.20012133, 0.20021124]\n",
      "[0.6054272, 0.2, 0.20009707, 0.2002332]\n",
      "[0.60526717, 0.2, 0.20005922, 0.20011875]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16340 iterations: 3.8767717162768047 mins\n",
      "Train Loss: [0.60526717, 0.2, 0.20005922, 0.20011875]\n",
      "[0.605278, 0.2, 0.20008163, 0.20011488]\n",
      "[0.6053082, 0.2, 0.20007011, 0.20016399]\n",
      "[0.60545, 0.2, 0.20009354, 0.20028985]\n",
      "[0.60533243, 0.2, 0.20009024, 0.20018308]\n",
      "[0.6053102, 0.2, 0.2000822, 0.20017631]\n",
      "[0.60540205, 0.2, 0.2001113, 0.20024647]\n",
      "[0.60542375, 0.2, 0.20023455, 0.20015226]\n",
      "[0.60528183, 0.2, 0.20009267, 0.20015948]\n",
      "[0.60525584, 0.2, 0.20012534, 0.20010811]\n",
      "[0.6052116, 0.2, 0.20008981, 0.20010667]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16350 iterations: 3.8786428133646647 mins\n",
      "Train Loss: [0.6052116, 0.2, 0.20008981, 0.20010667]\n",
      "[0.60538965, 0.2, 0.20021826, 0.2001635]\n",
      "[0.6052651, 0.2, 0.20013836, 0.2001259]\n",
      "[0.60520047, 0.2, 0.20010222, 0.20010474]\n",
      "[0.60512, 0.2, 0.2, 0.20013362]\n",
      "[0.6051684, 0.2, 0.20007513, 0.20011395]\n",
      "[0.6052323, 0.2, 0.20010512, 0.2001548]\n",
      "[0.6052182, 0.2, 0.20010613, 0.20014663]\n",
      "[0.6054108, 0.2, 0.2002024, 0.20024996]\n",
      "[0.6051799, 0.2, 0.20009032, 0.20013794]\n",
      "[0.6051664, 0.2, 0.20006497, 0.20015663]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16360 iterations: 3.881268548965454 mins\n",
      "Train Loss: [0.6051664, 0.2, 0.20006497, 0.20015663]\n",
      "[0.60519207, 0.2, 0.20008929, 0.20016494]\n",
      "[0.6052335, 0.2, 0.2001335, 0.20016901]\n",
      "[0.60519516, 0.2, 0.20013614, 0.20013493]\n",
      "[0.60521317, 0.2, 0.20012158, 0.20017448]\n",
      "[0.60509396, 0.2, 0.20010285, 0.20008081]\n",
      "[0.6050984, 0.2, 0.2000718, 0.20012318]\n",
      "[0.60508, 0.2, 0.20006235, 0.20012096]\n",
      "[0.60504967, 0.2, 0.20006385, 0.20009583]\n",
      "[0.60509604, 0.2, 0.2000587, 0.2001541]\n",
      "[0.60515493, 0.2, 0.20014353, 0.20013492]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16370 iterations: 3.883315984408061 mins\n",
      "Train Loss: [0.60515493, 0.2, 0.20014353, 0.20013492]\n",
      "[0.6050698, 0.2, 0.2000531, 0.20014685]\n",
      "[0.60509, 0.2, 0.20008734, 0.20013934]\n",
      "[0.6050442, 0.2, 0.20007817, 0.20010917]\n",
      "[0.60505074, 0.2, 0.2000524, 0.20014787]\n",
      "[0.6050138, 0.2, 0.20005752, 0.20011213]\n",
      "[0.605065, 0.2, 0.20007531, 0.20015192]\n",
      "[0.6049632, 0.2, 0.20004675, 0.20008495]\n",
      "[0.60499805, 0.2, 0.20007007, 0.20010285]\n",
      "[0.60502994, 0.2, 0.20006815, 0.20014298]\n",
      "[0.6050158, 0.2, 0.20007637, 0.20012687]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16380 iterations: 3.885238432884216 mins\n",
      "Train Loss: [0.6050158, 0.2, 0.20007637, 0.20012687]\n",
      "[0.60495496, 0.2, 0.20005982, 0.2000888]\n",
      "[0.60504186, 0.2, 0.20004818, 0.2001935]\n",
      "[0.60500014, 0.2, 0.2000978, 0.20010829]\n",
      "[0.6049444, 0.2, 0.20004001, 0.20011649]\n",
      "[0.604947, 0.2, 0.20007376, 0.20009151]\n",
      "[0.60502106, 0.2, 0.20008636, 0.20015913]\n",
      "[0.6049931, 0.2, 0.20007843, 0.20014527]\n",
      "[0.6049017, 0.2, 0.20009603, 0.20004232]\n",
      "[0.6048148, 0.2, 0.2, 0.20005767]\n",
      "[0.6049836, 0.2, 0.2001156, 0.20011687]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16390 iterations: 3.8872671643892924 mins\n",
      "Train Loss: [0.6049836, 0.2, 0.2001156, 0.20011687]\n",
      "[0.60496193, 0.2, 0.20009908, 0.20011763]\n",
      "[0.6048435, 0.2, 0.20002814, 0.20007607]\n",
      "[0.604923, 0.2, 0.20011808, 0.20007162]\n",
      "[0.6048639, 0.2, 0.20004283, 0.20009355]\n",
      "[0.6049095, 0.2, 0.2000485, 0.20013933]\n",
      "[0.6049127, 0.2, 0.20006238, 0.20013446]\n",
      "[0.60489166, 0.2, 0.20004098, 0.20014063]\n",
      "[0.6048313, 0.2, 0.20005532, 0.20007156]\n",
      "[0.6050631, 0.2, 0.20017952, 0.20018488]\n",
      "[0.6048672, 0.2, 0.20006481, 0.20010938]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16400 iterations: 3.8891481518745423 mins\n",
      "Train Loss: [0.6048672, 0.2, 0.20006481, 0.20010938]\n",
      "[0.60492224, 0.2, 0.20010403, 0.20013092]\n",
      "[0.6048468, 0.2, 0.20007393, 0.20009132]\n",
      "[0.60494494, 0.2, 0.20012869, 0.20014036]\n",
      "[0.60483, 0.2, 0.20008752, 0.20007229]\n",
      "[0.60474885, 0.2, 0.20005533, 0.20002897]\n",
      "[0.6048631, 0.2, 0.20006467, 0.20013957]\n",
      "[0.604828, 0.2, 0.20008853, 0.2000863]\n",
      "[0.60481745, 0.2, 0.20005801, 0.200112]\n",
      "[0.60485923, 0.2, 0.2000967, 0.20012088]\n",
      "[0.60549337, 0.2, 0.20007804, 0.20077927]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16410 iterations: 3.891259129842122 mins\n",
      "Train Loss: [0.60549337, 0.2, 0.20007804, 0.20077927]\n",
      "[0.6047456, 0.2, 0.20005338, 0.20006186]\n",
      "[0.604798, 0.2, 0.20004202, 0.20013122]\n",
      "[0.60483265, 0.2, 0.20007755, 0.20013587]\n",
      "[0.60481393, 0.2, 0.20007154, 0.20012867]\n",
      "[0.60474026, 0.2, 0.20007846, 0.20005359]\n",
      "[0.60475117, 0.2, 0.20005369, 0.2000947]\n",
      "[0.6047148, 0.2, 0.20004198, 0.20007537]\n",
      "[0.60469496, 0.2, 0.20002927, 0.20007361]\n",
      "[0.6047037, 0.2, 0.20002952, 0.20008741]\n",
      "[0.60470647, 0.2, 0.20003611, 0.20008893]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16420 iterations: 3.893236033121745 mins\n",
      "Train Loss: [0.60470647, 0.2, 0.20003611, 0.20008893]\n",
      "[0.60476047, 0.2, 0.20004053, 0.20014374]\n",
      "[0.60479176, 0.2, 0.2000788, 0.20014204]\n",
      "[0.6047774, 0.2, 0.20006764, 0.20014411]\n",
      "[0.6046995, 0.2, 0.20005298, 0.2000861]\n",
      "[0.6046834, 0.2, 0.20004736, 0.20008089]\n",
      "[0.60464746, 0.2, 0.20003572, 0.20006181]\n",
      "[0.60469174, 0.2, 0.20005742, 0.20008954]\n",
      "[0.6046642, 0.2, 0.20005162, 0.20007303]\n",
      "[0.6046859, 0.2, 0.20006032, 0.20009124]\n",
      "[0.6047035, 0.2, 0.2000679, 0.20010638]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16430 iterations: 3.89518453280131 mins\n",
      "Train Loss: [0.6047035, 0.2, 0.2000679, 0.20010638]\n",
      "[0.6047696, 0.2, 0.2000511, 0.20019448]\n",
      "[0.6046147, 0.2, 0.20003915, 0.20005675]\n",
      "[0.6046962, 0.2, 0.20009676, 0.20008576]\n",
      "[0.6051062, 0.2, 0.20042396, 0.2001737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60468084, 0.2, 0.20005588, 0.20012154]\n",
      "[0.6047944, 0.2, 0.20011015, 0.20018582]\n",
      "[0.60474986, 0.2, 0.20007992, 0.20017657]\n",
      "[0.6049497, 0.2, 0.20036612, 0.2000951]\n",
      "[0.60464334, 0.2, 0.20007613, 0.20008363]\n",
      "[0.60478175, 0.2, 0.20009577, 0.20020726]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16440 iterations: 3.8987494309743247 mins\n",
      "Train Loss: [0.60478175, 0.2, 0.20009577, 0.20020726]\n",
      "[0.60474885, 0.2, 0.2001257, 0.2001494]\n",
      "[0.60462886, 0.2, 0.20006156, 0.20009848]\n",
      "[0.60467345, 0.2, 0.20009692, 0.20011258]\n",
      "[0.60462135, 0.2, 0.20005162, 0.20011066]\n",
      "[0.6046609, 0.2, 0.20003465, 0.20017207]\n",
      "[0.6526177, 0.2, 0.24800552, 0.20016277]\n",
      "[0.6421031, 0.2, 0.2366686, 0.20095146]\n",
      "[0.6249481, 0.2, 0.2201144, 0.20025936]\n",
      "[0.6246155, 0.2, 0.21838163, 0.20152028]\n",
      "[0.73679364, 0.2, 0.32973462, 0.20218705]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16450 iterations: 3.9007141828536986 mins\n",
      "Train Loss: [0.73679364, 0.2, 0.32973462, 0.20218705]\n",
      "[0.6409854, 0.2, 0.23250489, 0.20337178]\n",
      "[0.6298656, 0.2, 0.21778663, 0.20666118]\n",
      "[0.64104205, 0.2, 0.22614205, 0.20914516]\n",
      "[0.8509242, 0.2, 0.26701814, 0.3777857]\n",
      "[0.61601293, 0.2, 0.2021015, 0.20742439]\n",
      "[0.74785125, 0.2, 0.32289207, 0.21808065]\n",
      "[0.7012002, 0.2, 0.27411723, 0.21974799]\n",
      "[0.67934585, 0.2, 0.2533976, 0.21810679]\n",
      "[0.657012, 0.2, 0.2248469, 0.22379102]\n",
      "[0.6747846, 0.2, 0.2356435, 0.23021668]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16460 iterations: 3.902652831872304 mins\n",
      "Train Loss: [0.6747846, 0.2, 0.2356435, 0.23021668]\n",
      "[0.6444875, 0.2, 0.21519054, 0.21979213]\n",
      "[0.6629808, 0.2, 0.23333007, 0.21956648]\n",
      "[0.67400163, 0.2, 0.25006908, 0.21325888]\n",
      "[0.6530911, 0.2, 0.22662817, 0.21521276]\n",
      "[0.64807844, 0.2, 0.22405, 0.21223456]\n",
      "[0.65309006, 0.2, 0.23339608, 0.20738706]\n",
      "[0.65861595, 0.2, 0.21625012, 0.22956008]\n",
      "[0.67950743, 0.2, 0.25240377, 0.21384585]\n",
      "[0.6541035, 0.2, 0.2263213, 0.21409832]\n",
      "[0.65240633, 0.2, 0.22208716, 0.21624717]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16470 iterations: 3.9046823342641193 mins\n",
      "Train Loss: [0.65240633, 0.2, 0.22208716, 0.21624717]\n",
      "[0.6475323, 0.2, 0.21256831, 0.22053304]\n",
      "[0.6458097, 0.2, 0.22603363, 0.20502615]\n",
      "[0.6308972, 0.2, 0.21236663, 0.20348176]\n",
      "[0.62574166, 0.2, 0.20823374, 0.20221661]\n",
      "[0.62360775, 0.2, 0.20632389, 0.20179799]\n",
      "[0.63296247, 0.2, 0.2153631, 0.20196098]\n",
      "[0.62019205, 0.2, 0.20313406, 0.20130832]\n",
      "[0.6257172, 0.2, 0.20909026, 0.2008025]\n",
      "[0.6432578, 0.2, 0.2019635, 0.22542988]\n",
      "[0.6281673, 0.2, 0.20713925, 0.2051507]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16480 iterations: 3.90672253370285 mins\n",
      "Train Loss: [0.6281673, 0.2, 0.20713925, 0.2051507]\n",
      "[0.62067574, 0.2, 0.20328641, 0.20152698]\n",
      "[0.6222605, 0.2, 0.2054621, 0.20097542]\n",
      "[0.6264564, 0.2, 0.20869052, 0.202005]\n",
      "[0.6286939, 0.2, 0.21074988, 0.20226474]\n",
      "[0.6259306, 0.2, 0.20826991, 0.20207897]\n",
      "[0.62782663, 0.2, 0.20723392, 0.20512341]\n",
      "[0.630586, 0.2, 0.21297425, 0.20226626]\n",
      "[0.623927, 0.2, 0.20677572, 0.20193927]\n",
      "[0.6390931, 0.2, 0.22107671, 0.2029449]\n",
      "[0.62146044, 0.2, 0.20375805, 0.2027764]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16490 iterations: 3.908824384212494 mins\n",
      "Train Loss: [0.62146044, 0.2, 0.20375805, 0.2027764]\n",
      "[0.6194835, 0.2, 0.20335926, 0.2013478]\n",
      "[0.62391335, 0.2, 0.20671812, 0.20257111]\n",
      "[0.6238464, 0.2, 0.20516248, 0.20421346]\n",
      "[0.6215459, 0.2, 0.20555505, 0.20167466]\n",
      "[0.62666065, 0.2, 0.20965809, 0.20284048]\n",
      "[0.6248819, 0.2, 0.20768425, 0.20318854]\n",
      "[0.63008916, 0.2, 0.21501486, 0.20121631]\n",
      "[0.6258258, 0.2, 0.20926918, 0.20284736]\n",
      "[0.62317866, 0.2, 0.20820984, 0.20140618]\n",
      "[0.6239232, 0.2, 0.2070186, 0.20348622]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16500 iterations: 3.9107776323954266 mins\n",
      "Train Loss: [0.6239232, 0.2, 0.2070186, 0.20348622]\n",
      "[0.6205051, 0.2, 0.20558663, 0.20164137]\n",
      "[0.6252586, 0.2, 0.2084836, 0.2036361]\n",
      "[0.62601835, 0.2, 0.20841995, 0.20459507]\n",
      "[0.62803406, 0.2, 0.2122389, 0.20292453]\n",
      "[0.6232328, 0.2, 0.20903099, 0.20146126]\n",
      "[0.6251251, 0.2, 0.20809703, 0.20441416]\n",
      "[0.62218016, 0.2, 0.2081804, 0.20150927]\n",
      "[0.63107413, 0.2, 0.21207611, 0.2066277]\n",
      "[0.6215354, 0.2, 0.20771502, 0.20156808]\n",
      "[0.6188191, 0.2, 0.20430765, 0.20237395]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16510 iterations: 3.9126926501592 mins\n",
      "Train Loss: [0.6188191, 0.2, 0.20430765, 0.20237395]\n",
      "[0.615854, 0.2, 0.2018175, 0.20201097]\n",
      "[0.63868713, 0.2, 0.22368617, 0.20308454]\n",
      "[0.6304872, 0.2, 0.21445858, 0.20421825]\n",
      "[0.6182817, 0.2, 0.20532434, 0.20125051]\n",
      "[0.627889, 0.2, 0.21369842, 0.20258458]\n",
      "[0.6378114, 0.2, 0.22158566, 0.2047183]\n",
      "[0.62106687, 0.2, 0.20830877, 0.20134327]\n",
      "[0.63028705, 0.2, 0.20729545, 0.21166708]\n",
      "[0.6344904, 0.2, 0.20445836, 0.21879682]\n",
      "[0.61952144, 0.2, 0.20663217, 0.20173891]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16520 iterations: 3.91514169772466 mins\n",
      "Train Loss: [0.61952144, 0.2, 0.20663217, 0.20173891]\n",
      "[0.6211548, 0.2, 0.20874387, 0.20134361]\n",
      "[0.6216562, 0.2, 0.20816466, 0.20250496]\n",
      "[0.622599, 0.2, 0.20714623, 0.20454514]\n",
      "[0.6165821, 0.2, 0.2029941, 0.2027576]\n",
      "[0.61764747, 0.2, 0.20417532, 0.20271698]\n",
      "[0.62745047, 0.2, 0.21509938, 0.20166957]\n",
      "[0.61770505, 0.2, 0.20465085, 0.20244534]\n",
      "[0.62176293, 0.2, 0.21003875, 0.2011864]\n",
      "[0.62039995, 0.2, 0.20637934, 0.20355286]\n",
      "[0.6292812, 0.2, 0.21572708, 0.20315464]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16530 iterations: 3.916989600658417 mins\n",
      "Train Loss: [0.6292812, 0.2, 0.21572708, 0.20315464]\n",
      "[0.6316266, 0.2, 0.21645902, 0.20483513]\n",
      "[0.6233104, 0.2, 0.20864615, 0.20439759]\n",
      "[0.6240414, 0.2, 0.21048912, 0.20335023]\n",
      "[0.62071717, 0.2, 0.2089237, 0.20165507]\n",
      "[0.62445056, 0.2, 0.20775391, 0.20662057]\n",
      "[0.62219375, 0.2, 0.20845708, 0.20372155]\n",
      "[0.61998534, 0.2, 0.2049375, 0.20509252]\n",
      "[0.6165954, 0.2, 0.20470686, 0.20199196]\n",
      "[0.6211989, 0.2, 0.20823814, 0.20312142]\n",
      "[0.61953145, 0.2, 0.20840509, 0.20134304]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16540 iterations: 3.9190695842107135 mins\n",
      "Train Loss: [0.61953145, 0.2, 0.20840509, 0.20134304]\n",
      "[0.6170421, 0.2, 0.20501071, 0.20230305]\n",
      "[0.6239821, 0.2, 0.21240105, 0.20190658]\n",
      "[0.6255581, 0.2, 0.21164824, 0.20428804]\n",
      "[0.6198545, 0.2, 0.20898521, 0.2012993]\n",
      "[0.6149709, 0.2, 0.20258068, 0.20287144]\n",
      "[0.6214936, 0.2, 0.20737746, 0.2046478]\n",
      "[0.6215502, 0.2, 0.2088704, 0.2032614]\n",
      "[0.6167487, 0.2, 0.20276608, 0.20461336]\n",
      "[0.6191826, 0.2, 0.20520328, 0.20465842]\n",
      "[0.6167801, 0.2, 0.20387971, 0.20362715]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16550 iterations: 3.920935797691345 mins\n",
      "Train Loss: [0.6167801, 0.2, 0.20387971, 0.20362715]\n",
      "[0.61433923, 0.2, 0.20407945, 0.20103352]\n",
      "[0.61453205, 0.2, 0.20217878, 0.20317335]\n",
      "[0.61329013, 0.2, 0.20218095, 0.2019745]\n",
      "[0.6278458, 0.2, 0.21526636, 0.20348942]\n",
      "[0.6263504, 0.2, 0.21271849, 0.20458627]\n",
      "[0.61444885, 0.2, 0.20252977, 0.20291689]\n",
      "[0.6253468, 0.2, 0.21380156, 0.20258579]\n",
      "[0.6196996, 0.2, 0.20612991, 0.20465215]\n",
      "[0.62968695, 0.2, 0.21835123, 0.20245896]\n",
      "[0.6374741, 0.2, 0.20964357, 0.2189922]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16560 iterations: 3.9229195674260455 mins\n",
      "Train Loss: [0.6374741, 0.2, 0.20964357, 0.2189922]\n",
      "[0.6324082, 0.2, 0.22164251, 0.2019652]\n",
      "[0.62146217, 0.2, 0.20802453, 0.20467389]\n",
      "[0.62118095, 0.2, 0.20937759, 0.20307572]\n",
      "[0.6261154, 0.2, 0.21502443, 0.20239802]\n",
      "[0.6226048, 0.2, 0.21237902, 0.20156656]\n",
      "[0.61769396, 0.2, 0.20572136, 0.20334668]\n",
      "[0.6121059, 0.2, 0.20229553, 0.20121722]\n",
      "[0.61694175, 0.2, 0.20630041, 0.2020806]\n",
      "[0.6215477, 0.2, 0.20999993, 0.20301898]\n",
      "[0.61560345, 0.2, 0.20299964, 0.2041065]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16570 iterations: 3.9249335328737893 mins\n",
      "Train Loss: [0.61560345, 0.2, 0.20299964, 0.2041065]\n",
      "[0.62239033, 0.2, 0.21026224, 0.20366219]\n",
      "[0.64680403, 0.2, 0.21632674, 0.22204232]\n",
      "[0.6214151, 0.2, 0.20864062, 0.20436999]\n",
      "[0.6184188, 0.2, 0.20682177, 0.20322219]\n",
      "[0.6189109, 0.2, 0.20823093, 0.20233415]\n",
      "[0.6222136, 0.2, 0.21164449, 0.20225208]\n",
      "[0.6201248, 0.2, 0.2085855, 0.20325083]\n",
      "[0.6118008, 0.2, 0.20181988, 0.20172067]\n",
      "[0.6205723, 0.2, 0.2109771, 0.20136283]\n",
      "[0.658331, 0.2, 0.2483851, 0.2017412]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16580 iterations: 3.9271628499031066 mins\n",
      "Train Loss: [0.658331, 0.2, 0.2483851, 0.2017412]\n",
      "[0.6162825, 0.2, 0.20617276, 0.2019342]\n",
      "[0.61826324, 0.2, 0.20808686, 0.20202945]\n",
      "[0.62407714, 0.2, 0.21365894, 0.2022995]\n",
      "[0.6290912, 0.2, 0.20095044, 0.22004947]\n",
      "[0.619573, 0.2, 0.20888835, 0.20262119]\n",
      "[0.6292217, 0.2, 0.21095854, 0.21022683]\n",
      "[0.6378884, 0.2, 0.22716197, 0.20271726]\n",
      "[0.62214196, 0.2, 0.2101486, 0.20401095]\n",
      "[0.62007046, 0.2, 0.20898202, 0.20313205]\n",
      "[0.61814404, 0.2, 0.2063789, 0.2038341]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16590 iterations: 3.9291377663612366 mins\n",
      "Train Loss: [0.61814404, 0.2, 0.2063789, 0.2038341]\n",
      "[0.6203609, 0.2, 0.20540869, 0.20704602]\n",
      "[0.6159833, 0.2, 0.2057933, 0.20230862]\n",
      "[0.6304909, 0.2, 0.21852076, 0.2041135]\n",
      "[0.62081015, 0.2, 0.2100564, 0.20292097]\n",
      "[0.6118867, 0.2, 0.202635, 0.20144215]\n",
      "[0.61331886, 0.2, 0.20349462, 0.20203769]\n",
      "[0.63820726, 0.2, 0.22663975, 0.20380381]\n",
      "[0.611819, 0.2, 0.20061038, 0.2034678]\n",
      "[0.6191957, 0.2, 0.20786028, 0.20361723]\n",
      "[0.61124843, 0.2, 0.20118071, 0.20237198]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16600 iterations: 3.9316034356753033 mins\n",
      "Train Loss: [0.61124843, 0.2, 0.20118071, 0.20237198]\n",
      "[0.6161413, 0.2, 0.20678538, 0.20168255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61710894, 0.2, 0.20645612, 0.20300123]\n",
      "[0.62409776, 0.2, 0.21514954, 0.20131846]\n",
      "[0.61582935, 0.2, 0.20461863, 0.20360233]\n",
      "[0.6210821, 0.2, 0.21076548, 0.20272914]\n",
      "[0.6147663, 0.2, 0.20596303, 0.20123653]\n",
      "[0.6159352, 0.2, 0.20605128, 0.2023377]\n",
      "[0.622688, 0.2, 0.21274655, 0.2024157]\n",
      "[0.61679703, 0.2, 0.20740716, 0.20188455]\n",
      "[0.62906915, 0.2, 0.21891356, 0.20267071]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16610 iterations: 3.9338027358055117 mins\n",
      "Train Loss: [0.62906915, 0.2, 0.21891356, 0.20267071]\n",
      "[0.62312305, 0.2, 0.21401061, 0.20164745]\n",
      "[0.6146334, 0.2, 0.2058632, 0.20132484]\n",
      "[0.612105, 0.2, 0.20336212, 0.20131701]\n",
      "[0.61621267, 0.2, 0.206655, 0.20215115]\n",
      "[0.6119925, 0.2, 0.20227616, 0.20232902]\n",
      "[0.615532, 0.2, 0.20495316, 0.20321082]\n",
      "[0.6106254, 0.2, 0.2012845, 0.20199215]\n",
      "[0.6216906, 0.2, 0.21194945, 0.20241138]\n",
      "[0.6165767, 0.2, 0.20564237, 0.20362306]\n",
      "[0.6223143, 0.2, 0.21290927, 0.20211196]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16620 iterations: 3.935737152894338 mins\n",
      "Train Loss: [0.6223143, 0.2, 0.21290927, 0.20211196]\n",
      "[0.61359364, 0.2, 0.20440263, 0.20191583]\n",
      "[0.6166393, 0.2, 0.20534171, 0.20404026]\n",
      "[0.6142403, 0.2, 0.20556287, 0.20143779]\n",
      "[0.6114871, 0.2, 0.20204343, 0.2022214]\n",
      "[0.61923206, 0.2, 0.2108573, 0.20116973]\n",
      "[0.6169488, 0.2, 0.20724437, 0.20251632]\n",
      "[0.62140083, 0.2, 0.21205209, 0.2021774]\n",
      "[0.6301036, 0.2, 0.21998867, 0.2029603]\n",
      "[0.61636543, 0.2, 0.20734389, 0.20188339]\n",
      "[0.6282487, 0.2, 0.20684497, 0.21428183]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16630 iterations: 3.937762765089671 mins\n",
      "Train Loss: [0.6282487, 0.2, 0.20684497, 0.21428183]\n",
      "[0.6216228, 0.2, 0.21240811, 0.20210934]\n",
      "[0.65184855, 0.2, 0.20792584, 0.23683348]\n",
      "[0.615621, 0.2, 0.20695099, 0.20159666]\n",
      "[0.6171701, 0.2, 0.20842768, 0.2016847]\n",
      "[0.62703013, 0.2, 0.21802963, 0.20195836]\n",
      "[0.6118187, 0.2, 0.20351914, 0.20126936]\n",
      "[0.6591811, 0.2, 0.22315826, 0.22900452]\n",
      "[0.6128556, 0.2, 0.20453584, 0.20131323]\n",
      "[0.6141641, 0.2, 0.20443806, 0.20273085]\n",
      "[0.6216105, 0.2, 0.21252614, 0.20210071]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16640 iterations: 3.9398738980293273 mins\n",
      "Train Loss: [0.6216105, 0.2, 0.21252614, 0.20210071]\n",
      "[0.6172307, 0.2, 0.20872328, 0.20153579]\n",
      "[0.6257497, 0.2, 0.20484059, 0.21394964]\n",
      "[0.6094852, 0.2, 0.2014197, 0.20111938]\n",
      "[0.6221646, 0.2, 0.21316735, 0.2020641]\n",
      "[0.61464924, 0.2, 0.20660956, 0.2011188]\n",
      "[0.6117113, 0.2, 0.2019265, 0.20287594]\n",
      "[0.61181235, 0.2, 0.20224775, 0.20266779]\n",
      "[0.645621, 0.2, 0.23619792, 0.20253825]\n",
      "[0.6130416, 0.2, 0.2043222, 0.20184419]\n",
      "[0.6762853, 0.2, 0.26781756, 0.20160238]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16650 iterations: 3.9418821851412456 mins\n",
      "Train Loss: [0.6762853, 0.2, 0.26781756, 0.20160238]\n",
      "[0.61681616, 0.2, 0.20745733, 0.20250551]\n",
      "[0.6164708, 0.2, 0.20567793, 0.2039515]\n",
      "[0.6130753, 0.2, 0.2042752, 0.20197037]\n",
      "[0.61567247, 0.2, 0.20666315, 0.20219125]\n",
      "[0.6150231, 0.2, 0.20324036, 0.2049762]\n",
      "[0.61473465, 0.2, 0.20635441, 0.20158556]\n",
      "[0.62340856, 0.2, 0.21265186, 0.20397435]\n",
      "[0.61269647, 0.2, 0.20360398, 0.20232211]\n",
      "[0.6116421, 0.2, 0.20176773, 0.20311594]\n",
      "[0.6151771, 0.2, 0.20570816, 0.20272242]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16660 iterations: 3.9439286986986795 mins\n",
      "Train Loss: [0.6151771, 0.2, 0.20570816, 0.20272242]\n",
      "[0.6122499, 0.2, 0.20444477, 0.20107058]\n",
      "[0.6132165, 0.2, 0.20505689, 0.20143731]\n",
      "[0.61415005, 0.2, 0.20333324, 0.20410687]\n",
      "[0.6265486, 0.2, 0.21766835, 0.20218295]\n",
      "[0.61854863, 0.2, 0.2066453, 0.20521833]\n",
      "[0.6120574, 0.2, 0.2040567, 0.20132801]\n",
      "[0.6123961, 0.2, 0.20501177, 0.20072414]\n",
      "[0.6178544, 0.2, 0.20715448, 0.20405205]\n",
      "[0.6136274, 0.2, 0.20504664, 0.20194519]\n",
      "[0.61539406, 0.2, 0.20742056, 0.20135014]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16670 iterations: 3.945893935362498 mins\n",
      "Train Loss: [0.61539406, 0.2, 0.20742056, 0.20135014]\n",
      "[0.6128898, 0.2, 0.20373748, 0.20254111]\n",
      "[0.6188795, 0.2, 0.21078016, 0.20150024]\n",
      "[0.6131078, 0.2, 0.2054311, 0.2010894]\n",
      "[0.6170933, 0.2, 0.20797141, 0.20254633]\n",
      "[0.63093925, 0.2, 0.20465174, 0.21972345]\n",
      "[0.6133463, 0.2, 0.20397764, 0.20281617]\n",
      "[0.6126583, 0.2, 0.20162876, 0.20448849]\n",
      "[0.6156268, 0.2, 0.20731628, 0.20178075]\n",
      "[0.6137919, 0.2, 0.2061844, 0.2010889]\n",
      "[0.6150682, 0.2, 0.20739424, 0.20116647]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16680 iterations: 3.94839426279068 mins\n",
      "Train Loss: [0.6150682, 0.2, 0.20739424, 0.20116647]\n",
      "[0.6143008, 0.2, 0.20584169, 0.20196234]\n",
      "[0.61639583, 0.2, 0.20901415, 0.20089537]\n",
      "[0.6122262, 0.2, 0.20429239, 0.20145787]\n",
      "[0.61471874, 0.2, 0.20547077, 0.2027823]\n",
      "[0.6315389, 0.2, 0.217054, 0.20802984]\n",
      "[0.6152423, 0.2, 0.20511685, 0.20367786]\n",
      "[0.6159718, 0.2, 0.2060067, 0.20352498]\n",
      "[0.6146887, 0.2, 0.20638745, 0.20186865]\n",
      "[0.6156061, 0.2, 0.20584778, 0.20333342]\n",
      "[0.6143952, 0.2, 0.20642859, 0.20154932]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16690 iterations: 3.9505494197209674 mins\n",
      "Train Loss: [0.6143952, 0.2, 0.20642859, 0.20154932]\n",
      "[0.6447641, 0.2, 0.23695768, 0.20139654]\n",
      "[0.61012, 0.2, 0.20162752, 0.20209265]\n",
      "[0.6172269, 0.2, 0.20913963, 0.20169753]\n",
      "[0.6115753, 0.2, 0.20364635, 0.20154908]\n",
      "[0.6195649, 0.2, 0.21211712, 0.20107752]\n",
      "[0.6152862, 0.2, 0.20762599, 0.20129924]\n",
      "[0.61532253, 0.2, 0.2073209, 0.20164983]\n",
      "[0.61446756, 0.2, 0.20691179, 0.20121324]\n",
      "[0.6121116, 0.2, 0.20470591, 0.2010724]\n",
      "[0.6123284, 0.2, 0.20492922, 0.2010751]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16700 iterations: 3.9524238308270774 mins\n",
      "Train Loss: [0.6123284, 0.2, 0.20492922, 0.2010751]\n",
      "[0.651928, 0.2, 0.22158982, 0.22402367]\n",
      "[0.6104606, 0.2, 0.20141523, 0.20274031]\n",
      "[0.6151463, 0.2, 0.20670554, 0.20214523]\n",
      "[0.6139376, 0.2, 0.2049747, 0.20267685]\n",
      "[0.6192715, 0.2, 0.21066086, 0.2023338]\n",
      "[0.6150679, 0.2, 0.20651405, 0.20228606]\n",
      "[0.61714315, 0.2, 0.20968802, 0.20119637]\n",
      "[0.6143651, 0.2, 0.20603564, 0.2020799]\n",
      "[0.61398697, 0.2, 0.20489328, 0.20285329]\n",
      "[0.61239135, 0.2, 0.20382874, 0.20233148]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16710 iterations: 3.9545103987058003 mins\n",
      "Train Loss: [0.61239135, 0.2, 0.20382874, 0.20233148]\n",
      "[0.61460346, 0.2, 0.20527767, 0.20310411]\n",
      "[0.6117791, 0.2, 0.2021637, 0.20340343]\n",
      "[0.6114527, 0.2, 0.20356089, 0.20168951]\n",
      "[0.6200029, 0.2, 0.21038754, 0.20342274]\n",
      "[0.61502457, 0.2, 0.20712326, 0.20171857]\n",
      "[0.60880333, 0.2, 0.2013456, 0.20128493]\n",
      "[0.61271733, 0.2, 0.20517965, 0.20137468]\n",
      "[0.626256, 0.2, 0.20597965, 0.21412282]\n",
      "[0.61483157, 0.2, 0.2067562, 0.2019324]\n",
      "[0.6191083, 0.2, 0.21114723, 0.20182844]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16720 iterations: 3.9563743472099304 mins\n",
      "Train Loss: [0.6191083, 0.2, 0.21114723, 0.20182844]\n",
      "[0.61813277, 0.2, 0.21115974, 0.20084973]\n",
      "[0.6090323, 0.2, 0.20216386, 0.20075394]\n",
      "[0.6118161, 0.2, 0.20381679, 0.20189346]\n",
      "[0.6162051, 0.2, 0.2079747, 0.20213324]\n",
      "[0.6126644, 0.2, 0.20545387, 0.20112202]\n",
      "[0.6105703, 0.2, 0.20271724, 0.20177254]\n",
      "[0.61739206, 0.2, 0.2065798, 0.20473976]\n",
      "[0.6151418, 0.2, 0.20695075, 0.20212638]\n",
      "[0.6125522, 0.2, 0.20434204, 0.20215331]\n",
      "[0.6137275, 0.2, 0.20444667, 0.20323145]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16730 iterations: 3.9584733327229817 mins\n",
      "Train Loss: [0.6137275, 0.2, 0.20444667, 0.20323145]\n",
      "[0.6108907, 0.2, 0.20248261, 0.20236582]\n",
      "[0.61160505, 0.2, 0.20467426, 0.20089586]\n",
      "[0.6201453, 0.2, 0.21228077, 0.20183727]\n",
      "[0.6196329, 0.2, 0.21055324, 0.20306036]\n",
      "[0.6127489, 0.2, 0.20374162, 0.20299582]\n",
      "[0.6133823, 0.2, 0.2059992, 0.20137921]\n",
      "[0.6161311, 0.2, 0.20465893, 0.20547569]\n",
      "[0.6115857, 0.2, 0.20342721, 0.20216966]\n",
      "[0.61676544, 0.2, 0.20824203, 0.20254242]\n",
      "[0.6228565, 0.2, 0.21544604, 0.20143713]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16740 iterations: 3.9603718837102253 mins\n",
      "Train Loss: [0.6228565, 0.2, 0.21544604, 0.20143713]\n",
      "[0.61273044, 0.2, 0.20238727, 0.20437726]\n",
      "[0.615046, 0.2, 0.20748265, 0.20160466]\n",
      "[0.61004, 0.2, 0.20264909, 0.20143943]\n",
      "[0.61909896, 0.2, 0.21170583, 0.20144872]\n",
      "[0.6216477, 0.2, 0.20145471, 0.21425554]\n",
      "[0.6104657, 0.2, 0.20360366, 0.20093267]\n",
      "[0.6137644, 0.2, 0.20676564, 0.20107734]\n",
      "[0.61462325, 0.2, 0.20686743, 0.201842]\n",
      "[0.6193461, 0.2, 0.21063265, 0.2028068]\n",
      "[0.613852, 0.2, 0.2060165, 0.20193577]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16750 iterations: 3.9622684677441913 mins\n",
      "Train Loss: [0.613852, 0.2, 0.2060165, 0.20193577]\n",
      "[0.6147342, 0.2, 0.2074837, 0.20135708]\n",
      "[0.6138036, 0.2, 0.20657104, 0.20134543]\n",
      "[0.61726975, 0.2, 0.20976798, 0.20162083]\n",
      "[0.6175059, 0.2, 0.20766924, 0.20396182]\n",
      "[0.61184543, 0.2, 0.20464073, 0.20133594]\n",
      "[0.6573242, 0.2, 0.20573716, 0.24572419]\n",
      "[0.61891973, 0.2, 0.20854037, 0.20452122]\n",
      "[0.6216686, 0.2, 0.20436528, 0.21144964]\n",
      "[0.6187113, 0.2, 0.21069667, 0.20216572]\n",
      "[0.61148375, 0.2, 0.20474926, 0.20089048]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16760 iterations: 3.964852213859558 mins\n",
      "Train Loss: [0.61148375, 0.2, 0.20474926, 0.20089048]\n",
      "[0.6205841, 0.2, 0.21329336, 0.20145167]\n",
      "[0.62771696, 0.2, 0.2088518, 0.21303064]\n",
      "[0.6153073, 0.2, 0.20672624, 0.20275159]\n",
      "[0.61283964, 0.2, 0.20325771, 0.20375729]\n",
      "[0.6124419, 0.2, 0.20465958, 0.20196265]\n",
      "[0.6102545, 0.2, 0.20327264, 0.20116694]\n",
      "[0.61072356, 0.2, 0.20215544, 0.20275795]\n",
      "[0.6174762, 0.2, 0.20786697, 0.20380409]\n",
      "[0.6174472, 0.2, 0.2096087, 0.20203832]\n",
      "[0.62337136, 0.2, 0.21365678, 0.20391957]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16770 iterations: 3.9668067653973895 mins\n",
      "Train Loss: [0.62337136, 0.2, 0.21365678, 0.20391957]\n",
      "[0.6214113, 0.2, 0.2138256, 0.20179585]\n",
      "[0.61421824, 0.2, 0.2060695, 0.20236358]\n",
      "[0.61560446, 0.2, 0.20770666, 0.2021176]\n",
      "[0.6115221, 0.2, 0.20413968, 0.20160717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61794204, 0.2, 0.2104069, 0.20176509]\n",
      "[0.6144353, 0.2, 0.20714217, 0.20152825]\n",
      "[0.61279666, 0.2, 0.20446622, 0.20257096]\n",
      "[0.60949785, 0.2, 0.20206039, 0.20168333]\n",
      "[0.61703044, 0.2, 0.21062656, 0.20065528]\n",
      "[0.6227697, 0.2, 0.21321672, 0.20381013]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16780 iterations: 3.968888847033183 mins\n",
      "Train Loss: [0.6227697, 0.2, 0.21321672, 0.20381013]\n",
      "[0.60995775, 0.2, 0.20253709, 0.20168343]\n",
      "[0.61572796, 0.2, 0.20845127, 0.20154516]\n",
      "[0.6133428, 0.2, 0.20655297, 0.20106412]\n",
      "[0.62654114, 0.2, 0.20257209, 0.21824916]\n",
      "[0.638584, 0.2, 0.23030072, 0.20256965]\n",
      "[0.61338574, 0.2, 0.20685203, 0.20082736]\n",
      "[0.61521125, 0.2, 0.20775834, 0.20175324]\n",
      "[0.6152987, 0.2, 0.20765503, 0.20195055]\n",
      "[0.61205417, 0.2, 0.20518151, 0.20118588]\n",
      "[0.6091714, 0.2, 0.20197207, 0.20151885]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16790 iterations: 3.970711966355642 mins\n",
      "Train Loss: [0.6091714, 0.2, 0.20197207, 0.20151885]\n",
      "[0.6096255, 0.2, 0.20160073, 0.20235053]\n",
      "[0.6106864, 0.2, 0.20444402, 0.20057441]\n",
      "[0.6172753, 0.2, 0.20918459, 0.20242873]\n",
      "[0.60984206, 0.2, 0.20312844, 0.2010575]\n",
      "[0.6272074, 0.2, 0.21793035, 0.20362672]\n",
      "[0.61532605, 0.2, 0.2081781, 0.20150287]\n",
      "[0.6123573, 0.2, 0.20502003, 0.2016977]\n",
      "[0.6234258, 0.2, 0.21632904, 0.20146242]\n",
      "[0.6121133, 0.2, 0.20503765, 0.201446]\n",
      "[0.61384803, 0.2, 0.20568871, 0.20253433]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16800 iterations: 3.972743499279022 mins\n",
      "Train Loss: [0.61384803, 0.2, 0.20568871, 0.20253433]\n",
      "[0.6146426, 0.2, 0.20658349, 0.20243868]\n",
      "[0.6342737, 0.2, 0.20654124, 0.22211662]\n",
      "[0.6102632, 0.2, 0.20315544, 0.20149603]\n",
      "[0.6160406, 0.2, 0.20840251, 0.2020305]\n",
      "[0.6130201, 0.2, 0.20621154, 0.20120513]\n",
      "[0.613305, 0.2, 0.20623787, 0.20146792]\n",
      "[0.61374503, 0.2, 0.20597985, 0.20217004]\n",
      "[0.6200916, 0.2, 0.21230665, 0.20219398]\n",
      "[0.61191016, 0.2, 0.20506524, 0.20125793]\n",
      "[0.6146618, 0.2, 0.20730883, 0.20177008]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16810 iterations: 3.9746014992396037 mins\n",
      "Train Loss: [0.6146618, 0.2, 0.20730883, 0.20177008]\n",
      "[0.6124079, 0.2, 0.20532726, 0.20150213]\n",
      "[0.6166462, 0.2, 0.2086543, 0.20241788]\n",
      "[0.6127283, 0.2, 0.20537506, 0.20178407]\n",
      "[0.61901015, 0.2, 0.21182136, 0.2016242]\n",
      "[0.6145086, 0.2, 0.2080608, 0.2008878]\n",
      "[0.6080237, 0.2, 0.20178653, 0.20068157]\n",
      "[0.6175662, 0.2, 0.20988399, 0.20213129]\n",
      "[0.6125833, 0.2, 0.20590298, 0.20113397]\n",
      "[0.6323763, 0.2, 0.20555788, 0.22127672]\n",
      "[0.61337554, 0.2, 0.20639385, 0.20144415]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16820 iterations: 3.9767097155253093 mins\n",
      "Train Loss: [0.61337554, 0.2, 0.20639385, 0.20144415]\n",
      "[0.61331147, 0.2, 0.20653136, 0.20124699]\n",
      "[0.6125821, 0.2, 0.2057332, 0.20132011]\n",
      "[0.61068857, 0.2, 0.20412298, 0.20104091]\n",
      "[0.6215486, 0.2, 0.21415219, 0.20187579]\n",
      "[0.6156371, 0.2, 0.20894338, 0.20117705]\n",
      "[0.6107984, 0.2, 0.20416358, 0.20112193]\n",
      "[0.6153289, 0.2, 0.2077487, 0.20207094]\n",
      "[0.6130423, 0.2, 0.20616186, 0.20137464]\n",
      "[0.6289389, 0.2, 0.22281185, 0.20062493]\n",
      "[0.61511487, 0.2, 0.20809674, 0.20152174]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16830 iterations: 3.978641565640767 mins\n",
      "Train Loss: [0.61511487, 0.2, 0.20809674, 0.20152174]\n",
      "[0.6135611, 0.2, 0.20545582, 0.20261449]\n",
      "[0.61198795, 0.2, 0.20395723, 0.20254512]\n",
      "[0.6158243, 0.2, 0.20765063, 0.20269315]\n",
      "[0.61647063, 0.2, 0.20979239, 0.20120297]\n",
      "[0.61639225, 0.2, 0.20988578, 0.20103608]\n",
      "[0.61312735, 0.2, 0.20599157, 0.20167005]\n",
      "[0.6109989, 0.2, 0.20457725, 0.20096038]\n",
      "[0.6110019, 0.2, 0.2020459, 0.20349915]\n",
      "[0.61362326, 0.2, 0.20609944, 0.20207132]\n",
      "[0.6422208, 0.2, 0.21197908, 0.22479334]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16840 iterations: 3.9810852805773416 mins\n",
      "Train Loss: [0.6422208, 0.2, 0.21197908, 0.22479334]\n",
      "[0.61617184, 0.2, 0.20809723, 0.20263067]\n",
      "[0.61184233, 0.2, 0.20432736, 0.20207548]\n",
      "[0.61334836, 0.2, 0.20629223, 0.2016211]\n",
      "[0.61631256, 0.2, 0.20658875, 0.20429309]\n",
      "[0.6086609, 0.2, 0.20214203, 0.20109248]\n",
      "[0.6095587, 0.2, 0.2024444, 0.20169237]\n",
      "[0.6145987, 0.2, 0.20674327, 0.20243803]\n",
      "[0.61313707, 0.2, 0.20587857, 0.20184563]\n",
      "[0.6120479, 0.2, 0.20560089, 0.20103846]\n",
      "[0.6101747, 0.2, 0.20246916, 0.20230134]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16850 iterations: 3.9831108967463176 mins\n",
      "Train Loss: [0.6101747, 0.2, 0.20246916, 0.20230134]\n",
      "[0.61751235, 0.2, 0.20895009, 0.20316261]\n",
      "[0.6117004, 0.2, 0.2046091, 0.20169634]\n",
      "[0.6113061, 0.2, 0.20522723, 0.2006884]\n",
      "[0.61672497, 0.2, 0.20829505, 0.20304401]\n",
      "[0.61284924, 0.2, 0.20564544, 0.2018225]\n",
      "[0.6127202, 0.2, 0.20539361, 0.20194983]\n",
      "[0.6129826, 0.2, 0.20644684, 0.20116381]\n",
      "[0.6116236, 0.2, 0.20441082, 0.2018453]\n",
      "[0.61641186, 0.2, 0.20926288, 0.20178601]\n",
      "[0.61310834, 0.2, 0.20666751, 0.20108183]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16860 iterations: 3.9849886139233908 mins\n",
      "Train Loss: [0.61310834, 0.2, 0.20666751, 0.20108183]\n",
      "[0.616255, 0.2, 0.20988263, 0.20101732]\n",
      "[0.61011165, 0.2, 0.20299926, 0.20176125]\n",
      "[0.6192503, 0.2, 0.21139807, 0.20250526]\n",
      "[0.6151223, 0.2, 0.20827426, 0.20150506]\n",
      "[0.61274755, 0.2, 0.20647195, 0.20093681]\n",
      "[0.6128156, 0.2, 0.20566429, 0.20181665]\n",
      "[0.61553854, 0.2, 0.2077606, 0.20244735]\n",
      "[0.61295396, 0.2, 0.20658642, 0.2010408]\n",
      "[0.6304634, 0.2, 0.21033202, 0.21480857]\n",
      "[0.6097123, 0.2, 0.20239063, 0.20200257]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16870 iterations: 3.9871174812316896 mins\n",
      "Train Loss: [0.6097123, 0.2, 0.20239063, 0.20200257]\n",
      "[0.6093182, 0.2, 0.20247115, 0.20153138]\n",
      "[0.6126512, 0.2, 0.20530702, 0.20203164]\n",
      "[0.6140487, 0.2, 0.20573977, 0.20299946]\n",
      "[0.611484, 0.2, 0.20381382, 0.20236354]\n",
      "[0.6103197, 0.2, 0.2035002, 0.2015158]\n",
      "[0.6140319, 0.2, 0.20718788, 0.20154315]\n",
      "[0.6158337, 0.2, 0.20959438, 0.2009412]\n",
      "[0.61009854, 0.2, 0.20357166, 0.20123172]\n",
      "[0.6107158, 0.2, 0.2025578, 0.20286594]\n",
      "[0.61296433, 0.2, 0.20600419, 0.20167132]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16880 iterations: 3.9889830470085146 mins\n",
      "Train Loss: [0.61296433, 0.2, 0.20600419, 0.20167132]\n",
      "[0.61096126, 0.2, 0.20439929, 0.20127653]\n",
      "[0.6142604, 0.2, 0.2073322, 0.20164627]\n",
      "[0.6185321, 0.2, 0.21150762, 0.20174597]\n",
      "[0.6119043, 0.2, 0.20520054, 0.20142874]\n",
      "[0.610062, 0.2, 0.20407261, 0.20071775]\n",
      "[0.61540794, 0.2, 0.20868844, 0.20145117]\n",
      "[0.61406994, 0.2, 0.2078596, 0.20094532]\n",
      "[0.61326575, 0.2, 0.20633379, 0.20167024]\n",
      "[0.62482643, 0.2, 0.21779923, 0.20176882]\n",
      "[0.6127523, 0.2, 0.20675041, 0.20074834]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16890 iterations: 3.9910477797190347 mins\n",
      "Train Loss: [0.6127523, 0.2, 0.20675041, 0.20074834]\n",
      "[0.6153682, 0.2, 0.20870507, 0.20141384]\n",
      "[0.60761046, 0.2, 0.20141095, 0.20095393]\n",
      "[0.6165323, 0.2, 0.20917888, 0.20211147]\n",
      "[0.61030763, 0.2, 0.204425, 0.20064445]\n",
      "[0.60914564, 0.2, 0.20265886, 0.20125233]\n",
      "[0.61258805, 0.2, 0.20471245, 0.2026448]\n",
      "[0.6152275, 0.2, 0.2086874, 0.20131297]\n",
      "[0.61426765, 0.2, 0.20612197, 0.20292212]\n",
      "[0.61571026, 0.2, 0.20872107, 0.2017689]\n",
      "[0.61625475, 0.2, 0.20981951, 0.20121832]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16900 iterations: 3.9936427672704062 mins\n",
      "Train Loss: [0.61625475, 0.2, 0.20981951, 0.20121832]\n",
      "[0.60888034, 0.2, 0.20131312, 0.20235369]\n",
      "[0.6254753, 0.2, 0.21939115, 0.200874]\n",
      "[0.6128068, 0.2, 0.20584416, 0.20175597]\n",
      "[0.6133457, 0.2, 0.20696938, 0.20117313]\n",
      "[0.6121222, 0.2, 0.20550498, 0.20141737]\n",
      "[0.64295566, 0.2, 0.21339351, 0.22436596]\n",
      "[0.6128935, 0.2, 0.2066624, 0.20103827]\n",
      "[0.6118752, 0.2, 0.20450711, 0.20217793]\n",
      "[0.61269236, 0.2, 0.20646794, 0.20103705]\n",
      "[0.60843396, 0.2, 0.20121248, 0.20203678]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16910 iterations: 3.998307132720947 mins\n",
      "Train Loss: [0.60843396, 0.2, 0.20121248, 0.20203678]\n",
      "[0.61560214, 0.2, 0.20886324, 0.20155674]\n",
      "[0.6703494, 0.2, 0.26382512, 0.2013446]\n",
      "[0.61612666, 0.2, 0.20953766, 0.20140955]\n",
      "[0.6188848, 0.2, 0.21250673, 0.20119873]\n",
      "[0.6196235, 0.2, 0.21334335, 0.20110066]\n",
      "[0.612585, 0.2, 0.20543835, 0.20196715]\n",
      "[0.61024135, 0.2, 0.20346336, 0.20159903]\n",
      "[0.61000496, 0.2, 0.20323849, 0.20158803]\n",
      "[0.6138832, 0.2, 0.20606472, 0.20264082]\n",
      "[0.6127963, 0.2, 0.20611916, 0.20150073]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16920 iterations: 4.000728750228882 mins\n",
      "Train Loss: [0.6127963, 0.2, 0.20611916, 0.20150073]\n",
      "[0.61246544, 0.2, 0.20651248, 0.2007781]\n",
      "[0.6106756, 0.2, 0.20328005, 0.20222242]\n",
      "[0.61537683, 0.2, 0.20769109, 0.20251472]\n",
      "[0.6107058, 0.2, 0.20426483, 0.20127243]\n",
      "[0.6071062, 0.2, 0.20120375, 0.2007367]\n",
      "[0.616522, 0.2, 0.21023586, 0.20112349]\n",
      "[0.6162587, 0.2, 0.21049212, 0.20060717]\n",
      "[0.6118945, 0.2, 0.20592867, 0.20080963]\n",
      "[0.6071843, 0.2, 0.20142996, 0.20060138]\n",
      "[0.6098869, 0.2, 0.20133357, 0.20340368]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16930 iterations: 4.002907435099284 mins\n",
      "Train Loss: [0.6098869, 0.2, 0.20133357, 0.20340368]\n",
      "[0.61881405, 0.2, 0.21244633, 0.20122156]\n",
      "[0.6107169, 0.2, 0.20408939, 0.20148471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6104842, 0.2, 0.20339373, 0.2019513]\n",
      "[0.6138026, 0.2, 0.20798074, 0.20068634]\n",
      "[0.6104372, 0.2, 0.20323165, 0.20207378]\n",
      "[0.6149397, 0.2, 0.2084212, 0.2013906]\n",
      "[0.60867864, 0.2, 0.20228072, 0.20127386]\n",
      "[0.6137636, 0.2, 0.20704284, 0.20160057]\n",
      "[0.62174976, 0.2, 0.21529457, 0.20133886]\n",
      "[0.61115897, 0.2, 0.20484607, 0.20120144]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16940 iterations: 4.005234797795613 mins\n",
      "Train Loss: [0.61115897, 0.2, 0.20484607, 0.20120144]\n",
      "[0.6159321, 0.2, 0.20944414, 0.20138097]\n",
      "[0.61381555, 0.2, 0.20744456, 0.20126817]\n",
      "[0.61319125, 0.2, 0.20625983, 0.20183255]\n",
      "[0.6091971, 0.2, 0.20280835, 0.2012938]\n",
      "[0.61043656, 0.2, 0.20382959, 0.20151599]\n",
      "[0.6103438, 0.2, 0.20452613, 0.20073055]\n",
      "[0.61135757, 0.2, 0.2051772, 0.20109724]\n",
      "[0.6117876, 0.2, 0.20572454, 0.20098387]\n",
      "[0.6269873, 0.2, 0.20395663, 0.21795525]\n",
      "[0.6097258, 0.2, 0.20400347, 0.20065011]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16950 iterations: 4.007414817810059 mins\n",
      "Train Loss: [0.6097258, 0.2, 0.20400347, 0.20065011]\n",
      "[0.6108068, 0.2, 0.20396167, 0.20177615]\n",
      "[0.6131804, 0.2, 0.2068437, 0.20127061]\n",
      "[0.6126806, 0.2, 0.20495625, 0.20266138]\n",
      "[0.6124088, 0.2, 0.20624113, 0.20110758]\n",
      "[0.6115489, 0.2, 0.20538998, 0.20110156]\n",
      "[0.6090206, 0.2, 0.20259506, 0.2013707]\n",
      "[0.6106017, 0.2, 0.20475009, 0.20079939]\n",
      "[0.6151359, 0.2, 0.2086471, 0.20143929]\n",
      "[0.61372006, 0.2, 0.2073136, 0.20135988]\n",
      "[0.64023566, 0.2, 0.2105764, 0.2246154]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16960 iterations: 4.010206349690756 mins\n",
      "Train Loss: [0.64023566, 0.2, 0.2105764, 0.2246154]\n",
      "[0.6097087, 0.2, 0.20324212, 0.20142621]\n",
      "[0.62556386, 0.2, 0.20709187, 0.21343498]\n",
      "[0.6180262, 0.2, 0.21131614, 0.20167519]\n",
      "[0.6111924, 0.2, 0.20473439, 0.20142476]\n",
      "[0.6093966, 0.2, 0.20341042, 0.2009545]\n",
      "[0.6070388, 0.2, 0.20061381, 0.20139487]\n",
      "[0.61723286, 0.2, 0.21115775, 0.20104653]\n",
      "[0.6099739, 0.2, 0.20387799, 0.20106925]\n",
      "[0.6104741, 0.2, 0.20390813, 0.20154141]\n",
      "[0.6124611, 0.2, 0.20636638, 0.2010724]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16970 iterations: 4.012561984856924 mins\n",
      "Train Loss: [0.6124611, 0.2, 0.20636638, 0.2010724]\n",
      "[0.6152475, 0.2, 0.20804882, 0.20217893]\n",
      "[0.6073719, 0.2, 0.20153561, 0.20081925]\n",
      "[0.61036235, 0.2, 0.20402478, 0.2013233]\n",
      "[0.61192375, 0.2, 0.20535348, 0.20155887]\n",
      "[0.61401373, 0.2, 0.20713018, 0.20187531]\n",
      "[0.62874097, 0.2, 0.22218215, 0.2015544]\n",
      "[0.6116984, 0.2, 0.20440045, 0.20229584]\n",
      "[0.6111198, 0.2, 0.20524698, 0.20087253]\n",
      "[0.61148334, 0.2, 0.20540236, 0.20108226]\n",
      "[0.6075364, 0.2, 0.20169182, 0.20084739]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16980 iterations: 4.015065868695577 mins\n",
      "Train Loss: [0.6075364, 0.2, 0.20169182, 0.20084739]\n",
      "[0.613868, 0.2, 0.20774603, 0.20112602]\n",
      "[0.6124659, 0.2, 0.20539588, 0.20207515]\n",
      "[0.61783785, 0.2, 0.21206194, 0.20078222]\n",
      "[0.61810297, 0.2, 0.21232264, 0.20078726]\n",
      "[0.60952306, 0.2, 0.203345, 0.20118572]\n",
      "[0.62013805, 0.2, 0.21413518, 0.2010111]\n",
      "[0.6109422, 0.2, 0.20482819, 0.20112231]\n",
      "[0.6079939, 0.2, 0.20222542, 0.2007764]\n",
      "[0.6148977, 0.2, 0.20917884, 0.20072605]\n",
      "[0.6150543, 0.2, 0.20907603, 0.20098363]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16990 iterations: 4.016943248112996 mins\n",
      "Train Loss: [0.6150543, 0.2, 0.20907603, 0.20098363]\n",
      "[0.6133443, 0.2, 0.20735525, 0.20099254]\n",
      "[0.6097856, 0.2, 0.20397349, 0.20081238]\n",
      "[0.61152846, 0.2, 0.2058573, 0.2006669]\n",
      "[0.6257024, 0.2, 0.20678337, 0.21390891]\n",
      "[0.62682384, 0.2, 0.22086273, 0.20094104]\n",
      "[0.63341075, 0.2, 0.22598414, 0.20238838]\n",
      "[0.61275876, 0.2, 0.20631894, 0.20137614]\n",
      "[0.61078113, 0.2, 0.20492199, 0.20076731]\n",
      "[0.6121257, 0.2, 0.20590898, 0.2010955]\n",
      "[0.62492335, 0.2, 0.20422713, 0.21554588]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17000 iterations: 4.0189352830251055 mins\n",
      "Train Loss: [0.62492335, 0.2, 0.20422713, 0.21554588]\n",
      "[0.61353207, 0.2, 0.20725693, 0.20110026]\n",
      "[0.6144737, 0.2, 0.20794529, 0.20133059]\n",
      "[0.6112541, 0.2, 0.20473202, 0.20130356]\n",
      "[0.60816765, 0.2, 0.20230943, 0.20062187]\n",
      "[0.63710713, 0.2, 0.2050816, 0.22677404]\n",
      "[0.6142417, 0.2, 0.20771533, 0.20126547]\n",
      "[0.6127089, 0.2, 0.20412175, 0.2033188]\n",
      "[0.6110715, 0.2, 0.20301338, 0.20278454]\n",
      "[0.61118054, 0.2, 0.20391937, 0.20198444]\n",
      "[0.61052746, 0.2, 0.20357849, 0.20167118]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17010 iterations: 4.020818150043487 mins\n",
      "Train Loss: [0.61052746, 0.2, 0.20357849, 0.20167118]\n",
      "[0.61487573, 0.2, 0.20759815, 0.20200051]\n",
      "[0.6124042, 0.2, 0.20577832, 0.20135146]\n",
      "[0.6125135, 0.2, 0.20568506, 0.20155843]\n",
      "[0.6098519, 0.2, 0.20392694, 0.2006605]\n",
      "[0.61516595, 0.2, 0.20885028, 0.20105769]\n",
      "[0.6250877, 0.2, 0.20797788, 0.21185936]\n",
      "[0.611986, 0.2, 0.20610386, 0.20063987]\n",
      "[0.6129578, 0.2, 0.20617947, 0.20154475]\n",
      "[0.60839, 0.2, 0.20158842, 0.20157702]\n",
      "[0.613673, 0.2, 0.20613417, 0.20232366]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17020 iterations: 4.022906716664632 mins\n",
      "Train Loss: [0.613673, 0.2, 0.20613417, 0.20232366]\n",
      "[0.6104663, 0.2, 0.20406678, 0.20119405]\n",
      "[0.6408212, 0.2, 0.20598824, 0.22963727]\n",
      "[0.6115444, 0.2, 0.20464769, 0.20170987]\n",
      "[0.60997283, 0.2, 0.20334885, 0.20144618]\n",
      "[0.6147976, 0.2, 0.20708051, 0.2025484]\n",
      "[0.62104136, 0.2, 0.21400408, 0.20187727]\n",
      "[0.6132335, 0.2, 0.20504774, 0.203034]\n",
      "[0.60997117, 0.2, 0.2033989, 0.2014288]\n",
      "[0.6162535, 0.2, 0.20870018, 0.20241822]\n",
      "[0.61117727, 0.2, 0.20443627, 0.20161411]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17030 iterations: 4.024828298886617 mins\n",
      "Train Loss: [0.61117727, 0.2, 0.20443627, 0.20161411]\n",
      "[0.6104459, 0.2, 0.20446797, 0.20085898]\n",
      "[0.6128495, 0.2, 0.20692149, 0.20081662]\n",
      "[0.6129076, 0.2, 0.20545171, 0.20235214]\n",
      "[0.6349668, 0.2, 0.22869572, 0.2011747]\n",
      "[0.61041963, 0.2, 0.20380317, 0.20152831]\n",
      "[0.6253921, 0.2, 0.21832424, 0.20198758]\n",
      "[0.6130542, 0.2, 0.2073939, 0.2005875]\n",
      "[0.6143164, 0.2, 0.20807159, 0.20117952]\n",
      "[0.61340666, 0.2, 0.20679596, 0.20155253]\n",
      "[0.61161125, 0.2, 0.20556699, 0.20099263]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17040 iterations: 4.02681831518809 mins\n",
      "Train Loss: [0.61161125, 0.2, 0.20556699, 0.20099263]\n",
      "[0.6119319, 0.2, 0.20568258, 0.20120417]\n",
      "[0.6093773, 0.2, 0.20345552, 0.2008828]\n",
      "[0.60804534, 0.2, 0.20201017, 0.20100226]\n",
      "[0.6109413, 0.2, 0.20467117, 0.20124304]\n",
      "[0.6109322, 0.2, 0.2036618, 0.20224872]\n",
      "[0.6121519, 0.2, 0.20500992, 0.20212573]\n",
      "[0.61192393, 0.2, 0.20545363, 0.20145951]\n",
      "[0.6122411, 0.2, 0.2065036, 0.20073208]\n",
      "[0.6139169, 0.2, 0.20811151, 0.20080498]\n",
      "[0.6101463, 0.2, 0.2022703, 0.20288078]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17050 iterations: 4.028925331433614 mins\n",
      "Train Loss: [0.6101463, 0.2, 0.2022703, 0.20288078]\n",
      "[0.6107125, 0.2, 0.20354421, 0.2021784]\n",
      "[0.61092263, 0.2, 0.20531303, 0.20062456]\n",
      "[0.6122954, 0.2, 0.20477177, 0.20254302]\n",
      "[0.6105282, 0.2, 0.20478949, 0.20076251]\n",
      "[0.6124405, 0.2, 0.20587967, 0.20158902]\n",
      "[0.60877615, 0.2, 0.20264824, 0.20116052]\n",
      "[0.6109296, 0.2, 0.20494409, 0.2010226]\n",
      "[0.610744, 0.2, 0.20478784, 0.2009977]\n",
      "[0.6080137, 0.2, 0.20218128, 0.20087838]\n",
      "[0.61048716, 0.2, 0.20436244, 0.20117503]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17060 iterations: 4.031376532713572 mins\n",
      "Train Loss: [0.61048716, 0.2, 0.20436244, 0.20117503]\n",
      "[0.6141947, 0.2, 0.20822753, 0.20102179]\n",
      "[0.6169749, 0.2, 0.21034896, 0.20168486]\n",
      "[0.6101602, 0.2, 0.20412317, 0.2011005]\n",
      "[0.60908544, 0.2, 0.20328037, 0.20087305]\n",
      "[0.6077547, 0.2, 0.201649, 0.2011781]\n",
      "[0.6109285, 0.2, 0.20424822, 0.20175688]\n",
      "[0.6071378, 0.2, 0.2009801, 0.2012384]\n",
      "[0.6144768, 0.2, 0.20859332, 0.20096819]\n",
      "[0.6086482, 0.2, 0.2016313, 0.2021055]\n",
      "[0.61102563, 0.2, 0.20514461, 0.2009735]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17070 iterations: 4.033404815196991 mins\n",
      "Train Loss: [0.61102563, 0.2, 0.20514461, 0.2009735]\n",
      "[0.6231293, 0.2, 0.21594374, 0.20228195]\n",
      "[0.61312246, 0.2, 0.20772569, 0.2004976]\n",
      "[0.6094218, 0.2, 0.20340434, 0.20112243]\n",
      "[0.6112938, 0.2, 0.2055009, 0.20090216]\n",
      "[0.60964227, 0.2, 0.20412056, 0.20063502]\n",
      "[0.61459285, 0.2, 0.20887002, 0.20084007]\n",
      "[0.607333, 0.2, 0.20158751, 0.20086643]\n",
      "[0.6116594, 0.2, 0.20542628, 0.20135768]\n",
      "[0.61376256, 0.2, 0.20686746, 0.20202312]\n",
      "[0.6152821, 0.2, 0.20932683, 0.20108666]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17080 iterations: 4.035424967606862 mins\n",
      "Train Loss: [0.6152821, 0.2, 0.20932683, 0.20108666]\n",
      "[0.60637224, 0.2, 0.20069678, 0.20080975]\n",
      "[0.6124973, 0.2, 0.20706138, 0.2005731]\n",
      "[0.6078743, 0.2, 0.20214528, 0.20086923]\n",
      "[0.6122342, 0.2, 0.20576333, 0.20161413]\n",
      "[0.6092408, 0.2, 0.20366502, 0.20072229]\n",
      "[0.61203784, 0.2, 0.20604715, 0.20114046]\n",
      "[0.6089492, 0.2, 0.20313056, 0.20097157]\n",
      "[0.6111034, 0.2, 0.2054887, 0.20077074]\n",
      "[0.6135134, 0.2, 0.20422244, 0.20444994]\n",
      "[0.61566484, 0.2, 0.2099254, 0.2009015]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17090 iterations: 4.037460013230642 mins\n",
      "Train Loss: [0.61566484, 0.2, 0.2099254, 0.2009015]\n",
      "[0.6120963, 0.2, 0.2063329, 0.20092869]\n",
      "[0.6112175, 0.2, 0.20463802, 0.20174792]\n",
      "[0.6098306, 0.2, 0.20359792, 0.20140404]\n",
      "[0.613864, 0.2, 0.20769969, 0.20133837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6197082, 0.2, 0.2122706, 0.2026143]\n",
      "[0.6286476, 0.2, 0.22315547, 0.20067148]\n",
      "[0.6109816, 0.2, 0.20505157, 0.20111102]\n",
      "[0.60668516, 0.2, 0.20122322, 0.20064493]\n",
      "[0.61427736, 0.2, 0.20876531, 0.20069717]\n",
      "[0.6137404, 0.2, 0.20831214, 0.20061545]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17100 iterations: 4.039630031585693 mins\n",
      "Train Loss: [0.6137404, 0.2, 0.20831214, 0.20061545]\n",
      "[0.60857236, 0.2, 0.20284727, 0.20091443]\n",
      "[0.6118588, 0.2, 0.20611508, 0.20093547]\n",
      "[0.6115092, 0.2, 0.20505294, 0.2016504]\n",
      "[0.6112974, 0.2, 0.20597263, 0.20052153]\n",
      "[0.6086647, 0.2, 0.20311671, 0.20074734]\n",
      "[0.6089653, 0.2, 0.20331003, 0.20085719]\n",
      "[0.6122694, 0.2, 0.20694625, 0.20052788]\n",
      "[0.60780185, 0.2, 0.2025671, 0.20044196]\n",
      "[0.612348, 0.2, 0.20582883, 0.20172885]\n",
      "[0.6112231, 0.2, 0.20572853, 0.20070659]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17110 iterations: 4.042817600568136 mins\n",
      "Train Loss: [0.6112231, 0.2, 0.20572853, 0.20070659]\n",
      "[0.61247164, 0.2, 0.20640527, 0.20128083]\n",
      "[0.6083701, 0.2, 0.20308511, 0.20050201]\n",
      "[0.61064124, 0.2, 0.20502366, 0.20083731]\n",
      "[0.6100809, 0.2, 0.20459041, 0.20071305]\n",
      "[0.60987526, 0.2, 0.20381202, 0.20128885]\n",
      "[0.6140487, 0.2, 0.20809835, 0.20117916]\n",
      "[0.6484995, 0.2, 0.21209025, 0.23164101]\n",
      "[0.60875946, 0.2, 0.20338377, 0.20060971]\n",
      "[0.61185294, 0.2, 0.20625272, 0.20083646]\n",
      "[0.6159812, 0.2, 0.20991863, 0.20130093]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17120 iterations: 4.045039447148641 mins\n",
      "Train Loss: [0.6159812, 0.2, 0.20991863, 0.20130093]\n",
      "[0.6148476, 0.2, 0.20917869, 0.20090948]\n",
      "[0.6140574, 0.2, 0.2083053, 0.20099503]\n",
      "[0.6108932, 0.2, 0.20459367, 0.20154469]\n",
      "[0.6207372, 0.2, 0.2144074, 0.20157747]\n",
      "[0.6091204, 0.2, 0.20362535, 0.20074521]\n",
      "[0.6217714, 0.2, 0.20819566, 0.20882836]\n",
      "[0.60889345, 0.2, 0.20333007, 0.20081912]\n",
      "[0.6126572, 0.2, 0.20719019, 0.20072556]\n",
      "[0.61408496, 0.2, 0.20830391, 0.20104238]\n",
      "[0.6141051, 0.2, 0.20849471, 0.2008742]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17130 iterations: 4.0476902484893795 mins\n",
      "Train Loss: [0.6141051, 0.2, 0.20849471, 0.2008742]\n",
      "[0.61100453, 0.2, 0.2055093, 0.20076151]\n",
      "[0.6082122, 0.2, 0.20295155, 0.20052913]\n",
      "[0.6135314, 0.2, 0.20773138, 0.20107073]\n",
      "[0.6167276, 0.2, 0.21041834, 0.2015821]\n",
      "[0.6088363, 0.2, 0.20239443, 0.20171691]\n",
      "[0.60966, 0.2, 0.20362765, 0.20130941]\n",
      "[0.61096966, 0.2, 0.20471184, 0.20153688]\n",
      "[0.6137402, 0.2, 0.20847161, 0.20054977]\n",
      "[0.61038876, 0.2, 0.20471546, 0.20095669]\n",
      "[0.6210983, 0.2, 0.20519607, 0.21118782]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17140 iterations: 4.049766731262207 mins\n",
      "Train Loss: [0.6210983, 0.2, 0.20519607, 0.21118782]\n",
      "[0.61438936, 0.2, 0.2083901, 0.2012872]\n",
      "[0.60915226, 0.2, 0.20372215, 0.20072018]\n",
      "[0.6170637, 0.2, 0.21067585, 0.20168008]\n",
      "[0.61455804, 0.2, 0.208531, 0.20132142]\n",
      "[0.60883707, 0.2, 0.20327778, 0.20085585]\n",
      "[0.63544303, 0.2, 0.20983268, 0.22090901]\n",
      "[0.6311388, 0.2, 0.21791825, 0.20852047]\n",
      "[0.60753876, 0.2, 0.20215586, 0.2006821]\n",
      "[0.61086977, 0.2, 0.20533685, 0.20083137]\n",
      "[0.60916555, 0.2, 0.20309676, 0.20136645]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17150 iterations: 4.05171586672465 mins\n",
      "Train Loss: [0.60916555, 0.2, 0.20309676, 0.20136645]\n",
      "[0.6095299, 0.2, 0.20349015, 0.20133674]\n",
      "[0.60970974, 0.2, 0.20372961, 0.20127639]\n",
      "[0.6114251, 0.2, 0.20604703, 0.20067371]\n",
      "[0.6323853, 0.2, 0.20582274, 0.22185726]\n",
      "[0.6120259, 0.2, 0.20610967, 0.20121045]\n",
      "[0.60812, 0.2, 0.20145199, 0.20196167]\n",
      "[0.617763, 0.2, 0.2120913, 0.20096512]\n",
      "[0.60892767, 0.2, 0.20281513, 0.20140599]\n",
      "[0.61311364, 0.2, 0.20728943, 0.20111771]\n",
      "[0.61213464, 0.2, 0.20556496, 0.2018633]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17160 iterations: 4.053855999310811 mins\n",
      "Train Loss: [0.61213464, 0.2, 0.20556496, 0.2018633]\n",
      "[0.61511666, 0.2, 0.20945257, 0.20095804]\n",
      "[0.61022854, 0.2, 0.20335728, 0.20216584]\n",
      "[0.60954976, 0.2, 0.20378737, 0.20105763]\n",
      "[0.6086399, 0.2, 0.2030841, 0.20085181]\n",
      "[0.61104566, 0.2, 0.20543572, 0.2009067]\n",
      "[0.6124275, 0.2, 0.20677939, 0.2009457]\n",
      "[0.61036277, 0.2, 0.20475271, 0.20090826]\n",
      "[0.6122321, 0.2, 0.20657262, 0.20095794]\n",
      "[0.6146082, 0.2, 0.20876794, 0.20113865]\n",
      "[0.61715984, 0.2, 0.21177894, 0.20067884]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17170 iterations: 4.055742466449738 mins\n",
      "Train Loss: [0.61715984, 0.2, 0.21177894, 0.20067884]\n",
      "[0.6124487, 0.2, 0.20718044, 0.20056574]\n",
      "[0.61331576, 0.2, 0.2074523, 0.20116003]\n",
      "[0.6137347, 0.2, 0.20843889, 0.20059174]\n",
      "[0.6136261, 0.2, 0.20768915, 0.20123231]\n",
      "[0.6135562, 0.2, 0.207422, 0.20142895]\n",
      "[0.60948926, 0.2, 0.20411326, 0.20067054]\n",
      "[0.6085931, 0.2, 0.20301892, 0.20086865]\n",
      "[0.61362565, 0.2, 0.20808204, 0.20083833]\n",
      "[0.60720074, 0.2, 0.20187388, 0.20062175]\n",
      "[0.60794437, 0.2, 0.2014308, 0.20180899]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17180 iterations: 4.0578256964683534 mins\n",
      "Train Loss: [0.60794437, 0.2, 0.2014308, 0.20180899]\n",
      "[0.65773845, 0.2, 0.21078502, 0.24224955]\n",
      "[0.61237735, 0.2, 0.20665532, 0.20101827]\n",
      "[0.61251193, 0.2, 0.20701316, 0.2007954]\n",
      "[0.6220975, 0.2, 0.21602963, 0.20136508]\n",
      "[0.6125964, 0.2, 0.20729288, 0.2006014]\n",
      "[0.61440235, 0.2, 0.20737982, 0.2023215]\n",
      "[0.60919, 0.2, 0.20395756, 0.20053223]\n",
      "[0.6105409, 0.2, 0.20452358, 0.20131844]\n",
      "[0.60876447, 0.2, 0.20188887, 0.20217778]\n",
      "[0.6088949, 0.2, 0.20295759, 0.20124073]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17190 iterations: 4.059900685151418 mins\n",
      "Train Loss: [0.6088949, 0.2, 0.20295759, 0.20124073]\n",
      "[0.6273685, 0.2, 0.22171193, 0.2009613]\n",
      "[0.6091161, 0.2, 0.20352629, 0.2008968]\n",
      "[0.6080098, 0.2, 0.20199314, 0.20132564]\n",
      "[0.6144868, 0.2, 0.20807113, 0.20172668]\n",
      "[0.61242265, 0.2, 0.20648523, 0.20125045]\n",
      "[0.6118055, 0.2, 0.20585316, 0.2012674]\n",
      "[0.60903597, 0.2, 0.20344372, 0.2009092]\n",
      "[0.60924083, 0.2, 0.20364915, 0.20091069]\n",
      "[0.61041266, 0.2, 0.2047408, 0.20099291]\n",
      "[0.6101564, 0.2, 0.20409013, 0.20138948]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17200 iterations: 4.0618799487749735 mins\n",
      "Train Loss: [0.6101564, 0.2, 0.20409013, 0.20138948]\n",
      "[0.6099073, 0.2, 0.2033006, 0.20193207]\n",
      "[0.64309955, 0.2, 0.23701471, 0.20141236]\n",
      "[0.6099101, 0.2, 0.20408782, 0.20115018]\n",
      "[0.6116638, 0.2, 0.20593609, 0.20105626]\n",
      "[0.6085293, 0.2, 0.20344809, 0.20041077]\n",
      "[0.61008614, 0.2, 0.204715, 0.2007019]\n",
      "[0.6090148, 0.2, 0.20346269, 0.20088416]\n",
      "[0.60783666, 0.2, 0.20232914, 0.20084128]\n",
      "[0.6129869, 0.2, 0.20679034, 0.20153204]\n",
      "[0.6113762, 0.2, 0.20610872, 0.2006047]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17210 iterations: 4.0644375006357825 mins\n",
      "Train Loss: [0.6113762, 0.2, 0.20610872, 0.2006047]\n",
      "[0.6104865, 0.2, 0.2050513, 0.20077418]\n",
      "[0.61199343, 0.2, 0.20601578, 0.20131853]\n",
      "[0.60813713, 0.2, 0.202984, 0.20049608]\n",
      "[0.6074077, 0.2, 0.20191851, 0.20083413]\n",
      "[0.61259025, 0.2, 0.2074995, 0.20043786]\n",
      "[0.6079565, 0.2, 0.20254606, 0.20076002]\n",
      "[0.61122966, 0.2, 0.20557168, 0.20101]\n",
      "[0.60802764, 0.2, 0.20299685, 0.20038553]\n",
      "[0.61264086, 0.2, 0.20691526, 0.20108289]\n",
      "[0.6109254, 0.2, 0.20539424, 0.20089088]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17220 iterations: 4.066323033968607 mins\n",
      "Train Loss: [0.6109254, 0.2, 0.20539424, 0.20089088]\n",
      "[0.62567955, 0.2, 0.22039875, 0.20064321]\n",
      "[0.619031, 0.2, 0.21372151, 0.20067567]\n",
      "[0.60986036, 0.2, 0.20444669, 0.20078374]\n",
      "[0.6119577, 0.2, 0.20634915, 0.20098223]\n",
      "[0.6112105, 0.2, 0.2060443, 0.2005429]\n",
      "[0.61344916, 0.2, 0.20781812, 0.2010105]\n",
      "[0.6103794, 0.2, 0.2046026, 0.20115913]\n",
      "[0.6102459, 0.2, 0.20477483, 0.20085593]\n",
      "[0.6120633, 0.2, 0.20678039, 0.20067017]\n",
      "[0.6118992, 0.2, 0.20637268, 0.20091559]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17230 iterations: 4.068426247437795 mins\n",
      "Train Loss: [0.6118992, 0.2, 0.20637268, 0.20091559]\n",
      "[0.6185797, 0.2, 0.212241, 0.20172967]\n",
      "[0.61598974, 0.2, 0.2104426, 0.20093992]\n",
      "[0.61261946, 0.2, 0.20682257, 0.20119111]\n",
      "[0.6151123, 0.2, 0.2099678, 0.20054027]\n",
      "[0.60976934, 0.2, 0.20450328, 0.2006634]\n",
      "[0.6101369, 0.2, 0.20466721, 0.2008686]\n",
      "[0.6099178, 0.2, 0.20365264, 0.20166561]\n",
      "[0.62047946, 0.2, 0.20458707, 0.2112943]\n",
      "[0.63953, 0.2, 0.23431112, 0.20062256]\n",
      "[0.6111904, 0.2, 0.20557368, 0.20102064]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17240 iterations: 4.070593214035034 mins\n",
      "Train Loss: [0.6111904, 0.2, 0.20557368, 0.20102064]\n",
      "[0.6089794, 0.2, 0.20304325, 0.20134029]\n",
      "[0.61268485, 0.2, 0.20727597, 0.20081328]\n",
      "[0.61694187, 0.2, 0.21115756, 0.20118904]\n",
      "[0.61325914, 0.2, 0.20719214, 0.20147209]\n",
      "[0.6097029, 0.2, 0.20406862, 0.20103975]\n",
      "[0.6094989, 0.2, 0.20453356, 0.20037147]\n",
      "[0.6081927, 0.2, 0.202379, 0.20122027]\n",
      "[0.6077686, 0.2, 0.2019463, 0.20122968]\n",
      "[0.63989913, 0.2, 0.2055086, 0.22979878]\n",
      "[0.61129284, 0.2, 0.2058713, 0.20083073]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17250 iterations: 4.072550932566325 mins\n",
      "Train Loss: [0.61129284, 0.2, 0.2058713, 0.20083073]\n",
      "[0.60995424, 0.2, 0.20441498, 0.20094948]\n",
      "[0.6111187, 0.2, 0.20585603, 0.20067386]\n",
      "[0.6092935, 0.2, 0.20375603, 0.20094994]\n",
      "[0.6120404, 0.2, 0.20679732, 0.20065698]\n",
      "[0.6103389, 0.2, 0.20478041, 0.20097394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61867446, 0.2, 0.21365522, 0.20043634]\n",
      "[0.61478025, 0.2, 0.20885131, 0.20134787]\n",
      "[0.64248246, 0.2, 0.20786178, 0.23004167]\n",
      "[0.6215968, 0.2, 0.20092487, 0.2160943]\n",
      "[0.60816693, 0.2, 0.20187329, 0.20171654]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17260 iterations: 4.074642765522003 mins\n",
      "Train Loss: [0.60816693, 0.2, 0.20187329, 0.20171654]\n",
      "[0.6118194, 0.2, 0.20666951, 0.20057285]\n",
      "[0.61973053, 0.2, 0.21456201, 0.20059112]\n",
      "[0.6104252, 0.2, 0.20480382, 0.20104317]\n",
      "[0.62846553, 0.2, 0.20456095, 0.21932548]\n",
      "[0.61396843, 0.2, 0.20825267, 0.2011356]\n",
      "[0.6114917, 0.2, 0.20626287, 0.20064723]\n",
      "[0.6070616, 0.2, 0.20114931, 0.20132926]\n",
      "[0.6203717, 0.2, 0.20452942, 0.21125801]\n",
      "[0.60891277, 0.2, 0.20300528, 0.20132276]\n",
      "[0.609481, 0.2, 0.20389424, 0.20100139]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17270 iterations: 4.076582503318787 mins\n",
      "Train Loss: [0.609481, 0.2, 0.20389424, 0.20100139]\n",
      "[0.61286837, 0.2, 0.20699805, 0.20128457]\n",
      "[0.6095655, 0.2, 0.20455237, 0.2004274]\n",
      "[0.60924447, 0.2, 0.2037491, 0.2009098]\n",
      "[0.6089274, 0.2, 0.2024136, 0.20192856]\n",
      "[0.6291282, 0.2, 0.2041521, 0.22039138]\n",
      "[0.61066145, 0.2, 0.20523618, 0.20084073]\n",
      "[0.61080444, 0.2, 0.2056058, 0.2006145]\n",
      "[0.6101718, 0.2, 0.20399658, 0.20159164]\n",
      "[0.6254269, 0.2, 0.20749633, 0.2133476]\n",
      "[0.6226019, 0.2, 0.20103446, 0.21698552]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17280 iterations: 4.078673851490021 mins\n",
      "Train Loss: [0.6226019, 0.2, 0.20103446, 0.21698552]\n",
      "[0.61279505, 0.2, 0.20714952, 0.20106396]\n",
      "[0.61151296, 0.2, 0.2061964, 0.20073536]\n",
      "[0.6190987, 0.2, 0.2046693, 0.20984879]\n",
      "[0.6118919, 0.2, 0.20620513, 0.20110603]\n",
      "[0.61048293, 0.2, 0.20550215, 0.20039994]\n",
      "[0.61035424, 0.2, 0.20521465, 0.20055866]\n",
      "[0.6114474, 0.2, 0.20599295, 0.20087361]\n",
      "[0.6130168, 0.2, 0.20533994, 0.20309614]\n",
      "[0.6193881, 0.2, 0.20520832, 0.20959936]\n",
      "[0.61165357, 0.2, 0.20634103, 0.2007319]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17290 iterations: 4.081401713689169 mins\n",
      "Train Loss: [0.61165357, 0.2, 0.20634103, 0.2007319]\n",
      "[0.61249745, 0.2, 0.20706384, 0.20085278]\n",
      "[0.6123877, 0.2, 0.20695467, 0.20085193]\n",
      "[0.6079449, 0.2, 0.2025277, 0.2008361]\n",
      "[0.6086605, 0.2, 0.20353372, 0.2005459]\n",
      "[0.61414844, 0.2, 0.20854802, 0.20101984]\n",
      "[0.6119392, 0.2, 0.2049317, 0.20242728]\n",
      "[0.61923677, 0.2, 0.21359414, 0.20106298]\n",
      "[0.6448793, 0.2, 0.20648114, 0.23382014]\n",
      "[0.6098463, 0.2, 0.20424905, 0.20102227]\n",
      "[0.6072605, 0.2, 0.20204346, 0.2006448]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17300 iterations: 4.083298365275065 mins\n",
      "Train Loss: [0.6072605, 0.2, 0.20204346, 0.2006448]\n",
      "[0.6312342, 0.2, 0.22523561, 0.20142888]\n",
      "[0.61092633, 0.2, 0.20599718, 0.20036471]\n",
      "[0.61106324, 0.2, 0.2057784, 0.20072521]\n",
      "[0.6127523, 0.2, 0.20752743, 0.20066942]\n",
      "[0.60788983, 0.2, 0.20262825, 0.2007099]\n",
      "[0.61101764, 0.2, 0.20582396, 0.20064549]\n",
      "[0.61049306, 0.2, 0.2053376, 0.2006104]\n",
      "[0.620957, 0.2, 0.21450013, 0.20191449]\n",
      "[0.6141774, 0.2, 0.20195569, 0.20768136]\n",
      "[0.6086755, 0.2, 0.20348614, 0.20065]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17310 iterations: 4.08542396624883 mins\n",
      "Train Loss: [0.6086755, 0.2, 0.20348614, 0.20065]\n",
      "[0.6099938, 0.2, 0.20502976, 0.2004255]\n",
      "[0.6102112, 0.2, 0.20459324, 0.20107989]\n",
      "[0.6061485, 0.2, 0.2004019, 0.2012089]\n",
      "[0.617605, 0.2, 0.21129769, 0.20176986]\n",
      "[0.6159774, 0.2, 0.20944037, 0.20199983]\n",
      "[0.63662606, 0.2, 0.23145938, 0.20062953]\n",
      "[0.6146123, 0.2, 0.20860857, 0.20146494]\n",
      "[0.61223024, 0.2, 0.20642512, 0.2012649]\n",
      "[0.61177534, 0.2, 0.20579213, 0.2014417]\n",
      "[0.6088819, 0.2, 0.20294772, 0.2013915]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17320 iterations: 4.087301182746887 mins\n",
      "Train Loss: [0.6088819, 0.2, 0.20294772, 0.2013915]\n",
      "[0.60962254, 0.2, 0.20448261, 0.20059647]\n",
      "[0.64758587, 0.2, 0.2050809, 0.23796108]\n",
      "[0.60902715, 0.2, 0.20363794, 0.20084542]\n",
      "[0.60862356, 0.2, 0.20334572, 0.20073439]\n",
      "[0.6139227, 0.2, 0.20756653, 0.20181297]\n",
      "[0.6115724, 0.2, 0.20638306, 0.20064682]\n",
      "[0.6108979, 0.2, 0.20545244, 0.20090367]\n",
      "[0.6094902, 0.2, 0.20410858, 0.20084064]\n",
      "[0.6078953, 0.2, 0.20279917, 0.20055598]\n",
      "[0.6121302, 0.2, 0.20694862, 0.20064247]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17330 iterations: 4.08940255244573 mins\n",
      "Train Loss: [0.6121302, 0.2, 0.20694862, 0.20064247]\n",
      "[0.60877854, 0.2, 0.20349005, 0.2007505]\n",
      "[0.62843865, 0.2, 0.22296658, 0.2009351]\n",
      "[0.610994, 0.2, 0.20569478, 0.20076124]\n",
      "[0.6139721, 0.2, 0.20873614, 0.20069708]\n",
      "[0.61713135, 0.2, 0.21138929, 0.20120232]\n",
      "[0.61131763, 0.2, 0.20511624, 0.20166068]\n",
      "[0.6077424, 0.2, 0.20146513, 0.20173575]\n",
      "[0.60772234, 0.2, 0.20261504, 0.20056519]\n",
      "[0.61283135, 0.2, 0.20781553, 0.20047353]\n",
      "[0.60909605, 0.2, 0.20304309, 0.20151076]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17340 iterations: 4.0912961999575295 mins\n",
      "Train Loss: [0.60909605, 0.2, 0.20304309, 0.20151076]\n",
      "[0.6082578, 0.2, 0.20261654, 0.20109917]\n",
      "[0.60948753, 0.2, 0.20463055, 0.2003155]\n",
      "[0.61225075, 0.2, 0.20705608, 0.20065396]\n",
      "[0.6123327, 0.2, 0.20675208, 0.20104113]\n",
      "[0.61180115, 0.2, 0.20630282, 0.2009601]\n",
      "[0.621812, 0.2, 0.20556459, 0.21171023]\n",
      "[0.60882837, 0.2, 0.20379478, 0.20049796]\n",
      "[0.60919005, 0.2, 0.20375335, 0.20090267]\n",
      "[0.6118256, 0.2, 0.20693962, 0.20035326]\n",
      "[0.60975933, 0.2, 0.2044291, 0.20079827]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17350 iterations: 4.093338231245677 mins\n",
      "Train Loss: [0.60975933, 0.2, 0.2044291, 0.20079827]\n",
      "[0.60617733, 0.2, 0.20105237, 0.20059335]\n",
      "[0.60906065, 0.2, 0.20385805, 0.20067075]\n",
      "[0.6092853, 0.2, 0.20384689, 0.20090607]\n",
      "[0.6106119, 0.2, 0.2049833, 0.20109563]\n",
      "[0.6091509, 0.2, 0.20417419, 0.20044301]\n",
      "[0.63936025, 0.2, 0.23416686, 0.20065916]\n",
      "[0.6059598, 0.2, 0.20063657, 0.20078938]\n",
      "[0.61382115, 0.2, 0.20857972, 0.20070815]\n",
      "[0.6080759, 0.2, 0.20291366, 0.20062971]\n",
      "[0.61184067, 0.2, 0.20555627, 0.20175295]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17360 iterations: 4.095408733685812 mins\n",
      "Train Loss: [0.61184067, 0.2, 0.20555627, 0.20175295]\n",
      "[0.61099064, 0.2, 0.20610179, 0.20035887]\n",
      "[0.6108516, 0.2, 0.20548725, 0.200836]\n",
      "[0.6137091, 0.2, 0.20841637, 0.20076592]\n",
      "[0.61432904, 0.2, 0.20921749, 0.2005863]\n",
      "[0.6097415, 0.2, 0.20368128, 0.201536]\n",
      "[0.6206477, 0.2, 0.2064993, 0.20962542]\n",
      "[0.6086776, 0.2, 0.2024905, 0.20166503]\n",
      "[0.6110667, 0.2, 0.20409892, 0.20244682]\n",
      "[0.6180099, 0.2, 0.21273996, 0.20075041]\n",
      "[0.60847205, 0.2, 0.20274192, 0.2012119]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17370 iterations: 4.098240232467651 mins\n",
      "Train Loss: [0.60847205, 0.2, 0.20274192, 0.2012119]\n",
      "[0.6085303, 0.2, 0.2027795, 0.20123422]\n",
      "[0.61828345, 0.2, 0.21139492, 0.20237376]\n",
      "[0.619865, 0.2, 0.21447518, 0.20087674]\n",
      "[0.61054873, 0.2, 0.20560169, 0.20043561]\n",
      "[0.6190485, 0.2, 0.21392474, 0.20061372]\n",
      "[0.60959274, 0.2, 0.20443182, 0.2006525]\n",
      "[0.61236644, 0.2, 0.20742713, 0.20043255]\n",
      "[0.613917, 0.2, 0.20908695, 0.20032483]\n",
      "[0.61038226, 0.2, 0.2049231, 0.20095548]\n",
      "[0.61080176, 0.2, 0.2054249, 0.2008749]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17380 iterations: 4.100467268625895 mins\n",
      "Train Loss: [0.61080176, 0.2, 0.2054249, 0.2008749]\n",
      "[0.60985583, 0.2, 0.20477797, 0.20057759]\n",
      "[0.6103424, 0.2, 0.20537712, 0.2004666]\n",
      "[0.6088659, 0.2, 0.20377894, 0.20059004]\n",
      "[0.618949, 0.2, 0.21415839, 0.20029533]\n",
      "[0.6151284, 0.2, 0.21004188, 0.2005944]\n",
      "[0.6113536, 0.2, 0.20620239, 0.20066175]\n",
      "[0.6141452, 0.2, 0.20916763, 0.2004907]\n",
      "[0.61085534, 0.2, 0.20560849, 0.2007622]\n",
      "[0.61338925, 0.2, 0.20850551, 0.2004011]\n",
      "[0.6088686, 0.2, 0.20381622, 0.20057166]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17390 iterations: 4.102510484059652 mins\n",
      "Train Loss: [0.6088686, 0.2, 0.20381622, 0.20057166]\n",
      "[0.61084986, 0.2, 0.20583457, 0.20053627]\n",
      "[0.61589605, 0.2, 0.21041651, 0.20100194]\n",
      "[0.629195, 0.2, 0.20767047, 0.21704827]\n",
      "[0.6073928, 0.2, 0.20204723, 0.20087065]\n",
      "[0.6143333, 0.2, 0.20922476, 0.20063433]\n",
      "[0.60852635, 0.2, 0.20304528, 0.20100729]\n",
      "[0.609661, 0.2, 0.20433486, 0.20085247]\n",
      "[0.6113672, 0.2, 0.2061729, 0.20072024]\n",
      "[0.61041147, 0.2, 0.20545623, 0.20048088]\n",
      "[0.6077713, 0.2, 0.20223236, 0.20106418]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17400 iterations: 4.104602646827698 mins\n",
      "Train Loss: [0.6077713, 0.2, 0.20223236, 0.20106418]\n",
      "[0.6085713, 0.2, 0.20362474, 0.20047134]\n",
      "[0.6149572, 0.2, 0.20944947, 0.20103227]\n",
      "[0.6165773, 0.2, 0.21091837, 0.20118341]\n",
      "[0.61006784, 0.2, 0.20448418, 0.20110814]\n",
      "[0.6124093, 0.2, 0.20564285, 0.20229098]\n",
      "[0.6149562, 0.2, 0.20999902, 0.20048201]\n",
      "[0.63940966, 0.2, 0.20845744, 0.22647749]\n",
      "[0.61025417, 0.2, 0.20402463, 0.20175543]\n",
      "[0.61682475, 0.2, 0.21145397, 0.20089737]\n",
      "[0.61653584, 0.2, 0.21099915, 0.20106408]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17410 iterations: 4.106705101331075 mins\n",
      "Train Loss: [0.61653584, 0.2, 0.21099915, 0.20106408]\n",
      "[0.61470497, 0.2, 0.20913135, 0.2011018]\n",
      "[0.61252826, 0.2, 0.2062527, 0.20180438]\n",
      "[0.6125849, 0.2, 0.2074936, 0.20062101]\n",
      "[0.6097933, 0.2, 0.20341402, 0.20190984]\n",
      "[0.60984284, 0.2, 0.20449267, 0.20088169]\n",
      "[0.6100035, 0.2, 0.20462032, 0.20091584]\n",
      "[0.6099562, 0.2, 0.20436794, 0.20112234]\n",
      "[0.6101358, 0.2, 0.20474127, 0.20093012]\n",
      "[0.6094391, 0.2, 0.20446439, 0.20051196]\n",
      "[0.6080662, 0.2, 0.20279533, 0.20080991]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17420 iterations: 4.1087362686793005 mins\n",
      "Train Loss: [0.6080662, 0.2, 0.20279533, 0.20080991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6104223, 0.2, 0.20499162, 0.20097142]\n",
      "[0.6092956, 0.2, 0.20415653, 0.20068148]\n",
      "[0.610984, 0.2, 0.20605569, 0.2004727]\n",
      "[0.6096507, 0.2, 0.2047584, 0.20043853]\n",
      "[0.60884744, 0.2, 0.20379668, 0.2005991]\n",
      "[0.6128897, 0.2, 0.20762385, 0.20081633]\n",
      "[0.6080471, 0.2, 0.20299242, 0.20060726]\n",
      "[0.6082962, 0.2, 0.20352538, 0.20032527]\n",
      "[0.6146967, 0.2, 0.20956323, 0.20068982]\n",
      "[0.6095839, 0.2, 0.2040912, 0.20105095]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17430 iterations: 4.11080371538798 mins\n",
      "Train Loss: [0.6095839, 0.2, 0.2040912, 0.20105095]\n",
      "[0.6160695, 0.2, 0.21089216, 0.20073749]\n",
      "[0.6074397, 0.2, 0.20252945, 0.20047207]\n",
      "[0.61013436, 0.2, 0.20431533, 0.20138262]\n",
      "[0.6098596, 0.2, 0.2048064, 0.20061862]\n",
      "[0.61093825, 0.2, 0.20549342, 0.20101193]\n",
      "[0.60854363, 0.2, 0.20347004, 0.20064257]\n",
      "[0.6095394, 0.2, 0.20410323, 0.20100689]\n",
      "[0.6088114, 0.2, 0.20334262, 0.20104127]\n",
      "[0.61558557, 0.2, 0.21038345, 0.2007763]\n",
      "[0.6123515, 0.2, 0.20710503, 0.20082206]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17440 iterations: 4.112807019551595 mins\n",
      "Train Loss: [0.6123515, 0.2, 0.20710503, 0.20082206]\n",
      "[0.6125141, 0.2, 0.20761776, 0.20047349]\n",
      "[0.60681015, 0.2, 0.20191932, 0.20046945]\n",
      "[0.62861496, 0.2, 0.20204651, 0.22214855]\n",
      "[0.60735637, 0.2, 0.20205538, 0.20088233]\n",
      "[0.607542, 0.2, 0.20266645, 0.20045768]\n",
      "[0.6067266, 0.2, 0.20205985, 0.2002494]\n",
      "[0.60563976, 0.2, 0.20083295, 0.20038983]\n",
      "[0.6103948, 0.2, 0.20559192, 0.20038624]\n",
      "[0.6104461, 0.2, 0.20554954, 0.20048025]\n",
      "[0.6154004, 0.2, 0.21041238, 0.2005719]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17450 iterations: 4.115353580315908 mins\n",
      "Train Loss: [0.6154004, 0.2, 0.21041238, 0.2005719]\n",
      "[0.6066756, 0.2, 0.20149124, 0.20076843]\n",
      "[0.6094544, 0.2, 0.20447052, 0.20056799]\n",
      "[0.60797256, 0.2, 0.20327738, 0.2002794]\n",
      "[0.60854185, 0.2, 0.20285064, 0.20127566]\n",
      "[0.614432, 0.2, 0.20947142, 0.20054531]\n",
      "[0.6207761, 0.2, 0.21554855, 0.20081273]\n",
      "[0.6105977, 0.2, 0.20546035, 0.20072293]\n",
      "[0.612851, 0.2, 0.20770867, 0.20072845]\n",
      "[0.6087385, 0.2, 0.20350946, 0.20081589]\n",
      "[0.61045545, 0.2, 0.20573568, 0.20030738]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17460 iterations: 4.117367780208587 mins\n",
      "Train Loss: [0.61045545, 0.2, 0.20573568, 0.20030738]\n",
      "[0.6105205, 0.2, 0.20540231, 0.20070685]\n",
      "[0.6087448, 0.2, 0.20380162, 0.20053314]\n",
      "[0.60689604, 0.2, 0.20210133, 0.200386]\n",
      "[0.61159104, 0.2, 0.20686111, 0.20032257]\n",
      "[0.60879236, 0.2, 0.20395762, 0.2004285]\n",
      "[0.60967255, 0.2, 0.20474564, 0.20052177]\n",
      "[0.6084352, 0.2, 0.20374362, 0.20028788]\n",
      "[0.6105383, 0.2, 0.20549022, 0.20064588]\n",
      "[0.61009014, 0.2, 0.20502204, 0.20066758]\n",
      "[0.61567485, 0.2, 0.21042547, 0.20085056]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17470 iterations: 4.11935639778773 mins\n",
      "Train Loss: [0.61567485, 0.2, 0.21042547, 0.20085056]\n",
      "[0.61134714, 0.2, 0.2058973, 0.20105276]\n",
      "[0.6057875, 0.2, 0.2007212, 0.20067109]\n",
      "[0.6105407, 0.2, 0.20551683, 0.20063059]\n",
      "[0.61366314, 0.2, 0.208762, 0.20051]\n",
      "[0.6096964, 0.2, 0.2043819, 0.20092547]\n",
      "[0.6146549, 0.2, 0.20981817, 0.20044968]\n",
      "[0.60658944, 0.2, 0.20182307, 0.20038137]\n",
      "[0.63385063, 0.2, 0.22912166, 0.20034607]\n",
      "[0.6117029, 0.2, 0.20673437, 0.200584]\n",
      "[0.6113935, 0.2, 0.20613784, 0.20086692]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17480 iterations: 4.121415928999583 mins\n",
      "Train Loss: [0.6113935, 0.2, 0.20613784, 0.20086692]\n",
      "[0.60631996, 0.2, 0.20120488, 0.2007146]\n",
      "[0.6091608, 0.2, 0.20403689, 0.20070457]\n",
      "[0.60994315, 0.2, 0.20429344, 0.20120707]\n",
      "[0.61140037, 0.2, 0.20596425, 0.20096783]\n",
      "[0.6129833, 0.2, 0.20735458, 0.20113413]\n",
      "[0.61342114, 0.2, 0.20788927, 0.20101199]\n",
      "[0.60891473, 0.2, 0.20327282, 0.20109811]\n",
      "[0.610656, 0.2, 0.20528401, 0.20080689]\n",
      "[0.6246495, 0.2, 0.20628141, 0.21378441]\n",
      "[0.6113259, 0.2, 0.20561281, 0.20111305]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17490 iterations: 4.1234650135040285 mins\n",
      "Train Loss: [0.6113259, 0.2, 0.20561281, 0.20111305]\n",
      "[0.61145186, 0.2, 0.20543015, 0.20140837]\n",
      "[0.6072769, 0.2, 0.20142509, 0.20122792]\n",
      "[0.61287224, 0.2, 0.20710257, 0.20113806]\n",
      "[0.6092989, 0.2, 0.20365246, 0.20100957]\n",
      "[0.62605494, 0.2, 0.22027303, 0.20114195]\n",
      "[0.6107141, 0.2, 0.20496973, 0.20110323]\n",
      "[0.6087801, 0.2, 0.20356217, 0.20057745]\n",
      "[0.612562, 0.2, 0.20750733, 0.2004163]\n",
      "[0.61179423, 0.2, 0.20564133, 0.2015179]\n",
      "[0.6111741, 0.2, 0.205105, 0.20143858]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17500 iterations: 4.125399931271871 mins\n",
      "Train Loss: [0.6111741, 0.2, 0.205105, 0.20143858]\n",
      "[0.6289804, 0.2, 0.20480637, 0.21954873]\n",
      "[0.6121904, 0.2, 0.20528567, 0.20228525]\n",
      "[0.61134696, 0.2, 0.2060742, 0.20065954]\n",
      "[0.6092177, 0.2, 0.20358633, 0.20102508]\n",
      "[0.60845524, 0.2, 0.20262496, 0.20123093]\n",
      "[0.61611724, 0.2, 0.2107569, 0.20076801]\n",
      "[0.6111462, 0.2, 0.2055695, 0.20099106]\n",
      "[0.6118398, 0.2, 0.20602342, 0.2012372]\n",
      "[0.61067545, 0.2, 0.20542242, 0.20068057]\n",
      "[0.6136114, 0.2, 0.20826608, 0.20077953]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17510 iterations: 4.127446182568868 mins\n",
      "Train Loss: [0.6136114, 0.2, 0.20826608, 0.20077953]\n",
      "[0.6107593, 0.2, 0.2047026, 0.20149736]\n",
      "[0.6098533, 0.2, 0.20390634, 0.201394]\n",
      "[0.6087239, 0.2, 0.20299757, 0.20117953]\n",
      "[0.6085118, 0.2, 0.20208886, 0.20188223]\n",
      "[0.6130279, 0.2, 0.20741743, 0.20107587]\n",
      "[0.61112285, 0.2, 0.20589396, 0.20070025]\n",
      "[0.6079021, 0.2, 0.20253445, 0.20084476]\n",
      "[0.61593574, 0.2, 0.21027125, 0.20114717]\n",
      "[0.61429834, 0.2, 0.2094428, 0.20034398]\n",
      "[0.6157468, 0.2, 0.20978384, 0.20145692]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17520 iterations: 4.1293496012687685 mins\n",
      "Train Loss: [0.6157468, 0.2, 0.20978384, 0.20145692]\n",
      "[0.6111414, 0.2, 0.20507789, 0.20156282]\n",
      "[0.6196736, 0.2, 0.21421261, 0.20096567]\n",
      "[0.61415416, 0.2, 0.20812614, 0.20153749]\n",
      "[0.605861, 0.2, 0.20082554, 0.20054953]\n",
      "[0.60969096, 0.2, 0.20467797, 0.20053175]\n",
      "[0.62201357, 0.2, 0.21571785, 0.20181902]\n",
      "[0.61044174, 0.2, 0.2051136, 0.20085494]\n",
      "[0.610054, 0.2, 0.20500417, 0.20057997]\n",
      "[0.6062946, 0.2, 0.20099556, 0.20083237]\n",
      "[0.60719436, 0.2, 0.20190766, 0.20082326]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17530 iterations: 4.13189746538798 mins\n",
      "Train Loss: [0.60719436, 0.2, 0.20190766, 0.20082326]\n",
      "[0.6212466, 0.2, 0.21612571, 0.20066063]\n",
      "[0.6124434, 0.2, 0.20740215, 0.20058255]\n",
      "[0.6108924, 0.2, 0.20595689, 0.20047845]\n",
      "[0.6110862, 0.2, 0.20599046, 0.20064038]\n",
      "[0.6066857, 0.2, 0.20106447, 0.20116766]\n",
      "[0.60989714, 0.2, 0.20452552, 0.20091982]\n",
      "[0.6209979, 0.2, 0.20652236, 0.21002543]\n",
      "[0.6120193, 0.2, 0.20651421, 0.20105721]\n",
      "[0.6090328, 0.2, 0.2041693, 0.20041744]\n",
      "[0.60959154, 0.2, 0.204648, 0.2004991]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17540 iterations: 4.133726346492767 mins\n",
      "Train Loss: [0.60959154, 0.2, 0.204648, 0.2004991]\n",
      "[0.6089523, 0.2, 0.20409124, 0.20041816]\n",
      "[0.60865897, 0.2, 0.20339926, 0.20081866]\n",
      "[0.6082504, 0.2, 0.20329326, 0.20051761]\n",
      "[0.61044896, 0.2, 0.20521258, 0.20079821]\n",
      "[0.60806036, 0.2, 0.20289119, 0.20073196]\n",
      "[0.6546572, 0.2, 0.21333559, 0.236885]\n",
      "[0.62341386, 0.2, 0.20191614, 0.21706107]\n",
      "[0.6098031, 0.2, 0.20459619, 0.20077005]\n",
      "[0.6151822, 0.2, 0.20976987, 0.2009753]\n",
      "[0.60951376, 0.2, 0.2029181, 0.20215826]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17550 iterations: 4.137111334005992 mins\n",
      "Train Loss: [0.60951376, 0.2, 0.2029181, 0.20215826]\n",
      "[0.6085337, 0.2, 0.20220134, 0.20189469]\n",
      "[0.6143376, 0.2, 0.20872778, 0.20117188]\n",
      "[0.6264403, 0.2, 0.22102624, 0.20097585]\n",
      "[0.61491716, 0.2, 0.20914374, 0.2013353]\n",
      "[0.61003643, 0.2, 0.20476529, 0.20083353]\n",
      "[0.60904247, 0.2, 0.20285295, 0.20175222]\n",
      "[0.6137133, 0.2, 0.20754485, 0.20173156]\n",
      "[0.6085202, 0.2, 0.20265824, 0.20142573]\n",
      "[0.61418706, 0.2, 0.20750107, 0.20225063]\n",
      "[0.61263597, 0.2, 0.20721218, 0.20098923]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17560 iterations: 4.140069917837779 mins\n",
      "Train Loss: [0.61263597, 0.2, 0.20721218, 0.20098923]\n",
      "[0.60945207, 0.2, 0.2024945, 0.202524]\n",
      "[0.61295336, 0.2, 0.20672481, 0.20179604]\n",
      "[0.61206925, 0.2, 0.20658423, 0.20105372]\n",
      "[0.60790443, 0.2, 0.2013125, 0.202162]\n",
      "[0.61038905, 0.2, 0.20524421, 0.20071644]\n",
      "[0.60891473, 0.2, 0.20305505, 0.20143275]\n",
      "[0.6097456, 0.2, 0.20412296, 0.20119742]\n",
      "[0.6139391, 0.2, 0.2075336, 0.20198199]\n",
      "[0.6161995, 0.2, 0.2109688, 0.20080888]\n",
      "[0.6075553, 0.2, 0.20211983, 0.20101567]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17570 iterations: 4.141991782188415 mins\n",
      "Train Loss: [0.6075553, 0.2, 0.20211983, 0.20101567]\n",
      "[0.6137204, 0.2, 0.20836146, 0.20094135]\n",
      "[0.6074474, 0.2, 0.20222493, 0.200807]\n",
      "[0.61283636, 0.2, 0.20757794, 0.20084518]\n",
      "[0.6129399, 0.2, 0.20772383, 0.20080507]\n",
      "[0.6089583, 0.2, 0.20396905, 0.20058045]\n",
      "[0.6141816, 0.2, 0.20915264, 0.2006224]\n",
      "[0.60774016, 0.2, 0.20246756, 0.20086856]\n",
      "[0.61096805, 0.2, 0.20518285, 0.2013837]\n",
      "[0.6090363, 0.2, 0.2040806, 0.2005568]\n",
      "[0.6090292, 0.2, 0.20359172, 0.20104112]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17580 iterations: 4.14400223493576 mins\n",
      "Train Loss: [0.6090292, 0.2, 0.20359172, 0.20104112]\n",
      "[0.6109527, 0.2, 0.20542441, 0.20113446]\n",
      "[0.6090872, 0.2, 0.2039713, 0.20072453]\n",
      "[0.60995126, 0.2, 0.20470153, 0.20086087]\n",
      "[0.6311799, 0.2, 0.20621878, 0.22057492]\n",
      "[0.60805863, 0.2, 0.20253487, 0.20113891]\n",
      "[0.6093415, 0.2, 0.20426735, 0.20069087]\n",
      "[0.61338186, 0.2, 0.20744286, 0.2015568]\n",
      "[0.61231166, 0.2, 0.20710772, 0.20082273]\n",
      "[0.6101452, 0.2, 0.2041614, 0.20160356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60918444, 0.2, 0.2030766, 0.20172876]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17590 iterations: 4.145957831541697 mins\n",
      "Train Loss: [0.60918444, 0.2, 0.2030766, 0.20172876]\n",
      "[0.6141146, 0.2, 0.20841722, 0.20131934]\n",
      "[0.64283013, 0.2, 0.20484328, 0.23361005]\n",
      "[0.6096544, 0.2, 0.20260142, 0.20267855]\n",
      "[0.60621566, 0.2, 0.20110042, 0.20074314]\n",
      "[0.6409007, 0.2, 0.20770875, 0.22882223]\n",
      "[0.6100409, 0.2, 0.20517884, 0.2004952]\n",
      "[0.60957867, 0.2, 0.20474957, 0.20046483]\n",
      "[0.61284244, 0.2, 0.20763011, 0.20085031]\n",
      "[0.6087112, 0.2, 0.20383911, 0.20051216]\n",
      "[0.60788786, 0.2, 0.20301026, 0.20051955]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17600 iterations: 4.148471597830454 mins\n",
      "Train Loss: [0.60788786, 0.2, 0.20301026, 0.20051955]\n",
      "[0.61162263, 0.2, 0.20654851, 0.20071773]\n",
      "[0.6098926, 0.2, 0.20511688, 0.20042078]\n",
      "[0.610655, 0.2, 0.20551811, 0.20078333]\n",
      "[0.6094238, 0.2, 0.20462708, 0.20044458]\n",
      "[0.62023896, 0.2, 0.21555173, 0.20033656]\n",
      "[0.61380386, 0.2, 0.2085801, 0.20087314]\n",
      "[0.6101116, 0.2, 0.20525064, 0.20050867]\n",
      "[0.60763323, 0.2, 0.2028926, 0.2003839]\n",
      "[0.6066553, 0.2, 0.20189458, 0.20039585]\n",
      "[0.6112014, 0.2, 0.20638144, 0.2004437]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17610 iterations: 4.151380185286204 mins\n",
      "Train Loss: [0.6112014, 0.2, 0.20638144, 0.2004437]\n",
      "[0.61018234, 0.2, 0.20504901, 0.2007444]\n",
      "[0.6060803, 0.2, 0.20130685, 0.20037061]\n",
      "[0.6123469, 0.2, 0.20725442, 0.20067532]\n",
      "[0.6108608, 0.2, 0.20487891, 0.20155099]\n",
      "[0.6148074, 0.2, 0.20907626, 0.20128721]\n",
      "[0.61545, 0.2, 0.20988724, 0.20110685]\n",
      "[0.61160016, 0.2, 0.2053318, 0.20180152]\n",
      "[0.61331993, 0.2, 0.20744695, 0.2013968]\n",
      "[0.6092351, 0.2, 0.20379542, 0.20095554]\n",
      "[0.6169658, 0.2, 0.21193966, 0.2005354]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17620 iterations: 4.153893399238586 mins\n",
      "Train Loss: [0.6169658, 0.2, 0.21193966, 0.2005354]\n",
      "[0.6118185, 0.2, 0.20565945, 0.20166321]\n",
      "[0.6160258, 0.2, 0.20891793, 0.20260791]\n",
      "[0.61170685, 0.2, 0.2056132, 0.2015906]\n",
      "[0.61108786, 0.2, 0.20514801, 0.20143463]\n",
      "[0.61443853, 0.2, 0.208507, 0.20142505]\n",
      "[0.6329911, 0.2, 0.2252965, 0.2031874]\n",
      "[0.61144817, 0.2, 0.20573685, 0.20120382]\n",
      "[0.61049, 0.2, 0.20323463, 0.20274866]\n",
      "[0.6087389, 0.2, 0.20381902, 0.20041412]\n",
      "[0.6180311, 0.2, 0.21184152, 0.20168519]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17630 iterations: 4.156437035401662 mins\n",
      "Train Loss: [0.6180311, 0.2, 0.21184152, 0.20168519]\n",
      "[0.6110634, 0.2, 0.20559168, 0.20096871]\n",
      "[0.60941416, 0.2, 0.20327726, 0.20163536]\n",
      "[0.6088751, 0.2, 0.20283057, 0.2015447]\n",
      "[0.6107402, 0.2, 0.20485815, 0.20138413]\n",
      "[0.6085576, 0.2, 0.20344828, 0.2006137]\n",
      "[0.60977256, 0.2, 0.2026304, 0.20264898]\n",
      "[0.6113219, 0.2, 0.20467241, 0.20215902]\n",
      "[0.61235946, 0.2, 0.20697828, 0.20089339]\n",
      "[0.6135007, 0.2, 0.20717746, 0.20183827]\n",
      "[0.6310626, 0.2, 0.2238556, 0.20272498]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17640 iterations: 4.158463982741038 mins\n",
      "Train Loss: [0.6310626, 0.2, 0.2238556, 0.20272498]\n",
      "[0.6118071, 0.2, 0.20560458, 0.20172466]\n",
      "[0.61662173, 0.2, 0.21086632, 0.2012815]\n",
      "[0.60924125, 0.2, 0.20380391, 0.2009669]\n",
      "[0.6083429, 0.2, 0.20331396, 0.20056191]\n",
      "[0.6176643, 0.2, 0.20252839, 0.21067224]\n",
      "[0.612338, 0.2, 0.20687659, 0.20100038]\n",
      "[0.61136585, 0.2, 0.20552063, 0.20138665]\n",
      "[0.612163, 0.2, 0.20637995, 0.20132688]\n",
      "[0.6086302, 0.2, 0.20289709, 0.20127924]\n",
      "[0.6089405, 0.2, 0.20340241, 0.20108657]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17650 iterations: 4.160453768571218 mins\n",
      "Train Loss: [0.6089405, 0.2, 0.20340241, 0.20108657]\n",
      "[0.6110896, 0.2, 0.20461203, 0.20202827]\n",
      "[0.62110895, 0.2, 0.20671053, 0.20995142]\n",
      "[0.61104447, 0.2, 0.20276359, 0.20383552]\n",
      "[0.6117937, 0.2, 0.20613389, 0.20121601]\n",
      "[0.6132514, 0.2, 0.20784168, 0.20096731]\n",
      "[0.6105672, 0.2, 0.20444793, 0.20167845]\n",
      "[0.62193817, 0.2, 0.21660714, 0.20089185]\n",
      "[0.6119352, 0.2, 0.20677201, 0.20072576]\n",
      "[0.6119624, 0.2, 0.20689674, 0.20063017]\n",
      "[0.61246866, 0.2, 0.2073006, 0.20073442]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17660 iterations: 4.162361947695414 mins\n",
      "Train Loss: [0.61246866, 0.2, 0.2073006, 0.20073442]\n",
      "[0.6106838, 0.2, 0.2046729, 0.20157926]\n",
      "[0.61266387, 0.2, 0.20644087, 0.20179316]\n",
      "[0.61034894, 0.2, 0.20416568, 0.20175546]\n",
      "[0.61209196, 0.2, 0.2065506, 0.20111564]\n",
      "[0.6096013, 0.2, 0.20430604, 0.20087197]\n",
      "[0.61434615, 0.2, 0.2091547, 0.20077048]\n",
      "[0.6087158, 0.2, 0.20365046, 0.2006469]\n",
      "[0.61042935, 0.2, 0.20491828, 0.20109521]\n",
      "[0.61163723, 0.2, 0.20626609, 0.2009578]\n",
      "[0.61635035, 0.2, 0.21057516, 0.20136417]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17670 iterations: 4.164956132570903 mins\n",
      "Train Loss: [0.61635035, 0.2, 0.21057516, 0.20136417]\n",
      "[0.6121001, 0.2, 0.20671244, 0.20097929]\n",
      "[0.6089518, 0.2, 0.2036325, 0.20091382]\n",
      "[0.6131187, 0.2, 0.20782232, 0.20089382]\n",
      "[0.63309854, 0.2, 0.2274786, 0.20121998]\n",
      "[0.6098698, 0.2, 0.20480254, 0.20066881]\n",
      "[0.6100092, 0.2, 0.20347081, 0.20214143]\n",
      "[0.60802335, 0.2, 0.20271125, 0.20091657]\n",
      "[0.6121218, 0.2, 0.20710935, 0.20061848]\n",
      "[0.6145713, 0.2, 0.20984083, 0.20033808]\n",
      "[0.6092321, 0.2, 0.20336354, 0.2014778]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17680 iterations: 4.167058614889781 mins\n",
      "Train Loss: [0.6092321, 0.2, 0.20336354, 0.2014778]\n",
      "[0.6117997, 0.2, 0.20703249, 0.2003781]\n",
      "[0.60974044, 0.2, 0.20477325, 0.20057988]\n",
      "[0.6086918, 0.2, 0.20377699, 0.20052929]\n",
      "[0.6191462, 0.2, 0.20375982, 0.2110025]\n",
      "[0.60590273, 0.2, 0.20126805, 0.20025168]\n",
      "[0.6257855, 0.2, 0.2053001, 0.21610343]\n",
      "[0.6089344, 0.2, 0.20401181, 0.20054117]\n",
      "[0.609081, 0.2, 0.20431781, 0.20038234]\n",
      "[0.611918, 0.2, 0.20712706, 0.20041062]\n",
      "[0.61105585, 0.2, 0.20593707, 0.2007393]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17690 iterations: 4.16893299818039 mins\n",
      "Train Loss: [0.61105585, 0.2, 0.20593707, 0.2007393]\n",
      "[0.6131962, 0.2, 0.20752503, 0.2012926]\n",
      "[0.6123343, 0.2, 0.20658548, 0.20137133]\n",
      "[0.60761625, 0.2, 0.20256107, 0.20067878]\n",
      "[0.610741, 0.2, 0.20496963, 0.20139614]\n",
      "[0.6130402, 0.2, 0.20736623, 0.2013001]\n",
      "[0.6093849, 0.2, 0.20386672, 0.20114578]\n",
      "[0.611058, 0.2, 0.20546694, 0.20121989]\n",
      "[0.6092633, 0.2, 0.20429732, 0.20059606]\n",
      "[0.6120236, 0.2, 0.20725965, 0.20039378]\n",
      "[0.61052245, 0.2, 0.2053456, 0.20080416]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17700 iterations: 4.171135532855987 mins\n",
      "Train Loss: [0.61052245, 0.2, 0.2053456, 0.20080416]\n",
      "[0.61116356, 0.2, 0.20557807, 0.20120731]\n",
      "[0.6229792, 0.2, 0.21738388, 0.20120917]\n",
      "[0.61015445, 0.2, 0.20527416, 0.20048419]\n",
      "[0.60820967, 0.2, 0.20327628, 0.2005264]\n",
      "[0.6298117, 0.2, 0.22395393, 0.20143993]\n",
      "[0.6080302, 0.2, 0.20305121, 0.2005509]\n",
      "[0.6093861, 0.2, 0.20395084, 0.2009977]\n",
      "[0.6150933, 0.2, 0.20968123, 0.20096597]\n",
      "[0.6113599, 0.2, 0.20613171, 0.20077467]\n",
      "[0.60767436, 0.2, 0.20235269, 0.20086208]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17710 iterations: 4.173043048381805 mins\n",
      "Train Loss: [0.60767436, 0.2, 0.20235269, 0.20086208]\n",
      "[0.60656893, 0.2, 0.20133822, 0.20076631]\n",
      "[0.64515656, 0.2, 0.20779386, 0.23289491]\n",
      "[0.6105689, 0.2, 0.20452224, 0.20157726]\n",
      "[0.61136264, 0.2, 0.2060073, 0.20088539]\n",
      "[0.60935044, 0.2, 0.20319825, 0.20168246]\n",
      "[0.6077606, 0.2, 0.20253526, 0.20075674]\n",
      "[0.6065094, 0.2, 0.20169315, 0.2003494]\n",
      "[0.6156443, 0.2, 0.21038671, 0.2007932]\n",
      "[0.6066428, 0.2, 0.2015365, 0.2006451]\n",
      "[0.6113397, 0.2, 0.20516339, 0.20171882]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17720 iterations: 4.175222031275431 mins\n",
      "Train Loss: [0.6113397, 0.2, 0.20516339, 0.20171882]\n",
      "[0.61920625, 0.2, 0.21419026, 0.20056248]\n",
      "[0.60599, 0.2, 0.20099762, 0.20054318]\n",
      "[0.6112982, 0.2, 0.20635667, 0.20049688]\n",
      "[0.6085876, 0.2, 0.20333797, 0.20080975]\n",
      "[0.60675234, 0.2, 0.20119515, 0.20112205]\n",
      "[0.6105245, 0.2, 0.20491724, 0.20117697]\n",
      "[0.6191211, 0.2, 0.21418868, 0.20050697]\n",
      "[0.6085558, 0.2, 0.20344718, 0.2006878]\n",
      "[0.60976946, 0.2, 0.20456342, 0.20078978]\n",
      "[0.6078091, 0.2, 0.20210537, 0.20129213]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17730 iterations: 4.177258698145549 mins\n",
      "Train Loss: [0.6078091, 0.2, 0.20210537, 0.20129213]\n",
      "[0.6078615, 0.2, 0.20199777, 0.20145671]\n",
      "[0.6098129, 0.2, 0.20435253, 0.20105793]\n",
      "[0.60889333, 0.2, 0.20378664, 0.20070855]\n",
      "[0.61414474, 0.2, 0.2090824, 0.20066848]\n",
      "[0.6158629, 0.2, 0.21006238, 0.20141053]\n",
      "[0.6101439, 0.2, 0.20530272, 0.20045498]\n",
      "[0.60945845, 0.2, 0.2046919, 0.20038417]\n",
      "[0.623418, 0.2, 0.218083, 0.20095624]\n",
      "[0.6116789, 0.2, 0.20667043, 0.20063421]\n",
      "[0.60674936, 0.2, 0.20170306, 0.20067632]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17740 iterations: 4.17918903430303 mins\n",
      "Train Loss: [0.60674936, 0.2, 0.20170306, 0.20067632]\n",
      "[0.6134241, 0.2, 0.2085489, 0.20050928]\n",
      "[0.61027074, 0.2, 0.2055747, 0.20033383]\n",
      "[0.61245596, 0.2, 0.2071838, 0.20091361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60683966, 0.2, 0.20173126, 0.20075339]\n",
      "[0.610247, 0.2, 0.20515981, 0.20073567]\n",
      "[0.60633194, 0.2, 0.20166358, 0.20032021]\n",
      "[0.6101208, 0.2, 0.20508376, 0.20069206]\n",
      "[0.61099875, 0.2, 0.20589736, 0.20075972]\n",
      "[0.6091597, 0.2, 0.20412058, 0.20070064]\n",
      "[0.62600774, 0.2, 0.20739502, 0.21427721]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17750 iterations: 4.1818453669548035 mins\n",
      "Train Loss: [0.62600774, 0.2, 0.20739502, 0.21427721]\n",
      "[0.60864764, 0.2, 0.20384805, 0.20046718]\n",
      "[0.6142872, 0.2, 0.2093104, 0.20064734]\n",
      "[0.6092309, 0.2, 0.20449992, 0.2004043]\n",
      "[0.61259836, 0.2, 0.20753404, 0.20074041]\n",
      "[0.6098264, 0.2, 0.20470269, 0.20080239]\n",
      "[0.60751027, 0.2, 0.20262466, 0.20056692]\n",
      "[0.60598224, 0.2, 0.20118381, 0.20048201]\n",
      "[0.61023927, 0.2, 0.20512237, 0.20080271]\n",
      "[0.6145144, 0.2, 0.20968908, 0.20051335]\n",
      "[0.6163332, 0.2, 0.21138157, 0.20064145]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17760 iterations: 4.183700350920359 mins\n",
      "Train Loss: [0.6163332, 0.2, 0.21138157, 0.20064145]\n",
      "[0.6127018, 0.2, 0.20749868, 0.20089437]\n",
      "[0.61010057, 0.2, 0.20414218, 0.20165117]\n",
      "[0.60922366, 0.2, 0.20435898, 0.20055921]\n",
      "[0.6091499, 0.2, 0.2041349, 0.20071143]\n",
      "[0.6188428, 0.2, 0.2137599, 0.20078132]\n",
      "[0.6129187, 0.2, 0.20752119, 0.20109788]\n",
      "[0.6091473, 0.2, 0.20437238, 0.20047736]\n",
      "[0.6109759, 0.2, 0.2058182, 0.20086218]\n",
      "[0.6095485, 0.2, 0.20470732, 0.20054756]\n",
      "[0.60698444, 0.2, 0.20154592, 0.2011468]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17770 iterations: 4.185717769463857 mins\n",
      "Train Loss: [0.60698444, 0.2, 0.20154592, 0.2011468]\n",
      "[0.60819113, 0.2, 0.20333557, 0.20056565]\n",
      "[0.6152462, 0.2, 0.21037576, 0.20058213]\n",
      "[0.61295116, 0.2, 0.20821014, 0.20045455]\n",
      "[0.6114363, 0.2, 0.20669499, 0.20045637]\n",
      "[0.6097562, 0.2, 0.20507313, 0.20039944]\n",
      "[0.6169201, 0.2, 0.20220914, 0.21042874]\n",
      "[0.60744077, 0.2, 0.20266551, 0.20049427]\n",
      "[0.60944223, 0.2, 0.20497346, 0.20018911]\n",
      "[0.60575575, 0.2, 0.20036192, 0.20111547]\n",
      "[0.6193692, 0.2, 0.2144241, 0.20066811]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17780 iterations: 4.187661250432332 mins\n",
      "Train Loss: [0.6193692, 0.2, 0.2144241, 0.20066811]\n",
      "[0.6142766, 0.2, 0.20970471, 0.20029582]\n",
      "[0.6081469, 0.2, 0.20341194, 0.20046009]\n",
      "[0.61068577, 0.2, 0.20560269, 0.20080924]\n",
      "[0.6086628, 0.2, 0.20358002, 0.20081012]\n",
      "[0.61297953, 0.2, 0.20792939, 0.20077872]\n",
      "[0.61090416, 0.2, 0.20625599, 0.20037816]\n",
      "[0.62769914, 0.2, 0.21240906, 0.21102135]\n",
      "[0.6123325, 0.2, 0.207261, 0.20080414]\n",
      "[0.6110834, 0.2, 0.20656334, 0.20025387]\n",
      "[0.60750407, 0.2, 0.20280263, 0.20043638]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17790 iterations: 4.190586884816487 mins\n",
      "Train Loss: [0.60750407, 0.2, 0.20280263, 0.20043638]\n",
      "[0.6137543, 0.2, 0.20919092, 0.20029928]\n",
      "[0.62171566, 0.2, 0.21694918, 0.20050313]\n",
      "[0.6107944, 0.2, 0.2061403, 0.20039107]\n",
      "[0.63726753, 0.2, 0.21211426, 0.22089028]\n",
      "[0.6220847, 0.2, 0.20478278, 0.21303886]\n",
      "[0.6097564, 0.2, 0.20520528, 0.20028658]\n",
      "[0.6084029, 0.2, 0.20372264, 0.20041399]\n",
      "[0.6129269, 0.2, 0.20801039, 0.20064834]\n",
      "[0.6089186, 0.2, 0.20415471, 0.2004939]\n",
      "[0.6090256, 0.2, 0.203569, 0.20118482]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17800 iterations: 4.192608034610748 mins\n",
      "Train Loss: [0.6090256, 0.2, 0.203569, 0.20118482]\n",
      "[0.6086912, 0.2, 0.20387934, 0.20053847]\n",
      "[0.60746026, 0.2, 0.20253716, 0.2006482]\n",
      "[0.61189437, 0.2, 0.20730402, 0.20031424]\n",
      "[0.6220866, 0.2, 0.20422427, 0.21358527]\n",
      "[0.61016667, 0.2, 0.20546132, 0.20042732]\n",
      "[0.6114252, 0.2, 0.20554858, 0.20159753]\n",
      "[0.60785496, 0.2, 0.20304877, 0.20052622]\n",
      "[0.61053956, 0.2, 0.2049598, 0.20129906]\n",
      "[0.60905254, 0.2, 0.20380393, 0.20096754]\n",
      "[0.6141145, 0.2, 0.20848669, 0.2013467]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17810 iterations: 4.194623533884684 mins\n",
      "Train Loss: [0.6141145, 0.2, 0.20848669, 0.2013467]\n",
      "[0.6108673, 0.2, 0.2061749, 0.20041119]\n",
      "[0.61330324, 0.2, 0.20846802, 0.20055404]\n",
      "[0.6193279, 0.2, 0.21363492, 0.20141202]\n",
      "[0.61115444, 0.2, 0.20619906, 0.20067495]\n",
      "[0.615281, 0.2, 0.21040475, 0.20059639]\n",
      "[0.61349094, 0.2, 0.20794296, 0.20126884]\n",
      "[0.6235546, 0.2, 0.2025756, 0.21670069]\n",
      "[0.6108835, 0.2, 0.20620129, 0.20040463]\n",
      "[0.6118893, 0.2, 0.20667188, 0.20094076]\n",
      "[0.611699, 0.2, 0.20488912, 0.2025342]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17820 iterations: 4.1966767827669775 mins\n",
      "Train Loss: [0.611699, 0.2, 0.20488912, 0.2025342]\n",
      "[0.6169108, 0.2, 0.2117943, 0.2008421]\n",
      "[0.6136719, 0.2, 0.20860164, 0.20079722]\n",
      "[0.6095195, 0.2, 0.20478971, 0.20045795]\n",
      "[0.6101805, 0.2, 0.20515282, 0.20075716]\n",
      "[0.620877, 0.2, 0.20232308, 0.21428478]\n",
      "[0.6061471, 0.2, 0.20118709, 0.2006904]\n",
      "[0.6187095, 0.2, 0.21403791, 0.20040014]\n",
      "[0.60809803, 0.2, 0.20324455, 0.2005798]\n",
      "[0.6098457, 0.2, 0.20479348, 0.20077404]\n",
      "[0.61321515, 0.2, 0.2083604, 0.20057073]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17830 iterations: 4.199139865239461 mins\n",
      "Train Loss: [0.61321515, 0.2, 0.2083604, 0.20057073]\n",
      "[0.61858314, 0.2, 0.21303165, 0.20126104]\n",
      "[0.6421904, 0.2, 0.20345004, 0.23444308]\n",
      "[0.6109289, 0.2, 0.20497158, 0.20165437]\n",
      "[0.6094287, 0.2, 0.20381065, 0.20130958]\n",
      "[0.61161834, 0.2, 0.20514552, 0.20215923]\n",
      "[0.6192567, 0.2, 0.21355174, 0.20138666]\n",
      "[0.6107057, 0.2, 0.20479739, 0.20158637]\n",
      "[0.6106697, 0.2, 0.20522746, 0.20111695]\n",
      "[0.62031156, 0.2, 0.21433976, 0.20164388]\n",
      "[0.6094328, 0.2, 0.20402262, 0.2010802]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17840 iterations: 4.201278817653656 mins\n",
      "Train Loss: [0.6094328, 0.2, 0.20402262, 0.2010802]\n",
      "[0.6114832, 0.2, 0.20528853, 0.20186327]\n",
      "[0.6104688, 0.2, 0.20417917, 0.20195726]\n",
      "[0.61290497, 0.2, 0.20710248, 0.20146964]\n",
      "[0.61824995, 0.2, 0.2132102, 0.20070694]\n",
      "[0.6095022, 0.2, 0.20367378, 0.20149603]\n",
      "[0.60678935, 0.2, 0.20143051, 0.20102726]\n",
      "[0.6107254, 0.2, 0.20557198, 0.20082292]\n",
      "[0.606864, 0.2, 0.2015529, 0.20098183]\n",
      "[0.61446494, 0.2, 0.20895387, 0.2011834]\n",
      "[0.60821784, 0.2, 0.20257887, 0.20131329]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17850 iterations: 4.203466065724691 mins\n",
      "Train Loss: [0.60821784, 0.2, 0.20257887, 0.20131329]\n",
      "[0.65516216, 0.2, 0.21599153, 0.23484722]\n",
      "[0.6096052, 0.2, 0.20454441, 0.20074074]\n",
      "[0.60654664, 0.2, 0.20166978, 0.20056002]\n",
      "[0.6110519, 0.2, 0.20626728, 0.2004709]\n",
      "[0.6340447, 0.2, 0.21159355, 0.2181405]\n",
      "[0.61305535, 0.2, 0.2065335, 0.20221396]\n",
      "[0.61255264, 0.2, 0.20714913, 0.20109822]\n",
      "[0.6132763, 0.2, 0.2077801, 0.20119333]\n",
      "[0.61017436, 0.2, 0.20538867, 0.20048526]\n",
      "[0.60548365, 0.2, 0.20035651, 0.2008291]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17860 iterations: 4.205365979671479 mins\n",
      "Train Loss: [0.60548365, 0.2, 0.20035651, 0.2008291]\n",
      "[0.609795, 0.2, 0.20494051, 0.20055881]\n",
      "[0.6253603, 0.2, 0.20517957, 0.21588746]\n",
      "[0.6282261, 0.2, 0.20849605, 0.2154392]\n",
      "[0.6105568, 0.2, 0.20560794, 0.20065974]\n",
      "[0.6088325, 0.2, 0.20347993, 0.20106494]\n",
      "[0.61200863, 0.2, 0.20623837, 0.20148416]\n",
      "[0.6104343, 0.2, 0.20526256, 0.20088692]\n",
      "[0.6126045, 0.2, 0.20780306, 0.20051776]\n",
      "[0.6085587, 0.2, 0.20344408, 0.20083196]\n",
      "[0.6084297, 0.2, 0.20272158, 0.20142657]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17870 iterations: 4.207405201594034 mins\n",
      "Train Loss: [0.6084297, 0.2, 0.20272158, 0.20142657]\n",
      "[0.6209573, 0.2, 0.21376352, 0.20291328]\n",
      "[0.6115353, 0.2, 0.20471564, 0.20254017]\n",
      "[0.612481, 0.2, 0.20774978, 0.20045291]\n",
      "[0.6306818, 0.2, 0.20206654, 0.22433811]\n",
      "[0.60975206, 0.2, 0.20362243, 0.2018533]\n",
      "[0.6087948, 0.2, 0.20376809, 0.20075129]\n",
      "[0.6186575, 0.2, 0.21318212, 0.2012009]\n",
      "[0.60957456, 0.2, 0.2042612, 0.20104045]\n",
      "[0.61611694, 0.2, 0.21074717, 0.20109841]\n",
      "[0.6121371, 0.2, 0.20662583, 0.20124084]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17880 iterations: 4.2093833684921265 mins\n",
      "Train Loss: [0.6121371, 0.2, 0.20662583, 0.20124084]\n",
      "[0.61115277, 0.2, 0.20578831, 0.20109506]\n",
      "[0.6116549, 0.2, 0.20691656, 0.20047006]\n",
      "[0.6134987, 0.2, 0.20873551, 0.20049599]\n",
      "[0.62839496, 0.2, 0.22321245, 0.20091645]\n",
      "[0.6086009, 0.2, 0.20366639, 0.20066813]\n",
      "[0.613773, 0.2, 0.2090047, 0.20050165]\n",
      "[0.60773945, 0.2, 0.20261978, 0.20085292]\n",
      "[0.6242602, 0.2, 0.2076819, 0.21231157]\n",
      "[0.6117679, 0.2, 0.20632383, 0.20117702]\n",
      "[0.60751253, 0.2, 0.2028271, 0.20041806]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17890 iterations: 4.211432452996572 mins\n",
      "Train Loss: [0.60751253, 0.2, 0.2028271, 0.20041806]\n",
      "[0.60726213, 0.2, 0.20206113, 0.20093329]\n",
      "[0.61990786, 0.2, 0.21514854, 0.20049144]\n",
      "[0.60908765, 0.2, 0.20362356, 0.2011958]\n",
      "[0.608912, 0.2, 0.20384337, 0.20080027]\n",
      "[0.60718936, 0.2, 0.20255637, 0.20036478]\n",
      "[0.61356276, 0.2, 0.20863922, 0.20065562]\n",
      "[0.6088074, 0.2, 0.20348959, 0.20105016]\n",
      "[0.6071391, 0.2, 0.20222117, 0.20065084]\n",
      "[0.6359773, 0.2, 0.20147353, 0.23023736]\n",
      "[0.6343738, 0.2, 0.20413479, 0.2259738]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17900 iterations: 4.213356133302053 mins\n",
      "Train Loss: [0.6343738, 0.2, 0.20413479, 0.2259738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60817057, 0.2, 0.20354064, 0.20036647]\n",
      "[0.60904664, 0.2, 0.20434912, 0.20043534]\n",
      "[0.6058368, 0.2, 0.20103112, 0.20054483]\n",
      "[0.6088364, 0.2, 0.20394093, 0.20063592]\n",
      "[0.61024773, 0.2, 0.20562738, 0.20036215]\n",
      "[0.6134629, 0.2, 0.20871867, 0.20048724]\n",
      "[0.6241843, 0.2, 0.2191204, 0.20080821]\n",
      "[0.6089591, 0.2, 0.20438342, 0.20032172]\n",
      "[0.61074996, 0.2, 0.20604485, 0.20045294]\n",
      "[0.60614055, 0.2, 0.2013747, 0.20051542]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17910 iterations: 4.215860748291016 mins\n",
      "Train Loss: [0.60614055, 0.2, 0.2013747, 0.20051542]\n",
      "[0.6123255, 0.2, 0.2072447, 0.20083214]\n",
      "[0.60886526, 0.2, 0.20423032, 0.20038775]\n",
      "[0.61595756, 0.2, 0.21001603, 0.20169568]\n",
      "[0.6351307, 0.2, 0.20606773, 0.22481841]\n",
      "[0.6070699, 0.2, 0.20244192, 0.20038392]\n",
      "[0.61076933, 0.2, 0.20520106, 0.20132439]\n",
      "[0.61139035, 0.2, 0.20672493, 0.2004218]\n",
      "[0.6086187, 0.2, 0.20353563, 0.20083962]\n",
      "[0.612148, 0.2, 0.2076285, 0.20027635]\n",
      "[0.6196187, 0.2, 0.21465278, 0.20072316]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17920 iterations: 4.2177700161933895 mins\n",
      "Train Loss: [0.6196187, 0.2, 0.21465278, 0.20072316]\n",
      "[0.61440355, 0.2, 0.20953228, 0.20062971]\n",
      "[0.61424786, 0.2, 0.20884758, 0.20115991]\n",
      "[0.6126176, 0.2, 0.20770392, 0.2006745]\n",
      "[0.60827774, 0.2, 0.2030263, 0.20101331]\n",
      "[0.629344, 0.2, 0.20890206, 0.21620488]\n",
      "[0.60593003, 0.2, 0.20090331, 0.20079082]\n",
      "[0.6118683, 0.2, 0.20719494, 0.20043862]\n",
      "[0.6095041, 0.2, 0.20457023, 0.20070015]\n",
      "[0.6073077, 0.2, 0.20219134, 0.20088395]\n",
      "[0.6079161, 0.2, 0.20330507, 0.20038003]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17930 iterations: 4.219773650169373 mins\n",
      "Train Loss: [0.6079161, 0.2, 0.20330507, 0.20038003]\n",
      "[0.61064994, 0.2, 0.20604688, 0.20037338]\n",
      "[0.6096408, 0.2, 0.20504528, 0.20036723]\n",
      "[0.61148095, 0.2, 0.2069264, 0.20032762]\n",
      "[0.605699, 0.2, 0.20084707, 0.20062636]\n",
      "[0.61190087, 0.2, 0.20733382, 0.20034294]\n",
      "[0.60930413, 0.2, 0.20454505, 0.20053644]\n",
      "[0.6097039, 0.2, 0.20523034, 0.20025253]\n",
      "[0.6099471, 0.2, 0.20432581, 0.20140195]\n",
      "[0.6080258, 0.2, 0.20304294, 0.2007652]\n",
      "[0.6086802, 0.2, 0.20337476, 0.20108943]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17940 iterations: 4.221813666820526 mins\n",
      "Train Loss: [0.6086802, 0.2, 0.20337476, 0.20108943]\n",
      "[0.6196649, 0.2, 0.2033018, 0.21214874]\n",
      "[0.6116585, 0.2, 0.2069045, 0.20054083]\n",
      "[0.6079773, 0.2, 0.2033743, 0.20039093]\n",
      "[0.61218286, 0.2, 0.20743734, 0.20053475]\n",
      "[0.60824853, 0.2, 0.20353347, 0.20050561]\n",
      "[0.6089255, 0.2, 0.20407218, 0.20064516]\n",
      "[0.60856915, 0.2, 0.20381354, 0.20054856]\n",
      "[0.60833937, 0.2, 0.20374177, 0.20039178]\n",
      "[0.61028844, 0.2, 0.2057011, 0.2003825]\n",
      "[0.6108441, 0.2, 0.2063673, 0.20027299]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17950 iterations: 4.223727981249492 mins\n",
      "Train Loss: [0.6108441, 0.2, 0.2063673, 0.20027299]\n",
      "[0.61591923, 0.2, 0.2114064, 0.20030999]\n",
      "[0.60781294, 0.2, 0.2030626, 0.20054834]\n",
      "[0.60683554, 0.2, 0.20177156, 0.2008629]\n",
      "[0.60766786, 0.2, 0.2027675, 0.20070016]\n",
      "[0.6069371, 0.2, 0.2021267, 0.20061128]\n",
      "[0.6123358, 0.2, 0.20764418, 0.20049354]\n",
      "[0.61025155, 0.2, 0.2057958, 0.20025899]\n",
      "[0.6059699, 0.2, 0.20083378, 0.20094053]\n",
      "[0.60984135, 0.2, 0.2049311, 0.20071597]\n",
      "[0.6064951, 0.2, 0.20190337, 0.20039865]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17960 iterations: 4.225799798965454 mins\n",
      "Train Loss: [0.6064951, 0.2, 0.20190337, 0.20039865]\n",
      "[0.6193019, 0.2, 0.21455447, 0.20055579]\n",
      "[0.61053354, 0.2, 0.20595573, 0.20038778]\n",
      "[0.61163056, 0.2, 0.20718278, 0.20025922]\n",
      "[0.6331359, 0.2, 0.20396274, 0.22498578]\n",
      "[0.61084694, 0.2, 0.20628415, 0.20037682]\n",
      "[0.6131803, 0.2, 0.20820053, 0.2007953]\n",
      "[0.6069849, 0.2, 0.20186514, 0.20093676]\n",
      "[0.61082995, 0.2, 0.20609418, 0.20055407]\n",
      "[0.60994357, 0.2, 0.20471585, 0.2010473]\n",
      "[0.6119374, 0.2, 0.20707044, 0.20068757]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17970 iterations: 4.2277188181877134 mins\n",
      "Train Loss: [0.6119374, 0.2, 0.20707044, 0.20068757]\n",
      "[0.61365205, 0.2, 0.20894657, 0.20052709]\n",
      "[0.6062911, 0.2, 0.20150228, 0.2006115]\n",
      "[0.6074027, 0.2, 0.20280759, 0.20041876]\n",
      "[0.612508, 0.2, 0.20750378, 0.20082888]\n",
      "[0.6097263, 0.2, 0.20492986, 0.20062213]\n",
      "[0.6112073, 0.2, 0.20649792, 0.20053603]\n",
      "[0.60916615, 0.2, 0.20411332, 0.2008804]\n",
      "[0.610343, 0.2, 0.20583963, 0.20033178]\n",
      "[0.60920244, 0.2, 0.20462464, 0.20040728]\n",
      "[0.6186519, 0.2, 0.21386465, 0.20061782]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17980 iterations: 4.229716885089874 mins\n",
      "Train Loss: [0.6186519, 0.2, 0.21386465, 0.20061782]\n",
      "[0.6131128, 0.2, 0.2082544, 0.20069058]\n",
      "[0.60807365, 0.2, 0.20317344, 0.20073366]\n",
      "[0.6065573, 0.2, 0.20190968, 0.20048216]\n",
      "[0.6076916, 0.2, 0.20317239, 0.20035481]\n",
      "[0.6072663, 0.2, 0.20250565, 0.20059744]\n",
      "[0.60880315, 0.2, 0.20405956, 0.2005815]\n",
      "[0.61049265, 0.2, 0.20594983, 0.20038196]\n",
      "[0.6151405, 0.2, 0.21049665, 0.20048416]\n",
      "[0.6107229, 0.2, 0.20596473, 0.20059955]\n",
      "[0.60613066, 0.2, 0.20151494, 0.20045829]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17990 iterations: 4.232358467578888 mins\n",
      "Train Loss: [0.60613066, 0.2, 0.20151494, 0.20045829]\n",
      "[0.6125755, 0.2, 0.20812581, 0.20029336]\n",
      "[0.6092165, 0.2, 0.20471998, 0.20034146]\n",
      "[0.61281955, 0.2, 0.20817102, 0.20049445]\n",
      "[0.6057898, 0.2, 0.20087993, 0.2007568]\n",
      "[0.6102381, 0.2, 0.20543171, 0.20065434]\n",
      "[0.60704774, 0.2, 0.20233597, 0.20056076]\n",
      "[0.6101866, 0.2, 0.20543747, 0.20059934]\n",
      "[0.63376534, 0.2, 0.20443308, 0.22518373]\n",
      "[0.6075449, 0.2, 0.20290689, 0.20049073]\n",
      "[0.6148947, 0.2, 0.21002685, 0.2007217]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18000 iterations: 4.23426011800766 mins\n",
      "Train Loss: [0.6148947, 0.2, 0.21002685, 0.2007217]\n",
      "[0.6090808, 0.2, 0.20427315, 0.20066273]\n",
      "[0.6114407, 0.2, 0.20626752, 0.2010295]\n",
      "[0.6176903, 0.2, 0.21310611, 0.2004414]\n",
      "[0.61012983, 0.2, 0.20549092, 0.20049861]\n",
      "[0.6094176, 0.2, 0.20489639, 0.20038301]\n",
      "[0.6088388, 0.2, 0.20441195, 0.20029023]\n",
      "[0.60801643, 0.2, 0.2033281, 0.20055327]\n",
      "[0.61190665, 0.2, 0.20706402, 0.20070899]\n",
      "[0.6099104, 0.2, 0.20516069, 0.20061725]\n",
      "[0.62019974, 0.2, 0.21563599, 0.20043224]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18010 iterations: 4.2363408009211225 mins\n",
      "Train Loss: [0.62019974, 0.2, 0.21563599, 0.20043224]\n",
      "[0.60923547, 0.2, 0.20478342, 0.2003226]\n",
      "[0.608954, 0.2, 0.20419566, 0.20063066]\n",
      "[0.6099317, 0.2, 0.20514269, 0.20066273]\n",
      "[0.60995936, 0.2, 0.20542312, 0.20041113]\n",
      "[0.60688627, 0.2, 0.20144631, 0.2013158]\n",
      "[0.6092602, 0.2, 0.20475136, 0.20038557]\n",
      "[0.61271054, 0.2, 0.20744212, 0.20114607]\n",
      "[0.6090379, 0.2, 0.20358197, 0.20133422]\n",
      "[0.61260104, 0.2, 0.20804596, 0.200434]\n",
      "[0.61428726, 0.2, 0.20906763, 0.20109917]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18020 iterations: 4.238228718439738 mins\n",
      "Train Loss: [0.61428726, 0.2, 0.20906763, 0.20109917]\n",
      "[0.6080626, 0.2, 0.2030328, 0.20090991]\n",
      "[0.61509037, 0.2, 0.21035546, 0.20061573]\n",
      "[0.61504996, 0.2, 0.21026872, 0.20066303]\n",
      "[0.6097976, 0.2, 0.20408504, 0.20159534]\n",
      "[0.60892135, 0.2, 0.20412627, 0.20067869]\n",
      "[0.60908884, 0.2, 0.20446855, 0.20050478]\n",
      "[0.6071635, 0.2, 0.2025735, 0.20047544]\n",
      "[0.60849434, 0.2, 0.20389545, 0.20048532]\n",
      "[0.6138662, 0.2, 0.20925143, 0.200502]\n",
      "[0.6127297, 0.2, 0.20763987, 0.20097819]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18030 iterations: 4.240420536200205 mins\n",
      "Train Loss: [0.6127297, 0.2, 0.20763987, 0.20097819]\n",
      "[0.6090527, 0.2, 0.20398837, 0.20095377]\n",
      "[0.6201075, 0.2, 0.21560866, 0.20038925]\n",
      "[0.60959643, 0.2, 0.2051065, 0.20038101]\n",
      "[0.66462284, 0.2, 0.23913163, 0.2213831]\n",
      "[0.60949296, 0.2, 0.20457579, 0.20080957]\n",
      "[0.6177004, 0.2, 0.21311174, 0.20048143]\n",
      "[0.626243, 0.2, 0.20571709, 0.2164187]\n",
      "[0.6136506, 0.2, 0.20896928, 0.2005737]\n",
      "[0.60655266, 0.2, 0.20174299, 0.20070182]\n",
      "[0.60961336, 0.2, 0.20488083, 0.20062445]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18040 iterations: 4.242381183306376 mins\n",
      "Train Loss: [0.60961336, 0.2, 0.20488083, 0.20062445]\n",
      "[0.60865563, 0.2, 0.20400976, 0.20053735]\n",
      "[0.60968107, 0.2, 0.20497444, 0.20059787]\n",
      "[0.6100006, 0.2, 0.20528021, 0.20061138]\n",
      "[0.60745794, 0.2, 0.20298992, 0.20035884]\n",
      "[0.6058571, 0.2, 0.2012672, 0.20048063]\n",
      "[0.64219236, 0.2, 0.20864394, 0.22943923]\n",
      "[0.62678933, 0.2, 0.20389187, 0.21878824]\n",
      "[0.6127369, 0.2, 0.20837536, 0.2002516]\n",
      "[0.6142989, 0.2, 0.20990501, 0.20028351]\n",
      "[0.61558765, 0.2, 0.21095626, 0.20052034]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18050 iterations: 4.244365080197652 mins\n",
      "Train Loss: [0.61558765, 0.2, 0.21095626, 0.20052034]\n",
      "[0.6073049, 0.2, 0.20260689, 0.20058575]\n",
      "[0.60800654, 0.2, 0.20364746, 0.20024556]\n",
      "[0.6088219, 0.2, 0.20394029, 0.20076694]\n",
      "[0.612531, 0.2, 0.20792504, 0.20049006]\n",
      "[0.6077211, 0.2, 0.20272271, 0.20088136]\n",
      "[0.6082777, 0.2, 0.20375179, 0.20040786]\n",
      "[0.6077449, 0.2, 0.20308916, 0.20053674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61137986, 0.2, 0.20665427, 0.20060563]\n",
      "[0.6081297, 0.2, 0.20342219, 0.20058672]\n",
      "[0.6065788, 0.2, 0.2021041, 0.20035319]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18060 iterations: 4.2463964502016704 mins\n",
      "Train Loss: [0.6065788, 0.2, 0.2021041, 0.20035319]\n",
      "[0.6131449, 0.2, 0.20854022, 0.20048258]\n",
      "[0.6115263, 0.2, 0.20681834, 0.2005855]\n",
      "[0.60885864, 0.2, 0.20396025, 0.2007756]\n",
      "[0.6080727, 0.2, 0.20325586, 0.20069407]\n",
      "[0.60785776, 0.2, 0.20303334, 0.20070197]\n",
      "[0.6098296, 0.2, 0.20537835, 0.20032917]\n",
      "[0.61250097, 0.2, 0.20802028, 0.2003589]\n",
      "[0.6102621, 0.2, 0.20542966, 0.20071095]\n",
      "[0.61372954, 0.2, 0.2092314, 0.20037684]\n",
      "[0.61401844, 0.2, 0.20928589, 0.20061177]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18070 iterations: 4.248821131388346 mins\n",
      "Train Loss: [0.61401844, 0.2, 0.20928589, 0.20061177]\n",
      "[0.60635936, 0.2, 0.20141095, 0.20082809]\n",
      "[0.6107655, 0.2, 0.20619436, 0.2004512]\n",
      "[0.61606705, 0.2, 0.21155436, 0.20039332]\n",
      "[0.61014384, 0.2, 0.20559223, 0.20043314]\n",
      "[0.61617744, 0.2, 0.21126604, 0.20079376]\n",
      "[0.607821, 0.2, 0.20339663, 0.20030724]\n",
      "[0.61074704, 0.2, 0.20584457, 0.20078592]\n",
      "[0.62356234, 0.2, 0.20187652, 0.21756993]\n",
      "[0.6155111, 0.2, 0.2107406, 0.20065546]\n",
      "[0.62272406, 0.2, 0.21813397, 0.20047615]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18080 iterations: 4.2508316000302635 mins\n",
      "Train Loss: [0.62272406, 0.2, 0.21813397, 0.20047615]\n",
      "[0.63811874, 0.2, 0.20402683, 0.22997926]\n",
      "[0.6108274, 0.2, 0.20628189, 0.20043474]\n",
      "[0.61189705, 0.2, 0.20703569, 0.20075192]\n",
      "[0.60634726, 0.2, 0.20153, 0.20070893]\n",
      "[0.6088199, 0.2, 0.20427532, 0.20043698]\n",
      "[0.6141347, 0.2, 0.20958556, 0.20044218]\n",
      "[0.60712636, 0.2, 0.20251526, 0.2005046]\n",
      "[0.608859, 0.2, 0.20370194, 0.20105085]\n",
      "[0.6082218, 0.2, 0.20355722, 0.20055854]\n",
      "[0.6150843, 0.2, 0.2104689, 0.20050961]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18090 iterations: 4.25287758509318 mins\n",
      "Train Loss: [0.6150843, 0.2, 0.2104689, 0.20050961]\n",
      "[0.60991174, 0.2, 0.20524608, 0.20056045]\n",
      "[0.60743016, 0.2, 0.20134911, 0.2019765]\n",
      "[0.60906625, 0.2, 0.20440508, 0.20055723]\n",
      "[0.62339866, 0.2, 0.21812308, 0.20117238]\n",
      "[0.61700094, 0.2, 0.21224982, 0.2006497]\n",
      "[0.6066985, 0.2, 0.20219548, 0.20040305]\n",
      "[0.60811514, 0.2, 0.20360842, 0.20040822]\n",
      "[0.6179026, 0.2, 0.21271418, 0.20109124]\n",
      "[0.60755587, 0.2, 0.20284761, 0.20061202]\n",
      "[0.6104823, 0.2, 0.20569217, 0.20069486]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18100 iterations: 4.254775762557983 mins\n",
      "Train Loss: [0.6104823, 0.2, 0.20569217, 0.20069486]\n",
      "[0.6072696, 0.2, 0.20239212, 0.20078321]\n",
      "[0.60709053, 0.2, 0.20253354, 0.20046374]\n",
      "[0.6118681, 0.2, 0.20703228, 0.20074345]\n",
      "[0.60890096, 0.2, 0.20357478, 0.20123513]\n",
      "[0.60822886, 0.2, 0.20352025, 0.20061858]\n",
      "[0.6128262, 0.2, 0.20833845, 0.20039873]\n",
      "[0.6107976, 0.2, 0.20630692, 0.2004026]\n",
      "[0.62635016, 0.2, 0.20820391, 0.2140592]\n",
      "[0.61252177, 0.2, 0.20791936, 0.20051585]\n",
      "[0.6062332, 0.2, 0.20190242, 0.20024456]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18110 iterations: 4.256803329785665 mins\n",
      "Train Loss: [0.6062332, 0.2, 0.20190242, 0.20024456]\n",
      "[0.6073264, 0.2, 0.20217338, 0.2010672]\n",
      "[0.6096782, 0.2, 0.20463215, 0.20096076]\n",
      "[0.612104, 0.2, 0.20728353, 0.20073566]\n",
      "[0.6066409, 0.2, 0.20204318, 0.2005135]\n",
      "[0.6149332, 0.2, 0.21038182, 0.20046778]\n",
      "[0.61429495, 0.2, 0.2100037, 0.20020844]\n",
      "[0.61397034, 0.2, 0.20965284, 0.20023541]\n",
      "[0.6109272, 0.2, 0.20562021, 0.20122552]\n",
      "[0.61271065, 0.2, 0.20807526, 0.20055439]\n",
      "[0.61097383, 0.2, 0.2044127, 0.20248081]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18120 iterations: 4.258739197254181 mins\n",
      "Train Loss: [0.61097383, 0.2, 0.2044127, 0.20248081]\n",
      "[0.62055427, 0.2, 0.20227158, 0.21420275]\n",
      "[0.61846966, 0.2, 0.21210958, 0.20228027]\n",
      "[0.6077001, 0.2, 0.20300801, 0.20061243]\n",
      "[0.60850424, 0.2, 0.20392445, 0.20050019]\n",
      "[0.61206627, 0.2, 0.2074238, 0.20056306]\n",
      "[0.6216478, 0.2, 0.2064563, 0.21111247]\n",
      "[0.61252636, 0.2, 0.2065134, 0.20193386]\n",
      "[0.61147636, 0.2, 0.20646147, 0.20093553]\n",
      "[0.6061774, 0.2, 0.20132168, 0.20077616]\n",
      "[0.6098274, 0.2, 0.20504223, 0.20070563]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18130 iterations: 4.260829365253448 mins\n",
      "Train Loss: [0.6098274, 0.2, 0.20504223, 0.20070563]\n",
      "[0.61521965, 0.2, 0.21047272, 0.20066741]\n",
      "[0.6074829, 0.2, 0.20276926, 0.20063415]\n",
      "[0.60899997, 0.2, 0.2043108, 0.20060988]\n",
      "[0.61144966, 0.2, 0.20653994, 0.20083076]\n",
      "[0.6117756, 0.2, 0.20703524, 0.20066164]\n",
      "[0.608492, 0.2, 0.2032845, 0.201129]\n",
      "[0.6105161, 0.2, 0.20484784, 0.20158978]\n",
      "[0.6091828, 0.2, 0.20474283, 0.20036162]\n",
      "[0.61508805, 0.2, 0.21042052, 0.20058887]\n",
      "[0.6285826, 0.2, 0.22404294, 0.20046061]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18140 iterations: 4.262792865435283 mins\n",
      "Train Loss: [0.6285826, 0.2, 0.22404294, 0.20046061]\n",
      "[0.6071295, 0.2, 0.20128556, 0.20176409]\n",
      "[0.6097938, 0.2, 0.20525056, 0.20046261]\n",
      "[0.6146518, 0.2, 0.20981197, 0.20075844]\n",
      "[0.6209292, 0.2, 0.21618952, 0.2006575]\n",
      "[0.62385553, 0.2, 0.20685242, 0.21292038]\n",
      "[0.6377848, 0.2, 0.20541096, 0.22829063]\n",
      "[0.62386036, 0.2, 0.2176898, 0.20208737]\n",
      "[0.61093026, 0.2, 0.20636067, 0.2004855]\n",
      "[0.6092559, 0.2, 0.2042483, 0.20092271]\n",
      "[0.64295125, 0.2, 0.20956948, 0.229296]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18150 iterations: 4.265405933062236 mins\n",
      "Train Loss: [0.64295125, 0.2, 0.20956948, 0.229296]\n",
      "[0.62132233, 0.2, 0.21675687, 0.20047899]\n",
      "[0.6339962, 0.2, 0.22965117, 0.20025602]\n",
      "[0.6109988, 0.2, 0.20655708, 0.20035246]\n",
      "[0.6124396, 0.2, 0.2077008, 0.20064785]\n",
      "[0.60895854, 0.2, 0.20454606, 0.20031898]\n",
      "[0.606219, 0.2, 0.20176637, 0.20035584]\n",
      "[0.61547047, 0.2, 0.21087252, 0.20049722]\n",
      "[0.6085962, 0.2, 0.20390996, 0.20058237]\n",
      "[0.6146126, 0.2, 0.20769602, 0.20280811]\n",
      "[0.60902756, 0.2, 0.20302097, 0.20189287]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18160 iterations: 4.267546665668488 mins\n",
      "Train Loss: [0.60902756, 0.2, 0.20302097, 0.20189287]\n",
      "[0.6204471, 0.2, 0.20614937, 0.21017839]\n",
      "[0.6155437, 0.2, 0.21072218, 0.20069572]\n",
      "[0.61703575, 0.2, 0.21120955, 0.20169403]\n",
      "[0.60999316, 0.2, 0.20453115, 0.20132406]\n",
      "[0.6100075, 0.2, 0.2040595, 0.2018048]\n",
      "[0.6751783, 0.2, 0.26850373, 0.20252663]\n",
      "[0.6121859, 0.2, 0.20537013, 0.20266406]\n",
      "[0.61151135, 0.2, 0.20403334, 0.20332292]\n",
      "[0.6140755, 0.2, 0.20751627, 0.20240118]\n",
      "[0.61641496, 0.2, 0.21025372, 0.20200084]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18170 iterations: 4.2695086677869165 mins\n",
      "Train Loss: [0.61641496, 0.2, 0.21025372, 0.20200084]\n",
      "[0.61353844, 0.2, 0.20756812, 0.20180804]\n",
      "[0.61047536, 0.2, 0.20369467, 0.20261694]\n",
      "[0.6131957, 0.2, 0.20575833, 0.2032724]\n",
      "[0.616745, 0.2, 0.2070536, 0.2055256]\n",
      "[0.6129357, 0.2, 0.20808797, 0.20068158]\n",
      "[0.6112631, 0.2, 0.2048146, 0.20228218]\n",
      "[0.61206526, 0.2, 0.20660584, 0.20129327]\n",
      "[0.6607375, 0.2, 0.25350615, 0.20306554]\n",
      "[0.609324, 0.2, 0.20387189, 0.20128214]\n",
      "[0.61240536, 0.2, 0.20714507, 0.20108646]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18180 iterations: 4.271645613511404 mins\n",
      "Train Loss: [0.61240536, 0.2, 0.20714507, 0.20108646]\n",
      "[0.6116392, 0.2, 0.20606157, 0.20140053]\n",
      "[0.60824895, 0.2, 0.20296621, 0.20110284]\n",
      "[0.6195267, 0.2, 0.21358158, 0.20176288]\n",
      "[0.61192834, 0.2, 0.20539936, 0.20234312]\n",
      "[0.60980916, 0.2, 0.2045018, 0.20111789]\n",
      "[0.6409951, 0.2, 0.23476413, 0.2020387]\n",
      "[0.6085525, 0.2, 0.20312619, 0.20123303]\n",
      "[0.6117289, 0.2, 0.20480229, 0.2027324]\n",
      "[0.60877705, 0.2, 0.20311828, 0.2014635]\n",
      "[0.6150952, 0.2, 0.20946456, 0.2014341]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18190 iterations: 4.273577264944712 mins\n",
      "Train Loss: [0.6150952, 0.2, 0.20946456, 0.2014341]\n",
      "[0.61122316, 0.2, 0.20520087, 0.20182478]\n",
      "[0.61256534, 0.2, 0.20608601, 0.20228098]\n",
      "[0.61085296, 0.2, 0.2058033, 0.20085064]\n",
      "[0.61249363, 0.2, 0.20714688, 0.20114727]\n",
      "[0.6189038, 0.2, 0.21395195, 0.20075217]\n",
      "[0.6095376, 0.2, 0.20432279, 0.20101482]\n",
      "[0.6092876, 0.2, 0.20375484, 0.20133252]\n",
      "[0.6079615, 0.2, 0.20262389, 0.20113733]\n",
      "[0.6185155, 0.2, 0.21305218, 0.20126317]\n",
      "[0.6091763, 0.2, 0.20261654, 0.20235997]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18200 iterations: 4.275728436311086 mins\n",
      "Train Loss: [0.6091763, 0.2, 0.20261654, 0.20235997]\n",
      "[0.6258245, 0.2, 0.20865284, 0.21297258]\n",
      "[0.6101766, 0.2, 0.20342943, 0.20254925]\n",
      "[0.6085384, 0.2, 0.20214531, 0.20219614]\n",
      "[0.61495644, 0.2, 0.20797276, 0.20278807]\n",
      "[0.64179283, 0.2, 0.20786893, 0.22972986]\n",
      "[0.60835135, 0.2, 0.20161296, 0.202546]\n",
      "[0.60855633, 0.2, 0.20244826, 0.20191701]\n",
      "[0.61317986, 0.2, 0.20589389, 0.20309567]\n",
      "[0.60925835, 0.2, 0.20326494, 0.201804]\n",
      "[0.60815006, 0.2, 0.20252776, 0.20143363]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18210 iterations: 4.277783981959025 mins\n",
      "Train Loss: [0.60815006, 0.2, 0.20252776, 0.20143363]\n",
      "[0.611473, 0.2, 0.2056721, 0.20161289]\n",
      "[0.64825386, 0.2, 0.24259058, 0.20147601]\n",
      "[0.61282635, 0.2, 0.20596081, 0.20267971]\n",
      "[0.61272806, 0.2, 0.20646042, 0.20208308]\n",
      "[0.6088418, 0.2, 0.20263815, 0.20202036]\n",
      "[0.6091919, 0.2, 0.20358363, 0.20142615]\n",
      "[0.6137614, 0.2, 0.2078387, 0.20174178]\n",
      "[0.60861766, 0.2, 0.20289627, 0.2015419]\n",
      "[0.62549603, 0.2, 0.21880223, 0.20251586]\n",
      "[0.61650723, 0.2, 0.21115822, 0.20117351]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18220 iterations: 4.279645113150279 mins\n",
      "Train Loss: [0.61650723, 0.2, 0.21115822, 0.20117351]\n",
      "[0.60846907, 0.2, 0.20304695, 0.20124881]\n",
      "[0.6108893, 0.2, 0.20517996, 0.20153812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6093795, 0.2, 0.2042942, 0.20091593]\n",
      "[0.61022824, 0.2, 0.20495553, 0.20110525]\n",
      "[0.6171812, 0.2, 0.21155344, 0.20146196]\n",
      "[0.6274783, 0.2, 0.20518346, 0.21813072]\n",
      "[0.6107719, 0.2, 0.20516416, 0.2014455]\n",
      "[0.6102739, 0.2, 0.20509386, 0.20101942]\n",
      "[0.60901076, 0.2, 0.20270054, 0.20215075]\n",
      "[0.6123644, 0.2, 0.20658559, 0.20162062]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18230 iterations: 4.282280067602794 mins\n",
      "Train Loss: [0.6123644, 0.2, 0.20658559, 0.20162062]\n",
      "[0.6125532, 0.2, 0.20672736, 0.20166866]\n",
      "[0.6109774, 0.2, 0.2052723, 0.20154895]\n",
      "[0.6080215, 0.2, 0.20257492, 0.20129116]\n",
      "[0.612645, 0.2, 0.20765941, 0.20083112]\n",
      "[0.61588186, 0.2, 0.21022943, 0.20149893]\n",
      "[0.6091115, 0.2, 0.20296955, 0.20198919]\n",
      "[0.6275841, 0.2, 0.20393588, 0.21949609]\n",
      "[0.6135827, 0.2, 0.20820773, 0.20122352]\n",
      "[0.6113296, 0.2, 0.20579048, 0.20138825]\n",
      "[0.6119777, 0.2, 0.20475921, 0.20306818]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18240 iterations: 4.284218867619832 mins\n",
      "Train Loss: [0.6119777, 0.2, 0.20475921, 0.20306818]\n",
      "[0.6194447, 0.2, 0.2126638, 0.20263115]\n",
      "[0.62333584, 0.2, 0.21808179, 0.20110409]\n",
      "[0.61738515, 0.2, 0.21151662, 0.20171812]\n",
      "[0.6271216, 0.2, 0.20331135, 0.21965942]\n",
      "[0.6097574, 0.2, 0.2041702, 0.20143583]\n",
      "[0.6157616, 0.2, 0.21016572, 0.20144393]\n",
      "[0.614433, 0.2, 0.20958178, 0.2006988]\n",
      "[0.62847537, 0.2, 0.20744477, 0.21687785]\n",
      "[0.60822684, 0.2, 0.20162961, 0.20244406]\n",
      "[0.63321406, 0.2, 0.21603917, 0.21302149]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18250 iterations: 4.286297365029653 mins\n",
      "Train Loss: [0.63321406, 0.2, 0.21603917, 0.21302149]\n",
      "[0.64160025, 0.2, 0.20566277, 0.2317837]\n",
      "[0.6099388, 0.2, 0.20440155, 0.20138288]\n",
      "[0.608781, 0.2, 0.20336926, 0.20125678]\n",
      "[0.6146025, 0.2, 0.20954892, 0.20089824]\n",
      "[0.6060684, 0.2, 0.20128404, 0.20062868]\n",
      "[0.6098584, 0.2, 0.20437604, 0.20132664]\n",
      "[0.61069345, 0.2, 0.2053729, 0.20116472]\n",
      "[0.60714406, 0.2, 0.20142584, 0.20156248]\n",
      "[0.6095698, 0.2, 0.20365122, 0.20176303]\n",
      "[0.61382216, 0.2, 0.2059769, 0.20369]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18260 iterations: 4.288466763496399 mins\n",
      "Train Loss: [0.61382216, 0.2, 0.2059769, 0.20369]\n",
      "[0.61059207, 0.2, 0.20456825, 0.2018689]\n",
      "[0.6273519, 0.2, 0.22124192, 0.20195541]\n",
      "[0.61090046, 0.2, 0.20426579, 0.20248021]\n",
      "[0.6089785, 0.2, 0.20364149, 0.20118266]\n",
      "[0.6071548, 0.2, 0.2023355, 0.20066506]\n",
      "[0.6117026, 0.2, 0.20539926, 0.2021493]\n",
      "[0.61560756, 0.2, 0.20977405, 0.20167981]\n",
      "[0.61708117, 0.2, 0.20687126, 0.20605667]\n",
      "[0.6103373, 0.2, 0.20352882, 0.2026558]\n",
      "[0.6109825, 0.2, 0.20550278, 0.2013275]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18270 iterations: 4.290364682674408 mins\n",
      "Train Loss: [0.6109825, 0.2, 0.20550278, 0.2013275]\n",
      "[0.60994184, 0.2, 0.20490022, 0.2008902]\n",
      "[0.6061178, 0.2, 0.20128234, 0.20068473]\n",
      "[0.61154, 0.2, 0.20612077, 0.20126933]\n",
      "[0.6068502, 0.2, 0.20134278, 0.20135857]\n",
      "[0.6092749, 0.2, 0.20369522, 0.20143192]\n",
      "[0.61635685, 0.2, 0.21083288, 0.20137732]\n",
      "[0.6126414, 0.2, 0.20632748, 0.20216846]\n",
      "[0.61851674, 0.2, 0.20550407, 0.20886824]\n",
      "[0.6090679, 0.2, 0.20367184, 0.2012527]\n",
      "[0.6298203, 0.2, 0.20217, 0.22350821]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18280 iterations: 4.292384433746338 mins\n",
      "Train Loss: [0.6298203, 0.2, 0.20217, 0.22350821]\n",
      "[0.6090301, 0.2, 0.2037624, 0.20112687]\n",
      "[0.61523545, 0.2, 0.20972699, 0.20136862]\n",
      "[0.61204857, 0.2, 0.20718937, 0.20072053]\n",
      "[0.609414, 0.2, 0.20438524, 0.20089118]\n",
      "[0.6122223, 0.2, 0.20595878, 0.2021269]\n",
      "[0.6124899, 0.2, 0.2062678, 0.20208609]\n",
      "[0.60651284, 0.2, 0.20189019, 0.20048726]\n",
      "[0.6166976, 0.2, 0.21154316, 0.20101938]\n",
      "[0.6133518, 0.2, 0.20795809, 0.20126036]\n",
      "[0.6232707, 0.2, 0.20261161, 0.21652739]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18290 iterations: 4.294200348854065 mins\n",
      "Train Loss: [0.6232707, 0.2, 0.20261161, 0.21652739]\n",
      "[0.60998315, 0.2, 0.20460305, 0.20125009]\n",
      "[0.6077147, 0.2, 0.20267385, 0.20091215]\n",
      "[0.60977536, 0.2, 0.20421576, 0.20143187]\n",
      "[0.6100697, 0.2, 0.20458293, 0.20135984]\n",
      "[0.60819674, 0.2, 0.2033573, 0.20071322]\n",
      "[0.62504274, 0.2, 0.2048103, 0.21610674]\n",
      "[0.61318874, 0.2, 0.20803264, 0.20103103]\n",
      "[0.6113966, 0.2, 0.20466664, 0.2026052]\n",
      "[0.6100208, 0.2, 0.20388694, 0.20200929]\n",
      "[0.6088231, 0.2, 0.20339568, 0.20130298]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18300 iterations: 4.296223735809326 mins\n",
      "Train Loss: [0.6088231, 0.2, 0.20339568, 0.20130298]\n",
      "[0.6072223, 0.2, 0.20132072, 0.20177734]\n",
      "[0.6139389, 0.2, 0.20840415, 0.20141071]\n",
      "[0.61607176, 0.2, 0.20984457, 0.20210329]\n",
      "[0.61543834, 0.2, 0.21017091, 0.20114368]\n",
      "[0.609005, 0.2, 0.2034802, 0.2014009]\n",
      "[0.6132332, 0.2, 0.20778713, 0.20132221]\n",
      "[0.63647383, 0.2, 0.21128137, 0.22106847]\n",
      "[0.6222734, 0.2, 0.21675204, 0.20139697]\n",
      "[0.6159892, 0.2, 0.20997663, 0.20188776]\n",
      "[0.61222935, 0.2, 0.205048, 0.20305616]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18310 iterations: 4.298923635482788 mins\n",
      "Train Loss: [0.61222935, 0.2, 0.205048, 0.20305616]\n",
      "[0.6193211, 0.2, 0.21324657, 0.20194915]\n",
      "[0.63000816, 0.2, 0.22493291, 0.2009497]\n",
      "[0.613079, 0.2, 0.2060748, 0.20287743]\n",
      "[0.6111571, 0.2, 0.20309158, 0.20393768]\n",
      "[0.6104438, 0.2, 0.20494263, 0.20137218]\n",
      "[0.60964674, 0.2, 0.20473163, 0.20078504]\n",
      "[0.6268088, 0.2, 0.20316854, 0.21950921]\n",
      "[0.61795473, 0.2, 0.21265465, 0.20116857]\n",
      "[0.6065807, 0.2, 0.20148692, 0.20096147]\n",
      "[0.6142511, 0.2, 0.2088037, 0.20131437]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18320 iterations: 4.300851897398631 mins\n",
      "Train Loss: [0.6142511, 0.2, 0.2088037, 0.20131437]\n",
      "[0.61121744, 0.2, 0.20587273, 0.20121114]\n",
      "[0.6109915, 0.2, 0.2049464, 0.201911]\n",
      "[0.61243147, 0.2, 0.20312262, 0.20517448]\n",
      "[0.61472434, 0.2, 0.20797767, 0.20261206]\n",
      "[0.6154709, 0.2, 0.21056211, 0.20077415]\n",
      "[0.6085408, 0.2, 0.20343995, 0.20096631]\n",
      "[0.6116883, 0.2, 0.20608515, 0.20146872]\n",
      "[0.60903835, 0.2, 0.20268449, 0.2022194]\n",
      "[0.61023647, 0.2, 0.20465128, 0.201451]\n",
      "[0.61027765, 0.2, 0.20488077, 0.20126314]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18330 iterations: 4.303010201454162 mins\n",
      "Train Loss: [0.61027765, 0.2, 0.20488077, 0.20126314]\n",
      "[0.61059815, 0.2, 0.20499064, 0.20147416]\n",
      "[0.608756, 0.2, 0.20342694, 0.20119621]\n",
      "[0.62345415, 0.2, 0.20269929, 0.21662255]\n",
      "[0.61041653, 0.2, 0.2050701, 0.20121448]\n",
      "[0.6114848, 0.2, 0.20457107, 0.20278214]\n",
      "[0.60761875, 0.2, 0.20254004, 0.20094761]\n",
      "[0.61136127, 0.2, 0.20525888, 0.20197184]\n",
      "[0.60623366, 0.2, 0.20159951, 0.20050429]\n",
      "[0.60820156, 0.2, 0.20302002, 0.20105241]\n",
      "[0.61184436, 0.2, 0.20718943, 0.20052668]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18340 iterations: 4.304928664366404 mins\n",
      "Train Loss: [0.61184436, 0.2, 0.20718943, 0.20052668]\n",
      "[0.60868454, 0.2, 0.20386079, 0.20069622]\n",
      "[0.60835886, 0.2, 0.2034637, 0.20076843]\n",
      "[0.62598807, 0.2, 0.20492871, 0.21693338]\n",
      "[0.60652304, 0.2, 0.20107295, 0.20132457]\n",
      "[0.6108303, 0.2, 0.20591986, 0.20078538]\n",
      "[0.6090988, 0.2, 0.20395374, 0.20102036]\n",
      "[0.61009216, 0.2, 0.2047151, 0.2012527]\n",
      "[0.61059904, 0.2, 0.20555085, 0.20092404]\n",
      "[0.6081779, 0.2, 0.20294605, 0.20110801]\n",
      "[0.60602, 0.2, 0.20082517, 0.20107162]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18350 iterations: 4.307033916314443 mins\n",
      "Train Loss: [0.60602, 0.2, 0.20082517, 0.20107162]\n",
      "[0.6139003, 0.2, 0.20822595, 0.20155197]\n",
      "[0.6098595, 0.2, 0.20483401, 0.200904]\n",
      "[0.6103151, 0.2, 0.20537695, 0.20081767]\n",
      "[0.6101394, 0.2, 0.20478967, 0.20123045]\n",
      "[0.62509483, 0.2, 0.21995305, 0.20102353]\n",
      "[0.6095271, 0.2, 0.20513506, 0.20027293]\n",
      "[0.6095192, 0.2, 0.20363995, 0.2017597]\n",
      "[0.61304504, 0.2, 0.2045967, 0.20432864]\n",
      "[0.6087057, 0.2, 0.20314224, 0.20144378]\n",
      "[0.62926894, 0.2, 0.20275521, 0.22239415]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18360 iterations: 4.309006714820862 mins\n",
      "Train Loss: [0.62926894, 0.2, 0.20275521, 0.22239415]\n",
      "[0.6086921, 0.2, 0.20393828, 0.20063452]\n",
      "[0.6086252, 0.2, 0.20340747, 0.2010987]\n",
      "[0.6097856, 0.2, 0.20384891, 0.20181796]\n",
      "[0.60933536, 0.2, 0.20437056, 0.2008465]\n",
      "[0.6312752, 0.2, 0.20486237, 0.222295]\n",
      "[0.61166185, 0.2, 0.2064747, 0.20106985]\n",
      "[0.6170769, 0.2, 0.20287831, 0.21008183]\n",
      "[0.6101455, 0.2, 0.20460221, 0.20142744]\n",
      "[0.61113656, 0.2, 0.20428419, 0.20273732]\n",
      "[0.6104236, 0.2, 0.20494813, 0.20136105]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18370 iterations: 4.311054380734761 mins\n",
      "Train Loss: [0.6104236, 0.2, 0.20494813, 0.20136105]\n",
      "[0.6094993, 0.2, 0.20376481, 0.20162041]\n",
      "[0.6101656, 0.2, 0.2038357, 0.20221627]\n",
      "[0.6066079, 0.2, 0.20147036, 0.20102446]\n",
      "[0.6137073, 0.2, 0.20774822, 0.20184654]\n",
      "[0.62774193, 0.2, 0.20520192, 0.21842813]\n",
      "[0.60774314, 0.2, 0.20220377, 0.20142773]\n",
      "[0.61528313, 0.2, 0.21030001, 0.20087181]\n",
      "[0.6363397, 0.2, 0.2052249, 0.22700378]\n",
      "[0.6069322, 0.2, 0.2013551, 0.20146641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61302626, 0.2, 0.20540257, 0.20351326]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18380 iterations: 4.312893784046173 mins\n",
      "Train Loss: [0.61302626, 0.2, 0.20540257, 0.20351326]\n",
      "[0.6095337, 0.2, 0.20427707, 0.20114665]\n",
      "[0.611524, 0.2, 0.20555806, 0.20185663]\n",
      "[0.6122293, 0.2, 0.20712782, 0.20099266]\n",
      "[0.61124915, 0.2, 0.20624033, 0.20090073]\n",
      "[0.6175106, 0.2, 0.21095878, 0.20244442]\n",
      "[0.6095719, 0.2, 0.20287538, 0.20258974]\n",
      "[0.61163664, 0.2, 0.20622191, 0.2013088]\n",
      "[0.6101009, 0.2, 0.20492269, 0.20107317]\n",
      "[0.61274767, 0.2, 0.20741692, 0.20122652]\n",
      "[0.61349356, 0.2, 0.2069003, 0.20248987]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18390 iterations: 4.315485898653666 mins\n",
      "Train Loss: [0.61349356, 0.2, 0.2069003, 0.20248987]\n",
      "[0.6083863, 0.2, 0.20305045, 0.20123333]\n",
      "[0.61473405, 0.2, 0.20846213, 0.20217033]\n",
      "[0.6121075, 0.2, 0.20686698, 0.20114]\n",
      "[0.6111541, 0.2, 0.20604435, 0.20100999]\n",
      "[0.6153084, 0.2, 0.21006303, 0.20114626]\n",
      "[0.6074116, 0.2, 0.20174572, 0.20156728]\n",
      "[0.61355495, 0.2, 0.20834278, 0.20111397]\n",
      "[0.61514324, 0.2, 0.21039815, 0.20064723]\n",
      "[0.6161481, 0.2, 0.21104172, 0.20100869]\n",
      "[0.6061163, 0.2, 0.2014302, 0.20058846]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18400 iterations: 4.317771331469218 mins\n",
      "Train Loss: [0.6061163, 0.2, 0.2014302, 0.20058846]\n",
      "[0.6145561, 0.2, 0.20967123, 0.20078725]\n",
      "[0.608579, 0.2, 0.20367838, 0.20080322]\n",
      "[0.613342, 0.2, 0.20816036, 0.2010845]\n",
      "[0.6078493, 0.2, 0.20287403, 0.20087841]\n",
      "[0.6089011, 0.2, 0.20317166, 0.20163296]\n",
      "[0.6229743, 0.2, 0.20866476, 0.2102134]\n",
      "[0.6075856, 0.2, 0.20190057, 0.20158964]\n",
      "[0.6079385, 0.2, 0.2033582, 0.20048554]\n",
      "[0.6093329, 0.2, 0.20492427, 0.20031428]\n",
      "[0.6136016, 0.2, 0.20834114, 0.20116648]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18410 iterations: 4.321515802542368 mins\n",
      "Train Loss: [0.6136016, 0.2, 0.20834114, 0.20116648]\n",
      "[0.6137688, 0.2, 0.20934495, 0.20033027]\n",
      "[0.60963935, 0.2, 0.204039, 0.20150709]\n",
      "[0.61305547, 0.2, 0.20726518, 0.20169747]\n",
      "[0.61257017, 0.2, 0.20713845, 0.2013394]\n",
      "[0.6103295, 0.2, 0.20469879, 0.20153904]\n",
      "[0.6085686, 0.2, 0.20382814, 0.20064938]\n",
      "[0.6097849, 0.2, 0.20522127, 0.20047313]\n",
      "[0.60955137, 0.2, 0.20492132, 0.2005402]\n",
      "[0.6094318, 0.2, 0.2044984, 0.20084397]\n",
      "[0.60730577, 0.2, 0.20267753, 0.2005396]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18420 iterations: 4.32411226828893 mins\n",
      "Train Loss: [0.60730577, 0.2, 0.20267753, 0.2005396]\n",
      "[0.6111111, 0.2, 0.2058763, 0.20114687]\n",
      "[0.6135515, 0.2, 0.20782109, 0.20164302]\n",
      "[0.61160964, 0.2, 0.20663312, 0.20088977]\n",
      "[0.61058784, 0.2, 0.20548521, 0.20101647]\n",
      "[0.6078421, 0.2, 0.20141779, 0.20233881]\n",
      "[0.6135194, 0.2, 0.20864186, 0.20079269]\n",
      "[0.6125132, 0.2, 0.20722425, 0.20120473]\n",
      "[0.608507, 0.2, 0.2032602, 0.20116301]\n",
      "[0.60943484, 0.2, 0.2042522, 0.2010993]\n",
      "[0.6137261, 0.2, 0.2084531, 0.20119035]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18430 iterations: 4.326886932055156 mins\n",
      "Train Loss: [0.6137261, 0.2, 0.2084531, 0.20119035]\n",
      "[0.6120868, 0.2, 0.20702186, 0.20098288]\n",
      "[0.6131038, 0.2, 0.20819879, 0.20082363]\n",
      "[0.60862637, 0.2, 0.20391963, 0.20062588]\n",
      "[0.6082851, 0.2, 0.20295474, 0.20125006]\n",
      "[0.6110297, 0.2, 0.20555042, 0.20139962]\n",
      "[0.60727465, 0.2, 0.20214838, 0.20104755]\n",
      "[0.6093518, 0.2, 0.20393018, 0.20134374]\n",
      "[0.6069465, 0.2, 0.20215632, 0.20071329]\n",
      "[0.60915864, 0.2, 0.2040226, 0.20106007]\n",
      "[0.6067045, 0.2, 0.20128933, 0.20134]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18440 iterations: 4.32946871916453 mins\n",
      "Train Loss: [0.6067045, 0.2, 0.20128933, 0.20134]\n",
      "[0.6070314, 0.2, 0.2020589, 0.20089822]\n",
      "[0.6088453, 0.2, 0.20368333, 0.20108852]\n",
      "[0.60982424, 0.2, 0.20448087, 0.20127068]\n",
      "[0.6085009, 0.2, 0.20362711, 0.20080192]\n",
      "[0.607955, 0.2, 0.20289114, 0.20099275]\n",
      "[0.60797924, 0.2, 0.20318921, 0.2007197]\n",
      "[0.60816836, 0.2, 0.20280643, 0.20129229]\n",
      "[0.6081875, 0.2, 0.20327388, 0.20084466]\n",
      "[0.6086468, 0.2, 0.20309302, 0.20148534]\n",
      "[0.6155232, 0.2, 0.20863271, 0.20282263]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18450 iterations: 4.331467433770498 mins\n",
      "Train Loss: [0.6155232, 0.2, 0.20863271, 0.20282263]\n",
      "[0.62364554, 0.2, 0.21781056, 0.20176773]\n",
      "[0.6104083, 0.2, 0.20477673, 0.20156586]\n",
      "[0.6097894, 0.2, 0.20324856, 0.20247707]\n",
      "[0.6057701, 0.2, 0.20103776, 0.20067024]\n",
      "[0.60825974, 0.2, 0.20301932, 0.20117989]\n",
      "[0.6058944, 0.2, 0.20124432, 0.20059091]\n",
      "[0.6088886, 0.2, 0.20393778, 0.20089303]\n",
      "[0.6113269, 0.2, 0.2059956, 0.2012746]\n",
      "[0.6092161, 0.2, 0.20403427, 0.20112637]\n",
      "[0.60636497, 0.2, 0.20122308, 0.2010874]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18460 iterations: 4.333647414048513 mins\n",
      "Train Loss: [0.60636497, 0.2, 0.20122308, 0.2010874]\n",
      "[0.61232626, 0.2, 0.2074391, 0.20083374]\n",
      "[0.6252658, 0.2, 0.21993038, 0.20128301]\n",
      "[0.61505294, 0.2, 0.21003945, 0.20095903]\n",
      "[0.6084209, 0.2, 0.20368604, 0.20067838]\n",
      "[0.60680765, 0.2, 0.20231771, 0.2004314]\n",
      "[0.60950345, 0.2, 0.20494172, 0.2005014]\n",
      "[0.6108076, 0.2, 0.20500378, 0.20174177]\n",
      "[0.61769944, 0.2, 0.21122153, 0.20241445]\n",
      "[0.60858023, 0.2, 0.20266983, 0.20184605]\n",
      "[0.6121398, 0.2, 0.20470251, 0.2033719]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18470 iterations: 4.336748782793681 mins\n",
      "Train Loss: [0.6121398, 0.2, 0.20470251, 0.2033719]\n",
      "[0.609213, 0.2, 0.20476523, 0.20038138]\n",
      "[0.6062431, 0.2, 0.20173061, 0.20044518]\n",
      "[0.6101612, 0.2, 0.20426041, 0.2018327]\n",
      "[0.61163765, 0.2, 0.20544478, 0.20212401]\n",
      "[0.6110148, 0.2, 0.205751, 0.20119429]\n",
      "[0.61637163, 0.2, 0.21109666, 0.201205]\n",
      "[0.6096732, 0.2, 0.20280373, 0.202799]\n",
      "[0.6307343, 0.2, 0.22564246, 0.20102106]\n",
      "[0.6122065, 0.2, 0.20731875, 0.20081611]\n",
      "[0.6068827, 0.2, 0.20189533, 0.20091496]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18480 iterations: 4.338853549957276 mins\n",
      "Train Loss: [0.6068827, 0.2, 0.20189533, 0.20091496]\n",
      "[0.6101978, 0.2, 0.20330039, 0.2028245]\n",
      "[0.60745454, 0.2, 0.20284191, 0.20053954]\n",
      "[0.61433154, 0.2, 0.20793533, 0.20232302]\n",
      "[0.677242, 0.2, 0.27113208, 0.20203666]\n",
      "[0.6072975, 0.2, 0.20234938, 0.20087253]\n",
      "[0.6107097, 0.2, 0.20538303, 0.20124911]\n",
      "[0.6347426, 0.2, 0.22977373, 0.20088927]\n",
      "[0.6072245, 0.2, 0.20256, 0.20058121]\n",
      "[0.6111645, 0.2, 0.2061883, 0.20088947]\n",
      "[0.6112815, 0.2, 0.20634417, 0.20084774]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18490 iterations: 4.341360032558441 mins\n",
      "Train Loss: [0.6112815, 0.2, 0.20634417, 0.20084774]\n",
      "[0.60766214, 0.2, 0.20273495, 0.20083517]\n",
      "[0.606933, 0.2, 0.2017916, 0.20104723]\n",
      "[0.6151934, 0.2, 0.21063891, 0.20045847]\n",
      "[0.6120265, 0.2, 0.20560639, 0.20232242]\n",
      "[0.61113876, 0.2, 0.2063484, 0.20069122]\n",
      "[0.6094261, 0.2, 0.2037838, 0.20154203]\n",
      "[0.60862404, 0.2, 0.20395914, 0.20056348]\n",
      "[0.6076651, 0.2, 0.20273045, 0.20083238]\n",
      "[0.60848373, 0.2, 0.20375124, 0.20062967]\n",
      "[0.6083413, 0.2, 0.20371379, 0.20052433]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18500 iterations: 4.343554282188416 mins\n",
      "Train Loss: [0.6083413, 0.2, 0.20371379, 0.20052433]\n",
      "[0.60553366, 0.2, 0.20106007, 0.20037022]\n",
      "[0.6155555, 0.2, 0.21027035, 0.20118168]\n",
      "[0.607313, 0.2, 0.20240925, 0.20080015]\n",
      "[0.6077628, 0.2, 0.20316464, 0.2004948]\n",
      "[0.6085333, 0.2, 0.20338419, 0.201046]\n",
      "[0.6090927, 0.2, 0.20448232, 0.20050758]\n",
      "[0.61417955, 0.2, 0.20970471, 0.20037244]\n",
      "[0.60847014, 0.2, 0.20366499, 0.20070317]\n",
      "[0.6139257, 0.2, 0.2088173, 0.20100708]\n",
      "[0.6082898, 0.2, 0.20344909, 0.20073996]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18510 iterations: 4.3453971664110815 mins\n",
      "Train Loss: [0.6082898, 0.2, 0.20344909, 0.20073996]\n",
      "[0.60953206, 0.2, 0.20479913, 0.20063284]\n",
      "[0.60825205, 0.2, 0.20363526, 0.2005174]\n",
      "[0.6092667, 0.2, 0.20474495, 0.200423]\n",
      "[0.6102206, 0.2, 0.20486349, 0.20125903]\n",
      "[0.6109001, 0.2, 0.20618401, 0.20061871]\n",
      "[0.61066836, 0.2, 0.20538177, 0.2011899]\n",
      "[0.60721976, 0.2, 0.20229778, 0.20082606]\n",
      "[0.62909925, 0.2, 0.2026667, 0.22233742]\n",
      "[0.610565, 0.2, 0.20612164, 0.20034875]\n",
      "[0.6079419, 0.2, 0.20349014, 0.20035759]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18520 iterations: 4.347457563877105 mins\n",
      "Train Loss: [0.6079419, 0.2, 0.20349014, 0.20035759]\n",
      "[0.61190355, 0.2, 0.2069991, 0.20081052]\n",
      "[0.6085265, 0.2, 0.20404519, 0.20038776]\n",
      "[0.6094622, 0.2, 0.20297141, 0.2023975]\n",
      "[0.61005723, 0.2, 0.20555182, 0.2004119]\n",
      "[0.6086711, 0.2, 0.20402445, 0.20055306]\n",
      "[0.6080625, 0.2, 0.20322524, 0.20074373]\n",
      "[0.60844827, 0.2, 0.20284584, 0.20150912]\n",
      "[0.6093489, 0.2, 0.20472425, 0.20053169]\n",
      "[0.6177931, 0.2, 0.21304591, 0.2006549]\n",
      "[0.6078682, 0.2, 0.20296639, 0.20081142]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18530 iterations: 4.350279664993286 mins\n",
      "Train Loss: [0.6078682, 0.2, 0.20296639, 0.20081142]\n",
      "[0.62124467, 0.2, 0.2165607, 0.20059526]\n",
      "[0.61412483, 0.2, 0.20900239, 0.20103525]\n",
      "[0.6099821, 0.2, 0.20524724, 0.20064874]\n",
      "[0.61121076, 0.2, 0.20567207, 0.20145358]\n",
      "[0.60740626, 0.2, 0.20290631, 0.20041586]\n",
      "[0.60842144, 0.2, 0.20365989, 0.20067853]\n",
      "[0.6145658, 0.2, 0.20988864, 0.20059514]\n",
      "[0.60772604, 0.2, 0.20200238, 0.2016426]\n",
      "[0.6128138, 0.2, 0.20721304, 0.20152056]\n",
      "[0.60662115, 0.2, 0.20198461, 0.2005571]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18540 iterations: 4.35224369764328 mins\n",
      "Train Loss: [0.60662115, 0.2, 0.20198461, 0.2005571]\n",
      "[0.6071416, 0.2, 0.20237564, 0.20068745]\n",
      "[0.6101468, 0.2, 0.20535034, 0.2007188]\n",
      "[0.6103659, 0.2, 0.2059748, 0.20031443]\n",
      "[0.6079594, 0.2, 0.20249367, 0.20139001]\n",
      "[0.62849003, 0.2, 0.2087987, 0.21561658]\n",
      "[0.60888386, 0.2, 0.20435335, 0.2004558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61025244, 0.2, 0.20578337, 0.20039423]\n",
      "[0.6093817, 0.2, 0.20466276, 0.20064372]\n",
      "[0.60758346, 0.2, 0.20284992, 0.20065823]\n",
      "[0.61021465, 0.2, 0.20564224, 0.20049693]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18550 iterations: 4.354438781738281 mins\n",
      "Train Loss: [0.61021465, 0.2, 0.20564224, 0.20049693]\n",
      "[0.6116311, 0.2, 0.20703101, 0.20052473]\n",
      "[0.60985845, 0.2, 0.20548345, 0.20029967]\n",
      "[0.60731685, 0.2, 0.20255305, 0.20068869]\n",
      "[0.6129106, 0.2, 0.20842342, 0.20041232]\n",
      "[0.61261314, 0.2, 0.20774543, 0.20079356]\n",
      "[0.6094917, 0.2, 0.20426902, 0.20114897]\n",
      "[0.60956717, 0.2, 0.2047406, 0.20075357]\n",
      "[0.61042655, 0.2, 0.20561384, 0.20074037]\n",
      "[0.60652184, 0.2, 0.20207347, 0.20037676]\n",
      "[0.6115703, 0.2, 0.2069156, 0.20058388]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18560 iterations: 4.3563942313194275 mins\n",
      "Train Loss: [0.6115703, 0.2, 0.2069156, 0.20058388]\n",
      "[0.60721797, 0.2, 0.20240857, 0.2007397]\n",
      "[0.60874987, 0.2, 0.2040746, 0.20060672]\n",
      "[0.6056206, 0.2, 0.20084645, 0.2007065]\n",
      "[0.61014783, 0.2, 0.20537832, 0.20070279]\n",
      "[0.6127441, 0.2, 0.20835985, 0.2003188]\n",
      "[0.6072924, 0.2, 0.20272319, 0.20050569]\n",
      "[0.60864365, 0.2, 0.20384304, 0.2007387]\n",
      "[0.617441, 0.2, 0.2123077, 0.20107296]\n",
      "[0.6056193, 0.2, 0.20081015, 0.20074974]\n",
      "[0.6102729, 0.2, 0.20544584, 0.20076856]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18570 iterations: 4.358540650208791 mins\n",
      "Train Loss: [0.6102729, 0.2, 0.20544584, 0.20076856]\n",
      "[0.60931677, 0.2, 0.20493236, 0.20032685]\n",
      "[0.60789806, 0.2, 0.2032462, 0.20059523]\n",
      "[0.6088395, 0.2, 0.20410636, 0.20067747]\n",
      "[0.61022365, 0.2, 0.20488437, 0.2012845]\n",
      "[0.6297672, 0.2, 0.2248989, 0.20081456]\n",
      "[0.6147994, 0.2, 0.21033753, 0.20040767]\n",
      "[0.62333, 0.2, 0.20616892, 0.21310645]\n",
      "[0.6094159, 0.2, 0.20447831, 0.20088221]\n",
      "[0.6084331, 0.2, 0.20399697, 0.20038]\n",
      "[0.6129096, 0.2, 0.20845692, 0.20039593]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18580 iterations: 4.360360383987427 mins\n",
      "Train Loss: [0.6129096, 0.2, 0.20845692, 0.20039593]\n",
      "[0.61100465, 0.2, 0.2064565, 0.20049065]\n",
      "[0.60968655, 0.2, 0.20517814, 0.20045035]\n",
      "[0.6096796, 0.2, 0.20495752, 0.20066334]\n",
      "[0.60705566, 0.2, 0.20219289, 0.2008034]\n",
      "[0.6145046, 0.2, 0.20997413, 0.20047054]\n",
      "[0.61082923, 0.2, 0.20609213, 0.20067666]\n",
      "[0.6151083, 0.2, 0.2106975, 0.20034999]\n",
      "[0.61086655, 0.2, 0.20626734, 0.20053816]\n",
      "[0.6089794, 0.2, 0.20377147, 0.20114693]\n",
      "[0.6078099, 0.2, 0.20291919, 0.20082968]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18590 iterations: 4.362680451075236 mins\n",
      "Train Loss: [0.6078099, 0.2, 0.20291919, 0.20082968]\n",
      "[0.60697454, 0.2, 0.2020424, 0.20087127]\n",
      "[0.6094061, 0.2, 0.20457397, 0.20077154]\n",
      "[0.60814345, 0.2, 0.20316824, 0.20091492]\n",
      "[0.61270267, 0.2, 0.20784882, 0.200794]\n",
      "[0.6138986, 0.2, 0.20874757, 0.20109165]\n",
      "[0.6136988, 0.2, 0.20867023, 0.20096977]\n",
      "[0.6089556, 0.2, 0.20353903, 0.20135847]\n",
      "[0.6071735, 0.2, 0.2026171, 0.20049888]\n",
      "[0.6093335, 0.2, 0.20485213, 0.20042443]\n",
      "[0.61125827, 0.2, 0.20647438, 0.20072733]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18600 iterations: 4.364812501271566 mins\n",
      "Train Loss: [0.61125827, 0.2, 0.20647438, 0.20072733]\n",
      "[0.61313707, 0.2, 0.20684426, 0.20223662]\n",
      "[0.60834986, 0.2, 0.20390052, 0.20039386]\n",
      "[0.60852104, 0.2, 0.20364857, 0.20081772]\n",
      "[0.60880756, 0.2, 0.20425202, 0.20050146]\n",
      "[0.61035955, 0.2, 0.20565714, 0.20064917]\n",
      "[0.6102806, 0.2, 0.20501368, 0.20121443]\n",
      "[0.6195168, 0.2, 0.21479766, 0.20066746]\n",
      "[0.6076634, 0.2, 0.20301887, 0.20059371]\n",
      "[0.6098912, 0.2, 0.20465274, 0.20118861]\n",
      "[0.60844576, 0.2, 0.20416869, 0.20022807]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18610 iterations: 4.366751432418823 mins\n",
      "Train Loss: [0.60844576, 0.2, 0.20416869, 0.20022807]\n",
      "[0.60940176, 0.2, 0.20502928, 0.20032439]\n",
      "[0.6211707, 0.2, 0.20398116, 0.21314244]\n",
      "[0.6085095, 0.2, 0.20399404, 0.20046842]\n",
      "[0.6140447, 0.2, 0.2094105, 0.20058717]\n",
      "[0.6078444, 0.2, 0.2030915, 0.20070589]\n",
      "[0.6086364, 0.2, 0.20409161, 0.20049787]\n",
      "[0.6175492, 0.2, 0.21276203, 0.20074035]\n",
      "[0.6089036, 0.2, 0.20395905, 0.20089811]\n",
      "[0.6104051, 0.2, 0.20576778, 0.20059109]\n",
      "[0.6108829, 0.2, 0.20638588, 0.20045063]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18620 iterations: 4.368868700663248 mins\n",
      "Train Loss: [0.6108829, 0.2, 0.20638588, 0.20045063]\n",
      "[0.6116115, 0.2, 0.20718205, 0.20038283]\n",
      "[0.6232569, 0.2, 0.20383568, 0.21537371]\n",
      "[0.64563376, 0.2, 0.20436712, 0.23721649]\n",
      "[0.6145774, 0.2, 0.21003446, 0.20049103]\n",
      "[0.612963, 0.2, 0.20828466, 0.20062362]\n",
      "[0.60994214, 0.2, 0.2055001, 0.20038408]\n",
      "[0.6127529, 0.2, 0.20814666, 0.20054497]\n",
      "[0.6065594, 0.2, 0.20211534, 0.20037943]\n",
      "[0.60779244, 0.2, 0.20306425, 0.20066045]\n",
      "[0.60926116, 0.2, 0.204846, 0.20034474]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18630 iterations: 4.370726581414541 mins\n",
      "Train Loss: [0.60926116, 0.2, 0.204846, 0.20034474]\n",
      "[0.6126292, 0.2, 0.20786674, 0.20068996]\n",
      "[0.6067953, 0.2, 0.20227619, 0.20044488]\n",
      "[0.6109108, 0.2, 0.20650655, 0.20032872]\n",
      "[0.61568093, 0.2, 0.21027927, 0.2013253]\n",
      "[0.6125391, 0.2, 0.2080645, 0.20039788]\n",
      "[0.6093348, 0.2, 0.20480838, 0.2004496]\n",
      "[0.60999715, 0.2, 0.20462292, 0.2012976]\n",
      "[0.6060462, 0.2, 0.20117974, 0.20079038]\n",
      "[0.61473674, 0.2, 0.20984308, 0.20081823]\n",
      "[0.60920626, 0.2, 0.20385885, 0.20127304]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18640 iterations: 4.372853366533915 mins\n",
      "Train Loss: [0.60920626, 0.2, 0.20385885, 0.20127304]\n",
      "[0.6059753, 0.2, 0.2015167, 0.20038517]\n",
      "[0.60925055, 0.2, 0.20388114, 0.20129713]\n",
      "[0.6148842, 0.2, 0.20972258, 0.20109051]\n",
      "[0.61371833, 0.2, 0.20871921, 0.20092933]\n",
      "[0.6082903, 0.2, 0.2028104, 0.20141141]\n",
      "[0.6091767, 0.2, 0.20467013, 0.20043947]\n",
      "[0.61002445, 0.2, 0.20460436, 0.20135452]\n",
      "[0.60657537, 0.2, 0.20185, 0.20066132]\n",
      "[0.60900784, 0.2, 0.20444307, 0.20050217]\n",
      "[0.61593163, 0.2, 0.21123068, 0.20063981]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18650 iterations: 4.374721999963125 mins\n",
      "Train Loss: [0.61593163, 0.2, 0.21123068, 0.20063981]\n",
      "[0.6126655, 0.2, 0.20750876, 0.20109712]\n",
      "[0.6070725, 0.2, 0.20256455, 0.2004497]\n",
      "[0.60886973, 0.2, 0.20419337, 0.2006195]\n",
      "[0.60822487, 0.2, 0.20185769, 0.2023117]\n",
      "[0.60736346, 0.2, 0.2030504, 0.20025887]\n",
      "[0.60893863, 0.2, 0.20432265, 0.20056306]\n",
      "[0.6099844, 0.2, 0.20551813, 0.20041466]\n",
      "[0.608591, 0.2, 0.20368157, 0.20085907]\n",
      "[0.615356, 0.2, 0.21058115, 0.20072575]\n",
      "[0.6067548, 0.2, 0.20241332, 0.20029345]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18660 iterations: 4.376812946796417 mins\n",
      "Train Loss: [0.6067548, 0.2, 0.20241332, 0.20029345]\n",
      "[0.6129743, 0.2, 0.20779465, 0.20113273]\n",
      "[0.61022264, 0.2, 0.20519286, 0.20098387]\n",
      "[0.6082965, 0.2, 0.20393433, 0.2003173]\n",
      "[0.6075018, 0.2, 0.20283307, 0.20062481]\n",
      "[0.6053374, 0.2, 0.2009425, 0.20035176]\n",
      "[0.6082278, 0.2, 0.20389804, 0.2002876]\n",
      "[0.61733335, 0.2, 0.20275624, 0.21053584]\n",
      "[0.6130831, 0.2, 0.20778012, 0.20126273]\n",
      "[0.611545, 0.2, 0.20679188, 0.2007138]\n",
      "[0.6161033, 0.2, 0.21160068, 0.2004642]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18670 iterations: 4.378966232140859 mins\n",
      "Train Loss: [0.6161033, 0.2, 0.21160068, 0.2004642]\n",
      "[0.61252886, 0.2, 0.20759867, 0.20089376]\n",
      "[0.61106837, 0.2, 0.20662825, 0.20040546]\n",
      "[0.6124064, 0.2, 0.20794164, 0.20043185]\n",
      "[0.61684585, 0.2, 0.21182336, 0.20099114]\n",
      "[0.60803014, 0.2, 0.2030627, 0.20093736]\n",
      "[0.612287, 0.2, 0.20782733, 0.20043081]\n",
      "[0.6116122, 0.2, 0.20717192, 0.20041242]\n",
      "[0.61091304, 0.2, 0.20631616, 0.20056985]\n",
      "[0.61031455, 0.2, 0.2056514, 0.20063694]\n",
      "[0.6125709, 0.2, 0.20814578, 0.20039979]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18680 iterations: 4.38138914903005 mins\n",
      "Train Loss: [0.6125709, 0.2, 0.20814578, 0.20039979]\n",
      "[0.6062581, 0.2, 0.20163831, 0.20059527]\n",
      "[0.6082227, 0.2, 0.20245689, 0.20174214]\n",
      "[0.60992974, 0.2, 0.20551166, 0.20039514]\n",
      "[0.60962474, 0.2, 0.20500958, 0.20059317]\n",
      "[0.6096517, 0.2, 0.20499197, 0.2006387]\n",
      "[0.6087162, 0.2, 0.20436443, 0.2003317]\n",
      "[0.60874325, 0.2, 0.20437925, 0.20034494]\n",
      "[0.61330426, 0.2, 0.20902178, 0.20026441]\n",
      "[0.6092191, 0.2, 0.2048307, 0.20037095]\n",
      "[0.6073583, 0.2, 0.2030437, 0.2002978]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18690 iterations: 4.3835112651189165 mins\n",
      "Train Loss: [0.6073583, 0.2, 0.2030437, 0.2002978]\n",
      "[0.61744386, 0.2, 0.20161702, 0.211811]\n",
      "[0.6098977, 0.2, 0.2055065, 0.20037618]\n",
      "[0.6075149, 0.2, 0.20307495, 0.20042562]\n",
      "[0.6149024, 0.2, 0.21038887, 0.20049998]\n",
      "[0.6151324, 0.2, 0.21086538, 0.20025423]\n",
      "[0.61167425, 0.2, 0.20667121, 0.20099126]\n",
      "[0.60999894, 0.2, 0.2052227, 0.20076543]\n",
      "[0.60720944, 0.2, 0.20282173, 0.20037808]\n",
      "[0.617454, 0.2, 0.20524834, 0.20819701]\n",
      "[0.608747, 0.2, 0.20424594, 0.20049252]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18700 iterations: 4.385474832852681 mins\n",
      "Train Loss: [0.608747, 0.2, 0.20424594, 0.20049252]\n",
      "[0.62654966, 0.2, 0.20261502, 0.21992607]\n",
      "[0.6090317, 0.2, 0.20425124, 0.20077214]\n",
      "[0.60885185, 0.2, 0.20408846, 0.20075536]\n",
      "[0.60616297, 0.2, 0.20171869, 0.2004365]\n",
      "[0.60941786, 0.2, 0.20467183, 0.20073853]\n",
      "[0.6068272, 0.2, 0.20211762, 0.20070234]\n",
      "[0.6082259, 0.2, 0.20379592, 0.20042284]\n",
      "[0.6109754, 0.2, 0.20658775, 0.2003807]\n",
      "[0.6144065, 0.2, 0.20979583, 0.200604]\n",
      "[0.61502415, 0.2, 0.21067554, 0.2003421]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18710 iterations: 4.3873363335927325 mins\n",
      "Train Loss: [0.61502415, 0.2, 0.21067554, 0.2003421]\n",
      "[0.6413575, 0.2, 0.20665719, 0.23069412]\n",
      "[0.61264867, 0.2, 0.20800796, 0.20063564]\n",
      "[0.6109231, 0.2, 0.20595948, 0.20095968]\n",
      "[0.6529283, 0.2, 0.22352509, 0.22540015]\n",
      "[0.60907567, 0.2, 0.20457943, 0.2004934]\n",
      "[0.6095406, 0.2, 0.20491765, 0.2006201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6087479, 0.2, 0.2041218, 0.2006231]\n",
      "[0.6097997, 0.2, 0.20537373, 0.20042284]\n",
      "[0.6127466, 0.2, 0.20857374, 0.20016967]\n",
      "[0.6141913, 0.2, 0.20935509, 0.20083314]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18720 iterations: 4.389446798960368 mins\n",
      "Train Loss: [0.6141913, 0.2, 0.20935509, 0.20083314]\n",
      "[0.6072793, 0.2, 0.2027032, 0.20057346]\n",
      "[0.6093038, 0.2, 0.20470397, 0.20059751]\n",
      "[0.6070515, 0.2, 0.20241362, 0.20063592]\n",
      "[0.6102299, 0.2, 0.20539925, 0.2008289]\n",
      "[0.61167485, 0.2, 0.20645255, 0.20122091]\n",
      "[0.6093945, 0.2, 0.20480181, 0.20059174]\n",
      "[0.6083438, 0.2, 0.20365469, 0.20068863]\n",
      "[0.61014706, 0.2, 0.20554984, 0.20059717]\n",
      "[0.60970545, 0.2, 0.20483671, 0.20086914]\n",
      "[0.6103434, 0.2, 0.20515281, 0.20119143]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18730 iterations: 4.391348632176717 mins\n",
      "Train Loss: [0.6103434, 0.2, 0.20515281, 0.20119143]\n",
      "[0.6109375, 0.2, 0.20599279, 0.2009458]\n",
      "[0.6180765, 0.2, 0.2136558, 0.20042212]\n",
      "[0.6080743, 0.2, 0.20359866, 0.2004771]\n",
      "[0.6189684, 0.2, 0.21446718, 0.20050289]\n",
      "[0.6377466, 0.2, 0.2331981, 0.20055044]\n",
      "[0.6080373, 0.2, 0.2035505, 0.20049083]\n",
      "[0.60998535, 0.2, 0.20529354, 0.20069773]\n",
      "[0.62639064, 0.2, 0.2221138, 0.2002843]\n",
      "[0.6106185, 0.2, 0.2060495, 0.20057662]\n",
      "[0.60935163, 0.2, 0.20482425, 0.20053504]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18740 iterations: 4.39337899684906 mins\n",
      "Train Loss: [0.60935163, 0.2, 0.20482425, 0.20053504]\n",
      "[0.60881877, 0.2, 0.20452088, 0.20030539]\n",
      "[0.606501, 0.2, 0.20217119, 0.2003371]\n",
      "[0.6096959, 0.2, 0.20519735, 0.20050582]\n",
      "[0.6137071, 0.2, 0.20945671, 0.20025772]\n",
      "[0.6095351, 0.2, 0.20526366, 0.20027883]\n",
      "[0.6110497, 0.2, 0.20600815, 0.20104909]\n",
      "[0.6076308, 0.2, 0.20316194, 0.2004764]\n",
      "[0.6103093, 0.2, 0.20604108, 0.2002759]\n",
      "[0.60925025, 0.2, 0.20447692, 0.20078112]\n",
      "[0.6075971, 0.2, 0.20290057, 0.20070465]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18750 iterations: 4.395555969079336 mins\n",
      "Train Loss: [0.6075971, 0.2, 0.20290057, 0.20070465]\n",
      "[0.6110802, 0.2, 0.20647499, 0.20061359]\n",
      "[0.6081352, 0.2, 0.20370421, 0.20043963]\n",
      "[0.6094748, 0.2, 0.2050183, 0.20046546]\n",
      "[0.6071955, 0.2, 0.20298836, 0.2002165]\n",
      "[0.61003464, 0.2, 0.20550151, 0.2005429]\n",
      "[0.6089636, 0.2, 0.20425989, 0.20071378]\n",
      "[0.6087767, 0.2, 0.20443203, 0.20035511]\n",
      "[0.60901415, 0.2, 0.20449963, 0.20052533]\n",
      "[0.63027567, 0.2, 0.20269805, 0.2235891]\n",
      "[0.608547, 0.2, 0.20416251, 0.20039567]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18760 iterations: 4.398978865146637 mins\n",
      "Train Loss: [0.608547, 0.2, 0.20416251, 0.20039567]\n",
      "[0.6058698, 0.2, 0.20140424, 0.20047651]\n",
      "[0.60818285, 0.2, 0.20395711, 0.20023638]\n",
      "[0.6096256, 0.2, 0.20523867, 0.2003974]\n",
      "[0.6127678, 0.2, 0.2084888, 0.20028958]\n",
      "[0.6159838, 0.2, 0.211636, 0.20035845]\n",
      "[0.6055454, 0.2, 0.2012, 0.20035595]\n",
      "[0.61342895, 0.2, 0.20915517, 0.20028417]\n",
      "[0.61191547, 0.2, 0.20754816, 0.2003776]\n",
      "[0.60808533, 0.2, 0.20378248, 0.20031281]\n",
      "[0.61130786, 0.2, 0.20711885, 0.20019855]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18770 iterations: 4.401071552435557 mins\n",
      "Train Loss: [0.61130786, 0.2, 0.20711885, 0.20019855]\n",
      "[0.60723335, 0.2, 0.20282093, 0.20042147]\n",
      "[0.61138093, 0.2, 0.2070182, 0.20037153]\n",
      "[0.6277626, 0.2, 0.20497194, 0.21879923]\n",
      "[0.61348367, 0.2, 0.20865414, 0.20083883]\n",
      "[0.61107445, 0.2, 0.20609388, 0.20099062]\n",
      "[0.6077415, 0.2, 0.20256574, 0.20118624]\n",
      "[0.60806566, 0.2, 0.20256282, 0.20151389]\n",
      "[0.60658956, 0.2, 0.20167379, 0.20092732]\n",
      "[0.60876995, 0.2, 0.2039189, 0.20086326]\n",
      "[0.6397397, 0.2, 0.2171052, 0.21864744]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18780 iterations: 4.402914567788442 mins\n",
      "Train Loss: [0.6397397, 0.2, 0.2171052, 0.21864744]\n",
      "[0.61448973, 0.2, 0.20916562, 0.20133792]\n",
      "[0.6100218, 0.2, 0.20482165, 0.20121504]\n",
      "[0.6077592, 0.2, 0.20116277, 0.20261207]\n",
      "[0.61047554, 0.2, 0.20448965, 0.20200235]\n",
      "[0.6285682, 0.2, 0.20758708, 0.21699823]\n",
      "[0.6089211, 0.2, 0.203909, 0.20102988]\n",
      "[0.6108182, 0.2, 0.20557559, 0.20126083]\n",
      "[0.611089, 0.2, 0.20375736, 0.20335008]\n",
      "[0.60858876, 0.2, 0.20338196, 0.20122561]\n",
      "[0.6094786, 0.2, 0.20452277, 0.20097503]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18790 iterations: 4.404932169119517 mins\n",
      "Train Loss: [0.6094786, 0.2, 0.20452277, 0.20097503]\n",
      "[0.606252, 0.2, 0.20171899, 0.20055264]\n",
      "[0.609789, 0.2, 0.20467825, 0.20113072]\n",
      "[0.6221505, 0.2, 0.20411445, 0.21405646]\n",
      "[0.60937196, 0.2, 0.20430017, 0.20109253]\n",
      "[0.6082502, 0.2, 0.20351847, 0.20075282]\n",
      "[0.6103073, 0.2, 0.20481636, 0.20151223]\n",
      "[0.6083454, 0.2, 0.20357038, 0.20079648]\n",
      "[0.6088045, 0.2, 0.20336415, 0.20146218]\n",
      "[0.6323682, 0.2, 0.20399483, 0.2243955]\n",
      "[0.6067187, 0.2, 0.20176257, 0.20097786]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18800 iterations: 4.406853612263998 mins\n",
      "Train Loss: [0.6067187, 0.2, 0.20176257, 0.20097786]\n",
      "[0.6089097, 0.2, 0.20386222, 0.2010689]\n",
      "[0.6274058, 0.2, 0.22182436, 0.20160258]\n",
      "[0.63344955, 0.2, 0.20700024, 0.22246842]\n",
      "[0.6131126, 0.2, 0.20688674, 0.20224309]\n",
      "[0.61350036, 0.2, 0.20777626, 0.20173958]\n",
      "[0.60646385, 0.2, 0.20148033, 0.20099738]\n",
      "[0.60857385, 0.2, 0.20254973, 0.20203637]\n",
      "[0.6098373, 0.2, 0.20508723, 0.20076096]\n",
      "[0.6101119, 0.2, 0.2054929, 0.20062861]\n",
      "[0.61254495, 0.2, 0.20683302, 0.20172042]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18810 iterations: 4.40885823170344 mins\n",
      "Train Loss: [0.61254495, 0.2, 0.20683302, 0.20172042]\n",
      "[0.609349, 0.2, 0.20319617, 0.20216027]\n",
      "[0.60956246, 0.2, 0.20406735, 0.20150195]\n",
      "[0.6089292, 0.2, 0.20348926, 0.20144634]\n",
      "[0.61348075, 0.2, 0.20689875, 0.20258799]\n",
      "[0.6163069, 0.2, 0.21024361, 0.2020691]\n",
      "[0.60661185, 0.2, 0.20165019, 0.20096725]\n",
      "[0.6120281, 0.2, 0.206687, 0.20134653]\n",
      "[0.610727, 0.2, 0.2055541, 0.20117812]\n",
      "[0.6082368, 0.2, 0.20308083, 0.2011611]\n",
      "[0.6096907, 0.2, 0.20345892, 0.20223692]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18820 iterations: 4.410889931519827 mins\n",
      "Train Loss: [0.6096907, 0.2, 0.20345892, 0.20223692]\n",
      "[0.6114095, 0.2, 0.20540045, 0.20201425]\n",
      "[0.6074332, 0.2, 0.20286728, 0.2005715]\n",
      "[0.60723144, 0.2, 0.20238914, 0.20084824]\n",
      "[0.6099349, 0.2, 0.20506908, 0.20087229]\n",
      "[0.61276525, 0.2, 0.2057933, 0.20297882]\n",
      "[0.6069141, 0.2, 0.20179662, 0.20112501]\n",
      "[0.6084407, 0.2, 0.2034915, 0.20095752]\n",
      "[0.6087941, 0.2, 0.20277089, 0.20203243]\n",
      "[0.6200605, 0.2, 0.21487737, 0.20119332]\n",
      "[0.6081909, 0.2, 0.20265488, 0.2015476]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18830 iterations: 4.41275661389033 mins\n",
      "Train Loss: [0.6081909, 0.2, 0.20265488, 0.2015476]\n",
      "[0.60875225, 0.2, 0.20393316, 0.20083201]\n",
      "[0.61263865, 0.2, 0.20728032, 0.20137267]\n",
      "[0.6079405, 0.2, 0.20322572, 0.20073047]\n",
      "[0.6379845, 0.2, 0.23300916, 0.20099238]\n",
      "[0.6073685, 0.2, 0.20254576, 0.20083758]\n",
      "[0.6087706, 0.2, 0.2038698, 0.20091373]\n",
      "[0.60860944, 0.2, 0.2036036, 0.20101708]\n",
      "[0.6057593, 0.2, 0.20092621, 0.2008429]\n",
      "[0.60706407, 0.2, 0.20244274, 0.20062992]\n",
      "[0.62335974, 0.2, 0.20322564, 0.21614152]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18840 iterations: 4.4154242992401125 mins\n",
      "Train Loss: [0.62335974, 0.2, 0.20322564, 0.21614152]\n",
      "[0.60815924, 0.2, 0.20249133, 0.2016752]\n",
      "[0.609271, 0.2, 0.20344171, 0.20183635]\n",
      "[0.6103835, 0.2, 0.20562291, 0.20076777]\n",
      "[0.6075259, 0.2, 0.20257588, 0.20095721]\n",
      "[0.62150276, 0.2, 0.20421447, 0.21329553]\n",
      "[0.6081369, 0.2, 0.20228983, 0.20185444]\n",
      "[0.60890496, 0.2, 0.20303927, 0.20187324]\n",
      "[0.6211684, 0.2, 0.20720445, 0.2099719]\n",
      "[0.6108014, 0.2, 0.20470636, 0.20210339]\n",
      "[0.6087565, 0.2, 0.20353164, 0.20123366]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18850 iterations: 4.417296465237936 mins\n",
      "Train Loss: [0.6087565, 0.2, 0.20353164, 0.20123366]\n",
      "[0.606559, 0.2, 0.20173104, 0.20083714]\n",
      "[0.60989517, 0.2, 0.2052504, 0.20065436]\n",
      "[0.6088676, 0.2, 0.20317349, 0.20170422]\n",
      "[0.60707307, 0.2, 0.20212108, 0.20096256]\n",
      "[0.6109241, 0.2, 0.20442498, 0.20251016]\n",
      "[0.6113887, 0.2, 0.20633297, 0.20106721]\n",
      "[0.6095953, 0.2, 0.20481132, 0.2007959]\n",
      "[0.6103052, 0.2, 0.20451263, 0.20180477]\n",
      "[0.60994065, 0.2, 0.20456629, 0.20138684]\n",
      "[0.6149198, 0.2, 0.20986016, 0.20107234]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18860 iterations: 4.419304863611857 mins\n",
      "Train Loss: [0.6149198, 0.2, 0.20986016, 0.20107234]\n",
      "[0.60812527, 0.2, 0.20318002, 0.20095813]\n",
      "[0.6060093, 0.2, 0.2012115, 0.200811]\n",
      "[0.61128354, 0.2, 0.2063494, 0.20094775]\n",
      "[0.63645524, 0.2, 0.20439628, 0.22807285]\n",
      "[0.6118072, 0.2, 0.20682801, 0.20099325]\n",
      "[0.61149114, 0.2, 0.2058751, 0.20163013]\n",
      "[0.60780513, 0.2, 0.20255998, 0.20125926]\n",
      "[0.61958843, 0.2, 0.20452175, 0.21108112]\n",
      "[0.60927594, 0.2, 0.20386837, 0.20142213]\n",
      "[0.610074, 0.2, 0.2038529, 0.20223579]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18870 iterations: 4.421241132418315 mins\n",
      "Train Loss: [0.610074, 0.2, 0.2038529, 0.20223579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6096371, 0.2, 0.20407888, 0.20157291]\n",
      "[0.61159754, 0.2, 0.20645806, 0.20115411]\n",
      "[0.6126747, 0.2, 0.207481, 0.20120834]\n",
      "[0.6078644, 0.2, 0.20306642, 0.20081267]\n",
      "[0.6232705, 0.2, 0.21807086, 0.2012143]\n",
      "[0.60881037, 0.2, 0.20380343, 0.20101994]\n",
      "[0.6253971, 0.2, 0.20107202, 0.22033642]\n",
      "[0.6087641, 0.2, 0.20377527, 0.20099874]\n",
      "[0.6086167, 0.2, 0.20365255, 0.20097268]\n",
      "[0.6098554, 0.2, 0.20440634, 0.2014564]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18880 iterations: 4.423333585262299 mins\n",
      "Train Loss: [0.6098554, 0.2, 0.20440634, 0.2014564]\n",
      "[0.6131297, 0.2, 0.20755509, 0.20158082]\n",
      "[0.6134372, 0.2, 0.20792195, 0.20152089]\n",
      "[0.609802, 0.2, 0.20375681, 0.20205009]\n",
      "[0.63124347, 0.2, 0.20355846, 0.2236893]\n",
      "[0.60723436, 0.2, 0.20221339, 0.20102476]\n",
      "[0.6077904, 0.2, 0.20233375, 0.20146023]\n",
      "[0.61081517, 0.2, 0.20378818, 0.20303059]\n",
      "[0.60590696, 0.2, 0.20136096, 0.20054963]\n",
      "[0.6070321, 0.2, 0.20190357, 0.20113228]\n",
      "[0.6091055, 0.2, 0.20390633, 0.2012033]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18890 iterations: 4.425525097052256 mins\n",
      "Train Loss: [0.6091055, 0.2, 0.20390633, 0.2012033]\n",
      "[0.6167058, 0.2, 0.20615171, 0.20655857]\n",
      "[0.62110406, 0.2, 0.21608302, 0.20102572]\n",
      "[0.60736704, 0.2, 0.20185603, 0.20151664]\n",
      "[0.6154116, 0.2, 0.21043624, 0.2009819]\n",
      "[0.61158186, 0.2, 0.20585422, 0.20173508]\n",
      "[0.64973634, 0.2, 0.24474157, 0.20100316]\n",
      "[0.60816103, 0.2, 0.2025784, 0.2015936]\n",
      "[0.60948825, 0.2, 0.2045157, 0.200986]\n",
      "[0.60849386, 0.2, 0.20311998, 0.20138954]\n",
      "[0.6094205, 0.2, 0.20468096, 0.20075728]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18900 iterations: 4.4274273157119755 mins\n",
      "Train Loss: [0.6094205, 0.2, 0.20468096, 0.20075728]\n",
      "[0.612587, 0.2, 0.20749392, 0.20111267]\n",
      "[0.6070808, 0.2, 0.20196427, 0.20113772]\n",
      "[0.6103596, 0.2, 0.20493934, 0.20144303]\n",
      "[0.6131959, 0.2, 0.20822759, 0.2009926]\n",
      "[0.6091199, 0.2, 0.20422912, 0.2009166]\n",
      "[0.6087074, 0.2, 0.2031928, 0.20154181]\n",
      "[0.6120435, 0.2, 0.20680729, 0.20126472]\n",
      "[0.6156011, 0.2, 0.20511086, 0.20651998]\n",
      "[0.610745, 0.2, 0.20506155, 0.20171441]\n",
      "[0.60936195, 0.2, 0.20468307, 0.20071079]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18910 iterations: 4.429551831881205 mins\n",
      "Train Loss: [0.60936195, 0.2, 0.20468307, 0.20071079]\n",
      "[0.60627896, 0.2, 0.2013434, 0.20096827]\n",
      "[0.6190518, 0.2, 0.2031979, 0.21188736]\n",
      "[0.6099091, 0.2, 0.20503215, 0.20091054]\n",
      "[0.63830024, 0.2, 0.23371798, 0.2006159]\n",
      "[0.60915214, 0.2, 0.20368202, 0.2015019]\n",
      "[0.6068331, 0.2, 0.2017431, 0.20112017]\n",
      "[0.60699475, 0.2, 0.20250556, 0.20051792]\n",
      "[0.610403, 0.2, 0.20500644, 0.20142414]\n",
      "[0.6115624, 0.2, 0.20574676, 0.20184232]\n",
      "[0.61120385, 0.2, 0.2065865, 0.20064324]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18920 iterations: 4.432040031750997 mins\n",
      "Train Loss: [0.61120385, 0.2, 0.2065865, 0.20064324]\n",
      "[0.6121458, 0.2, 0.20616356, 0.20200717]\n",
      "[0.6086061, 0.2, 0.20276782, 0.20186238]\n",
      "[0.6192005, 0.2, 0.21338038, 0.2018435]\n",
      "[0.6069367, 0.2, 0.2020433, 0.20091611]\n",
      "[0.60757655, 0.2, 0.20282899, 0.20076972]\n",
      "[0.6090066, 0.2, 0.20423682, 0.20079152]\n",
      "[0.6084706, 0.2, 0.20334066, 0.20115148]\n",
      "[0.62551165, 0.2, 0.20559719, 0.21593595]\n",
      "[0.61095494, 0.2, 0.2048224, 0.20215401]\n",
      "[0.606492, 0.2, 0.20135713, 0.20115642]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18930 iterations: 4.434111928939819 mins\n",
      "Train Loss: [0.606492, 0.2, 0.20135713, 0.20115642]\n",
      "[0.6112965, 0.2, 0.20503528, 0.2022829]\n",
      "[0.6101798, 0.2, 0.2054742, 0.2007275]\n",
      "[0.6098014, 0.2, 0.20382038, 0.20200312]\n",
      "[0.6110961, 0.2, 0.20514676, 0.20197177]\n",
      "[0.6190491, 0.2, 0.21307468, 0.20199728]\n",
      "[0.60937214, 0.2, 0.20376085, 0.20163475]\n",
      "[0.60913926, 0.2, 0.20367432, 0.20148891]\n",
      "[0.6061177, 0.2, 0.2012773, 0.20086488]\n",
      "[0.60877943, 0.2, 0.20405152, 0.20075291]\n",
      "[0.6072391, 0.2, 0.20209062, 0.20117404]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18940 iterations: 4.436091295878092 mins\n",
      "Train Loss: [0.6072391, 0.2, 0.20209062, 0.20117404]\n",
      "[0.6126888, 0.2, 0.20818123, 0.20053348]\n",
      "[0.6093515, 0.2, 0.20456691, 0.20081104]\n",
      "[0.6063354, 0.2, 0.20142865, 0.20093374]\n",
      "[0.60643274, 0.2, 0.20174776, 0.20071247]\n",
      "[0.6113858, 0.2, 0.20668556, 0.20072839]\n",
      "[0.6071546, 0.2, 0.20284706, 0.20033625]\n",
      "[0.6104491, 0.2, 0.20546474, 0.20101343]\n",
      "[0.60973895, 0.2, 0.20494792, 0.2008205]\n",
      "[0.61049634, 0.2, 0.20556493, 0.20096129]\n",
      "[0.60959053, 0.2, 0.20499502, 0.20062605]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18950 iterations: 4.437989997863769 mins\n",
      "Train Loss: [0.60959053, 0.2, 0.20499502, 0.20062605]\n",
      "[0.6095485, 0.2, 0.20368668, 0.20189303]\n",
      "[0.6083816, 0.2, 0.20328635, 0.20112714]\n",
      "[0.61039966, 0.2, 0.20576118, 0.20067082]\n",
      "[0.60696954, 0.2, 0.20223856, 0.2007639]\n",
      "[0.60692436, 0.2, 0.20205809, 0.20089975]\n",
      "[0.6160082, 0.2, 0.211356, 0.20068634]\n",
      "[0.61877084, 0.2, 0.21308365, 0.20172192]\n",
      "[0.627285, 0.2, 0.21126424, 0.2120563]\n",
      "[0.61056924, 0.2, 0.20599678, 0.20060891]\n",
      "[0.60924876, 0.2, 0.20488705, 0.20039889]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18960 iterations: 4.440069218476613 mins\n",
      "Train Loss: [0.60924876, 0.2, 0.20488705, 0.20039889]\n",
      "[0.6153113, 0.2, 0.21050781, 0.20084111]\n",
      "[0.60645443, 0.2, 0.20169221, 0.20080012]\n",
      "[0.60972047, 0.2, 0.20501551, 0.20074306]\n",
      "[0.6108743, 0.2, 0.20612845, 0.2007843]\n",
      "[0.61810905, 0.2, 0.21360393, 0.20054388]\n",
      "[0.60871196, 0.2, 0.20373197, 0.20101926]\n",
      "[0.6098366, 0.2, 0.205164, 0.20071231]\n",
      "[0.6122123, 0.2, 0.20710312, 0.20114942]\n",
      "[0.6186218, 0.2, 0.21393168, 0.20073086]\n",
      "[0.6074297, 0.2, 0.20274717, 0.2007239]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18970 iterations: 4.442050099372864 mins\n",
      "Train Loss: [0.6074297, 0.2, 0.20274717, 0.2007239]\n",
      "[0.60645205, 0.2, 0.20157017, 0.20092405]\n",
      "[0.6081128, 0.2, 0.20342731, 0.20072848]\n",
      "[0.6090278, 0.2, 0.20460087, 0.20047069]\n",
      "[0.61136097, 0.2, 0.20662789, 0.20077774]\n",
      "[0.6169275, 0.2, 0.2122447, 0.20072848]\n",
      "[0.61049336, 0.2, 0.20562074, 0.20091917]\n",
      "[0.60966784, 0.2, 0.20461215, 0.201103]\n",
      "[0.6213096, 0.2, 0.207851, 0.20950674]\n",
      "[0.6125376, 0.2, 0.20763864, 0.20094828]\n",
      "[0.60656327, 0.2, 0.20134726, 0.20126615]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18980 iterations: 4.444075767199198 mins\n",
      "Train Loss: [0.60656327, 0.2, 0.20134726, 0.20126615]\n",
      "[0.6064114, 0.2, 0.20208484, 0.20037755]\n",
      "[0.6191149, 0.2, 0.2051973, 0.20996928]\n",
      "[0.61326265, 0.2, 0.20898296, 0.20033213]\n",
      "[0.61254364, 0.2, 0.20761442, 0.2009823]\n",
      "[0.6094087, 0.2, 0.2051244, 0.20033781]\n",
      "[0.60671514, 0.2, 0.20231548, 0.2004536]\n",
      "[0.60927826, 0.2, 0.20472138, 0.20061108]\n",
      "[0.6080644, 0.2, 0.20364961, 0.20046927]\n",
      "[0.61053663, 0.2, 0.20597376, 0.2006177]\n",
      "[0.6087797, 0.2, 0.20431133, 0.20052347]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18990 iterations: 4.445887998739878 mins\n",
      "Train Loss: [0.6087797, 0.2, 0.20431133, 0.20052347]\n",
      "[0.61372995, 0.2, 0.20945188, 0.20033336]\n",
      "[0.6109265, 0.2, 0.20650898, 0.20047304]\n",
      "[0.6080227, 0.2, 0.2035285, 0.2005498]\n",
      "[0.607569, 0.2, 0.2025939, 0.20103079]\n",
      "[0.6148894, 0.2, 0.21028633, 0.20065887]\n",
      "[0.6075386, 0.2, 0.20310338, 0.2004911]\n",
      "[0.62438303, 0.2, 0.20325832, 0.21718067]\n",
      "[0.60978955, 0.2, 0.2050234, 0.20082249]\n",
      "[0.6119079, 0.2, 0.20753604, 0.20042852]\n",
      "[0.60857755, 0.2, 0.20411703, 0.20051746]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19000 iterations: 4.4486440022786455 mins\n",
      "Train Loss: [0.60857755, 0.2, 0.20411703, 0.20051746]\n",
      "[0.60833997, 0.2, 0.20356902, 0.20082827]\n",
      "[0.6073404, 0.2, 0.20279025, 0.20060769]\n",
      "[0.60997254, 0.2, 0.20526801, 0.2007624]\n",
      "[0.6082781, 0.2, 0.20355275, 0.2007835]\n",
      "[0.6201271, 0.2, 0.2027572, 0.21342827]\n",
      "[0.60928136, 0.2, 0.20447403, 0.2008665]\n",
      "[0.60685164, 0.2, 0.20181933, 0.20109218]\n",
      "[0.6089043, 0.2, 0.2045696, 0.20039523]\n",
      "[0.61529094, 0.2, 0.2106565, 0.20069565]\n",
      "[0.61259127, 0.2, 0.20831479, 0.20033823]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19010 iterations: 4.450665485858917 mins\n",
      "Train Loss: [0.61259127, 0.2, 0.20831479, 0.20033823]\n",
      "[0.6334883, 0.2, 0.22920215, 0.20034832]\n",
      "[0.60725784, 0.2, 0.20275038, 0.20057194]\n",
      "[0.6082209, 0.2, 0.20394601, 0.20034134]\n",
      "[0.6085187, 0.2, 0.20392646, 0.20066066]\n",
      "[0.6108264, 0.2, 0.20653887, 0.20035766]\n",
      "[0.60631996, 0.2, 0.20206922, 0.20032242]\n",
      "[0.60850495, 0.2, 0.20425381, 0.20032416]\n",
      "[0.60828954, 0.2, 0.20404561, 0.20031819]\n",
      "[0.6085316, 0.2, 0.20437048, 0.20023642]\n",
      "[0.61197776, 0.2, 0.20744157, 0.20061152]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19020 iterations: 4.452555032571157 mins\n",
      "Train Loss: [0.61197776, 0.2, 0.20744157, 0.20061152]\n",
      "[0.6107108, 0.2, 0.20656715, 0.20021346]\n",
      "[0.61153936, 0.2, 0.20724255, 0.20035058]\n",
      "[0.60996795, 0.2, 0.20550756, 0.20048076]\n",
      "[0.64269614, 0.2, 0.20863715, 0.2300338]\n",
      "[0.6096988, 0.2, 0.2050728, 0.20054728]\n",
      "[0.60685605, 0.2, 0.20224601, 0.20047492]\n",
      "[0.60708904, 0.2, 0.2025342, 0.20036334]\n",
      "[0.6074589, 0.2, 0.20261104, 0.20060231]\n",
      "[0.60893387, 0.2, 0.20383365, 0.2008049]\n",
      "[0.6054858, 0.2, 0.20077595, 0.2003699]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19030 iterations: 4.454660030206044 mins\n",
      "Train Loss: [0.6054858, 0.2, 0.20077595, 0.2003699]\n",
      "[0.61455184, 0.2, 0.20952833, 0.2006448]\n",
      "[0.6102708, 0.2, 0.20524545, 0.20061386]\n",
      "[0.6097809, 0.2, 0.20450804, 0.20083468]\n",
      "[0.61170965, 0.2, 0.20510498, 0.20214593]\n",
      "[0.6072734, 0.2, 0.2023571, 0.20044252]\n",
      "[0.6106901, 0.2, 0.20429967, 0.20190701]\n",
      "[0.6103879, 0.2, 0.20524362, 0.20065582]\n",
      "[0.6157077, 0.2, 0.20197926, 0.20923913]\n",
      "[0.6077124, 0.2, 0.20224948, 0.2009769]\n",
      "[0.61621934, 0.2, 0.21127649, 0.20046318]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19040 iterations: 4.456555819511413 mins\n",
      "Train Loss: [0.61621934, 0.2, 0.21127649, 0.20046318]\n",
      "[0.6081818, 0.2, 0.20206788, 0.2016425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6074954, 0.2, 0.20223717, 0.20079732]\n",
      "[0.60901684, 0.2, 0.20339717, 0.2011709]\n",
      "[0.6073234, 0.2, 0.20218329, 0.20070493]\n",
      "[0.62672716, 0.2, 0.2077462, 0.21456039]\n",
      "[0.60763323, 0.2, 0.2024255, 0.20080237]\n",
      "[0.61037767, 0.2, 0.20483996, 0.20114803]\n",
      "[0.6109953, 0.2, 0.20625503, 0.20036682]\n",
      "[0.6079853, 0.2, 0.20305069, 0.20057744]\n",
      "[0.60732466, 0.2, 0.2020426, 0.20094109]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19050 iterations: 4.458686784903208 mins\n",
      "Train Loss: [0.60732466, 0.2, 0.2020426, 0.20094109]\n",
      "[0.60689676, 0.2, 0.2021218, 0.2004501]\n",
      "[0.61636245, 0.2, 0.2025142, 0.20953915]\n",
      "[0.60959715, 0.2, 0.20419697, 0.20110698]\n",
      "[0.6157058, 0.2, 0.21090643, 0.2005216]\n",
      "[0.6119242, 0.2, 0.20628962, 0.20137136]\n",
      "[0.6085837, 0.2, 0.20192847, 0.20240617]\n",
      "[0.60841066, 0.2, 0.20345113, 0.2007241]\n",
      "[0.6099243, 0.2, 0.20416038, 0.2015414]\n",
      "[0.6191337, 0.2, 0.21429613, 0.20062755]\n",
      "[0.6057089, 0.2, 0.20102966, 0.20048125]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19060 iterations: 4.460649434725443 mins\n",
      "Train Loss: [0.6057089, 0.2, 0.20102966, 0.20048125]\n",
      "[0.6055522, 0.2, 0.20089099, 0.2004746]\n",
      "[0.61040825, 0.2, 0.2056861, 0.20054656]\n",
      "[0.60817343, 0.2, 0.20351236, 0.20049591]\n",
      "[0.60969204, 0.2, 0.20441085, 0.20112595]\n",
      "[0.60891694, 0.2, 0.20376392, 0.2010073]\n",
      "[0.6111522, 0.2, 0.20643248, 0.20058304]\n",
      "[0.613695, 0.2, 0.20885155, 0.2007153]\n",
      "[0.61073935, 0.2, 0.2059521, 0.200667]\n",
      "[0.6061477, 0.2, 0.20147347, 0.20056155]\n",
      "[0.6139372, 0.2, 0.2082005, 0.20163123]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19070 iterations: 4.462544083595276 mins\n",
      "Train Loss: [0.6139372, 0.2, 0.2082005, 0.20163123]\n",
      "[0.614087, 0.2, 0.20851333, 0.201475]\n",
      "[0.60955626, 0.2, 0.20388044, 0.2015834]\n",
      "[0.6106073, 0.2, 0.20569506, 0.20082566]\n",
      "[0.61072445, 0.2, 0.20618057, 0.20046286]\n",
      "[0.6138684, 0.2, 0.20895171, 0.20084105]\n",
      "[0.60917544, 0.2, 0.20475698, 0.2003477]\n",
      "[0.6061975, 0.2, 0.2011377, 0.20099375]\n",
      "[0.6127195, 0.2, 0.20792656, 0.20073152]\n",
      "[0.6106188, 0.2, 0.20518506, 0.20137672]\n",
      "[0.6101632, 0.2, 0.20494677, 0.20116353]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19080 iterations: 4.465223745505015 mins\n",
      "Train Loss: [0.6101632, 0.2, 0.20494677, 0.20116353]\n",
      "[0.61198395, 0.2, 0.2069311, 0.20100412]\n",
      "[0.6118619, 0.2, 0.20753841, 0.20027857]\n",
      "[0.6109492, 0.2, 0.20567505, 0.20123312]\n",
      "[0.6104196, 0.2, 0.20559664, 0.20078568]\n",
      "[0.60586023, 0.2, 0.20117229, 0.2006542]\n",
      "[0.6105622, 0.2, 0.20616424, 0.20036767]\n",
      "[0.613539, 0.2, 0.20863053, 0.20088129]\n",
      "[0.6176484, 0.2, 0.20281751, 0.21080692]\n",
      "[0.61086655, 0.2, 0.2060054, 0.20084077]\n",
      "[0.61586314, 0.2, 0.21113369, 0.20071273]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19090 iterations: 4.468215386072795 mins\n",
      "Train Loss: [0.61586314, 0.2, 0.21113369, 0.20071273]\n",
      "[0.60601646, 0.2, 0.20151043, 0.20049277]\n",
      "[0.60927874, 0.2, 0.20439413, 0.20087464]\n",
      "[0.61090094, 0.2, 0.2062727, 0.2006214]\n",
      "[0.6082315, 0.2, 0.20372312, 0.20050457]\n",
      "[0.60932726, 0.2, 0.2042433, 0.20108302]\n",
      "[0.61067057, 0.2, 0.20558448, 0.20108783]\n",
      "[0.6116234, 0.2, 0.20713674, 0.20049104]\n",
      "[0.60892206, 0.2, 0.20455882, 0.20036983]\n",
      "[0.6110392, 0.2, 0.2066627, 0.2003854]\n",
      "[0.60822505, 0.2, 0.2038124, 0.20042379]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19100 iterations: 4.470176184177399 mins\n",
      "Train Loss: [0.60822505, 0.2, 0.2038124, 0.20042379]\n",
      "[0.61082536, 0.2, 0.20633927, 0.20049933]\n",
      "[0.60702217, 0.2, 0.20263676, 0.20040058]\n",
      "[0.6098648, 0.2, 0.20541275, 0.2004692]\n",
      "[0.61029, 0.2, 0.2057282, 0.20058097]\n",
      "[0.61592084, 0.2, 0.21161588, 0.20032623]\n",
      "[0.60874003, 0.2, 0.20454931, 0.200214]\n",
      "[0.60876936, 0.2, 0.2040487, 0.20074584]\n",
      "[0.6095082, 0.2, 0.20513833, 0.20039696]\n",
      "[0.60965776, 0.2, 0.20529406, 0.20039262]\n",
      "[0.608026, 0.2, 0.2037853, 0.20027134]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19110 iterations: 4.472383499145508 mins\n",
      "Train Loss: [0.608026, 0.2, 0.2037853, 0.20027134]\n",
      "[0.6092307, 0.2, 0.20483309, 0.20042977]\n",
      "[0.63892114, 0.2, 0.21633136, 0.21862248]\n",
      "[0.60752285, 0.2, 0.20329382, 0.20026018]\n",
      "[0.6083892, 0.2, 0.20334442, 0.201074]\n",
      "[0.6101302, 0.2, 0.2041423, 0.20201474]\n",
      "[0.6073043, 0.2, 0.20299911, 0.20032972]\n",
      "[0.60723335, 0.2, 0.2028125, 0.2004433]\n",
      "[0.6072981, 0.2, 0.20217435, 0.20114404]\n",
      "[0.60757464, 0.2, 0.20314772, 0.20044547]\n",
      "[0.6102106, 0.2, 0.20565072, 0.20057714]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19120 iterations: 4.474338062604269 mins\n",
      "Train Loss: [0.6102106, 0.2, 0.20565072, 0.20057714]\n",
      "[0.6106177, 0.2, 0.2058905, 0.20074351]\n",
      "[0.609249, 0.2, 0.20472763, 0.200537]\n",
      "[0.6119295, 0.2, 0.20544372, 0.20250125]\n",
      "[0.6103333, 0.2, 0.20564154, 0.2007073]\n",
      "[0.61626595, 0.2, 0.21132034, 0.20096163]\n",
      "[0.6076554, 0.2, 0.20275895, 0.2009119]\n",
      "[0.6124073, 0.2, 0.20756957, 0.20085295]\n",
      "[0.6116728, 0.2, 0.2065416, 0.20114625]\n",
      "[0.6077537, 0.2, 0.20284376, 0.20092507]\n",
      "[0.60879236, 0.2, 0.20304932, 0.20175852]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19130 iterations: 4.476509682337443 mins\n",
      "Train Loss: [0.60879236, 0.2, 0.20304932, 0.20175852]\n",
      "[0.60888666, 0.2, 0.20433639, 0.20056637]\n",
      "[0.6105413, 0.2, 0.2049902, 0.2015679]\n",
      "[0.61274207, 0.2, 0.20736904, 0.2013905]\n",
      "[0.60914916, 0.2, 0.20431109, 0.20085621]\n",
      "[0.61205053, 0.2, 0.20712481, 0.20094465]\n",
      "[0.60645896, 0.2, 0.20121537, 0.20126338]\n",
      "[0.6083201, 0.2, 0.20339578, 0.20094502]\n",
      "[0.606262, 0.2, 0.20133322, 0.2009505]\n",
      "[0.61120963, 0.2, 0.20540412, 0.20182833]\n",
      "[0.6060805, 0.2, 0.20134392, 0.20076062]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19140 iterations: 4.478556966781616 mins\n",
      "Train Loss: [0.6060805, 0.2, 0.20134392, 0.20076062]\n",
      "[0.6220892, 0.2, 0.20450503, 0.21360962]\n",
      "[0.6091412, 0.2, 0.20266053, 0.20250745]\n",
      "[0.6091455, 0.2, 0.2043457, 0.200828]\n",
      "[0.6062863, 0.2, 0.20159554, 0.20072028]\n",
      "[0.61099315, 0.2, 0.20638023, 0.20064376]\n",
      "[0.60948986, 0.2, 0.20504364, 0.20047848]\n",
      "[0.6197251, 0.2, 0.21082386, 0.20493501]\n",
      "[0.6249573, 0.2, 0.20854251, 0.21245024]\n",
      "[0.60619557, 0.2, 0.20117325, 0.20105971]\n",
      "[0.618593, 0.2, 0.21219702, 0.20243521]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19150 iterations: 4.482339366277059 mins\n",
      "Train Loss: [0.618593, 0.2, 0.21219702, 0.20243521]\n",
      "[0.60989654, 0.2, 0.20327349, 0.20266378]\n",
      "[0.61265534, 0.2, 0.20837717, 0.20032032]\n",
      "[0.6112891, 0.2, 0.20662646, 0.20070608]\n",
      "[0.60639596, 0.2, 0.20167702, 0.20076373]\n",
      "[0.6114734, 0.2, 0.20593084, 0.2015886]\n",
      "[0.6095176, 0.2, 0.20484242, 0.20072255]\n",
      "[0.6092394, 0.2, 0.20425606, 0.20103197]\n",
      "[0.60900587, 0.2, 0.20414007, 0.2009156]\n",
      "[0.6074028, 0.2, 0.20255202, 0.2009019]\n",
      "[0.61414725, 0.2, 0.20881239, 0.2013872]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19160 iterations: 4.4842210491498316 mins\n",
      "Train Loss: [0.61414725, 0.2, 0.20881239, 0.2013872]\n",
      "[0.6094216, 0.2, 0.2037905, 0.20168455]\n",
      "[0.60812455, 0.2, 0.20332855, 0.20085064]\n",
      "[0.6068647, 0.2, 0.20228073, 0.20063981]\n",
      "[0.60957414, 0.2, 0.20402987, 0.20160139]\n",
      "[0.6086067, 0.2, 0.20343314, 0.20123191]\n",
      "[0.60782015, 0.2, 0.2031081, 0.2007716]\n",
      "[0.60968244, 0.2, 0.2045871, 0.20115626]\n",
      "[0.60739446, 0.2, 0.20189504, 0.20156163]\n",
      "[0.6074865, 0.2, 0.20283404, 0.20071593]\n",
      "[0.60733175, 0.2, 0.2025385, 0.20085788]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19170 iterations: 4.4863398989041645 mins\n",
      "Train Loss: [0.60733175, 0.2, 0.2025385, 0.20085788]\n",
      "[0.61058486, 0.2, 0.20552458, 0.20112613]\n",
      "[0.6088451, 0.2, 0.20421137, 0.2007009]\n",
      "[0.61269623, 0.2, 0.20826939, 0.20049529]\n",
      "[0.60653335, 0.2, 0.20168263, 0.20092028]\n",
      "[0.60791785, 0.2, 0.20314705, 0.20084138]\n",
      "[0.60943556, 0.2, 0.20478798, 0.20071924]\n",
      "[0.61107683, 0.2, 0.20604956, 0.20109996]\n",
      "[0.60795933, 0.2, 0.20256756, 0.20146552]\n",
      "[0.62601376, 0.2, 0.2128239, 0.20926471]\n",
      "[0.6116491, 0.2, 0.20687425, 0.20084941]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19180 iterations: 4.488234647115072 mins\n",
      "Train Loss: [0.6116491, 0.2, 0.20687425, 0.20084941]\n",
      "[0.6189057, 0.2, 0.20352831, 0.21145137]\n",
      "[0.6088463, 0.2, 0.2040956, 0.20082411]\n",
      "[0.60756254, 0.2, 0.20268671, 0.20094857]\n",
      "[0.6092536, 0.2, 0.20455322, 0.2007726]\n",
      "[0.60842264, 0.2, 0.20389947, 0.20059489]\n",
      "[0.60795146, 0.2, 0.2026981, 0.20132473]\n",
      "[0.60920733, 0.2, 0.20412481, 0.20115358]\n",
      "[0.60933936, 0.2, 0.20389865, 0.20151132]\n",
      "[0.6121055, 0.2, 0.20742735, 0.20074832]\n",
      "[0.6066943, 0.2, 0.20145996, 0.20130435]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19190 iterations: 4.490311582883199 mins\n",
      "Train Loss: [0.6066943, 0.2, 0.20145996, 0.20130435]\n",
      "[0.6092105, 0.2, 0.20399801, 0.20128238]\n",
      "[0.6070831, 0.2, 0.20235011, 0.20080292]\n",
      "[0.6076173, 0.2, 0.20286934, 0.20081809]\n",
      "[0.61137, 0.2, 0.20671403, 0.20072635]\n",
      "[0.612853, 0.2, 0.2077529, 0.20117074]\n",
      "[0.6166484, 0.2, 0.21156606, 0.2011533]\n",
      "[0.61663055, 0.2, 0.2118529, 0.200849]\n",
      "[0.61031777, 0.2, 0.20507923, 0.20131032]\n",
      "[0.61007005, 0.2, 0.20382874, 0.20231372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6111897, 0.2, 0.20612006, 0.20114273]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19200 iterations: 4.492205417156219 mins\n",
      "Train Loss: [0.6111897, 0.2, 0.20612006, 0.20114273]\n",
      "[0.6131962, 0.2, 0.20804422, 0.2012256]\n",
      "[0.6108654, 0.2, 0.20612225, 0.20081747]\n",
      "[0.6117911, 0.2, 0.20560771, 0.20225832]\n",
      "[0.6130798, 0.2, 0.20787446, 0.20128098]\n",
      "[0.6145473, 0.2, 0.20330663, 0.20731683]\n",
      "[0.6163864, 0.2, 0.2107591, 0.20170468]\n",
      "[0.60895807, 0.2, 0.20405413, 0.20098273]\n",
      "[0.6089618, 0.2, 0.20419998, 0.20084184]\n",
      "[0.60896724, 0.2, 0.204134, 0.20091449]\n",
      "[0.60987854, 0.2, 0.20487128, 0.20108965]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19210 iterations: 4.494130484263102 mins\n",
      "Train Loss: [0.60987854, 0.2, 0.20487128, 0.20108965]\n",
      "[0.61044025, 0.2, 0.20557508, 0.20094858]\n",
      "[0.6134986, 0.2, 0.20844536, 0.20113759]\n",
      "[0.60839903, 0.2, 0.20362777, 0.20085643]\n",
      "[0.61884695, 0.2, 0.21467556, 0.20025754]\n",
      "[0.6080448, 0.2, 0.20297553, 0.2011547]\n",
      "[0.6070889, 0.2, 0.20263162, 0.2005419]\n",
      "[0.63212985, 0.2, 0.22705686, 0.20115688]\n",
      "[0.60596704, 0.2, 0.2012637, 0.20078515]\n",
      "[0.6081398, 0.2, 0.2034642, 0.2007555]\n",
      "[0.6146247, 0.2, 0.20917524, 0.2015275]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19220 iterations: 4.496205417315165 mins\n",
      "Train Loss: [0.6146247, 0.2, 0.20917524, 0.2015275]\n",
      "[0.6143139, 0.2, 0.20993222, 0.20045799]\n",
      "[0.6123677, 0.2, 0.20771386, 0.20072877]\n",
      "[0.61200887, 0.2, 0.20774505, 0.20033754]\n",
      "[0.6063467, 0.2, 0.20137116, 0.20104818]\n",
      "[0.6087387, 0.2, 0.2032425, 0.20156804]\n",
      "[0.6158523, 0.2, 0.21069647, 0.20122695]\n",
      "[0.6112782, 0.2, 0.20671491, 0.20063375]\n",
      "[0.6078991, 0.2, 0.20300947, 0.20095986]\n",
      "[0.607833, 0.2, 0.20252995, 0.20137303]\n",
      "[0.6096188, 0.2, 0.20480587, 0.20088285]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19230 iterations: 4.498425547281901 mins\n",
      "Train Loss: [0.6096188, 0.2, 0.20480587, 0.20088285]\n",
      "[0.6076848, 0.2, 0.20288159, 0.20087305]\n",
      "[0.6104892, 0.2, 0.20428768, 0.20227136]\n",
      "[0.6399133, 0.2, 0.23534642, 0.20063673]\n",
      "[0.61753845, 0.2, 0.20557007, 0.20803687]\n",
      "[0.607813, 0.2, 0.20280412, 0.20107642]\n",
      "[0.6078796, 0.2, 0.20223549, 0.20171072]\n",
      "[0.61618274, 0.2, 0.21139163, 0.20085713]\n",
      "[0.65336424, 0.2, 0.24884792, 0.20058191]\n",
      "[0.6093317, 0.2, 0.20432095, 0.20107727]\n",
      "[0.6068889, 0.2, 0.20195498, 0.20100133]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19240 iterations: 4.500449617703755 mins\n",
      "Train Loss: [0.6068889, 0.2, 0.20195498, 0.20100133]\n",
      "[0.6120019, 0.2, 0.20701547, 0.2010546]\n",
      "[0.61080366, 0.2, 0.20600498, 0.20086789]\n",
      "[0.6152552, 0.2, 0.20947957, 0.20184554]\n",
      "[0.6183176, 0.2, 0.21299392, 0.20139448]\n",
      "[0.60929555, 0.2, 0.20439933, 0.20096774]\n",
      "[0.618053, 0.2, 0.21295695, 0.20116827]\n",
      "[0.61381346, 0.2, 0.20909232, 0.20079419]\n",
      "[0.6094933, 0.2, 0.20455228, 0.20101488]\n",
      "[0.60897416, 0.2, 0.20470206, 0.2003467]\n",
      "[0.60714054, 0.2, 0.20253465, 0.20068122]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19250 iterations: 4.502277096112569 mins\n",
      "Train Loss: [0.60714054, 0.2, 0.20253465, 0.20068122]\n",
      "[0.61149466, 0.2, 0.20651305, 0.20105758]\n",
      "[0.6081108, 0.2, 0.20295794, 0.20122913]\n",
      "[0.60798895, 0.2, 0.2033361, 0.20072937]\n",
      "[0.60722756, 0.2, 0.20247558, 0.20082884]\n",
      "[0.6096168, 0.2, 0.20369539, 0.20199874]\n",
      "[0.6130393, 0.2, 0.20815985, 0.20095739]\n",
      "[0.61183864, 0.2, 0.2070971, 0.2008201]\n",
      "[0.61302125, 0.2, 0.20804374, 0.20105687]\n",
      "[0.606879, 0.2, 0.2024331, 0.20052606]\n",
      "[0.60626096, 0.2, 0.20180808, 0.20053384]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19260 iterations: 4.504283181826273 mins\n",
      "Train Loss: [0.60626096, 0.2, 0.20180808, 0.20053384]\n",
      "[0.6084532, 0.2, 0.20346408, 0.20107092]\n",
      "[0.607335, 0.2, 0.20292062, 0.20049687]\n",
      "[0.60803807, 0.2, 0.20356748, 0.20055382]\n",
      "[0.6121317, 0.2, 0.20763913, 0.20057674]\n",
      "[0.60957885, 0.2, 0.20481847, 0.2008452]\n",
      "[0.61135525, 0.2, 0.20717175, 0.20026901]\n",
      "[0.61115634, 0.2, 0.20680593, 0.20043671]\n",
      "[0.6094951, 0.2, 0.20475003, 0.2008322]\n",
      "[0.60682946, 0.2, 0.20239334, 0.20052415]\n",
      "[0.6195334, 0.2, 0.21493176, 0.2006906]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19270 iterations: 4.50615885257721 mins\n",
      "Train Loss: [0.6195334, 0.2, 0.21493176, 0.2006906]\n",
      "[0.61096907, 0.2, 0.20659955, 0.20045798]\n",
      "[0.6099357, 0.2, 0.20539859, 0.20062508]\n",
      "[0.61032975, 0.2, 0.20548135, 0.20093596]\n",
      "[0.60931575, 0.2, 0.20493747, 0.20046557]\n",
      "[0.6076383, 0.2, 0.20341192, 0.20031354]\n",
      "[0.61013645, 0.2, 0.20569244, 0.20053113]\n",
      "[0.6077627, 0.2, 0.20348802, 0.20036203]\n",
      "[0.61131394, 0.2, 0.20691323, 0.20048842]\n",
      "[0.6078904, 0.2, 0.20364107, 0.20033729]\n",
      "[0.6240733, 0.2, 0.20501569, 0.21514595]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19280 iterations: 4.508223001162211 mins\n",
      "Train Loss: [0.6240733, 0.2, 0.20501569, 0.21514595]\n",
      "[0.60846543, 0.2, 0.20378135, 0.20077227]\n",
      "[0.60720825, 0.2, 0.20297787, 0.2003184]\n",
      "[0.6091795, 0.2, 0.20495121, 0.2003163]\n",
      "[0.607517, 0.2, 0.20273633, 0.20086889]\n",
      "[0.61037946, 0.2, 0.20614275, 0.20032522]\n",
      "[0.6075513, 0.2, 0.20325752, 0.20038265]\n",
      "[0.61156774, 0.2, 0.2073604, 0.20029673]\n",
      "[0.60770637, 0.2, 0.20325728, 0.20053904]\n",
      "[0.65326875, 0.2, 0.2490069, 0.20035234]\n",
      "[0.6170226, 0.2, 0.21256703, 0.20054781]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19290 iterations: 4.510199681917826 mins\n",
      "Train Loss: [0.6170226, 0.2, 0.21256703, 0.20054781]\n",
      "[0.60691583, 0.2, 0.20252962, 0.20047969]\n",
      "[0.61287355, 0.2, 0.20842771, 0.20054053]\n",
      "[0.6089312, 0.2, 0.20450541, 0.20052117]\n",
      "[0.6141619, 0.2, 0.20994915, 0.20030847]\n",
      "[0.628061, 0.2, 0.20821598, 0.21594068]\n",
      "[0.60840976, 0.2, 0.20399193, 0.20051375]\n",
      "[0.6113525, 0.2, 0.20678274, 0.20066541]\n",
      "[0.60821843, 0.2, 0.20376442, 0.20054774]\n",
      "[0.6355791, 0.2, 0.20365536, 0.22801545]\n",
      "[0.6095686, 0.2, 0.2051046, 0.20055678]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19300 iterations: 4.512071029345194 mins\n",
      "Train Loss: [0.6095686, 0.2, 0.2051046, 0.20055678]\n",
      "[0.60737514, 0.2, 0.20280723, 0.20066118]\n",
      "[0.61127126, 0.2, 0.20694157, 0.20042308]\n",
      "[0.6101111, 0.2, 0.20570272, 0.20050146]\n",
      "[0.6105944, 0.2, 0.20587702, 0.20080975]\n",
      "[0.6100719, 0.2, 0.20573388, 0.20042972]\n",
      "[0.6086636, 0.2, 0.20439604, 0.20035855]\n",
      "[0.61104095, 0.2, 0.20660593, 0.2005256]\n",
      "[0.61047685, 0.2, 0.20624262, 0.20032464]\n",
      "[0.6122001, 0.2, 0.20804171, 0.20024861]\n",
      "[0.610391, 0.2, 0.20599097, 0.20049022]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19310 iterations: 4.5146034797032675 mins\n",
      "Train Loss: [0.610391, 0.2, 0.20599097, 0.20049022]\n",
      "[0.6136729, 0.2, 0.20938331, 0.20037983]\n",
      "[0.6340204, 0.2, 0.20973462, 0.22037613]\n",
      "[0.60832006, 0.2, 0.20416722, 0.20024309]\n",
      "[0.6068482, 0.2, 0.20276622, 0.2001721]\n",
      "[0.6096837, 0.2, 0.20550667, 0.20026709]\n",
      "[0.6066293, 0.2, 0.20233151, 0.2003879]\n",
      "[0.60771906, 0.2, 0.20353241, 0.20027688]\n",
      "[0.61068565, 0.2, 0.2063764, 0.20039967]\n",
      "[0.633519, 0.2, 0.21162008, 0.21798968]\n",
      "[0.60717964, 0.2, 0.2028952, 0.20037524]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19320 iterations: 4.516428915659587 mins\n",
      "Train Loss: [0.60717964, 0.2, 0.2028952, 0.20037524]\n",
      "[0.6172969, 0.2, 0.21306682, 0.20032099]\n",
      "[0.60838443, 0.2, 0.20397915, 0.20049646]\n",
      "[0.6141939, 0.2, 0.20995189, 0.20033348]\n",
      "[0.6057141, 0.2, 0.20154376, 0.20026213]\n",
      "[0.64119834, 0.2, 0.20267558, 0.23461509]\n",
      "[0.6248791, 0.2, 0.22063467, 0.2003374]\n",
      "[0.61055976, 0.2, 0.20617363, 0.20047876]\n",
      "[0.6120417, 0.2, 0.20759942, 0.20053454]\n",
      "[0.60999596, 0.2, 0.20565172, 0.20043616]\n",
      "[0.6064024, 0.2, 0.20216057, 0.20033336]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19330 iterations: 4.5184588154157 mins\n",
      "Train Loss: [0.6064024, 0.2, 0.20216057, 0.20033336]\n",
      "[0.6120638, 0.2, 0.2076565, 0.20049874]\n",
      "[0.6062784, 0.2, 0.20215012, 0.20021981]\n",
      "[0.6096363, 0.2, 0.2054652, 0.20026273]\n",
      "[0.6105641, 0.2, 0.20636323, 0.20029262]\n",
      "[0.60826683, 0.2, 0.20394972, 0.2004091]\n",
      "[0.6098308, 0.2, 0.20536987, 0.20055333]\n",
      "[0.6074314, 0.2, 0.20320854, 0.20031565]\n",
      "[0.6077948, 0.2, 0.20313826, 0.2007499]\n",
      "[0.60809124, 0.2, 0.2033229, 0.20086236]\n",
      "[0.60828274, 0.2, 0.20412579, 0.2002516]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19340 iterations: 4.520348449548085 mins\n",
      "Train Loss: [0.60828274, 0.2, 0.20412579, 0.2002516]\n",
      "[0.6130826, 0.2, 0.20776883, 0.2014091]\n",
      "[0.6083081, 0.2, 0.20396465, 0.20043953]\n",
      "[0.6170563, 0.2, 0.21285872, 0.20029429]\n",
      "[0.6069388, 0.2, 0.20266545, 0.20037055]\n",
      "[0.6075026, 0.2, 0.20320378, 0.20039645]\n",
      "[0.6085957, 0.2, 0.20429814, 0.20039597]\n",
      "[0.6078616, 0.2, 0.20306912, 0.20089142]\n",
      "[0.6095975, 0.2, 0.2054728, 0.20022449]\n",
      "[0.6110265, 0.2, 0.20684335, 0.20028396]\n",
      "[0.6093707, 0.2, 0.20491746, 0.20055506]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19350 iterations: 4.522419234116872 mins\n",
      "Train Loss: [0.6093707, 0.2, 0.20491746, 0.20055506]\n",
      "[0.6134869, 0.2, 0.20931114, 0.20027849]\n",
      "[0.6060377, 0.2, 0.20138425, 0.20075724]\n",
      "[0.6076648, 0.2, 0.20332934, 0.20044029]\n",
      "[0.6084152, 0.2, 0.20410515, 0.20041578]\n",
      "[0.60648143, 0.2, 0.20224419, 0.20034398]\n",
      "[0.6075256, 0.2, 0.20315601, 0.20047736]\n",
      "[0.6094671, 0.2, 0.20477341, 0.20080248]\n",
      "[0.60662305, 0.2, 0.20225397, 0.20047885]\n",
      "[0.6109485, 0.2, 0.20672041, 0.20033893]\n",
      "[0.60697556, 0.2, 0.20280498, 0.20028259]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19360 iterations: 4.524276185035705 mins\n",
      "Train Loss: [0.60697556, 0.2, 0.20280498, 0.20028259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6215128, 0.2, 0.20348312, 0.21414272]\n",
      "[0.60752255, 0.2, 0.20344013, 0.2001969]\n",
      "[0.608393, 0.2, 0.20402482, 0.200484]\n",
      "[0.6071248, 0.2, 0.2030257, 0.20021595]\n",
      "[0.6081076, 0.2, 0.20379849, 0.20042695]\n",
      "[0.6085138, 0.2, 0.20413932, 0.20049332]\n",
      "[0.61134946, 0.2, 0.20699963, 0.20046996]\n",
      "[0.6108669, 0.2, 0.20626426, 0.20072407]\n",
      "[0.6071287, 0.2, 0.20285997, 0.20039141]\n",
      "[0.60716856, 0.2, 0.20303589, 0.2002566]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19370 iterations: 4.526446497440338 mins\n",
      "Train Loss: [0.60716856, 0.2, 0.20303589, 0.2002566]\n",
      "[0.6088861, 0.2, 0.20468405, 0.20032713]\n",
      "[0.6589977, 0.2, 0.25494203, 0.20018198]\n",
      "[0.62344754, 0.2, 0.20521167, 0.21436347]\n",
      "[0.61961323, 0.2, 0.20437233, 0.2113699]\n",
      "[0.6135437, 0.2, 0.20945035, 0.20022237]\n",
      "[0.6111702, 0.2, 0.20699322, 0.2003059]\n",
      "[0.6074457, 0.2, 0.20311248, 0.20046185]\n",
      "[0.60944855, 0.2, 0.2050208, 0.20055619]\n",
      "[0.60611355, 0.2, 0.20189536, 0.20034641]\n",
      "[0.6319772, 0.2, 0.20512731, 0.22297785]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19380 iterations: 4.528505067030589 mins\n",
      "Train Loss: [0.6319772, 0.2, 0.20512731, 0.22297785]\n",
      "[0.6084358, 0.2, 0.20408633, 0.20047861]\n",
      "[0.6078767, 0.2, 0.20307666, 0.2009305]\n",
      "[0.63007176, 0.2, 0.20677854, 0.21942489]\n",
      "[0.6144473, 0.2, 0.21001291, 0.2005669]\n",
      "[0.60902053, 0.2, 0.20480898, 0.20034482]\n",
      "[0.6081145, 0.2, 0.20387284, 0.20037557]\n",
      "[0.6090682, 0.2, 0.20428647, 0.20091625]\n",
      "[0.6200832, 0.2, 0.20486306, 0.21135534]\n",
      "[0.6099595, 0.2, 0.20557962, 0.20051561]\n",
      "[0.6092901, 0.2, 0.20516156, 0.20026499]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19390 iterations: 4.530797282854716 mins\n",
      "Train Loss: [0.6092901, 0.2, 0.20516156, 0.20026499]\n",
      "[0.60837036, 0.2, 0.20424804, 0.20025934]\n",
      "[0.609577, 0.2, 0.20520702, 0.20050764]\n",
      "[0.61146164, 0.2, 0.20715596, 0.20044406]\n",
      "[0.60749745, 0.2, 0.20338446, 0.20025222]\n",
      "[0.6068164, 0.2, 0.20272759, 0.20022875]\n",
      "[0.6113062, 0.2, 0.20724621, 0.20020062]\n",
      "[0.60851365, 0.2, 0.20434228, 0.20031278]\n",
      "[0.6102948, 0.2, 0.20579489, 0.20064212]\n",
      "[0.6087198, 0.2, 0.20452982, 0.20033303]\n",
      "[0.60957587, 0.2, 0.20510632, 0.2006133]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19400 iterations: 4.532827866077423 mins\n",
      "Train Loss: [0.60957587, 0.2, 0.20510632, 0.2006133]\n",
      "[0.6081938, 0.2, 0.2041519, 0.20018652]\n",
      "[0.6072262, 0.2, 0.20308329, 0.20028839]\n",
      "[0.61640847, 0.2, 0.21220514, 0.20034978]\n",
      "[0.6081064, 0.2, 0.20346221, 0.20079233]\n",
      "[0.620839, 0.2, 0.2021458, 0.21484305]\n",
      "[0.60640985, 0.2, 0.2023636, 0.20019795]\n",
      "[0.6142779, 0.2, 0.20989278, 0.20053856]\n",
      "[0.6127405, 0.2, 0.2086642, 0.20023146]\n",
      "[0.60697734, 0.2, 0.20287167, 0.20026231]\n",
      "[0.6106099, 0.2, 0.2064519, 0.20031597]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19410 iterations: 4.534628967444102 mins\n",
      "Train Loss: [0.6106099, 0.2, 0.2064519, 0.20031597]\n",
      "[0.610858, 0.2, 0.20665091, 0.2003663]\n",
      "[0.6114199, 0.2, 0.20708176, 0.2004982]\n",
      "[0.60578334, 0.2, 0.20155269, 0.20039152]\n",
      "[0.6057346, 0.2, 0.2016863, 0.20020998]\n",
      "[0.6234462, 0.2, 0.21939006, 0.20021866]\n",
      "[0.6078953, 0.2, 0.20361178, 0.20044596]\n",
      "[0.6237381, 0.2, 0.20915584, 0.2107446]\n",
      "[0.6144919, 0.2, 0.21002588, 0.20062876]\n",
      "[0.6080921, 0.2, 0.20386069, 0.20039436]\n",
      "[0.6070576, 0.2, 0.20302622, 0.20019433]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19420 iterations: 4.536643397808075 mins\n",
      "Train Loss: [0.6070576, 0.2, 0.20302622, 0.20019433]\n",
      "[0.61201996, 0.2, 0.20798062, 0.20020191]\n",
      "[0.60794973, 0.2, 0.20377938, 0.20032838]\n",
      "[0.6091091, 0.2, 0.20488976, 0.20036685]\n",
      "[0.6090595, 0.2, 0.2048465, 0.20034634]\n",
      "[0.6077893, 0.2, 0.20359023, 0.20031573]\n",
      "[0.6099797, 0.2, 0.20552406, 0.20055479]\n",
      "[0.6104443, 0.2, 0.20632033, 0.20020565]\n",
      "[0.61374485, 0.2, 0.20846252, 0.20134743]\n",
      "[0.6084973, 0.2, 0.20418511, 0.20036197]\n",
      "[0.60912275, 0.2, 0.20482013, 0.2003387]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19430 iterations: 4.5385170698165895 mins\n",
      "Train Loss: [0.60912275, 0.2, 0.20482013, 0.2003387]\n",
      "[0.6093432, 0.2, 0.20425145, 0.20111613]\n",
      "[0.611907, 0.2, 0.20690963, 0.20101215]\n",
      "[0.6099857, 0.2, 0.20554003, 0.20045264]\n",
      "[0.61376697, 0.2, 0.20933789, 0.2004302]\n",
      "[0.6215855, 0.2, 0.20437099, 0.21321139]\n",
      "[0.6084496, 0.2, 0.20410235, 0.20034143]\n",
      "[0.6239269, 0.2, 0.21956691, 0.20035264]\n",
      "[0.61588746, 0.2, 0.21150678, 0.20037289]\n",
      "[0.6092211, 0.2, 0.2046899, 0.20052403]\n",
      "[0.60787725, 0.2, 0.20253375, 0.20133787]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19440 iterations: 4.540571296215058 mins\n",
      "Train Loss: [0.60787725, 0.2, 0.20253375, 0.20133787]\n",
      "[0.60964435, 0.2, 0.20531362, 0.20032744]\n",
      "[0.6125873, 0.2, 0.20827205, 0.20031488]\n",
      "[0.6123726, 0.2, 0.20794918, 0.20042644]\n",
      "[0.6111497, 0.2, 0.20691162, 0.20024489]\n",
      "[0.60827285, 0.2, 0.20412496, 0.2001587]\n",
      "[0.609437, 0.2, 0.20520166, 0.20025052]\n",
      "[0.6091664, 0.2, 0.20485936, 0.20032662]\n",
      "[0.6093361, 0.2, 0.20514931, 0.2002107]\n",
      "[0.6148237, 0.2, 0.21056458, 0.20028752]\n",
      "[0.6316078, 0.2, 0.22715941, 0.20048107]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19450 iterations: 4.54260843594869 mins\n",
      "Train Loss: [0.6316078, 0.2, 0.22715941, 0.20048107]\n",
      "[0.6090054, 0.2, 0.20469889, 0.20034276]\n",
      "[0.6095406, 0.2, 0.20517766, 0.20040284]\n",
      "[0.6113516, 0.2, 0.20694433, 0.20045084]\n",
      "[0.6095556, 0.2, 0.20516826, 0.20043497]\n",
      "[0.6061457, 0.2, 0.20192403, 0.20027325]\n",
      "[0.6108715, 0.2, 0.20667581, 0.20025127]\n",
      "[0.6070266, 0.2, 0.20254838, 0.20053768]\n",
      "[0.62141067, 0.2, 0.20155062, 0.21592325]\n",
      "[0.609312, 0.2, 0.20517062, 0.20020793]\n",
      "[0.6103147, 0.2, 0.20604044, 0.20034409]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19460 iterations: 4.54450493256251 mins\n",
      "Train Loss: [0.6103147, 0.2, 0.20604044, 0.20034409]\n",
      "[0.6084906, 0.2, 0.20416455, 0.20039903]\n",
      "[0.6071336, 0.2, 0.2030119, 0.20019795]\n",
      "[0.6211286, 0.2, 0.2169787, 0.20022944]\n",
      "[0.606444, 0.2, 0.20230292, 0.20022409]\n",
      "[0.6100633, 0.2, 0.20580049, 0.20034938]\n",
      "[0.60743034, 0.2, 0.2031212, 0.20039912]\n",
      "[0.61667186, 0.2, 0.2125029, 0.20026225]\n",
      "[0.6069536, 0.2, 0.20280698, 0.20024396]\n",
      "[0.6233556, 0.2, 0.2049133, 0.21454361]\n",
      "[0.61366886, 0.2, 0.20920298, 0.20057039]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19470 iterations: 4.546564197540283 mins\n",
      "Train Loss: [0.61366886, 0.2, 0.20920298, 0.20057039]\n",
      "[0.606475, 0.2, 0.2023494, 0.20023333]\n",
      "[0.61298877, 0.2, 0.20890802, 0.2001916]\n",
      "[0.61116385, 0.2, 0.206651, 0.20062661]\n",
      "[0.606115, 0.2, 0.20165409, 0.20057754]\n",
      "[0.6049491, 0.2, 0.20082986, 0.20023859]\n",
      "[0.60533535, 0.2, 0.2009121, 0.20054524]\n",
      "[0.6060582, 0.2, 0.20171, 0.2004728]\n",
      "[0.6142075, 0.2, 0.20989014, 0.20044453]\n",
      "[0.60845757, 0.2, 0.20437725, 0.20020992]\n",
      "[0.60830915, 0.2, 0.20414127, 0.20029995]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19480 iterations: 4.5490000486373905 mins\n",
      "Train Loss: [0.60830915, 0.2, 0.20414127, 0.20029995]\n",
      "[0.6062974, 0.2, 0.20195644, 0.20047548]\n",
      "[0.6067254, 0.2, 0.20247707, 0.20038521]\n",
      "[0.6091615, 0.2, 0.20498414, 0.20031658]\n",
      "[0.6091033, 0.2, 0.20485793, 0.20038687]\n",
      "[0.60936934, 0.2, 0.20521155, 0.20030148]\n",
      "[0.60772604, 0.2, 0.20361751, 0.20025432]\n",
      "[0.6074964, 0.2, 0.20300654, 0.20063744]\n",
      "[0.6150472, 0.2, 0.21071042, 0.20048627]\n",
      "[0.60505396, 0.2, 0.20091909, 0.20028624]\n",
      "[0.6078085, 0.2, 0.20349446, 0.20046717]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19490 iterations: 4.551118115584056 mins\n",
      "Train Loss: [0.6078085, 0.2, 0.20349446, 0.20046717]\n",
      "[0.6088603, 0.2, 0.20453507, 0.2004803]\n",
      "[0.60774434, 0.2, 0.20287828, 0.20102279]\n",
      "[0.6075806, 0.2, 0.20340274, 0.20033629]\n",
      "[0.60762614, 0.2, 0.20319873, 0.20058742]\n",
      "[0.6088409, 0.2, 0.20456222, 0.20044014]\n",
      "[0.60857296, 0.2, 0.20435995, 0.20037596]\n",
      "[0.6089325, 0.2, 0.20479444, 0.20030273]\n",
      "[0.6071807, 0.2, 0.20291905, 0.20042801]\n",
      "[0.6064426, 0.2, 0.20216843, 0.20044221]\n",
      "[0.60705847, 0.2, 0.20262703, 0.20060088]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19500 iterations: 4.552952567736308 mins\n",
      "Train Loss: [0.60705847, 0.2, 0.20262703, 0.20060088]\n",
      "[0.6254946, 0.2, 0.20603241, 0.21563283]\n",
      "[0.60768586, 0.2, 0.20341952, 0.20043857]\n",
      "[0.61781543, 0.2, 0.21367992, 0.20030916]\n",
      "[0.60604745, 0.2, 0.20165516, 0.20056659]\n",
      "[0.60896844, 0.2, 0.20476776, 0.20037542]\n",
      "[0.60980916, 0.2, 0.20548801, 0.20049624]\n",
      "[0.6053589, 0.2, 0.20115429, 0.20038012]\n",
      "[0.60527533, 0.2, 0.20111991, 0.20033129]\n",
      "[0.6126996, 0.2, 0.20853414, 0.20034176]\n",
      "[0.60948163, 0.2, 0.20519716, 0.2004605]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19510 iterations: 4.554923514525096 mins\n",
      "Train Loss: [0.60948163, 0.2, 0.20519716, 0.2004605]\n",
      "[0.6135713, 0.2, 0.2094338, 0.2003131]\n",
      "[0.60577345, 0.2, 0.20159636, 0.20035245]\n",
      "[0.6136142, 0.2, 0.2089764, 0.20081314]\n",
      "[0.60932446, 0.2, 0.20501572, 0.200484]\n",
      "[0.60678375, 0.2, 0.20278063, 0.20017825]\n",
      "[0.60992783, 0.2, 0.20522922, 0.20087378]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6089898, 0.2, 0.20448563, 0.2006796]\n",
      "[0.6054046, 0.2, 0.20111519, 0.2004653]\n",
      "[0.6204812, 0.2, 0.20428796, 0.21236958]\n",
      "[0.60814536, 0.2, 0.20401, 0.20031202]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19520 iterations: 4.5570129672686255 mins\n",
      "Train Loss: [0.60814536, 0.2, 0.20401, 0.20031202]\n",
      "[0.6066644, 0.2, 0.20254907, 0.20029247]\n",
      "[0.6071206, 0.2, 0.20310682, 0.20019138]\n",
      "[0.6128744, 0.2, 0.20860744, 0.20044506]\n",
      "[0.6082222, 0.2, 0.2041915, 0.20020917]\n",
      "[0.6104994, 0.2, 0.20636931, 0.20030889]\n",
      "[0.61044955, 0.2, 0.20613003, 0.20049891]\n",
      "[0.6092428, 0.2, 0.20488389, 0.20053893]\n",
      "[0.6086568, 0.2, 0.20453945, 0.20029831]\n",
      "[0.6061585, 0.2, 0.20217599, 0.20016442]\n",
      "[0.60873806, 0.2, 0.2045622, 0.20035878]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19530 iterations: 4.558900415897369 mins\n",
      "Train Loss: [0.60873806, 0.2, 0.2045622, 0.20035878]\n",
      "[0.6082216, 0.2, 0.20411846, 0.20028713]\n",
      "[0.60734385, 0.2, 0.20328335, 0.20024568]\n",
      "[0.6111263, 0.2, 0.20700604, 0.20030667]\n",
      "[0.6073825, 0.2, 0.20333579, 0.20023416]\n",
      "[0.6046677, 0.2, 0.20054555, 0.20031093]\n",
      "[0.60716426, 0.2, 0.2029556, 0.20039868]\n",
      "[0.6112448, 0.2, 0.2069499, 0.2004862]\n",
      "[0.6050843, 0.2, 0.20097108, 0.20030604]\n",
      "[0.60860443, 0.2, 0.20431642, 0.20048238]\n",
      "[0.6089882, 0.2, 0.20486785, 0.20031618]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19540 iterations: 4.560864881674449 mins\n",
      "Train Loss: [0.6089882, 0.2, 0.20486785, 0.20031618]\n",
      "[0.6092871, 0.2, 0.20490287, 0.20058148]\n",
      "[0.61091316, 0.2, 0.2068283, 0.2002835]\n",
      "[0.60862285, 0.2, 0.20443967, 0.20038338]\n",
      "[0.6079586, 0.2, 0.20386244, 0.2002979]\n",
      "[0.6076971, 0.2, 0.20355266, 0.20034778]\n",
      "[0.6050562, 0.2, 0.20092537, 0.20033564]\n",
      "[0.60636395, 0.2, 0.20238617, 0.20018409]\n",
      "[0.6103177, 0.2, 0.20625803, 0.20026775]\n",
      "[0.606024, 0.2, 0.2019617, 0.20027223]\n",
      "[0.60915864, 0.2, 0.20516442, 0.20020586]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19550 iterations: 4.562769683202108 mins\n",
      "Train Loss: [0.60915864, 0.2, 0.20516442, 0.20020586]\n",
      "[0.6091767, 0.2, 0.20507112, 0.20031878]\n",
      "[0.61208594, 0.2, 0.20813957, 0.2001609]\n",
      "[0.61485535, 0.2, 0.20049542, 0.2105759]\n",
      "[0.6060784, 0.2, 0.20206659, 0.20022921]\n",
      "[0.61865383, 0.2, 0.21464856, 0.20022409]\n",
      "[0.607901, 0.2, 0.20386003, 0.20026013]\n",
      "[0.6084691, 0.2, 0.20451275, 0.20017578]\n",
      "[0.60723376, 0.2, 0.2032443, 0.20020889]\n",
      "[0.60717326, 0.2, 0.20308755, 0.20030509]\n",
      "[0.6060015, 0.2, 0.20205154, 0.20016935]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19560 iterations: 4.565315198898316 mins\n",
      "Train Loss: [0.6060015, 0.2, 0.20205154, 0.20016935]\n",
      "[0.60841465, 0.2, 0.20409365, 0.20054054]\n",
      "[0.60869014, 0.2, 0.20458873, 0.2003209]\n",
      "[0.6100777, 0.2, 0.20545907, 0.20083821]\n",
      "[0.6050748, 0.2, 0.20095323, 0.20034122]\n",
      "[0.60792553, 0.2, 0.20386119, 0.20028415]\n",
      "[0.60976017, 0.2, 0.2058331, 0.20014709]\n",
      "[0.6062635, 0.2, 0.20219189, 0.20029193]\n",
      "[0.6171565, 0.2, 0.2131455, 0.2002316]\n",
      "[0.60461843, 0.2, 0.20059577, 0.20024228]\n",
      "[0.6099876, 0.2, 0.20593557, 0.2002708]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19570 iterations: 4.567198216915131 mins\n",
      "Train Loss: [0.6099876, 0.2, 0.20593557, 0.2002708]\n",
      "[0.6069275, 0.2, 0.20295677, 0.20018896]\n",
      "[0.62783664, 0.2, 0.20597544, 0.21807912]\n",
      "[0.6093829, 0.2, 0.20534696, 0.20025359]\n",
      "[0.6108825, 0.2, 0.20686348, 0.2002364]\n",
      "[0.6184766, 0.2, 0.2142718, 0.20042187]\n",
      "[0.6079597, 0.2, 0.20387496, 0.2003002]\n",
      "[0.6068658, 0.2, 0.20282723, 0.2002525]\n",
      "[0.60609984, 0.2, 0.20206769, 0.2002446]\n",
      "[0.60959196, 0.2, 0.20559412, 0.20020913]\n",
      "[0.6084828, 0.2, 0.20449322, 0.2001999]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19580 iterations: 4.569104282061259 mins\n",
      "Train Loss: [0.6084828, 0.2, 0.20449322, 0.2001999]\n",
      "[0.61278313, 0.2, 0.2087333, 0.20025945]\n",
      "[0.6089507, 0.2, 0.20493615, 0.20022373]\n",
      "[0.60863346, 0.2, 0.2047333, 0.2001092]\n",
      "[0.61363363, 0.2, 0.20914851, 0.2006943]\n",
      "[0.6101849, 0.2, 0.20562814, 0.20076609]\n",
      "[0.6069732, 0.2, 0.20294856, 0.20023428]\n",
      "[0.60946727, 0.2, 0.20546675, 0.2002106]\n",
      "[0.6065596, 0.2, 0.20263638, 0.20013379]\n",
      "[0.6083018, 0.2, 0.20434748, 0.20016544]\n",
      "[0.60862076, 0.2, 0.20467143, 0.20016113]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19590 iterations: 4.571227085590363 mins\n",
      "Train Loss: [0.60862076, 0.2, 0.20467143, 0.20016113]\n",
      "[0.60825276, 0.2, 0.20414273, 0.20032206]\n",
      "[0.6112496, 0.2, 0.20719883, 0.2002588]\n",
      "[0.61194223, 0.2, 0.2078011, 0.20033768]\n",
      "[0.6067289, 0.2, 0.20274009, 0.20016544]\n",
      "[0.61189276, 0.2, 0.20758067, 0.20045924]\n",
      "[0.60608387, 0.2, 0.20201485, 0.20017815]\n",
      "[0.60780543, 0.2, 0.20358191, 0.20028915]\n",
      "[0.60861284, 0.2, 0.20443729, 0.2001913]\n",
      "[0.61220473, 0.2, 0.20796973, 0.20019676]\n",
      "[0.60979456, 0.2, 0.20552912, 0.20017582]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19600 iterations: 4.573077217737834 mins\n",
      "Train Loss: [0.60979456, 0.2, 0.20552912, 0.20017582]\n",
      "[0.60578203, 0.2, 0.20130171, 0.20034103]\n",
      "[0.607955, 0.2, 0.20364487, 0.20012394]\n",
      "[0.6092067, 0.2, 0.2047844, 0.20019361]\n",
      "[0.61168355, 0.2, 0.20720835, 0.20021108]\n",
      "[0.62153316, 0.2, 0.21693465, 0.20030059]\n",
      "[0.6180674, 0.2, 0.21355787, 0.20018071]\n",
      "[0.6113147, 0.2, 0.20681489, 0.20014274]\n",
      "[0.61922884, 0.2, 0.21450421, 0.20033997]\n",
      "[0.61625654, 0.2, 0.21168832, 0.20015912]\n",
      "[0.6111248, 0.2, 0.20657754, 0.20011835]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19610 iterations: 4.575137301286062 mins\n",
      "Train Loss: [0.6111248, 0.2, 0.20657754, 0.20011835]\n",
      "[0.6222246, 0.2, 0.20768338, 0.21009643]\n",
      "[0.60801953, 0.2, 0.20337775, 0.20018399]\n",
      "[0.6105673, 0.2, 0.2059534, 0.20014542]\n",
      "[0.61063766, 0.2, 0.20598273, 0.2001769]\n",
      "[0.6124031, 0.2, 0.20776646, 0.20015177]\n",
      "[0.6059894, 0.2, 0.20136234, 0.20014012]\n",
      "[0.61149526, 0.2, 0.20681497, 0.200194]\n",
      "[0.60832024, 0.2, 0.203614, 0.20022096]\n",
      "[0.6126399, 0.2, 0.20788182, 0.20027635]\n",
      "[0.6066148, 0.2, 0.20200554, 0.20013395]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19620 iterations: 4.577009801069895 mins\n",
      "Train Loss: [0.6066148, 0.2, 0.20200554, 0.20013395]\n",
      "[0.60698754, 0.2, 0.20229845, 0.20022184]\n",
      "[0.6063175, 0.2, 0.20174359, 0.20011635]\n",
      "[0.62090385, 0.2, 0.21627812, 0.2001792]\n",
      "[0.60763323, 0.2, 0.20289849, 0.20030072]\n",
      "[0.6092747, 0.2, 0.20472878, 0.20012526]\n",
      "[0.60679936, 0.2, 0.2022622, 0.20013055]\n",
      "[0.60667735, 0.2, 0.20216751, 0.20011759]\n",
      "[0.60988885, 0.2, 0.20531194, 0.20019917]\n",
      "[0.6087454, 0.2, 0.20417869, 0.2002036]\n",
      "[0.60583246, 0.2, 0.20132196, 0.20016207]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19630 iterations: 4.579117600123087 mins\n",
      "Train Loss: [0.60583246, 0.2, 0.20132196, 0.20016207]\n",
      "[0.6096785, 0.2, 0.20523262, 0.20011218]\n",
      "[0.60943085, 0.2, 0.20497085, 0.20014104]\n",
      "[0.6083878, 0.2, 0.20380591, 0.20027737]\n",
      "[0.6102641, 0.2, 0.2056516, 0.20032214]\n",
      "[0.60755193, 0.2, 0.20317186, 0.2001033]\n",
      "[0.6539364, 0.2, 0.24950959, 0.2001634]\n",
      "[0.60938495, 0.2, 0.20500514, 0.20012814]\n",
      "[0.6111617, 0.2, 0.20676059, 0.20016006]\n",
      "[0.60893524, 0.2, 0.20444438, 0.20025982]\n",
      "[0.61034703, 0.2, 0.20583779, 0.20028767]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19640 iterations: 4.581639683246612 mins\n",
      "Train Loss: [0.61034703, 0.2, 0.20583779, 0.20028767]\n",
      "[0.6044902, 0.2, 0.20014854, 0.20012899]\n",
      "[0.60445535, 0.2, 0.20007382, 0.20017749]\n",
      "[0.60442764, 0.2, 0.20012455, 0.2001076]\n",
      "[0.60458994, 0.2, 0.20013401, 0.20026895]\n",
      "[0.6044313, 0.2, 0.20015106, 0.20010182]\n",
      "[0.6044673, 0.2, 0.20008467, 0.20021285]\n",
      "[0.60439914, 0.2, 0.20012473, 0.20011325]\n",
      "[0.60444134, 0.2, 0.2000821, 0.20020671]\n",
      "[0.60439533, 0.2, 0.20004854, 0.20020287]\n",
      "[0.60438347, 0.2, 0.200094, 0.20015408]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19650 iterations: 4.58361386458079 mins\n",
      "Train Loss: [0.60438347, 0.2, 0.200094, 0.20015408]\n",
      "[0.6043003, 0.2, 0.2000646, 0.20010896]\n",
      "[0.6043492, 0.2, 0.20010367, 0.2001273]\n",
      "[0.6044175, 0.2, 0.20010611, 0.20020163]\n",
      "[0.6043221, 0.2, 0.20012742, 0.20009321]\n",
      "[0.60434014, 0.2, 0.20015083, 0.20009606]\n",
      "[0.60421634, 0.2, 0.20004793, 0.20008326]\n",
      "[0.60494214, 0.2, 0.20012896, 0.20073578]\n",
      "[0.6042812, 0.2, 0.20009924, 0.2001123]\n",
      "[0.6042038, 0.2, 0.20008239, 0.20005937]\n",
      "[0.6042521, 0.2, 0.20010181, 0.20009561]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19660 iterations: 4.585552986462911 mins\n",
      "Train Loss: [0.6042521, 0.2, 0.20010181, 0.20009561]\n",
      "[0.604368, 0.2, 0.20011789, 0.20020257]\n",
      "[0.6042132, 0.2, 0.20006442, 0.20010816]\n",
      "[0.6042005, 0.2, 0.20003861, 0.20012808]\n",
      "[0.6041101, 0.2, 0.20000002, 0.20008282]\n",
      "[0.60416454, 0.2, 0.20006317, 0.20008059]\n",
      "[0.60420674, 0.2, 0.20008524, 0.200107]\n",
      "[0.60418415, 0.2, 0.20010416, 0.20007154]\n",
      "[0.6041866, 0.2, 0.20011373, 0.20007044]\n",
      "[0.6041683, 0.2, 0.20006008, 0.20011172]\n",
      "[0.60414064, 0.2, 0.20005243, 0.20009756]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19670 iterations: 4.587369914849599 mins\n",
      "Train Loss: [0.60414064, 0.2, 0.20005243, 0.20009756]\n",
      "[0.6041452, 0.2, 0.2000779, 0.20008235]\n",
      "[0.6041655, 0.2, 0.20006369, 0.20012239]\n",
      "[0.60415393, 0.2, 0.20008188, 0.20009808]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.604161, 0.2, 0.2000592, 0.20013325]\n",
      "[0.6041094, 0.2, 0.20005068, 0.20009553]\n",
      "[0.60415524, 0.2, 0.20006236, 0.20013495]\n",
      "[0.60401976, 0.2, 0.20002379, 0.2000432]\n",
      "[0.6040763, 0.2, 0.20007268, 0.200056]\n",
      "[0.6040921, 0.2, 0.20006537, 0.20008412]\n",
      "[0.60401154, 0.2, 0.20002736, 0.20004652]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19680 iterations: 4.589413436253865 mins\n",
      "Train Loss: [0.60401154, 0.2, 0.20002736, 0.20004652]\n",
      "[0.6040142, 0.2, 0.20004104, 0.2000404]\n",
      "[0.6040715, 0.2, 0.20005924, 0.2000843]\n",
      "[0.6042312, 0.2, 0.20004123, 0.20026678]\n",
      "[0.60402286, 0.2, 0.20004511, 0.20005931]\n",
      "[0.6040358, 0.2, 0.20005028, 0.20007154]\n",
      "[0.6040092, 0.2, 0.20004682, 0.20005293]\n",
      "[0.60402566, 0.2, 0.20005384, 0.20006676]\n",
      "[0.60397184, 0.2, 0.20003225, 0.20003888]\n",
      "[0.6039926, 0.2, 0.20003107, 0.20006506]\n",
      "[0.6039971, 0.2, 0.20007305, 0.20003194]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19690 iterations: 4.591224098205567 mins\n",
      "Train Loss: [0.6039971, 0.2, 0.20007305, 0.20003194]\n",
      "[0.6039775, 0.2, 0.20003553, 0.20005408]\n",
      "[0.6041885, 0.2, 0.20025611, 0.20004867]\n",
      "[0.6039875, 0.2, 0.20003366, 0.20007426]\n",
      "[0.6039428, 0.2, 0.20002374, 0.20004347]\n",
      "[0.6040646, 0.2, 0.20014179, 0.20005125]\n",
      "[0.6039652, 0.2, 0.20003998, 0.20005761]\n",
      "[0.60394347, 0.2, 0.20003721, 0.2000424]\n",
      "[0.60394955, 0.2, 0.20002237, 0.20006716]\n",
      "[0.60398304, 0.2, 0.20002125, 0.20010549]\n",
      "[0.6039767, 0.2, 0.20008855, 0.2000356]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19700 iterations: 4.593276397387187 mins\n",
      "Train Loss: [0.6039767, 0.2, 0.20008855, 0.2000356]\n",
      "[0.604262, 0.2, 0.20001833, 0.20039465]\n",
      "[0.6038843, 0.2, 0.20001543, 0.20002334]\n",
      "[0.6039273, 0.2, 0.20003259, 0.20005274]\n",
      "[0.6039057, 0.2, 0.20002906, 0.20003815]\n",
      "[0.60390896, 0.2, 0.20002644, 0.20004748]\n",
      "[0.60392576, 0.2, 0.20004709, 0.20004708]\n",
      "[0.60391974, 0.2, 0.20005868, 0.20003287]\n",
      "[0.6039279, 0.2, 0.2000319, 0.2000712]\n",
      "[0.6039156, 0.2, 0.2000272, 0.20006695]\n",
      "[0.6039593, 0.2, 0.20003428, 0.20010705]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19710 iterations: 4.5956520160039265 mins\n",
      "Train Loss: [0.6039593, 0.2, 0.20003428, 0.20010705]\n",
      "[0.603923, 0.2, 0.20005603, 0.20005235]\n",
      "[0.60396206, 0.2, 0.2001182, 0.20003256]\n",
      "[0.60387874, 0.2, 0.20002152, 0.20004916]\n",
      "[0.60388863, 0.2, 0.20003341, 0.20005049]\n",
      "[0.6038958, 0.2, 0.20002592, 0.20006844]\n",
      "[0.6038836, 0.2, 0.20004502, 0.20004031]\n",
      "[0.6038804, 0.2, 0.20003344, 0.20005196]\n",
      "[0.603866, 0.2, 0.20002162, 0.20005259]\n",
      "[0.6038353, 0.2, 0.20000507, 0.20004155]\n",
      "[0.6038583, 0.2, 0.20002678, 0.20004602]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19720 iterations: 4.5984891335169475 mins\n",
      "Train Loss: [0.6038583, 0.2, 0.20002678, 0.20004602]\n",
      "[0.6038515, 0.2, 0.2000339, 0.20003526]\n",
      "[0.6039104, 0.2, 0.20003952, 0.20009162]\n",
      "[0.6039019, 0.2, 0.2000843, 0.20004144]\n",
      "[0.60384977, 0.2, 0.200018, 0.20005874]\n",
      "[0.603877, 0.2, 0.20005935, 0.20004769]\n",
      "[0.60383964, 0.2, 0.20002419, 0.2000485]\n",
      "[0.6038575, 0.2, 0.20003372, 0.20005982]\n",
      "[0.6038426, 0.2, 0.20003247, 0.20004915]\n",
      "[0.6038293, 0.2, 0.20001929, 0.20005196]\n",
      "[0.60382926, 0.2, 0.20003295, 0.20004116]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19730 iterations: 4.6005825161933895 mins\n",
      "Train Loss: [0.60382926, 0.2, 0.20003295, 0.20004116]\n",
      "[0.6038371, 0.2, 0.20002751, 0.20005724]\n",
      "[0.6038188, 0.2, 0.2000227, 0.20004667]\n",
      "[0.6038563, 0.2, 0.20006558, 0.2000441]\n",
      "[0.60383976, 0.2, 0.20002162, 0.2000743]\n",
      "[0.60382706, 0.2, 0.20001842, 0.20006756]\n",
      "[0.6039009, 0.2, 0.20012888, 0.20003368]\n",
      "[0.603812, 0.2, 0.20002306, 0.20005326]\n",
      "[0.60380685, 0.2, 0.20003568, 0.20003822]\n",
      "[0.60391176, 0.2, 0.20005861, 0.20012286]\n",
      "[0.603827, 0.2, 0.2000148, 0.20008457]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19740 iterations: 4.602396432558695 mins\n",
      "Train Loss: [0.603827, 0.2, 0.2000148, 0.20008457]\n",
      "[0.60396427, 0.2, 0.20019303, 0.20004629]\n",
      "[0.60385126, 0.2, 0.20004015, 0.20008878]\n",
      "[0.6037722, 0.2, 0.20001411, 0.20003843]\n",
      "[0.6037834, 0.2, 0.20001864, 0.20004775]\n",
      "[0.6037762, 0.2, 0.20002003, 0.20004174]\n",
      "[0.60378814, 0.2, 0.20003098, 0.2000453]\n",
      "[0.603803, 0.2, 0.20001635, 0.2000773]\n",
      "[0.6038432, 0.2, 0.20008446, 0.20005196]\n",
      "[0.60384995, 0.2, 0.20009845, 0.2000472]\n",
      "[0.60375714, 0.2, 0.20002644, 0.20002887]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19750 iterations: 4.604447448253632 mins\n",
      "Train Loss: [0.60375714, 0.2, 0.20002644, 0.20002887]\n",
      "[0.6037567, 0.2, 0.20002773, 0.20002963]\n",
      "[0.60378593, 0.2, 0.20001327, 0.20007575]\n",
      "[0.60375994, 0.2, 0.20003703, 0.20002842]\n",
      "[0.60376734, 0.2, 0.20001553, 0.2000598]\n",
      "[0.60376894, 0.2, 0.20001492, 0.20006463]\n",
      "[0.60375696, 0.2, 0.20002773, 0.20004229]\n",
      "[0.60386556, 0.2, 0.20001982, 0.20016135]\n",
      "[0.6037732, 0.2, 0.20002428, 0.20006698]\n",
      "[0.6037367, 0.2, 0.20004267, 0.20001464]\n",
      "[0.60373497, 0.2, 0.20001425, 0.20004387]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19760 iterations: 4.606320830186208 mins\n",
      "Train Loss: [0.60373497, 0.2, 0.20001425, 0.20004387]\n",
      "[0.60378015, 0.2, 0.20003575, 0.20007007]\n",
      "[0.6037401, 0.2, 0.20002578, 0.20004241]\n",
      "[0.6037164, 0.2, 0.20002232, 0.20002468]\n",
      "[0.6040121, 0.2, 0.2003054, 0.20003967]\n",
      "[0.60373735, 0.2, 0.20004061, 0.20003211]\n",
      "[0.60372555, 0.2, 0.20002607, 0.20003718]\n",
      "[0.60371566, 0.2, 0.2000286, 0.20002718]\n",
      "[0.6037148, 0.2, 0.20003, 0.20002726]\n",
      "[0.60372126, 0.2, 0.20001975, 0.20004626]\n",
      "[0.6037127, 0.2, 0.20001413, 0.20004563]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19770 iterations: 4.608342679341634 mins\n",
      "Train Loss: [0.6037127, 0.2, 0.20001413, 0.20004563]\n",
      "[0.60371345, 0.2, 0.20001642, 0.20004639]\n",
      "[0.60370994, 0.2, 0.20002612, 0.20003554]\n",
      "[0.6037316, 0.2, 0.20003197, 0.2000536]\n",
      "[0.6036878, 0.2, 0.2000283, 0.20001586]\n",
      "[0.60367465, 0.2, 0.2000129, 0.20002025]\n",
      "[0.60373235, 0.2, 0.20002908, 0.20006403]\n",
      "[0.6036881, 0.2, 0.2000149, 0.20003626]\n",
      "[0.6037064, 0.2, 0.20002836, 0.20004329]\n",
      "[0.6036764, 0.2, 0.20001832, 0.20002548]\n",
      "[0.6036687, 0.2, 0.20001428, 0.20002408]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19780 iterations: 4.610191202163696 mins\n",
      "Train Loss: [0.6036687, 0.2, 0.20001428, 0.20002408]\n",
      "[0.60365856, 0.2, 0.2, 0.20003048]\n",
      "[0.6037198, 0.2, 0.20005609, 0.2000378]\n",
      "[0.60366553, 0.2, 0.20001765, 0.20002423]\n",
      "[0.60366327, 0.2, 0.20002213, 0.20001966]\n",
      "[0.6036557, 0.2, 0.20001058, 0.20002578]\n",
      "[0.6037007, 0.2, 0.20002896, 0.20005468]\n",
      "[0.6036697, 0.2, 0.20002313, 0.20003167]\n",
      "[0.6037069, 0.2, 0.2000204, 0.2000738]\n",
      "[0.60367733, 0.2, 0.20002824, 0.20003857]\n",
      "[0.60366553, 0.2, 0.20001714, 0.20004006]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19790 iterations: 4.61218136548996 mins\n",
      "Train Loss: [0.60366553, 0.2, 0.20001714, 0.20004006]\n",
      "[0.6036652, 0.2, 0.2000158, 0.20004317]\n",
      "[0.6036666, 0.2, 0.20003334, 0.20002921]\n",
      "[0.6036626, 0.2, 0.20002782, 0.20003292]\n",
      "[0.603652, 0.2, 0.20003152, 0.20002073]\n",
      "[0.6036582, 0.2, 0.20002496, 0.20003566]\n",
      "[0.6037819, 0.2, 0.2001369, 0.20004949]\n",
      "[0.60365933, 0.2, 0.20004375, 0.20002216]\n",
      "[0.6036376, 0.2, 0.20001724, 0.20002899]\n",
      "[0.60363686, 0.2, 0.20001566, 0.20003197]\n",
      "[0.6036228, 0.2, 0.20001514, 0.20002045]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19800 iterations: 4.614798931280772 mins\n",
      "Train Loss: [0.6036228, 0.2, 0.20001514, 0.20002045]\n",
      "[0.60361516, 0.2, 0.20001036, 0.20001964]\n",
      "[0.6036215, 0.2, 0.2000207, 0.20001765]\n",
      "[0.60361075, 0.2, 0.20001496, 0.20001474]\n",
      "[0.60362506, 0.2, 0.20001319, 0.20003283]\n",
      "[0.603622, 0.2, 0.2000196, 0.20002545]\n",
      "[0.60363287, 0.2, 0.20002845, 0.20002943]\n",
      "[0.6036441, 0.2, 0.20003007, 0.20004115]\n",
      "[0.6036285, 0.2, 0.2000434, 0.20001426]\n",
      "[0.60359555, 0.2, 0.20000713, 0.20001963]\n",
      "[0.603612, 0.2, 0.20001847, 0.20002672]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19810 iterations: 4.616689284642537 mins\n",
      "Train Loss: [0.603612, 0.2, 0.20001847, 0.20002672]\n",
      "[0.60360616, 0.2, 0.20002079, 0.20002061]\n",
      "[0.6035991, 0.2, 0.20001046, 0.20002587]\n",
      "[0.6036208, 0.2, 0.20001537, 0.20004478]\n",
      "[0.6036049, 0.2, 0.2000187, 0.20002745]\n",
      "[0.60363257, 0.2, 0.20001835, 0.20005754]\n",
      "[0.60359097, 0.2, 0.20001091, 0.20002528]\n",
      "[0.6036137, 0.2, 0.20002994, 0.20003088]\n",
      "[0.60358447, 0.2, 0.20001297, 0.2000206]\n",
      "[0.60358614, 0.2, 0.20001894, 0.20001821]\n",
      "[0.60362077, 0.2, 0.20001136, 0.2000624]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19820 iterations: 4.618749133745829 mins\n",
      "Train Loss: [0.60362077, 0.2, 0.20001136, 0.2000624]\n",
      "[0.6035828, 0.2, 0.20002119, 0.2000165]\n",
      "[0.60358924, 0.2, 0.2000225, 0.20002352]\n",
      "[0.6036053, 0.2, 0.20002437, 0.2000397]\n",
      "[0.6039607, 0.2, 0.2003971, 0.20002425]\n",
      "[0.6036356, 0.2, 0.20002228, 0.20007592]\n",
      "[0.6035755, 0.2, 0.20001803, 0.20002198]\n",
      "[0.6035605, 0.2, 0.20001441, 0.20001249]\n",
      "[0.6035814, 0.2, 0.20001402, 0.2000357]\n",
      "[0.6035848, 0.2, 0.20001377, 0.20004128]\n",
      "[0.6035977, 0.2, 0.20001994, 0.20004986]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19830 iterations: 4.621947284539541 mins\n",
      "Train Loss: [0.6035977, 0.2, 0.20001994, 0.20004986]\n",
      "[0.6035826, 0.2, 0.20002173, 0.20003498]\n",
      "[0.60357887, 0.2, 0.20002528, 0.20002961]\n",
      "[0.60354984, 0.2, 0.20000611, 0.20002161]\n",
      "[0.6035541, 0.2, 0.2, 0.20003393]\n",
      "[0.6035652, 0.2, 0.20002633, 0.20002067]\n",
      "[0.6035812, 0.2, 0.20001462, 0.2000502]\n",
      "[0.6035675, 0.2, 0.20002136, 0.20003168]\n",
      "[0.60362816, 0.2, 0.20005542, 0.20006028]\n",
      "[0.6035563, 0.2, 0.2000115, 0.20003417]\n",
      "[0.6035378, 0.2, 0.2000107, 0.20001839]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19840 iterations: 4.623815484841665 mins\n",
      "Train Loss: [0.6035378, 0.2, 0.2000107, 0.20001839]\n",
      "[0.6035594, 0.2, 0.2000243, 0.20002827]\n",
      "[0.6035387, 0.2, 0.20001316, 0.2000207]\n",
      "[0.6035525, 0.2, 0.20003116, 0.20001845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60354125, 0.2, 0.20001155, 0.20002875]\n",
      "[0.6035555, 0.2, 0.20003285, 0.20002367]\n",
      "[0.6035549, 0.2, 0.20001838, 0.20003949]\n",
      "[0.6037777, 0.2, 0.20003076, 0.20025185]\n",
      "[0.6035454, 0.2, 0.20002493, 0.20002727]\n",
      "[0.6035507, 0.2, 0.20002814, 0.20003128]\n",
      "[0.6035163, 0.2, 0.20001066, 0.2000162]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19850 iterations: 4.625885399182637 mins\n",
      "Train Loss: [0.6035163, 0.2, 0.20001066, 0.2000162]\n",
      "[0.6035472, 0.2, 0.20001568, 0.200044]\n",
      "[0.6035524, 0.2, 0.20003036, 0.20003636]\n",
      "[0.60355854, 0.2, 0.20004319, 0.20003158]\n",
      "[0.60359305, 0.2, 0.20002764, 0.20008352]\n",
      "[0.6035646, 0.2, 0.20002536, 0.20005916]\n",
      "[0.6035978, 0.2, 0.20002434, 0.20009522]\n",
      "[0.6035207, 0.2, 0.20001021, 0.2000341]\n",
      "[0.6035977, 0.2, 0.20000485, 0.20011829]\n",
      "[0.6035433, 0.2, 0.20001794, 0.20005262]\n",
      "[0.60368735, 0.2, 0.20018172, 0.20003475]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19860 iterations: 4.6277306318283085 mins\n",
      "Train Loss: [0.60368735, 0.2, 0.20018172, 0.20003475]\n",
      "[0.60355896, 0.2, 0.2000604, 0.20002942]\n",
      "[0.60353655, 0.2, 0.20003638, 0.20003276]\n",
      "[0.60355544, 0.2, 0.20002434, 0.20006551]\n",
      "[0.60349137, 0.2, 0.2, 0.20002742]\n",
      "[0.603495, 0.2, 0.20002013, 0.20001267]\n",
      "[0.6034997, 0.2, 0.20001733, 0.20002186]\n",
      "[0.60350126, 0.2, 0.20002064, 0.20002182]\n",
      "[0.6035198, 0.2, 0.2000279, 0.20003477]\n",
      "[0.60349685, 0.2, 0.20002411, 0.20001733]\n",
      "[0.6034874, 0.2, 0.20001227, 0.20002146]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19870 iterations: 4.629714167118072 mins\n",
      "Train Loss: [0.6034874, 0.2, 0.20001227, 0.20002146]\n",
      "[0.60348976, 0.2, 0.20002215, 0.2000157]\n",
      "[0.6034833, 0.2, 0.20001984, 0.20001328]\n",
      "[0.60362273, 0.2, 0.20003697, 0.20013726]\n",
      "[0.60348743, 0.2, 0.2000181, 0.20002255]\n",
      "[0.6035005, 0.2, 0.20001931, 0.20003611]\n",
      "[0.60348594, 0.2, 0.20001295, 0.20002969]\n",
      "[0.6035494, 0.2, 0.2000057, 0.20010224]\n",
      "[0.6034615, 0.2, 0.2000085, 0.2000133]\n",
      "[0.6034705, 0.2, 0.20001747, 0.2000151]\n",
      "[0.6034793, 0.2, 0.20001608, 0.20002708]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19880 iterations: 4.632143982251486 mins\n",
      "Train Loss: [0.6034793, 0.2, 0.20001608, 0.20002708]\n",
      "[0.6034665, 0.2, 0.2000122, 0.20001997]\n",
      "[0.6034661, 0.2, 0.20002218, 0.2000114]\n",
      "[0.6034743, 0.2, 0.20001867, 0.20002499]\n",
      "[0.6034665, 0.2, 0.2000132, 0.20002443]\n",
      "[0.6035106, 0.2, 0.2000638, 0.2000198]\n",
      "[0.6034524, 0.2, 0.20001067, 0.20001653]\n",
      "[0.60345083, 0.2, 0.20001006, 0.20001738]\n",
      "[0.60345834, 0.2, 0.20002541, 0.20001128]\n",
      "[0.6034616, 0.2, 0.20001122, 0.20003055]\n",
      "[0.60344213, 0.2, 0.20001319, 0.20001087]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19890 iterations: 4.634023280938466 mins\n",
      "Train Loss: [0.60344213, 0.2, 0.20001319, 0.20001087]\n",
      "[0.60347, 0.2, 0.20002368, 0.20003006]\n",
      "[0.60343856, 0.2, 0.20000945, 0.20001468]\n",
      "[0.6034493, 0.2, 0.20001578, 0.20002085]\n",
      "[0.603474, 0.2, 0.20002915, 0.20003398]\n",
      "[0.6034378, 0.2, 0.20000282, 0.20002586]\n",
      "[0.60342807, 0.2, 0.20000684, 0.20001397]\n",
      "[0.6034268, 0.2, 0.2, 0.20002131]\n",
      "[0.60344315, 0.2, 0.2000156, 0.20002383]\n",
      "[0.60346705, 0.2, 0.20001706, 0.20004803]\n",
      "[0.6034308, 0.2, 0.20001563, 0.20001501]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19900 iterations: 4.636025667190552 mins\n",
      "Train Loss: [0.6034308, 0.2, 0.20001563, 0.20001501]\n",
      "[0.6034354, 0.2, 0.20001742, 0.20001958]\n",
      "[0.6034273, 0.2, 0.20001303, 0.20001769]\n",
      "[0.6034205, 0.2, 0.20001824, 0.20000738]\n",
      "[0.60354817, 0.2, 0.2001412, 0.20001389]\n",
      "[0.60340583, 0.2, 0.20000696, 0.20000759]\n",
      "[0.6034939, 0.2, 0.20008525, 0.20001912]\n",
      "[0.6034087, 0.2, 0.200013, 0.20000796]\n",
      "[0.6034144, 0.2, 0.20001571, 0.20001267]\n",
      "[0.6034257, 0.2, 0.20001988, 0.20002148]\n",
      "[0.60340834, 0.2, 0.20001014, 0.20001563]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19910 iterations: 4.637916501363119 mins\n",
      "Train Loss: [0.60340834, 0.2, 0.20001014, 0.20001563]\n",
      "[0.6034135, 0.2, 0.20001885, 0.20001383]\n",
      "[0.60343486, 0.2, 0.20001537, 0.20004041]\n",
      "[0.60342187, 0.2, 0.2000123, 0.20003219]\n",
      "[0.6034239, 0.2, 0.20002131, 0.20002688]\n",
      "[0.60343575, 0.2, 0.20002745, 0.20003435]\n",
      "[0.60341024, 0.2, 0.20001507, 0.20002288]\n",
      "[0.60339314, 0.2, 0.20001021, 0.20001233]\n",
      "[0.6033988, 0.2, 0.20001028, 0.20001961]\n",
      "[0.6034052, 0.2, 0.20001069, 0.20002724]\n",
      "[0.60344815, 0.2, 0.20003073, 0.20005193]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19920 iterations: 4.639969348907471 mins\n",
      "Train Loss: [0.60344815, 0.2, 0.20003073, 0.20005193]\n",
      "[0.60350424, 0.2, 0.2000422, 0.2000982]\n",
      "[0.6034005, 0.2, 0.20002528, 0.20001318]\n",
      "[0.60340077, 0.2, 0.20000614, 0.20003429]\n",
      "[0.6033871, 0.2, 0.20001082, 0.20001769]\n",
      "[0.6033831, 0.2, 0.20000926, 0.200017]\n",
      "[0.60340357, 0.2, 0.20002013, 0.20002832]\n",
      "[0.603382, 0.2, 0.20001097, 0.20001759]\n",
      "[0.6033807, 0.2, 0.20000754, 0.20002145]\n",
      "[0.60337555, 0.2, 0.20001079, 0.2000148]\n",
      "[0.60336137, 0.2, 0.2, 0.20001316]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19930 iterations: 4.641947567462921 mins\n",
      "Train Loss: [0.60336137, 0.2, 0.2, 0.20001316]\n",
      "[0.6033972, 0.2, 0.2000092, 0.20004146]\n",
      "[0.60338527, 0.2, 0.20001402, 0.20002651]\n",
      "[0.6033857, 0.2, 0.20001246, 0.20003025]\n",
      "[0.6033615, 0.2, 0.20000634, 0.20001386]\n",
      "[0.60350883, 0.2, 0.20001358, 0.20015576]\n",
      "[0.60337037, 0.2, 0.20001072, 0.2000219]\n",
      "[0.6034624, 0.2, 0.20010984, 0.20001644]\n",
      "[0.60335106, 0.2, 0.20000789, 0.20000872]\n",
      "[0.6033977, 0.2, 0.20001128, 0.20005368]\n",
      "[0.6033532, 0.2, 0.20000952, 0.20001256]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19940 iterations: 4.643904217084249 mins\n",
      "Train Loss: [0.6033532, 0.2, 0.20000952, 0.20001256]\n",
      "[0.6033745, 0.2, 0.20000331, 0.20004171]\n",
      "[0.60334635, 0.2, 0.20000842, 0.20001008]\n",
      "[0.60337245, 0.2, 0.20003298, 0.20001315]\n",
      "[0.60336214, 0.2, 0.20001294, 0.20002457]\n",
      "[0.60342455, 0.2, 0.20007089, 0.20003071]\n",
      "[0.60336256, 0.2, 0.20001958, 0.20002164]\n",
      "[0.603407, 0.2, 0.20006858, 0.20001872]\n",
      "[0.6033474, 0.2, 0.20001201, 0.20001718]\n",
      "[0.6033437, 0.2, 0.2000089, 0.20001823]\n",
      "[0.6033632, 0.2, 0.20001502, 0.20003313]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19950 iterations: 4.645725750923157 mins\n",
      "Train Loss: [0.6033632, 0.2, 0.20001502, 0.20003313]\n",
      "[0.6033531, 0.2, 0.20001702, 0.20002264]\n",
      "[0.6033732, 0.2, 0.20000634, 0.20005499]\n",
      "[0.60335493, 0.2, 0.20002191, 0.20002285]\n",
      "[0.6033502, 0.2, 0.20002395, 0.20001777]\n",
      "[0.6033425, 0.2, 0.20000954, 0.20002604]\n",
      "[0.60333157, 0.2, 0.2000074, 0.20001882]\n",
      "[0.60335547, 0.2, 0.20001541, 0.20003635]\n",
      "[0.6033257, 0.2, 0.20000784, 0.20001583]\n",
      "[0.603333, 0.2, 0.20001543, 0.20001718]\n",
      "[0.6033375, 0.2, 0.20001656, 0.20002218]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19960 iterations: 4.648273432254792 mins\n",
      "Train Loss: [0.6033375, 0.2, 0.20001656, 0.20002218]\n",
      "[0.60331666, 0.2, 0.20000727, 0.20001222]\n",
      "[0.60331905, 0.2, 0.20000516, 0.20001833]\n",
      "[0.60336876, 0.2, 0.20006709, 0.20000777]\n",
      "[0.6033204, 0.2, 0.2000055, 0.20002268]\n",
      "[0.6033291, 0.2, 0.20001099, 0.20002759]\n",
      "[0.60332227, 0.2, 0.20001005, 0.20002334]\n",
      "[0.603325, 0.2, 0.20002027, 0.20001751]\n",
      "[0.6033098, 0.2, 0.20001581, 0.20000847]\n",
      "[0.6033026, 0.2, 0.20000613, 0.2000126]\n",
      "[0.60330606, 0.2, 0.20001131, 0.20001253]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19970 iterations: 4.65033391714096 mins\n",
      "Train Loss: [0.60330606, 0.2, 0.20001131, 0.20001253]\n",
      "[0.60332096, 0.2, 0.20001641, 0.200024]\n",
      "[0.60331357, 0.2, 0.20001626, 0.2000184]\n",
      "[0.6032899, 0.2, 0.20000315, 0.20000954]\n",
      "[0.60331404, 0.2, 0.20000587, 0.20003259]\n",
      "[0.6033024, 0.2, 0.20000938, 0.20001906]\n",
      "[0.60329306, 0.2, 0.20001133, 0.20000942]\n",
      "[0.6033211, 0.2, 0.20002387, 0.20002651]\n",
      "[0.6033179, 0.2, 0.20000467, 0.20004421]\n",
      "[0.6032909, 0.2, 0.20000856, 0.20001501]\n",
      "[0.6032854, 0.2, 0.20000756, 0.20001218]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19980 iterations: 4.652287797133128 mins\n",
      "Train Loss: [0.6032854, 0.2, 0.20000756, 0.20001218]\n",
      "[0.60330236, 0.2, 0.2000202, 0.20001811]\n",
      "[0.60331845, 0.2, 0.20003828, 0.20001774]\n",
      "[0.6032956, 0.2, 0.20001374, 0.20002113]\n",
      "[0.60328937, 0.2, 0.20001008, 0.20002016]\n",
      "[0.60328645, 0.2, 0.20001051, 0.20001842]\n",
      "[0.60328346, 0.2, 0.20000803, 0.20001957]\n",
      "[0.6032856, 0.2, 0.20001186, 0.20001945]\n",
      "[0.60329, 0.2, 0.20001289, 0.20002435]\n",
      "[0.60328317, 0.2, 0.20001537, 0.20001669]\n",
      "[0.60326, 0.2, 0.2, 0.20001039]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19990 iterations: 4.65493114789327 mins\n",
      "Train Loss: [0.60326, 0.2, 0.2, 0.20001039]\n",
      "[0.6032666, 0.2, 0.20000538, 0.2000132]\n",
      "[0.6032748, 0.2, 0.20001061, 0.20001781]\n",
      "[0.6032702, 0.2, 0.20000836, 0.20001695]\n",
      "[0.60327065, 0.2, 0.20001663, 0.20001075]\n",
      "[0.6032621, 0.2, 0.20001127, 0.20000917]\n",
      "[0.6032467, 0.2, 0.2, 0.20000656]\n",
      "[0.6032627, 0.2, 0.20001031, 0.2000139]\n",
      "[0.6032989, 0.2, 0.20000693, 0.2000551]\n",
      "[0.60327727, 0.2, 0.20001358, 0.20002842]\n",
      "[0.60327196, 0.2, 0.20002045, 0.2000179]\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 20000 iterations: 4.6569017688433325 mins\n",
      "Train Loss: [0.60327196, 0.2, 0.20002045, 0.2000179]\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "t_start = time.time()\n",
    "for i in range(1, n_iter+1):\n",
    "    (inputs, targets) = get_triplet_batch(batch_size, pos_train, neg_train, spoof_ground_truth.spoof_step1_truth1)\n",
    "    #(inp, tar) = triplet_generator()\n",
    "    loss = triplet_model.model.train_on_batch(inputs, targets)\n",
    "    print(loss)\n",
    "    if i % evaluate_every == 0:\n",
    "        print(\"\\n ------------- \\n\")\n",
    "        print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
    "        print(\"Train Loss: {0}\".format(loss)) \n",
    "      #  val_acc = test_oneshot(model, N_way, n_val, verbose=True)\n",
    "        triplet_model.model.save_weights(os.path.join(model_path, 'weights_triplet.{}.h5'.format(i)))\n",
    "       # if val_acc >= best:\n",
    "        #    print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
    "         #   best = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training_Pipeline(object):\n",
    "    def __init__(self):\n",
    "        self._birthdate = time.time()\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_batch(batch_size, positive_samples, negative_samples, anchor):\n",
    "        \"\"\"Create batch of n pairs, half same class, half different class\"\"\"\n",
    "        n_examples_p, d, w, h = positive_samples.shape\n",
    "        n_examples_n = negative_samples.shape[0]\n",
    "\n",
    "        # initialize 2 empty arrays for the input image batch\n",
    "        pairs = [np.zeros((batch_size, w, h, 1)) for i in range(2)]\n",
    "\n",
    "        # initialize vector for the targets\n",
    "        targets=np.zeros((batch_size,))\n",
    "\n",
    "        # make one half of it '1's, so 2nd half of batch has same class\n",
    "        targets[batch_size//2:] = 1\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            idx_p = rng.randint(0, n_examples_p)\n",
    "            idx_n = rng.randint(0, n_examples_n)\n",
    "            pairs[0][i,:,:,:] = anchor.reshape(w, h, 1)\n",
    "\n",
    "            if i >= batch_size // 2:\n",
    "                pairs[1][i,:,:,:] = positive_samples[idx_p].reshape(w, h, 1)\n",
    "            else:\n",
    "                pairs[1][i,:,:,:] = negative_samples[idx_n].reshape(w, h, 1)\n",
    "        return pairs, targets\n",
    "    \n",
    "    def make_oneshot_task(self, N, positive_samples, negative_samples, anchor):\n",
    "        \"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\n",
    "\n",
    "        n_examples_p, d, w, h = positive_samples.shape\n",
    "        n_examples_n = negative_samples.shape[0]\n",
    "\n",
    "        test_lob = np.asarray([anchor]*N).reshape(N, w, h, 1)\n",
    "\n",
    "       # print(test_lob)\n",
    "\n",
    "        p_index = rng.randint(0, n_examples_p, size=(1,))\n",
    "        n_index = rng.randint(0, n_examples_n, size=(N,))\n",
    "\n",
    "        support_set = negative_samples[n_index]\n",
    "       # print('n_index' + str(n_index))\n",
    "      #  print(support_set[0])\n",
    "      #  print(support_set[1])\n",
    "        support_set[0] = positive_samples[p_index]\n",
    "       # print('zero now')\n",
    "       # print(support_set[0])\n",
    "       # print('one now')\n",
    "      #  print(support_set[1])\n",
    "        support_set = support_set.reshape(N, w, h, 1)\n",
    "\n",
    "        targets = np.zeros((N,))\n",
    "        targets[0] = 1     \n",
    "       # print(targets)\n",
    "        targets, test_lob, support_set = shuffle(targets, test_lob, support_set)\n",
    "        pairs = [test_lob, support_set]\n",
    "        return pairs, targets\n",
    "\n",
    "    def test_oneshot(self, model, N, k, s = \"val\", verbose = 0):\n",
    "        \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
    "        n_correct = 0\n",
    "        inputs = []\n",
    "        targets = []\n",
    "        if verbose:\n",
    "            print(\"Evaluating model on {} random {} way one-shot learning tasks ... \\n\".format(k,N))\n",
    "        for i in range(k):\n",
    "            if s == 'train':\n",
    "                inputs, targets = self.make_oneshot_task(N, pos_train, neg_train, spoof_ground_truth.spoof_step1_truth1)\n",
    "            else:\n",
    "                inputs, targets = self.make_oneshot_task(N, pos_val, neg_val, spoof_ground_truth.spoof_step1_truth1)\n",
    "            probs = model.predict(inputs)\n",
    "            #print(probs)\n",
    "            if np.argmax(probs) == np.argmax(targets):\n",
    "                n_correct+=1\n",
    "        percent_correct = (100.0 * n_correct / k)\n",
    "        if verbose:\n",
    "            print(\"Got an average of {}% {} way one-shot learning accuracy \\n\".format(percent_correct,N))\n",
    "        return percent_correct\n",
    "    \n",
    "    \n",
    "    def generate(batch_size, s=\"train\"):\n",
    "        \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
    "        while True:\n",
    "            pairs, targets = get_batch(batch_size,s)\n",
    "            yield (pairs, targets)\n",
    "\n",
    "training_pipeline = Training_Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of concat image visualization\n",
    "np.set_printoptions(suppress=True)\n",
    "pairs, targets = training_pipeline.make_oneshot_task(15, pos_train, neg_train, spoof_ground_truth.spoof_step1_truth1)\n",
    "plot_oneshot_task(pairs, targets, 15)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting LOBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_oneshot_task(pairs, targets, N): \n",
    "    '''\n",
    "    Only prints out one before last element of a \n",
    "    '''\n",
    "    count = 0\n",
    "    fig, ax = plt.subplots(2, int(N/2), sharex='col', sharey='row', figsize=(15,15))\n",
    "    lob_matrix = []\n",
    "    lob_matrix.append(pairs[0][0])\n",
    "    for j in range(0,int(N)):\n",
    "        lob_matrix.append(pairs[1][j])\n",
    "     \n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    \n",
    "    for i in range(0,2):\n",
    "        for j in range(0,int(N/2)):\n",
    "            sns.heatmap(lob_matrix[count][:,:,0].reshape(2,30).T, vmin=0, vmax=50000, cmap='Greens', center=None,\n",
    "                        robust=False, annot=None, fmt='.2g', annot_kws=None, linewidths=0, linecolor='white', \n",
    "                        cbar=True, cbar_kws=None, cbar_ax=cbar_ax, square=False, xticklabels=True, \n",
    "                        yticklabels=True, mask=None, ax=ax[i, j])\n",
    "            count = count + 1\n",
    "            print(lob_matrix[count][:,:,0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_oneshot_task(pairs, N):\n",
    "    if N/2 == 1:\n",
    "        end = int(N/2)\n",
    "    else:\n",
    "        end = int(N/2)\n",
    "    fig, ax = plt.subplots(2, end, sharex='col', sharey='row', figsize=(15,15))\n",
    "   # im = ax[0, 0].matshow(pairs[0][0].reshape(2,30).T)\n",
    "   # print(pairs[0][1])\n",
    "   # print(pairs[1][0])\n",
    "   # print(pairs[0][0].shape)\n",
    "    data_array = []\n",
    "    data_array.append(pairs[0][0])\n",
    "    #print(data_array[0][:,:,0])\n",
    "    for j in range(0,int(N)):\n",
    "        data_array.append(pairs[1][j])\n",
    "    #print(np.moveaxis(data_array, -1, 0).shape)\n",
    "   # print(data_array[0])\n",
    "    count = 0\n",
    "    initial_pair = 0\n",
    "    for i in range(0,2):\n",
    "        for j in range(0,int(N/2)):\n",
    "            sns.heatmap(data_array[count][:,:,0].reshape(2,30).T, vmin=None, vmax=None, cmap=None, center=None,\n",
    "                robust=False, annot=None, fmt='.2g', annot_kws=None, \n",
    "                linewidths=0, linecolor='white', cbar=True, cbar_kws=None, \n",
    "                cbar_ax=None, square=False, xticklabels='auto',\n",
    "                yticklabels='auto', mask=None, ax=ax[i, j], **kwargs)\n",
    "           # im = ax[i, j].matshow(data_array[count][:,:,0].reshape(2,30).T, cmap='BuPu')\n",
    "            print(i)\n",
    "            print(j)\n",
    "            ax[i, j].text(0.5, 0.5, str((i, j)), fontsize=18, ha='right')\n",
    "            count = count + 1\n",
    "            initial_pair = 1\n",
    "    \n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    print(im)\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_oneshot_task(pairs, N):\n",
    "    if N/2 == 1:\n",
    "        end = int(N/2)\n",
    "    else:\n",
    "        end = int(N/2)\n",
    "    fig, ax = plt.subplots(2, end, sharex='col', sharey='row', figsize=(15,15))\n",
    "   # im = ax[0, 0].matshow(pairs[0][0].reshape(2,30).T)\n",
    "   # print(pairs[0][1])\n",
    "   # print(pairs[1][0])\n",
    "    data_array = pairs[0][0]\n",
    "    for j in range(0,int(N)):\n",
    "        data_array = np.append(data_array, pairs[1][j], axis=-1)\n",
    "    print(data_array)\n",
    "    print(data_array.shape)\n",
    "    print(np.moveaxis(data_array, -1, 0).shape)\n",
    "    count = 0\n",
    "    initial_pair = 0\n",
    "    for i in range(0,2):\n",
    "        for j in range(0,int(end)):\n",
    "            im = ax[i, j].matshow(pairs[initial_pair][count].reshape(2,30).T, cmap='BuPu')\n",
    "            ax[i, j].text(0.5, 0.5, str((i, j)), fontsize=18, ha='right')\n",
    "            count = count + 1\n",
    "            initial_pair = 1\n",
    "    \n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    print(im)\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "    plt.show()\n",
    "#(j-start)*(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_oneshot_task(pairs, N):\n",
    "    fig,(ax1,ax2) = plt.subplots(nrows=1, ncols=N, figsize=(15,15))\n",
    "    ax1.matshow(pairs[0][0].reshape(30,2), cmap='gray')\n",
    "    img = concat_images(pairs[1], N)\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax2.matshow(img,cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "#evaluate_every = 2 # interval for evaluating on one-shot tasks\n",
    "#batch_size = 32\n",
    "#n_iter = 20 # No. of training iterations\n",
    "#N_way = 4 # how many classes for testing one-shot tasks\n",
    "#n_val = 10 # how many one-shot tasks to validate on\n",
    "#best = -1\n",
    "#np.set_printoptions(suppress=True)\n",
    "\n",
    "evaluate_every = 10 # interval for evaluating on one-shot tasks\n",
    "loss_every = 20 # interval for printing loss (iterations)\n",
    "batch_size = 32\n",
    "n_iter = 20000\n",
    "N_way = 20 # how many classes for testing one-shot tasks>\n",
    "n_val = 250 # how many one-shot tasks to validate on?\n",
    "best = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "t_start = time.time()\n",
    "for i in range(1, n_iter+1):\n",
    "    inputs, targets = training_pipeline.get_batch(batch_size, pos_train, neg_train,\\\n",
    "                                                     spoof_ground_truth.spoof_step1_truth1)\n",
    "    loss = model.train_on_batch(inputs, targets)\n",
    "    if i % evaluate_every == 0:\n",
    "        print(\"\\n ------------- \\n\")\n",
    "        print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
    "        print(\"Train Loss: {0}\".format(loss)) \n",
    "        val_acc = training_pipeline.test_oneshot(model, N_way, n_val, verbose=True)\n",
    "        model.save_weights(os.path.join(model_path, 'weights.{}.h5'.format(i)))\n",
    "        if val_acc >= best:\n",
    "            print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
    "            best = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(model_path, \"weights.20000.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline model based on nearest neighbors using euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbour_correct(pairs,targets):\n",
    "    \"\"\"returns 1 if nearest neighbour gets the correct answer for a one-shot task\n",
    "        given by (pairs, targets)\"\"\"\n",
    "    L2_distances = np.zeros_like(targets)\n",
    "    for i in range(len(targets)):\n",
    "        L2_distances[i] = np.sum(np.sqrt(pairs[0][i]**2 - pairs[1][i]**2))\n",
    "    if np.argmin(L2_distances) == np.argmax(targets):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nn_accuracy(N_ways,n_trials):\n",
    "    \"\"\"Returns accuracy of NN approach \"\"\"\n",
    "    print(\"Evaluating nearest neighbour on {} unique {} way one-shot learning tasks ...\".format(n_trials,N_ways))\n",
    "\n",
    "    n_right = 0\n",
    "    \n",
    "    for i in range(n_trials):\n",
    "        pairs,targets = training_pipeline.make_oneshot_task(N_ways,pos_val, neg_val,\\\n",
    "                                                            spoof_ground_truth.spoof_step1_truth1)\n",
    "        correct = nearest_neighbour_correct(pairs,targets)\n",
    "        n_right += correct\n",
    "    return 100.0 * n_right / n_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ways = np.arange(1,15,2)\n",
    "resume =  False\n",
    "trials = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accs, train_accs,nn_accs = [], [], []\n",
    "for N in ways:    \n",
    "    val_accs.append(training_pipeline.test_oneshot(model, N, trials, \"val\", verbose=True))\n",
    "    train_accs.append(training_pipeline.test_oneshot(model, N, trials, \"train\", verbose=True))\n",
    "    nn_acc = test_nn_accuracy(N, trials)\n",
    "    nn_accs.append(nn_acc)\n",
    "    print (\"NN Accuracy = \", nn_acc)\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save accuracies on disk\n",
    "with open(os.path.join(project_path,\"accuracies.pickle\"), \"wb\") as f:\n",
    "    pickle.dump((val_accs,train_accs,nn_accs),f)\n",
    "    \n",
    "#Load accuraces from disk\n",
    "with open(os.path.join(project_path, \"accuracies.pickle\"), \"rb\") as f:\n",
    "    (val_accs, train_accs, nn_accs) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_images(X):\n",
    "    \"\"\"Concatenates a bunch of images into a big matrix for plotting purposes.\"\"\"\n",
    "    nc, h , w, _ = X.shape\n",
    "    X = X.reshape(nc, h, w)\n",
    "    n = np.ceil(np.sqrt(nc)).astype(\"int8\")\n",
    "    img = np.zeros((n*h,n*w))\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for example in range(nc):\n",
    "        img[x*h:(x+1)*h,y*w:(y+1)*w] = X[example]\n",
    "        y += 1\n",
    "        if y >= n:\n",
    "            y = 0\n",
    "            x += 1\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_oneshot_task(pairs):\n",
    "    fig,(ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15,15))\n",
    "    ax1.matshow(pairs[0][0].reshape(30,2), cmap='gray')\n",
    "    img = concat_images(pairs[1])\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax2.matshow(img,cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of concat image visualization\n",
    "pairs, targets = training_pipeline.make_oneshot_task(1,pos_train,neg_train,spoof_ground_truth.spoof_step1_truth1)\n",
    "plot_oneshot_task(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1)\n",
    "ax.plot(ways, val_accs, \"m\", label=\"Siamese(val set)\")\n",
    "ax.plot(ways, train_accs, \"y\", label=\"Siamese(train set)\")\n",
    "plt.plot(ways, nn_accs, label=\"Nearest neighbour\")\n",
    "\n",
    "ax.plot(ways, 100.0/ways, \"g\", label=\"Random guessing\")\n",
    "plt.xlabel(\"Number of possible classes in one-shot tasks\")\n",
    "plt.ylabel(\"% Accuracy\")\n",
    "plt.title(\"Omiglot One-Shot Learning Performance of a Siamese Network\")\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "#inputs,targets = make_oneshot_task(20, \"val\", 'Oriya')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:5 out of the last 20 calls to <function triplet_semihard_loss at 0x140074c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 20 calls to <function triplet_semihard_loss at 0x140074c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 103s 55ms/step - loss: 0.4322\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 96s 51ms/step - loss: 0.2825\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 98s 52ms/step - loss: 0.2518\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 103s 55ms/step - loss: 0.2350\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 86s 46ms/step - loss: 0.2219\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'io' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-9d34e0b25597>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vecs.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mout_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'meta.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mout_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'io' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "def _normalize_img(img, label):\n",
    "    img = tf.cast(img, tf.float32) / 255.\n",
    "    return (img, label)\n",
    "\n",
    "train_dataset, test_dataset = tfds.load(name=\"mnist\", split=['train', 'test'], as_supervised=True)\n",
    "\n",
    "# Build your input pipelines\n",
    "train_dataset = train_dataset.shuffle(1024).batch(32)\n",
    "train_dataset = train_dataset.map(_normalize_img)\n",
    "\n",
    "test_dataset = test_dataset.batch(32)\n",
    "test_dataset = test_dataset.map(_normalize_img)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation=None), # No activation on final dense layer\n",
    "    tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n",
    "\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tfa.losses.TripletSemiHardLoss())\n",
    "\n",
    "# Train the network\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=5)\n",
    "\n",
    "# Evaluate the network\n",
    "results = model.predict(test_dataset)\n",
    "\n",
    "# Save test embeddings for visualization in projector\n",
    "np.savetxt(\"vecs.tsv\", results, delimiter='\\t')\n",
    "\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "for img, labels in tfds.as_numpy(test_dataset):\n",
    "    [out_m.write(str(x) + \"\\n\") for x in labels]\n",
    "out_m.close()\n",
    "\n",
    "\n",
    "\n",
    "from google.colab import files\n",
    "files.download('vecs.tsv')\n",
    "files.download('meta.tsv')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
